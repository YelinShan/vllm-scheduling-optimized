INFO 07-11 15:19:23 [__init__.py:253] Automatically detected platform cuda.
INFO 07-11 15:19:30 [api_server.py:1623] vLLM API server version 0.9.2rc2.dev15+g87798b0be.d20250707
INFO 07-11 15:19:30 [cli_args.py:325] non-default args: {'model': '/home/yshan/Downloads/models/Qwen-1_5b', 'max_model_len': 30000, 'block_size': 16, 'gpu_memory_utilization': 0.2, 'enable_prefix_caching': True, 'max_num_batched_tokens': 8192, 'max_num_seqs': 256, 'enable_chunked_prefill': True, 'kv_transfer_config': KVTransferConfig(kv_connector='LMCacheConnectorV1', engine_id='522655a5-ffd3-4c0a-8c2c-c85e33e0cfca', kv_buffer_device='cuda', kv_buffer_size=1000000000.0, kv_role='kv_both', kv_rank=None, kv_parallel_size=1, kv_ip='127.0.0.1', kv_port=14579, kv_connector_extra_config={}, kv_connector_module_path=None), 'disable_log_requests': True}
INFO 07-11 15:19:35 [config.py:848] This model supports multiple tasks: {'generate', 'embed', 'reward', 'classify'}. Defaulting to 'generate'.
INFO 07-11 15:19:35 [config.py:1485] Using max model len 30000
INFO 07-11 15:19:35 [config.py:2298] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 07-11 15:19:39 [__init__.py:253] Automatically detected platform cuda.
INFO 07-11 15:19:41 [core.py:526] Waiting for init message from front-end.
INFO 07-11 15:19:41 [core.py:69] Initializing a V1 LLM engine (v0.9.2rc2.dev15+g87798b0be.d20250707) with config: model='/home/yshan/Downloads/models/Qwen-1_5b', speculative_config=None, tokenizer='/home/yshan/Downloads/models/Qwen-1_5b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=30000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/yshan/Downloads/models/Qwen-1_5b, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
INFO 07-11 15:19:42 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 07-11 15:19:42 [factory.py:74] Creating v1 connector with name: LMCacheConnectorV1 and engine_id: 522655a5-ffd3-4c0a-8c2c-c85e33e0cfca
WARNING 07-11 15:19:42 [base.py:71] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[32;20m[2025-07-11 15:19:42,383] LMCache INFO:[0m Loading LMCache config file /home/yshan/Programs/LMCache/lmcache_config.yaml [3m(utils.py:70:lmcache.integration.vllm.utils)[0m
[32;20m[2025-07-11 15:19:42,384] LMCache INFO:[0m LMCache Configuration: {'chunk_size': 128, 'cufile_buffer_size': None, 'local_cpu': True, 'max_local_cpu_size': '3.0 GB', 'local_disk': '/home/yshan/mnt/LMCache/local_disk', 'max_local_disk_size': '50.0 GB', 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'enable_blending': False, 'blend_recompute_ratio': 0.15, 'blend_min_tokens': 256, 'enable_p2p': False, 'lookup_url': None, 'distributed_url': None, 'error_handling': False, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'enable_nixl': False, 'nixl_role': None, 'nixl_receiver_host': None, 'nixl_receiver_port': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'nixl_enable_gc': False, 'weka_path': None, 'gds_path': None, 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None} [3m(config.py:697:lmcache.v1.config)[0m
[32;20m[2025-07-11 15:19:42,384] LMCache INFO:[0m Loading LMCache config file /home/yshan/Programs/LMCache/lmcache_config.yaml [3m(utils.py:70:lmcache.integration.vllm.utils)[0m
[32;20m[2025-07-11 15:19:42,385] LMCache INFO:[0m LMCache Configuration: {'chunk_size': 128, 'cufile_buffer_size': None, 'local_cpu': True, 'max_local_cpu_size': '3.0 GB', 'local_disk': '/home/yshan/mnt/LMCache/local_disk', 'max_local_disk_size': '50.0 GB', 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'enable_blending': False, 'blend_recompute_ratio': 0.15, 'blend_min_tokens': 256, 'enable_p2p': False, 'lookup_url': None, 'distributed_url': None, 'error_handling': False, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'enable_nixl': False, 'nixl_role': None, 'nixl_receiver_host': None, 'nixl_receiver_port': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'nixl_enable_gc': False, 'weka_path': None, 'gds_path': None, 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None} [3m(config.py:697:lmcache.v1.config)[0m
[32;20m[2025-07-11 15:19:42,385] LMCache INFO:[0m use mla: False, kv shape: (28, 2, 128, 2, 128) [3m(vllm_adapter.py:169:lmcache.integration.vllm.vllm_adapter)[0m
[32;20m[2025-07-11 15:19:42,386] LMCache INFO:[0m Creating LMCacheEngine instance vllm-instance [3m(cache_engine.py:740:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:19:44,157] LMCache INFO:[0m Creating LMCacheEngine with config: LMCacheEngineConfig(chunk_size=128, local_cpu=True, max_local_cpu_size=3.0, local_disk='/home/yshan/mnt/LMCache/local_disk', max_local_disk_size=50.0, remote_url=None, remote_serde='naive', use_layerwise=False, save_decode_cache=False, enable_blending=False, blend_recompute_ratio=0.15, blend_min_tokens=256, blend_special_str=' # # ', enable_p2p=False, lookup_url=None, distributed_url=None, error_handling=False, enable_controller=False, lmcache_instance_id='lmcache_default_instance', controller_url=None, lmcache_worker_port=None, enable_nixl=False, nixl_role=None, nixl_receiver_host=None, nixl_receiver_port=None, nixl_buffer_size=None, nixl_buffer_device=None, nixl_enable_gc=False, audit_actual_remote_url=None, weka_path=None, gds_path=None, cufile_buffer_size=None, extra_config=None, save_unfull_chunk=True, blocking_timeout_secs=10, external_lookup_client=None) [3m(cache_engine.py:87:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:19:44,158] LMCache INFO:[0m Created local disk cache directory: /home/yshan/mnt/LMCache/local_disk [3m(local_disk_backend.py:66:lmcache.v1.storage_backend.local_disk_backend)[0m
[32;20m[2025-07-11 15:19:44,158] LMCache INFO:[0m Initializing usage context. [3m(usage_context.py:274:lmcache.usage_context)[0m
[32;20m[2025-07-11 15:19:47,273] LMCache INFO:[0m Loading LMCache config file /home/yshan/Programs/LMCache/lmcache_config.yaml [3m(utils.py:70:lmcache.integration.vllm.utils)[0m
[32;20m[2025-07-11 15:19:47,274] LMCache INFO:[0m LMCache Configuration: {'chunk_size': 128, 'cufile_buffer_size': None, 'local_cpu': True, 'max_local_cpu_size': '3.0 GB', 'local_disk': '/home/yshan/mnt/LMCache/local_disk', 'max_local_disk_size': '50.0 GB', 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'enable_blending': False, 'blend_recompute_ratio': 0.15, 'blend_min_tokens': 256, 'enable_p2p': False, 'lookup_url': None, 'distributed_url': None, 'error_handling': False, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'enable_nixl': False, 'nixl_role': None, 'nixl_receiver_host': None, 'nixl_receiver_port': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'nixl_enable_gc': False, 'weka_path': None, 'gds_path': None, 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None} [3m(config.py:697:lmcache.v1.config)[0m
WARNING 07-11 15:19:47 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 07-11 15:19:47 [gpu_model_runner.py:1770] Starting to load model /home/yshan/Downloads/models/Qwen-1_5b...
INFO 07-11 15:19:47 [gpu_model_runner.py:1775] Loading model from scratch...
INFO 07-11 15:19:47 [cuda.py:285] Using Flash Attention backend on V1 engine.
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]

INFO 07-11 15:19:48 [default_loader.py:272] Loading weights took 0.91 seconds
INFO 07-11 15:19:48 [gpu_model_runner.py:1801] Model loading took 2.8871 GiB and 1.092709 seconds
INFO 07-11 15:19:54 [backends.py:529] Using cache directory: /home/yshan/.cache/vllm/torch_compile_cache/7dffd58a67/rank_0_0/backbone for vLLM's torch.compile
INFO 07-11 15:19:54 [backends.py:540] Dynamo bytecode transform time: 5.45 s
INFO 07-11 15:19:58 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.798 s
INFO 07-11 15:19:59 [monitor.py:34] torch.compile takes 5.45 s in total
INFO 07-11 15:19:59 [gpu_worker.py:233] Available KV cache memory: 1.79 GiB
INFO 07-11 15:19:59 [kv_cache_utils.py:716] GPU KV cache size: 67,120 tokens
INFO 07-11 15:19:59 [kv_cache_utils.py:720] Maximum concurrency for 30,000 tokens per request: 2.24x
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|▏         | 1/67 [00:00<00:13,  4.90it/s]Capturing CUDA graph shapes:   3%|▎         | 2/67 [00:00<00:11,  5.47it/s]Capturing CUDA graph shapes:   4%|▍         | 3/67 [00:00<00:11,  5.69it/s]Capturing CUDA graph shapes:   6%|▌         | 4/67 [00:00<00:10,  5.92it/s]Capturing CUDA graph shapes:   7%|▋         | 5/67 [00:00<00:10,  6.00it/s]Capturing CUDA graph shapes:   9%|▉         | 6/67 [00:01<00:10,  6.10it/s]Capturing CUDA graph shapes:  10%|█         | 7/67 [00:01<00:10,  5.98it/s]Capturing CUDA graph shapes:  12%|█▏        | 8/67 [00:01<00:10,  5.80it/s]Capturing CUDA graph shapes:  13%|█▎        | 9/67 [00:01<00:09,  5.83it/s]Capturing CUDA graph shapes:  15%|█▍        | 10/67 [00:01<00:09,  5.92it/s]Capturing CUDA graph shapes:  16%|█▋        | 11/67 [00:01<00:09,  6.02it/s]Capturing CUDA graph shapes:  18%|█▊        | 12/67 [00:02<00:09,  6.10it/s]Capturing CUDA graph shapes:  19%|█▉        | 13/67 [00:02<00:09,  5.89it/s]Capturing CUDA graph shapes:  21%|██        | 14/67 [00:02<00:08,  5.98it/s]Capturing CUDA graph shapes:  22%|██▏       | 15/67 [00:02<00:08,  6.07it/s]Capturing CUDA graph shapes:  24%|██▍       | 16/67 [00:02<00:08,  6.13it/s]Capturing CUDA graph shapes:  25%|██▌       | 17/67 [00:02<00:08,  6.18it/s]Capturing CUDA graph shapes:  27%|██▋       | 18/67 [00:03<00:07,  6.21it/s]Capturing CUDA graph shapes:  28%|██▊       | 19/67 [00:03<00:07,  6.23it/s]Capturing CUDA graph shapes:  30%|██▉       | 20/67 [00:03<00:07,  6.25it/s]Capturing CUDA graph shapes:  31%|███▏      | 21/67 [00:03<00:07,  6.23it/s]Capturing CUDA graph shapes:  33%|███▎      | 22/67 [00:03<00:07,  6.25it/s]Capturing CUDA graph shapes:  34%|███▍      | 23/67 [00:03<00:07,  6.25it/s]Capturing CUDA graph shapes:  36%|███▌      | 24/67 [00:03<00:06,  6.25it/s]Capturing CUDA graph shapes:  37%|███▋      | 25/67 [00:04<00:06,  6.24it/s]Capturing CUDA graph shapes:  39%|███▉      | 26/67 [00:04<00:06,  6.22it/s]Capturing CUDA graph shapes:  40%|████      | 27/67 [00:04<00:06,  6.20it/s]Capturing CUDA graph shapes:  42%|████▏     | 28/67 [00:04<00:06,  6.18it/s]Capturing CUDA graph shapes:  43%|████▎     | 29/67 [00:04<00:06,  6.16it/s]Capturing CUDA graph shapes:  45%|████▍     | 30/67 [00:04<00:06,  6.13it/s]Capturing CUDA graph shapes:  46%|████▋     | 31/67 [00:05<00:05,  6.14it/s]Capturing CUDA graph shapes:  48%|████▊     | 32/67 [00:05<00:05,  6.01it/s]Capturing CUDA graph shapes:  49%|████▉     | 33/67 [00:05<00:05,  6.03it/s]Capturing CUDA graph shapes:  51%|█████     | 34/67 [00:05<00:05,  6.07it/s]Capturing CUDA graph shapes:  52%|█████▏    | 35/67 [00:05<00:05,  5.66it/s]Capturing CUDA graph shapes:  54%|█████▎    | 36/67 [00:05<00:05,  5.80it/s]Capturing CUDA graph shapes:  55%|█████▌    | 37/67 [00:06<00:05,  5.91it/s]Capturing CUDA graph shapes:  57%|█████▋    | 38/67 [00:06<00:04,  5.97it/s]Capturing CUDA graph shapes:  58%|█████▊    | 39/67 [00:06<00:04,  6.03it/s]Capturing CUDA graph shapes:  60%|█████▉    | 40/67 [00:06<00:04,  5.76it/s]Capturing CUDA graph shapes:  61%|██████    | 41/67 [00:06<00:04,  5.88it/s]Capturing CUDA graph shapes:  63%|██████▎   | 42/67 [00:06<00:04,  5.92it/s]Capturing CUDA graph shapes:  64%|██████▍   | 43/67 [00:07<00:04,  6.00it/s]Capturing CUDA graph shapes:  66%|██████▌   | 44/67 [00:07<00:03,  6.06it/s]Capturing CUDA graph shapes:  67%|██████▋   | 45/67 [00:07<00:03,  6.11it/s]Capturing CUDA graph shapes:  69%|██████▊   | 46/67 [00:07<00:03,  5.69it/s]Capturing CUDA graph shapes:  70%|███████   | 47/67 [00:07<00:03,  5.80it/s]Capturing CUDA graph shapes:  72%|███████▏  | 48/67 [00:08<00:03,  5.45it/s]Capturing CUDA graph shapes:  73%|███████▎  | 49/67 [00:08<00:03,  5.64it/s]Capturing CUDA graph shapes:  75%|███████▍  | 50/67 [00:08<00:02,  5.79it/s]Capturing CUDA graph shapes:  76%|███████▌  | 51/67 [00:08<00:02,  5.90it/s]Capturing CUDA graph shapes:  78%|███████▊  | 52/67 [00:08<00:02,  5.97it/s]Capturing CUDA graph shapes:  79%|███████▉  | 53/67 [00:08<00:02,  6.00it/s]Capturing CUDA graph shapes:  81%|████████  | 54/67 [00:09<00:02,  5.84it/s]Capturing CUDA graph shapes:  82%|████████▏ | 55/67 [00:09<00:02,  5.86it/s]Capturing CUDA graph shapes:  84%|████████▎ | 56/67 [00:09<00:01,  5.90it/s]Capturing CUDA graph shapes:  85%|████████▌ | 57/67 [00:09<00:01,  5.98it/s]Capturing CUDA graph shapes:  87%|████████▋ | 58/67 [00:09<00:01,  6.06it/s]Capturing CUDA graph shapes:  88%|████████▊ | 59/67 [00:09<00:01,  6.09it/s]Capturing CUDA graph shapes:  90%|████████▉ | 60/67 [00:10<00:01,  6.14it/s]Capturing CUDA graph shapes:  91%|█████████ | 61/67 [00:10<00:00,  6.09it/s]Capturing CUDA graph shapes:  93%|█████████▎| 62/67 [00:10<00:00,  6.11it/s]Capturing CUDA graph shapes:  94%|█████████▍| 63/67 [00:10<00:00,  6.16it/s]Capturing CUDA graph shapes:  96%|█████████▌| 64/67 [00:10<00:00,  5.68it/s]Capturing CUDA graph shapes:  97%|█████████▋| 65/67 [00:10<00:00,  5.84it/s]Capturing CUDA graph shapes:  99%|█████████▊| 66/67 [00:11<00:00,  5.96it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:11<00:00,  5.83it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:11<00:00,  5.97it/s]
INFO 07-11 15:20:11 [gpu_model_runner.py:2326] Graph capturing finished in 11 secs, took 0.50 GiB
INFO 07-11 15:20:11 [core.py:172] init engine (profile, create kv cache, warmup model) took 22.38 seconds
INFO 07-11 15:20:11 [factory.py:74] Creating v1 connector with name: LMCacheConnectorV1 and engine_id: 522655a5-ffd3-4c0a-8c2c-c85e33e0cfca
WARNING 07-11 15:20:11 [base.py:71] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[32;20m[2025-07-11 15:20:11,525] LMCache INFO:[0m Loading LMCache config file /home/yshan/Programs/LMCache/lmcache_config.yaml [3m(utils.py:70:lmcache.integration.vllm.utils)[0m
[32;20m[2025-07-11 15:20:11,526] LMCache INFO:[0m LMCache Configuration: {'chunk_size': 128, 'cufile_buffer_size': None, 'local_cpu': True, 'max_local_cpu_size': '3.0 GB', 'local_disk': '/home/yshan/mnt/LMCache/local_disk', 'max_local_disk_size': '50.0 GB', 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'enable_blending': False, 'blend_recompute_ratio': 0.15, 'blend_min_tokens': 256, 'enable_p2p': False, 'lookup_url': None, 'distributed_url': None, 'error_handling': False, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'enable_nixl': False, 'nixl_role': None, 'nixl_receiver_host': None, 'nixl_receiver_port': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'nixl_enable_gc': False, 'weka_path': None, 'gds_path': None, 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None} [3m(config.py:697:lmcache.v1.config)[0m
[32;20m[2025-07-11 15:20:11,526] LMCache INFO:[0m Loading LMCache config file /home/yshan/Programs/LMCache/lmcache_config.yaml [3m(utils.py:70:lmcache.integration.vllm.utils)[0m
[32;20m[2025-07-11 15:20:11,526] LMCache INFO:[0m LMCache Configuration: {'chunk_size': 128, 'cufile_buffer_size': None, 'local_cpu': True, 'max_local_cpu_size': '3.0 GB', 'local_disk': '/home/yshan/mnt/LMCache/local_disk', 'max_local_disk_size': '50.0 GB', 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'enable_blending': False, 'blend_recompute_ratio': 0.15, 'blend_min_tokens': 256, 'enable_p2p': False, 'lookup_url': None, 'distributed_url': None, 'error_handling': False, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'enable_nixl': False, 'nixl_role': None, 'nixl_receiver_host': None, 'nixl_receiver_port': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'nixl_enable_gc': False, 'weka_path': None, 'gds_path': None, 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None} [3m(config.py:697:lmcache.v1.config)[0m
INFO 07-11 15:20:11 [loggers.py:137] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 4195
WARNING 07-11 15:20:11 [config.py:1399] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-11 15:20:11 [serving_responses.py:90] Using default chat sampling params from model: {'repetition_penalty': 1.1, 'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
INFO 07-11 15:20:11 [serving_chat.py:125] Using default chat sampling params from model: {'repetition_penalty': 1.1, 'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
INFO 07-11 15:20:11 [serving_completion.py:72] Using default completion sampling params from model: {'repetition_penalty': 1.1, 'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
INFO 07-11 15:20:11 [api_server.py:1685] Starting vLLM API server 0 on http://0.0.0.0:8000
INFO 07-11 15:20:11 [launcher.py:29] Available routes are:
INFO 07-11 15:20:11 [launcher.py:37] Route: /openapi.json, Methods: GET, HEAD
INFO 07-11 15:20:11 [launcher.py:37] Route: /docs, Methods: GET, HEAD
INFO 07-11 15:20:11 [launcher.py:37] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 07-11 15:20:11 [launcher.py:37] Route: /redoc, Methods: GET, HEAD
INFO 07-11 15:20:11 [launcher.py:37] Route: /health, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /load, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /ping, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /ping, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /tokenize, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /detokenize, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/models, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /version, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/responses, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/responses/{response_id}, Methods: GET
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/responses/{response_id}/cancel, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/chat/completions, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/completions, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/embeddings, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /pooling, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /classify, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /score, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/score, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/audio/translations, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /rerank, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v1/rerank, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /v2/rerank, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /invocations, Methods: POST
INFO 07-11 15:20:11 [launcher.py:37] Route: /metrics, Methods: GET
INFO:     Started server process [2615738]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 07-11 15:20:19 [chat_utils.py:451] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
INFO:     127.0.0.1:60314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60330 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:19,524] LMCache INFO:[0m Reqid: chatcmpl-1d4f48228f174b6d98419ca5d58e49d0, Total tokens 147, LMCache hit tokens: 0, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,577] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-1d4f48228f174b6d98419ca5d58e49d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,578] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.4370 ms, throughput: 2.7317 GB/s; offload_time: 1.2375 ms, put_time: 0.1995 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,584] LMCache INFO:[0m Reqid: chatcmpl-854c7fd53a0a449dab4405bf08ac8d16, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,584] LMCache INFO:[0m Reqid: chatcmpl-02026b3c9c4542edb888e697df1f551b, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,585] LMCache INFO:[0m Reqid: chatcmpl-a75ecd941a0c4ee5be09e37856fa119c, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,585] LMCache INFO:[0m Reqid: chatcmpl-5535c6e8a7094d9982b8f8b61dd0c8bf, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,586] LMCache INFO:[0m Reqid: chatcmpl-e9df4f60a4254b539be1d2a1963b2055, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,586] LMCache INFO:[0m Reqid: chatcmpl-b1ff6b8b7189489f8756b6a42d561489, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,587] LMCache INFO:[0m Reqid: chatcmpl-d5ff56d6953a496ea3f280dba1185cd4, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,587] LMCache INFO:[0m Reqid: chatcmpl-04993d5a23f340a18990a56a863363b5, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,588] LMCache INFO:[0m Reqid: chatcmpl-db4004e764d64b7da604e12d56d3aed3, Total tokens 147, LMCache hit tokens: 0, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,608] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-854c7fd53a0a449dab4405bf08ac8d16 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,609] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 0.7630 ms, throughput: 5.1446 GB/s; offload_time: 0.6552 ms, put_time: 0.1078 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,609] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-02026b3c9c4542edb888e697df1f551b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,611] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.7070 ms, throughput: 2.2996 GB/s; offload_time: 1.5897 ms, put_time: 0.1173 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,612] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-a75ecd941a0c4ee5be09e37856fa119c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,613] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.5059 ms, throughput: 2.6066 GB/s; offload_time: 1.3819 ms, put_time: 0.1240 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,614] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-5535c6e8a7094d9982b8f8b61dd0c8bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,616] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.6639 ms, throughput: 2.3590 GB/s; offload_time: 1.4721 ms, put_time: 0.1919 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,617] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-e9df4f60a4254b539be1d2a1963b2055 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,618] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 0.8628 ms, throughput: 4.5495 GB/s; offload_time: 0.6662 ms, put_time: 0.1966 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,618] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-b1ff6b8b7189489f8756b6a42d561489 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,619] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 0.9371 ms, throughput: 4.1888 GB/s; offload_time: 0.8075 ms, put_time: 0.1296 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,619] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-d5ff56d6953a496ea3f280dba1185cd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,621] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.1480 ms, throughput: 3.4192 GB/s; offload_time: 1.0386 ms, put_time: 0.1094 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,621] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-04993d5a23f340a18990a56a863363b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,623] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.7053 ms, throughput: 2.3019 GB/s; offload_time: 1.5735 ms, put_time: 0.1318 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:19,623] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-db4004e764d64b7da604e12d56d3aed3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:19,624] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.0693 ms, throughput: 3.6708 GB/s; offload_time: 0.9455 ms, put_time: 0.1238 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[33;20m[2025-07-11 15:20:20,009] LMCache WARNING:[0m In connector.start_load_kv, but the attn_metadata is None [3m(vllm_v1_adapter.py:411:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO 07-11 15:20:21 [loggers.py:118] Engine 000: Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 19.6%
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,419] LMCache INFO:[0m Reqid: chatcmpl-e5955a3ba58e45e99c4ee574278cdaea, Total tokens 150, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,428] LMCache INFO:[0m Storing KV cache for 150 out of 150 tokens (skip_leading_tokens=0) for request chatcmpl-e5955a3ba58e45e99c4ee574278cdaea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,429] LMCache INFO:[0m Stored 150 out of total 150 tokens. size: 0.0040 gb, cost 1.0826 ms, throughput: 3.6997 GB/s; offload_time: 0.9400 ms, put_time: 0.1427 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,521] LMCache INFO:[0m Reqid: chatcmpl-647ab8fa29544bfb801dfef0cfbf2690, Total tokens 182, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,529] LMCache INFO:[0m Storing KV cache for 182 out of 182 tokens (skip_leading_tokens=0) for request chatcmpl-647ab8fa29544bfb801dfef0cfbf2690 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,530] LMCache INFO:[0m Stored 182 out of total 182 tokens. size: 0.0049 gb, cost 0.6697 ms, throughput: 7.2571 GB/s; offload_time: 0.5693 ms, put_time: 0.1004 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,618] LMCache INFO:[0m Reqid: chatcmpl-f96b44e865a34352941e39e648d108db, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,622] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-f96b44e865a34352941e39e648d108db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,623] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4366 ms, throughput: 5.6274 GB/s; offload_time: 0.3668 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,720] LMCache INFO:[0m Reqid: chatcmpl-dc66912dc7ff4b219fdbbfd176d7c0c1, Total tokens 118, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,720] LMCache INFO:[0m Reqid: chatcmpl-bad5699830294186b1fd1f7bf49d1f01, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,725] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-dc66912dc7ff4b219fdbbfd176d7c0c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,726] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.4232 ms, throughput: 7.4453 GB/s; offload_time: 0.3515 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,726] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-bad5699830294186b1fd1f7bf49d1f01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,727] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.7986 ms, throughput: 3.1430 GB/s; offload_time: 0.6915 ms, put_time: 0.1072 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO 07-11 15:20:31 [loggers.py:118] Engine 000: Avg prompt throughput: 63.6 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 25.8%
[32;20m[2025-07-11 15:20:31,777] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-dc66912dc7ff4b219fdbbfd176d7c0c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,777] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4313 ms, throughput: 7.9250 GB/s; offload_time: 0.3492 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,822] LMCache INFO:[0m Reqid: chatcmpl-2794016944f1417dbe0fc5dcfa28ac39, Total tokens 114, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,823] LMCache INFO:[0m Reqid: chatcmpl-b9d00519ccd94e028408f514c1c99356, Total tokens 358, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,832] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-2794016944f1417dbe0fc5dcfa28ac39 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,833] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.4043 ms, throughput: 7.5301 GB/s; offload_time: 0.3355 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,833] LMCache INFO:[0m Storing KV cache for 358 out of 358 tokens (skip_leading_tokens=0) for request chatcmpl-b9d00519ccd94e028408f514c1c99356 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,834] LMCache INFO:[0m Stored 358 out of total 358 tokens. size: 0.0096 gb, cost 1.1517 ms, throughput: 8.3002 GB/s; offload_time: 0.9580 ms, put_time: 0.1938 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,910] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-647ab8fa29544bfb801dfef0cfbf2690 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,910] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4247 ms, throughput: 8.0483 GB/s; offload_time: 0.3553 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,911] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2794016944f1417dbe0fc5dcfa28ac39 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,911] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5116 ms, throughput: 6.6814 GB/s; offload_time: 0.4499 ms, put_time: 0.0617 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,919] LMCache INFO:[0m Reqid: chatcmpl-2c2c840012bc4826947901b32d225499, Total tokens 155, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:31,923] LMCache INFO:[0m Storing KV cache for 155 out of 155 tokens (skip_leading_tokens=0) for request chatcmpl-2c2c840012bc4826947901b32d225499 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,924] LMCache INFO:[0m Stored 27 out of total 155 tokens. size: 0.0007 gb, cost 0.4229 ms, throughput: 1.7049 GB/s; offload_time: 0.3478 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,926] LMCache INFO:[0m Reqid: chatcmpl-c3bab565e8fc47b185bf88d54ffc3fc1, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,931] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-c3bab565e8fc47b185bf88d54ffc3fc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,931] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.3886 ms, throughput: 7.2159 GB/s; offload_time: 0.3217 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,971] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e5955a3ba58e45e99c4ee574278cdaea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,971] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4352 ms, throughput: 7.8531 GB/s; offload_time: 0.3589 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:31,978] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b9d00519ccd94e028408f514c1c99356 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:31,978] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4273 ms, throughput: 7.9990 GB/s; offload_time: 0.3603 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,023] LMCache INFO:[0m Reqid: chatcmpl-51ed1a554df74a7097c0a9df55673ecb, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,028] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-51ed1a554df74a7097c0a9df55673ecb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,029] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.3919 ms, throughput: 7.2217 GB/s; offload_time: 0.3241 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,049] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c3bab565e8fc47b185bf88d54ffc3fc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,050] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4067 ms, throughput: 8.4051 GB/s; offload_time: 0.3378 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,130] LMCache INFO:[0m Reqid: chatcmpl-735d65fd8ef84a7fb10b9064c0d729e7, Total tokens 291, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,134] LMCache INFO:[0m Storing KV cache for 291 out of 291 tokens (skip_leading_tokens=0) for request chatcmpl-735d65fd8ef84a7fb10b9064c0d729e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,135] LMCache INFO:[0m Stored 35 out of total 291 tokens. size: 0.0009 gb, cost 0.4367 ms, throughput: 2.1402 GB/s; offload_time: 0.3692 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,137] LMCache INFO:[0m Reqid: chatcmpl-9f57699599774570b3ee2fe62d6e6577, Total tokens 471, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,138] LMCache INFO:[0m Reqid: chatcmpl-82a43ca9b9e542b88bcabb2e70189292, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,148] LMCache INFO:[0m Storing KV cache for 471 out of 471 tokens (skip_leading_tokens=0) for request chatcmpl-9f57699599774570b3ee2fe62d6e6577 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,149] LMCache INFO:[0m Stored 471 out of total 471 tokens. size: 0.0126 gb, cost 1.1068 ms, throughput: 11.3637 GB/s; offload_time: 0.8647 ms, put_time: 0.2420 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,150] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-82a43ca9b9e542b88bcabb2e70189292 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,152] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 1.7830 ms, throughput: 1.4078 GB/s; offload_time: 1.6621 ms, put_time: 0.1209 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,234] LMCache INFO:[0m Reqid: chatcmpl-2ab2d064270f4ad68e7a4af8b0453969, Total tokens 840, LMCache hit tokens: 384, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,235] LMCache INFO:[0m Reqid: chatcmpl-e0b3375beb8d4d9c9e27b9659bcf4188, Total tokens 118, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,245] LMCache INFO:[0m Storing KV cache for 840 out of 840 tokens (skip_leading_tokens=0) for request chatcmpl-2ab2d064270f4ad68e7a4af8b0453969 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,247] LMCache INFO:[0m Stored 456 out of total 840 tokens. size: 0.0122 gb, cost 1.2070 ms, throughput: 10.0881 GB/s; offload_time: 0.8926 ms, put_time: 0.3145 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,247] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-e0b3375beb8d4d9c9e27b9659bcf4188 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,250] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 1.4384 ms, throughput: 2.1905 GB/s; offload_time: 1.2818 ms, put_time: 0.1566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,252] LMCache INFO:[0m Reqid: chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb, Total tokens 139, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,259] LMCache INFO:[0m Storing KV cache for 139 out of 139 tokens (skip_leading_tokens=0) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,259] LMCache INFO:[0m Stored 139 out of total 139 tokens. size: 0.0037 gb, cost 0.6372 ms, throughput: 5.8246 GB/s; offload_time: 0.5327 ms, put_time: 0.1045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,305] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e0b3375beb8d4d9c9e27b9659bcf4188 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,305] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4231 ms, throughput: 8.0778 GB/s; offload_time: 0.3546 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,337] LMCache INFO:[0m Reqid: chatcmpl-27ef1e70925349c28705aa5c84731496, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,342] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-27ef1e70925349c28705aa5c84731496 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,342] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.4038 ms, throughput: 6.5462 GB/s; offload_time: 0.3284 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,432] LMCache INFO:[0m Reqid: chatcmpl-af67f335988241c4b65fff638e46faa6, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,437] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,437] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.4124 ms, throughput: 7.3823 GB/s; offload_time: 0.3394 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,488] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-27ef1e70925349c28705aa5c84731496 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,488] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4045 ms, throughput: 8.4498 GB/s; offload_time: 0.3370 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,509] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,509] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4329 ms, throughput: 7.8952 GB/s; offload_time: 0.3629 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,541] LMCache INFO:[0m Reqid: chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,546] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,547] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.3969 ms, throughput: 8.2079 GB/s; offload_time: 0.3234 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,578] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,579] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4024 ms, throughput: 8.4939 GB/s; offload_time: 0.3348 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,639] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-735d65fd8ef84a7fb10b9064c0d729e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,640] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4382 ms, throughput: 7.8006 GB/s; offload_time: 0.3623 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,642] LMCache INFO:[0m Reqid: chatcmpl-38944bc78db04f75b346b0442a5c8a74, Total tokens 166, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,643] LMCache INFO:[0m Reqid: chatcmpl-8a4c56b5fda145ce9edd5859591947af, Total tokens 151, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,651] LMCache INFO:[0m Storing KV cache for 166 out of 166 tokens (skip_leading_tokens=0) for request chatcmpl-38944bc78db04f75b346b0442a5c8a74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,652] LMCache INFO:[0m Stored 38 out of total 166 tokens. size: 0.0010 gb, cost 0.4172 ms, throughput: 2.4320 GB/s; offload_time: 0.3496 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,652] LMCache INFO:[0m Storing KV cache for 151 out of 151 tokens (skip_leading_tokens=0) for request chatcmpl-8a4c56b5fda145ce9edd5859591947af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,653] LMCache INFO:[0m Stored 151 out of total 151 tokens. size: 0.0040 gb, cost 1.0510 ms, throughput: 3.8366 GB/s; offload_time: 0.9585 ms, put_time: 0.0924 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,667] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e5955a3ba58e45e99c4ee574278cdaea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,667] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4455 ms, throughput: 7.6715 GB/s; offload_time: 0.3673 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,674] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b9d00519ccd94e028408f514c1c99356 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,674] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4402 ms, throughput: 7.7643 GB/s; offload_time: 0.3727 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,745] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c3bab565e8fc47b185bf88d54ffc3fc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,745] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4323 ms, throughput: 7.9067 GB/s; offload_time: 0.3568 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,747] LMCache INFO:[0m Reqid: chatcmpl-040aa4b8fac3484ab910be1d092fffb9, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,752] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-040aa4b8fac3484ab910be1d092fffb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,753] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.3998 ms, throughput: 6.3454 GB/s; offload_time: 0.3283 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,845] LMCache INFO:[0m Reqid: chatcmpl-446c8ef95bdc4ae19d787616f5f426d9, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,850] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-446c8ef95bdc4ae19d787616f5f426d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,850] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.3889 ms, throughput: 6.6607 GB/s; offload_time: 0.3195 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,877] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,877] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4264 ms, throughput: 8.0156 GB/s; offload_time: 0.3576 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,924] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-040aa4b8fac3484ab910be1d092fffb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,924] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4038 ms, throughput: 8.4652 GB/s; offload_time: 0.3355 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:32,947] LMCache INFO:[0m Reqid: chatcmpl-417d7a6782db4b3a94fbdaa8fa494eaf, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,952] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-417d7a6782db4b3a94fbdaa8fa494eaf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,952] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.4156 ms, throughput: 6.2330 GB/s; offload_time: 0.3477 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:32,983] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e0b3375beb8d4d9c9e27b9659bcf4188 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:32,983] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3519 ms, throughput: 9.7136 GB/s; offload_time: 0.2964 ms, put_time: 0.0554 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,012] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-446c8ef95bdc4ae19d787616f5f426d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,012] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3631 ms, throughput: 9.4121 GB/s; offload_time: 0.3014 ms, put_time: 0.0618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,051] LMCache INFO:[0m Reqid: chatcmpl-5575a958123a4aa1839b6ded0a54789d, Total tokens 319, LMCache hit tokens: 256, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,055] LMCache INFO:[0m Storing KV cache for 319 out of 319 tokens (skip_leading_tokens=0) for request chatcmpl-5575a958123a4aa1839b6ded0a54789d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,056] LMCache INFO:[0m Stored 63 out of total 319 tokens. size: 0.0017 gb, cost 0.3661 ms, throughput: 4.5950 GB/s; offload_time: 0.3094 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,058] LMCache INFO:[0m Reqid: chatcmpl-5699394359da427eb8f4fb951544e43e, Total tokens 136, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,058] LMCache INFO:[0m Reqid: chatcmpl-cbce59668d674e69bcf03029a7503647, Total tokens 290, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,066] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-5699394359da427eb8f4fb951544e43e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,067] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 0.5374 ms, throughput: 6.7580 GB/s; offload_time: 0.4556 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,067] LMCache INFO:[0m Storing KV cache for 290 out of 290 tokens (skip_leading_tokens=0) for request chatcmpl-cbce59668d674e69bcf03029a7503647 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,069] LMCache INFO:[0m Stored 162 out of total 290 tokens. size: 0.0043 gb, cost 1.2740 ms, throughput: 3.3955 GB/s; offload_time: 1.1947 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,113] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-417d7a6782db4b3a94fbdaa8fa494eaf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,113] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3439 ms, throughput: 9.9377 GB/s; offload_time: 0.2867 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,128] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-38944bc78db04f75b346b0442a5c8a74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,128] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3591 ms, throughput: 9.5172 GB/s; offload_time: 0.2975 ms, put_time: 0.0617 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,154] LMCache INFO:[0m Reqid: chatcmpl-f5c888e8b08548f69aa07d5112b6933b, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,158] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-f5c888e8b08548f69aa07d5112b6933b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,159] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.3371 ms, throughput: 7.2868 GB/s; offload_time: 0.2805 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,188] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,188] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3513 ms, throughput: 9.7284 GB/s; offload_time: 0.2948 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,249] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,250] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3515 ms, throughput: 9.7237 GB/s; offload_time: 0.2950 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,256] LMCache INFO:[0m Reqid: chatcmpl-99942fa842cc4bdf8c989e46d9a47c05, Total tokens 265, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,265] LMCache INFO:[0m Storing KV cache for 265 out of 265 tokens (skip_leading_tokens=0) for request chatcmpl-99942fa842cc4bdf8c989e46d9a47c05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,265] LMCache INFO:[0m Stored 137 out of total 265 tokens. size: 0.0037 gb, cost 0.5628 ms, throughput: 6.5006 GB/s; offload_time: 0.4690 ms, put_time: 0.0938 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,269] LMCache INFO:[0m Reqid: chatcmpl-c5e7014014d64b979e8bfc042269921a, Total tokens 158, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,269] LMCache INFO:[0m Reqid: chatcmpl-898bfc6828da4a23875e5941a14960bc, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,275] LMCache INFO:[0m Storing KV cache for 158 out of 158 tokens (skip_leading_tokens=0) for request chatcmpl-c5e7014014d64b979e8bfc042269921a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,275] LMCache INFO:[0m Stored 30 out of total 158 tokens. size: 0.0008 gb, cost 0.3537 ms, throughput: 2.2652 GB/s; offload_time: 0.2911 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,275] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-898bfc6828da4a23875e5941a14960bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,276] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.4807 ms, throughput: 5.6101 GB/s; offload_time: 0.4253 ms, put_time: 0.0555 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,320] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-735d65fd8ef84a7fb10b9064c0d729e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,321] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3724 ms, throughput: 9.1780 GB/s; offload_time: 0.3149 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,336] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e5955a3ba58e45e99c4ee574278cdaea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,336] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3663 ms, throughput: 9.3308 GB/s; offload_time: 0.3101 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,346] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f5c888e8b08548f69aa07d5112b6933b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,347] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3447 ms, throughput: 9.9158 GB/s; offload_time: 0.2861 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,358] LMCache INFO:[0m Reqid: chatcmpl-a05054b718ca46d3b49995fd930d8386, Total tokens 137, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,364] LMCache INFO:[0m Storing KV cache for 137 out of 137 tokens (skip_leading_tokens=0) for request chatcmpl-a05054b718ca46d3b49995fd930d8386 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,365] LMCache INFO:[0m Stored 137 out of total 137 tokens. size: 0.0037 gb, cost 0.5465 ms, throughput: 6.6942 GB/s; offload_time: 0.4608 ms, put_time: 0.0857 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,401] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5575a958123a4aa1839b6ded0a54789d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,401] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3669 ms, throughput: 9.3167 GB/s; offload_time: 0.3103 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,416] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-898bfc6828da4a23875e5941a14960bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,416] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3462 ms, throughput: 9.8726 GB/s; offload_time: 0.2887 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,461] LMCache INFO:[0m Reqid: chatcmpl-9b3bb66914ae4d79b5306f4b67ad519b, Total tokens 193, LMCache hit tokens: 128, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,466] LMCache INFO:[0m Storing KV cache for 193 out of 193 tokens (skip_leading_tokens=0) for request chatcmpl-9b3bb66914ae4d79b5306f4b67ad519b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,466] LMCache INFO:[0m Stored 65 out of total 193 tokens. size: 0.0017 gb, cost 0.3664 ms, throughput: 4.7367 GB/s; offload_time: 0.2923 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,468] LMCache INFO:[0m Reqid: chatcmpl-b3c78f3cedcf4fa2ba5352a082ffbf6e, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,474] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-b3c78f3cedcf4fa2ba5352a082ffbf6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,474] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.3710 ms, throughput: 7.8448 GB/s; offload_time: 0.3019 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,544] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,545] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3596 ms, throughput: 9.5040 GB/s; offload_time: 0.3024 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,555] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-cbce59668d674e69bcf03029a7503647 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,556] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3737 ms, throughput: 9.1452 GB/s; offload_time: 0.3097 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,558] LMCache INFO:[0m Reqid: chatcmpl-3aa9f0c56dc645ee9fc028e25f968e5d, Total tokens 301, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,565] LMCache INFO:[0m Storing KV cache for 301 out of 301 tokens (skip_leading_tokens=0) for request chatcmpl-3aa9f0c56dc645ee9fc028e25f968e5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,565] LMCache INFO:[0m Stored 173 out of total 301 tokens. size: 0.0046 gb, cost 0.5922 ms, throughput: 7.8010 GB/s; offload_time: 0.5002 ms, put_time: 0.0920 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,568] LMCache INFO:[0m Reqid: chatcmpl-1d8ddafe7b8a46eb83d233eae983baf5, Total tokens 429, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,579] LMCache INFO:[0m Storing KV cache for 429 out of 429 tokens (skip_leading_tokens=0) for request chatcmpl-1d8ddafe7b8a46eb83d233eae983baf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,580] LMCache INFO:[0m Stored 429 out of total 429 tokens. size: 0.0115 gb, cost 1.0231 ms, throughput: 11.1968 GB/s; offload_time: 0.7499 ms, put_time: 0.2732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,587] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-b3c78f3cedcf4fa2ba5352a082ffbf6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,588] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3403 ms, throughput: 10.0427 GB/s; offload_time: 0.2846 ms, put_time: 0.0558 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,608] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-040aa4b8fac3484ab910be1d092fffb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,608] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3522 ms, throughput: 9.7052 GB/s; offload_time: 0.2913 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,661] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e0b3375beb8d4d9c9e27b9659bcf4188 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,662] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3717 ms, throughput: 9.1943 GB/s; offload_time: 0.3139 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,669] LMCache INFO:[0m Reqid: chatcmpl-a7ce1c97bae04cd0b1d9f64c21a649df, Total tokens 187, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,674] LMCache INFO:[0m Storing KV cache for 187 out of 187 tokens (skip_leading_tokens=0) for request chatcmpl-a7ce1c97bae04cd0b1d9f64c21a649df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,674] LMCache INFO:[0m Stored 59 out of total 187 tokens. size: 0.0016 gb, cost 0.3486 ms, throughput: 4.5199 GB/s; offload_time: 0.2872 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,676] LMCache INFO:[0m Reqid: chatcmpl-e1e5993bf7f547399572caa1eadbd7be, Total tokens 159, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,682] LMCache INFO:[0m Storing KV cache for 159 out of 159 tokens (skip_leading_tokens=0) for request chatcmpl-e1e5993bf7f547399572caa1eadbd7be [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,683] LMCache INFO:[0m Stored 159 out of total 159 tokens. size: 0.0042 gb, cost 0.5685 ms, throughput: 7.4686 GB/s; offload_time: 0.4675 ms, put_time: 0.1010 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,709] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5699394359da427eb8f4fb951544e43e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,710] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3583 ms, throughput: 9.5394 GB/s; offload_time: 0.2950 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,789] LMCache INFO:[0m Reqid: chatcmpl-31bf0376e4c84defa1f3371252a38500, Total tokens 2639, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,835] LMCache INFO:[0m Storing KV cache for 2639 out of 2639 tokens (skip_leading_tokens=0) for request chatcmpl-31bf0376e4c84defa1f3371252a38500 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,841] LMCache INFO:[0m Stored 2639 out of total 2639 tokens. size: 0.0705 gb, cost 6.6520 ms, throughput: 10.5937 GB/s; offload_time: 3.1280 ms, put_time: 3.5240 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,864] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-38944bc78db04f75b346b0442a5c8a74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,864] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3777 ms, throughput: 9.0497 GB/s; offload_time: 0.3161 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,882] LMCache INFO:[0m Reqid: chatcmpl-e3c33f3a3fca4103a56188604ff972fc, Total tokens 1149, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,903] LMCache INFO:[0m Storing KV cache for 1149 out of 1149 tokens (skip_leading_tokens=0) for request chatcmpl-e3c33f3a3fca4103a56188604ff972fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,905] LMCache INFO:[0m Stored 1149 out of total 1149 tokens. size: 0.0307 gb, cost 1.6738 ms, throughput: 18.3307 GB/s; offload_time: 1.4622 ms, put_time: 0.2116 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,927] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-e3c33f3a3fca4103a56188604ff972fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,927] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4068 ms, throughput: 8.4024 GB/s; offload_time: 0.3445 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,953] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,954] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3584 ms, throughput: 9.5365 GB/s; offload_time: 0.3009 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:33,985] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-99942fa842cc4bdf8c989e46d9a47c05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,985] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3628 ms, throughput: 9.4205 GB/s; offload_time: 0.3060 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:33,988] LMCache INFO:[0m Reqid: chatcmpl-8e8e77250e464733930247deb8a4a799, Total tokens 432, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,994] LMCache INFO:[0m Storing KV cache for 432 out of 432 tokens (skip_leading_tokens=0) for request chatcmpl-8e8e77250e464733930247deb8a4a799 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:33,995] LMCache INFO:[0m Stored 48 out of total 432 tokens. size: 0.0013 gb, cost 0.4134 ms, throughput: 3.1008 GB/s; offload_time: 0.3549 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,003] LMCache INFO:[0m Reqid: chatcmpl-9c75e3ecdba948d08dfabab5072fcfb5, Total tokens 3237, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,056] LMCache INFO:[0m Storing KV cache for 3237 out of 3237 tokens (skip_leading_tokens=0) for request chatcmpl-9c75e3ecdba948d08dfabab5072fcfb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,061] LMCache INFO:[0m Stored 3237 out of total 3237 tokens. size: 0.0864 gb, cost 4.2945 ms, throughput: 20.1276 GB/s; offload_time: 3.6713 ms, put_time: 0.6232 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,084] LMCache INFO:[0m Reqid: chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3, Total tokens 632, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,085] LMCache INFO:[0m Reqid: chatcmpl-fef74d65784e410d833652e0d0726792, Total tokens 443, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,093] LMCache INFO:[0m Storing KV cache for 632 out of 632 tokens (skip_leading_tokens=0) for request chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,093] LMCache INFO:[0m Stored 120 out of total 632 tokens. size: 0.0032 gb, cost 0.4040 ms, throughput: 7.9307 GB/s; offload_time: 0.3474 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,093] LMCache INFO:[0m Storing KV cache for 443 out of 443 tokens (skip_leading_tokens=0) for request chatcmpl-fef74d65784e410d833652e0d0726792 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,094] LMCache INFO:[0m Stored 59 out of total 443 tokens. size: 0.0016 gb, cost 0.6333 ms, throughput: 2.4877 GB/s; offload_time: 0.5824 ms, put_time: 0.0509 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,096] LMCache INFO:[0m Reqid: chatcmpl-5774a96bb4e14c31ab48684df4c9ece3, Total tokens 128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,105] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5774a96bb4e14c31ab48684df4c9ece3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,106] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3543 ms, throughput: 9.6479 GB/s; offload_time: 0.2929 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,106] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,107] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5018 ms, throughput: 6.8118 GB/s; offload_time: 0.4507 ms, put_time: 0.0511 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,146] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,146] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3781 ms, throughput: 9.0392 GB/s; offload_time: 0.3172 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,167] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a05054b718ca46d3b49995fd930d8386 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,168] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3547 ms, throughput: 9.6358 GB/s; offload_time: 0.2975 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,179] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3aa9f0c56dc645ee9fc028e25f968e5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,179] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3641 ms, throughput: 9.3885 GB/s; offload_time: 0.3019 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,185] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1d8ddafe7b8a46eb83d233eae983baf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,186] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3694 ms, throughput: 9.2528 GB/s; offload_time: 0.3093 ms, put_time: 0.0601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,207] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a7ce1c97bae04cd0b1d9f64c21a649df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,207] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3569 ms, throughput: 9.5766 GB/s; offload_time: 0.2938 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,223] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-31bf0376e4c84defa1f3371252a38500 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,224] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 0.4902 ms, throughput: 6.9720 GB/s; offload_time: 0.4263 ms, put_time: 0.0640 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,256] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5575a958123a4aa1839b6ded0a54789d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,256] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3690 ms, throughput: 9.2628 GB/s; offload_time: 0.3135 ms, put_time: 0.0555 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,289] LMCache INFO:[0m Reqid: chatcmpl-2054f3db1bbf4adfb4acd57d5639980b, Total tokens 331, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,289] LMCache INFO:[0m Reqid: chatcmpl-5adde7d2e9174d3a9a9781186b8077ff, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,298] LMCache INFO:[0m Storing KV cache for 331 out of 331 tokens (skip_leading_tokens=0) for request chatcmpl-2054f3db1bbf4adfb4acd57d5639980b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,298] LMCache INFO:[0m Stored 75 out of total 331 tokens. size: 0.0020 gb, cost 0.3893 ms, throughput: 5.1443 GB/s; offload_time: 0.3311 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,298] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-5adde7d2e9174d3a9a9781186b8077ff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,299] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.6286 ms, throughput: 4.7576 GB/s; offload_time: 0.5768 ms, put_time: 0.0518 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,304] LMCache INFO:[0m Reqid: chatcmpl-6fc66e15fef44b69be9ab5250609abf2, Total tokens 192, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,311] LMCache INFO:[0m Storing KV cache for 192 out of 192 tokens (skip_leading_tokens=0) for request chatcmpl-6fc66e15fef44b69be9ab5250609abf2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,312] LMCache INFO:[0m Stored 64 out of total 192 tokens. size: 0.0017 gb, cost 0.3599 ms, throughput: 4.7491 GB/s; offload_time: 0.3017 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,316] LMCache INFO:[0m Reqid: chatcmpl-ffefa11aa7ec4484badfc758af65e2c4, Total tokens 1170, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,339] LMCache INFO:[0m Storing KV cache for 1170 out of 1170 tokens (skip_leading_tokens=0) for request chatcmpl-ffefa11aa7ec4484badfc758af65e2c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,341] LMCache INFO:[0m Stored 1170 out of total 1170 tokens. size: 0.0312 gb, cost 1.9604 ms, throughput: 15.9366 GB/s; offload_time: 1.7372 ms, put_time: 0.2233 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,433] LMCache INFO:[0m Reqid: chatcmpl-bd9e16bc506d4e5783c79bc1c94a7f02, Total tokens 2291, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,472] LMCache INFO:[0m Storing KV cache for 2291 out of 2291 tokens (skip_leading_tokens=0) for request chatcmpl-bd9e16bc506d4e5783c79bc1c94a7f02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,475] LMCache INFO:[0m Stored 2291 out of total 2291 tokens. size: 0.0612 gb, cost 3.1396 ms, throughput: 19.4852 GB/s; offload_time: 2.6311 ms, put_time: 0.5085 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,493] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,494] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3717 ms, throughput: 9.1953 GB/s; offload_time: 0.3148 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,505] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-cbce59668d674e69bcf03029a7503647 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,506] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3689 ms, throughput: 9.2651 GB/s; offload_time: 0.3133 ms, put_time: 0.0556 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,508] LMCache INFO:[0m Reqid: chatcmpl-fc5e76b2918944f4b649b1ce2fbfdb97, Total tokens 264, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,515] LMCache INFO:[0m Storing KV cache for 264 out of 264 tokens (skip_leading_tokens=0) for request chatcmpl-fc5e76b2918944f4b649b1ce2fbfdb97 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,516] LMCache INFO:[0m Stored 136 out of total 264 tokens. size: 0.0036 gb, cost 0.5372 ms, throughput: 6.7600 GB/s; offload_time: 0.4566 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,524] LMCache INFO:[0m Reqid: chatcmpl-bb0a4cf3731248b3b20634c7a2bc076d, Total tokens 1544, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,525] LMCache INFO:[0m Reqid: chatcmpl-6e4ba9f3c9ed4d37a959301ed98e25df, Total tokens 117, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,553] LMCache INFO:[0m Storing KV cache for 1544 out of 1544 tokens (skip_leading_tokens=0) for request chatcmpl-bb0a4cf3731248b3b20634c7a2bc076d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,555] LMCache INFO:[0m Stored 1544 out of total 1544 tokens. size: 0.0412 gb, cost 2.5689 ms, throughput: 16.0494 GB/s; offload_time: 1.9392 ms, put_time: 0.6297 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,557] LMCache INFO:[0m Storing KV cache for 117 out of 117 tokens (skip_leading_tokens=0) for request chatcmpl-6e4ba9f3c9ed4d37a959301ed98e25df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,559] LMCache INFO:[0m Stored 117 out of total 117 tokens. size: 0.0031 gb, cost 1.8688 ms, throughput: 1.6718 GB/s; offload_time: 1.6297 ms, put_time: 0.2391 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,597] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-bd9e16bc506d4e5783c79bc1c94a7f02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,597] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.4765 ms, throughput: 7.1727 GB/s; offload_time: 0.4143 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,609] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fef74d65784e410d833652e0d0726792 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,609] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3680 ms, throughput: 9.2886 GB/s; offload_time: 0.3100 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,622] LMCache INFO:[0m Reqid: chatcmpl-1e0d75c064834d36a027cea47af108d1, Total tokens 536, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,630] LMCache INFO:[0m Storing KV cache for 536 out of 536 tokens (skip_leading_tokens=0) for request chatcmpl-1e0d75c064834d36a027cea47af108d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,630] LMCache INFO:[0m Stored 24 out of total 536 tokens. size: 0.0006 gb, cost 0.3995 ms, throughput: 1.6040 GB/s; offload_time: 0.3425 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,631] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6e4ba9f3c9ed4d37a959301ed98e25df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,631] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5801 ms, throughput: 5.8921 GB/s; offload_time: 0.5211 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,647] LMCache INFO:[0m Reqid: chatcmpl-95cd3443a930462eac505d4a8929b85e, Total tokens 2293, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,687] LMCache INFO:[0m Storing KV cache for 2293 out of 2293 tokens (skip_leading_tokens=0) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,690] LMCache INFO:[0m Stored 2293 out of total 2293 tokens. size: 0.0612 gb, cost 3.1484 ms, throughput: 19.4480 GB/s; offload_time: 2.6433 ms, put_time: 0.5051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,690] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8e8e77250e464733930247deb8a4a799 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,694] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 3.1862 ms, throughput: 1.0727 GB/s; offload_time: 3.0228 ms, put_time: 0.1633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,707] LMCache INFO:[0m Reqid: chatcmpl-84144ea88d864e1d8b32e0f01f32b416, Total tokens 1292, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,732] LMCache INFO:[0m Storing KV cache for 1292 out of 1292 tokens (skip_leading_tokens=0) for request chatcmpl-84144ea88d864e1d8b32e0f01f32b416 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,734] LMCache INFO:[0m Stored 1292 out of total 1292 tokens. size: 0.0345 gb, cost 1.9373 ms, throughput: 17.8086 GB/s; offload_time: 1.7120 ms, put_time: 0.2252 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,778] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5699394359da427eb8f4fb951544e43e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,778] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3643 ms, throughput: 9.3811 GB/s; offload_time: 0.3076 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,791] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,791] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.4751 ms, throughput: 7.1945 GB/s; offload_time: 0.4176 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,803] LMCache INFO:[0m Storing KV cache for 128 out of 3328 tokens (skip_leading_tokens=3200) for request chatcmpl-9c75e3ecdba948d08dfabab5072fcfb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,804] LMCache INFO:[0m Stored 128 out of total 3328 tokens. size: 0.0034 gb, cost 0.5238 ms, throughput: 6.5251 GB/s; offload_time: 0.4678 ms, put_time: 0.0560 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,804] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2054f3db1bbf4adfb4acd57d5639980b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,805] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4937 ms, throughput: 6.9226 GB/s; offload_time: 0.4380 ms, put_time: 0.0558 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,828] LMCache INFO:[0m Reqid: chatcmpl-d62f5a30971f459394b3fec33741562b, Total tokens 1154, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,852] LMCache INFO:[0m Storing KV cache for 1154 out of 1154 tokens (skip_leading_tokens=0) for request chatcmpl-d62f5a30971f459394b3fec33741562b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,854] LMCache INFO:[0m Stored 1154 out of total 1154 tokens. size: 0.0308 gb, cost 2.1040 ms, throughput: 14.6460 GB/s; offload_time: 1.5660 ms, put_time: 0.5380 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,896] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6fc66e15fef44b69be9ab5250609abf2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,897] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3522 ms, throughput: 9.7048 GB/s; offload_time: 0.2957 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:34,926] LMCache INFO:[0m Reqid: chatcmpl-144c3a35ec8446c28bd268255a944577, Total tokens 1266, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,952] LMCache INFO:[0m Storing KV cache for 1266 out of 1266 tokens (skip_leading_tokens=0) for request chatcmpl-144c3a35ec8446c28bd268255a944577 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,954] LMCache INFO:[0m Stored 1266 out of total 1266 tokens. size: 0.0338 gb, cost 2.3042 ms, throughput: 14.6712 GB/s; offload_time: 1.5542 ms, put_time: 0.7500 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:34,987] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-e3c33f3a3fca4103a56188604ff972fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:34,988] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4088 ms, throughput: 8.3615 GB/s; offload_time: 0.3526 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,016] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,016] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3697 ms, throughput: 9.2458 GB/s; offload_time: 0.3121 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,030] LMCache INFO:[0m Reqid: chatcmpl-90453b93c59b4893b7c8e462fd6a7fde, Total tokens 611, LMCache hit tokens: 512, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,038] LMCache INFO:[0m Storing KV cache for 611 out of 611 tokens (skip_leading_tokens=0) for request chatcmpl-90453b93c59b4893b7c8e462fd6a7fde [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,038] LMCache INFO:[0m Stored 99 out of total 611 tokens. size: 0.0026 gb, cost 0.3922 ms, throughput: 6.7405 GB/s; offload_time: 0.3334 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,047] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-144c3a35ec8446c28bd268255a944577 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,047] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4119 ms, throughput: 8.2973 GB/s; offload_time: 0.3546 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,055] LMCache INFO:[0m Reqid: chatcmpl-87a5dc7f923d4552831cf005f2a8ea8b, Total tokens 1155, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,079] LMCache INFO:[0m Storing KV cache for 1155 out of 1155 tokens (skip_leading_tokens=0) for request chatcmpl-87a5dc7f923d4552831cf005f2a8ea8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,081] LMCache INFO:[0m Stored 1155 out of total 1155 tokens. size: 0.0308 gb, cost 2.1105 ms, throughput: 14.6137 GB/s; offload_time: 1.5557 ms, put_time: 0.5548 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,081] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-99942fa842cc4bdf8c989e46d9a47c05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,084] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.9526 ms, throughput: 1.1576 GB/s; offload_time: 2.8848 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,127] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,128] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3826 ms, throughput: 8.9333 GB/s; offload_time: 0.3174 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,167] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,168] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3811 ms, throughput: 8.9679 GB/s; offload_time: 0.3248 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,170] LMCache INFO:[0m Reqid: chatcmpl-837310105e4645f986078132a6dab23d, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,178] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-837310105e4645f986078132a6dab23d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,178] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.3649 ms, throughput: 7.9036 GB/s; offload_time: 0.3093 ms, put_time: 0.0555 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,196] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a05054b718ca46d3b49995fd930d8386 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,196] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3678 ms, throughput: 9.2926 GB/s; offload_time: 0.3044 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,214] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1d8ddafe7b8a46eb83d233eae983baf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,214] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3802 ms, throughput: 8.9907 GB/s; offload_time: 0.3169 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,228] LMCache INFO:[0m Reqid: chatcmpl-0e88e056ac0e471382413c378f443d85, Total tokens 523, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,236] LMCache INFO:[0m Storing KV cache for 523 out of 523 tokens (skip_leading_tokens=0) for request chatcmpl-0e88e056ac0e471382413c378f443d85 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,236] LMCache INFO:[0m Stored 139 out of total 523 tokens. size: 0.0037 gb, cost 0.5798 ms, throughput: 6.4021 GB/s; offload_time: 0.4946 ms, put_time: 0.0852 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,245] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a7ce1c97bae04cd0b1d9f64c21a649df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,245] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3676 ms, throughput: 9.2980 GB/s; offload_time: 0.3097 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,252] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-90453b93c59b4893b7c8e462fd6a7fde [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,252] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3868 ms, throughput: 8.8364 GB/s; offload_time: 0.3238 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,255] LMCache INFO:[0m Reqid: chatcmpl-004aa44f1f8b42fd8ceb792352356896, Total tokens 320, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,267] LMCache INFO:[0m Storing KV cache for 320 out of 320 tokens (skip_leading_tokens=0) for request chatcmpl-004aa44f1f8b42fd8ceb792352356896 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,267] LMCache INFO:[0m Stored 320 out of total 320 tokens. size: 0.0085 gb, cost 0.7165 ms, throughput: 11.9267 GB/s; offload_time: 0.6121 ms, put_time: 0.1044 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,277] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-31bf0376e4c84defa1f3371252a38500 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,277] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 0.5026 ms, throughput: 6.8005 GB/s; offload_time: 0.4451 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,317] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-837310105e4645f986078132a6dab23d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,318] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3576 ms, throughput: 9.5579 GB/s; offload_time: 0.2922 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,398] LMCache INFO:[0m Reqid: chatcmpl-95dbd23d23bf4e4d99f387d875da3ec7, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,406] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-95dbd23d23bf4e4d99f387d875da3ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,406] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.3712 ms, throughput: 7.4095 GB/s; offload_time: 0.3144 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,430] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1e0d75c064834d36a027cea47af108d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,430] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3787 ms, throughput: 9.0259 GB/s; offload_time: 0.3237 ms, put_time: 0.0550 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,448] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-fc5e76b2918944f4b649b1ce2fbfdb97 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,448] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3616 ms, throughput: 9.4529 GB/s; offload_time: 0.3043 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,460] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-bb0a4cf3731248b3b20634c7a2bc076d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,461] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4419 ms, throughput: 7.7342 GB/s; offload_time: 0.3846 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,463] LMCache INFO:[0m Reqid: chatcmpl-a0e7a086ed8b4ae8a9201205a4cfe005, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,471] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-a0e7a086ed8b4ae8a9201205a4cfe005 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,471] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.3734 ms, throughput: 7.9384 GB/s; offload_time: 0.3103 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,483] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,484] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3774 ms, throughput: 9.0570 GB/s; offload_time: 0.3149 ms, put_time: 0.0625 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,534] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-84144ea88d864e1d8b32e0f01f32b416 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,534] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4179 ms, throughput: 8.1783 GB/s; offload_time: 0.3606 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,546] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-bd9e16bc506d4e5783c79bc1c94a7f02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,547] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.4755 ms, throughput: 7.1884 GB/s; offload_time: 0.4178 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,559] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-fef74d65784e410d833652e0d0726792 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,559] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3794 ms, throughput: 9.0083 GB/s; offload_time: 0.3137 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,559] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-95dbd23d23bf4e4d99f387d875da3ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,560] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5514 ms, throughput: 6.1987 GB/s; offload_time: 0.4974 ms, put_time: 0.0540 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,568] LMCache INFO:[0m Reqid: chatcmpl-1fc7d54d1071425286eb73d6a7ae94fe, Total tokens 576, LMCache hit tokens: 512, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,576] LMCache INFO:[0m Storing KV cache for 576 out of 576 tokens (skip_leading_tokens=0) for request chatcmpl-1fc7d54d1071425286eb73d6a7ae94fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,576] LMCache INFO:[0m Stored 64 out of total 576 tokens. size: 0.0017 gb, cost 0.4284 ms, throughput: 3.9891 GB/s; offload_time: 0.3624 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,577] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a0e7a086ed8b4ae8a9201205a4cfe005 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,577] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6295 ms, throughput: 5.4299 GB/s; offload_time: 0.5727 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,580] LMCache INFO:[0m Reqid: chatcmpl-e724325689c54a7ca869d53a9f07fa61, Total tokens 404, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,588] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-e724325689c54a7ca869d53a9f07fa61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,588] LMCache INFO:[0m Stored 20 out of total 404 tokens. size: 0.0005 gb, cost 0.5516 ms, throughput: 0.9682 GB/s; offload_time: 0.4874 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,591] LMCache INFO:[0m Reqid: chatcmpl-d9d86d5860ae4e41ae990da684868ac7, Total tokens 699, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,600] LMCache INFO:[0m Storing KV cache for 699 out of 699 tokens (skip_leading_tokens=0) for request chatcmpl-d9d86d5860ae4e41ae990da684868ac7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,600] LMCache INFO:[0m Stored 59 out of total 699 tokens. size: 0.0016 gb, cost 0.4223 ms, throughput: 3.7304 GB/s; offload_time: 0.3645 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,602] LMCache INFO:[0m Reqid: chatcmpl-74527a29ee01419fa3ecee7bf369f89f, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,611] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-74527a29ee01419fa3ecee7bf369f89f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,611] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3530 ms, throughput: 7.8664 GB/s; offload_time: 0.2946 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,618] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8e8e77250e464733930247deb8a4a799 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,618] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3922 ms, throughput: 8.7149 GB/s; offload_time: 0.3306 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,654] LMCache INFO:[0m Reqid: chatcmpl-94bd6ada6802419ea00084c2868c4d9e, Total tokens 126, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,663] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-94bd6ada6802419ea00084c2868c4d9e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,663] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 0.3669 ms, throughput: 9.1709 GB/s; offload_time: 0.3059 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,675] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-94bd6ada6802419ea00084c2868c4d9e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,676] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3445 ms, throughput: 9.9229 GB/s; offload_time: 0.2872 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,682] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-004aa44f1f8b42fd8ceb792352356896 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,683] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3760 ms, throughput: 9.0892 GB/s; offload_time: 0.3114 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,689] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,690] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.4786 ms, throughput: 7.1413 GB/s; offload_time: 0.4162 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,703] LMCache INFO:[0m Storing KV cache for 128 out of 3456 tokens (skip_leading_tokens=3328) for request chatcmpl-9c75e3ecdba948d08dfabab5072fcfb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,703] LMCache INFO:[0m Stored 128 out of total 3456 tokens. size: 0.0034 gb, cost 0.5591 ms, throughput: 6.1139 GB/s; offload_time: 0.4692 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,703] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2054f3db1bbf4adfb4acd57d5639980b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,704] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5746 ms, throughput: 5.9485 GB/s; offload_time: 0.5262 ms, put_time: 0.0484 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,722] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-d62f5a30971f459394b3fec33741562b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,723] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4200 ms, throughput: 8.1372 GB/s; offload_time: 0.3637 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,764] LMCache INFO:[0m Reqid: chatcmpl-cc4ec569811c49919600511ddde65072, Total tokens 684, LMCache hit tokens: 640, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,772] LMCache INFO:[0m Storing KV cache for 684 out of 684 tokens (skip_leading_tokens=0) for request chatcmpl-cc4ec569811c49919600511ddde65072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,773] LMCache INFO:[0m Stored 44 out of total 684 tokens. size: 0.0012 gb, cost 0.4379 ms, throughput: 2.6830 GB/s; offload_time: 0.3813 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,779] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6fc66e15fef44b69be9ab5250609abf2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,780] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3643 ms, throughput: 9.3829 GB/s; offload_time: 0.3062 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,782] LMCache INFO:[0m Reqid: chatcmpl-6fd24db452cf48c99b84a61aff9bec42, Total tokens 136, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,790] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-6fd24db452cf48c99b84a61aff9bec42 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,791] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 0.5353 ms, throughput: 6.7844 GB/s; offload_time: 0.4577 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,806] LMCache INFO:[0m Reqid: chatcmpl-a0638f812b984caa91ee050e73ebc0e3, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,815] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-a0638f812b984caa91ee050e73ebc0e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,815] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.3761 ms, throughput: 6.9576 GB/s; offload_time: 0.3129 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,882] LMCache INFO:[0m Reqid: chatcmpl-9b8c1b001c964a708113bc49c8d274f3, Total tokens 745, LMCache hit tokens: 512, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,892] LMCache INFO:[0m Storing KV cache for 745 out of 745 tokens (skip_leading_tokens=0) for request chatcmpl-9b8c1b001c964a708113bc49c8d274f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,893] LMCache INFO:[0m Stored 233 out of total 745 tokens. size: 0.0062 gb, cost 0.6113 ms, throughput: 10.1772 GB/s; offload_time: 0.5197 ms, put_time: 0.0916 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,893] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,895] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1310 ms, throughput: 3.0220 GB/s; offload_time: 1.0616 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,897] LMCache INFO:[0m Reqid: chatcmpl-085fb1feca8e4bfda0f40d84c6a91aa2, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,905] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-085fb1feca8e4bfda0f40d84c6a91aa2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,906] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.3703 ms, throughput: 7.5722 GB/s; offload_time: 0.3083 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,918] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-87a5dc7f923d4552831cf005f2a8ea8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,919] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4213 ms, throughput: 8.1138 GB/s; offload_time: 0.3622 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:35,975] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8baf2c246d3b47aa9c175b9d9d88888b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,976] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3770 ms, throughput: 9.0654 GB/s; offload_time: 0.3197 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:35,978] LMCache INFO:[0m Reqid: chatcmpl-c836a4699ea047098d94a8a311a1261b, Total tokens 746, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,987] LMCache INFO:[0m Storing KV cache for 746 out of 746 tokens (skip_leading_tokens=0) for request chatcmpl-c836a4699ea047098d94a8a311a1261b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:35,987] LMCache INFO:[0m Stored 106 out of total 746 tokens. size: 0.0028 gb, cost 0.4354 ms, throughput: 6.5004 GB/s; offload_time: 0.3771 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,017] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1fc7d54d1071425286eb73d6a7ae94fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,017] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3749 ms, throughput: 9.1169 GB/s; offload_time: 0.3163 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,024] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,024] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4021 ms, throughput: 8.5007 GB/s; offload_time: 0.3460 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,042] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9b8c1b001c964a708113bc49c8d274f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,043] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4021 ms, throughput: 8.4998 GB/s; offload_time: 0.3383 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,045] LMCache INFO:[0m Reqid: chatcmpl-1f0c95ae70644522872aa7e73d26feea, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,053] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-1f0c95ae70644522872aa7e73d26feea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,054] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 0.3665 ms, throughput: 8.2325 GB/s; offload_time: 0.3008 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,054] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a05054b718ca46d3b49995fd930d8386 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,055] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6437 ms, throughput: 5.3097 GB/s; offload_time: 0.5915 ms, put_time: 0.0522 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,055] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-085fb1feca8e4bfda0f40d84c6a91aa2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,056] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4882 ms, throughput: 7.0009 GB/s; offload_time: 0.4397 ms, put_time: 0.0485 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,068] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-d9d86d5860ae4e41ae990da684868ac7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,069] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3824 ms, throughput: 8.9377 GB/s; offload_time: 0.3251 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,082] LMCache INFO:[0m Reqid: chatcmpl-d1abf37f639a4271a1237ad5bbf2cdba, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,091] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-d1abf37f639a4271a1237ad5bbf2cdba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,091] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.3531 ms, throughput: 7.4872 GB/s; offload_time: 0.2954 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,103] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a7ce1c97bae04cd0b1d9f64c21a649df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,104] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3782 ms, throughput: 9.0384 GB/s; offload_time: 0.3215 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,122] LMCache INFO:[0m Storing KV cache for 128 out of 2944 tokens (skip_leading_tokens=2816) for request chatcmpl-31bf0376e4c84defa1f3371252a38500 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,122] LMCache INFO:[0m Stored 128 out of total 2944 tokens. size: 0.0034 gb, cost 0.5091 ms, throughput: 6.7136 GB/s; offload_time: 0.4435 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,135] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c836a4699ea047098d94a8a311a1261b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,135] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3796 ms, throughput: 9.0036 GB/s; offload_time: 0.3230 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,153] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1f0c95ae70644522872aa7e73d26feea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,153] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3485 ms, throughput: 9.8082 GB/s; offload_time: 0.2915 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,165] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-837310105e4645f986078132a6dab23d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,166] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3505 ms, throughput: 9.7503 GB/s; offload_time: 0.2936 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,202] LMCache INFO:[0m Reqid: chatcmpl-48b8726bc690466384837cba6c2c45ea, Total tokens 502, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,215] LMCache INFO:[0m Storing KV cache for 502 out of 502 tokens (skip_leading_tokens=0) for request chatcmpl-48b8726bc690466384837cba6c2c45ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,216] LMCache INFO:[0m Stored 502 out of total 502 tokens. size: 0.0134 gb, cost 0.9036 ms, throughput: 14.8344 GB/s; offload_time: 0.7739 ms, put_time: 0.1298 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,276] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d1abf37f639a4271a1237ad5bbf2cdba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,276] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3451 ms, throughput: 9.9046 GB/s; offload_time: 0.2844 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,277] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-48b8726bc690466384837cba6c2c45ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,277] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6987 ms, throughput: 4.8917 GB/s; offload_time: 0.5869 ms, put_time: 0.1119 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,311] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e724325689c54a7ca869d53a9f07fa61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,312] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3769 ms, throughput: 9.0696 GB/s; offload_time: 0.3199 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,315] LMCache INFO:[0m Reqid: chatcmpl-df9a6ef0df034252bee9294eaddfa314, Total tokens 810, LMCache hit tokens: 768, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,323] LMCache INFO:[0m Storing KV cache for 810 out of 810 tokens (skip_leading_tokens=0) for request chatcmpl-df9a6ef0df034252bee9294eaddfa314 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,323] LMCache INFO:[0m Stored 42 out of total 810 tokens. size: 0.0011 gb, cost 0.4499 ms, throughput: 2.4927 GB/s; offload_time: 0.3909 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,325] LMCache INFO:[0m Reqid: chatcmpl-ca6a8e6d1d4c42ac9212b7802604ed1a, Total tokens 262, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,334] LMCache INFO:[0m Storing KV cache for 262 out of 262 tokens (skip_leading_tokens=0) for request chatcmpl-ca6a8e6d1d4c42ac9212b7802604ed1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,335] LMCache INFO:[0m Stored 134 out of total 262 tokens. size: 0.0036 gb, cost 0.8089 ms, throughput: 4.4233 GB/s; offload_time: 0.7270 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,338] LMCache INFO:[0m Reqid: chatcmpl-221922ebf5414c02aa19abbb4182a49a, Total tokens 222, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,348] LMCache INFO:[0m Storing KV cache for 222 out of 222 tokens (skip_leading_tokens=0) for request chatcmpl-221922ebf5414c02aa19abbb4182a49a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,349] LMCache INFO:[0m Stored 222 out of total 222 tokens. size: 0.0059 gb, cost 0.5391 ms, throughput: 10.9971 GB/s; offload_time: 0.4580 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,349] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-cc4ec569811c49919600511ddde65072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,351] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3759 ms, throughput: 2.4841 GB/s; offload_time: 1.3210 ms, put_time: 0.0549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,359] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a50ffdb7ac8b422a89caee2ca01389eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,359] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3855 ms, throughput: 8.8659 GB/s; offload_time: 0.3288 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,401] LMCache INFO:[0m Reqid: chatcmpl-85a6e674b5844c4f8811adb9ab9c0341, Total tokens 1343, LMCache hit tokens: 1280, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,409] LMCache INFO:[0m Storing KV cache for 1343 out of 1343 tokens (skip_leading_tokens=0) for request chatcmpl-85a6e674b5844c4f8811adb9ab9c0341 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,409] LMCache INFO:[0m Stored 63 out of total 1343 tokens. size: 0.0017 gb, cost 0.4319 ms, throughput: 3.8952 GB/s; offload_time: 0.3751 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,429] LMCache INFO:[0m Reqid: chatcmpl-84f5d3b303514b6386288f58d175e0b7, Total tokens 272, LMCache hit tokens: 128, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,437] LMCache INFO:[0m Storing KV cache for 272 out of 272 tokens (skip_leading_tokens=0) for request chatcmpl-84f5d3b303514b6386288f58d175e0b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,437] LMCache INFO:[0m Stored 144 out of total 272 tokens. size: 0.0038 gb, cost 0.5619 ms, throughput: 6.8435 GB/s; offload_time: 0.4724 ms, put_time: 0.0895 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,441] LMCache INFO:[0m Reqid: chatcmpl-0035d672065a4c6987729a5bc88b50e5, Total tokens 187, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,449] LMCache INFO:[0m Storing KV cache for 187 out of 187 tokens (skip_leading_tokens=0) for request chatcmpl-0035d672065a4c6987729a5bc88b50e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,450] LMCache INFO:[0m Stored 59 out of total 187 tokens. size: 0.0016 gb, cost 0.3851 ms, throughput: 4.0914 GB/s; offload_time: 0.3279 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,450] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-95dbd23d23bf4e4d99f387d875da3ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,450] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5092 ms, throughput: 6.7126 GB/s; offload_time: 0.4592 ms, put_time: 0.0500 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,453] LMCache INFO:[0m Reqid: chatcmpl-74cd409024b040c0baa04cadcedbc612, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,463] LMCache INFO:[0m Storing KV cache for 270 out of 270 tokens (skip_leading_tokens=0) for request chatcmpl-74cd409024b040c0baa04cadcedbc612 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,464] LMCache INFO:[0m Stored 270 out of total 270 tokens. size: 0.0072 gb, cost 0.7889 ms, throughput: 9.1390 GB/s; offload_time: 0.6056 ms, put_time: 0.1833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,508] LMCache INFO:[0m Reqid: chatcmpl-28bf7ba223934532867000b25a88e25e, Total tokens 778, LMCache hit tokens: 640, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,516] LMCache INFO:[0m Storing KV cache for 778 out of 778 tokens (skip_leading_tokens=0) for request chatcmpl-28bf7ba223934532867000b25a88e25e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,517] LMCache INFO:[0m Stored 138 out of total 778 tokens. size: 0.0037 gb, cost 0.5919 ms, throughput: 6.2257 GB/s; offload_time: 0.5108 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,526] LMCache INFO:[0m Reqid: chatcmpl-81786e680be44c6f935e8bf27c35f694, Total tokens 714, LMCache hit tokens: 384, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,538] LMCache INFO:[0m Storing KV cache for 714 out of 714 tokens (skip_leading_tokens=0) for request chatcmpl-81786e680be44c6f935e8bf27c35f694 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,539] LMCache INFO:[0m Stored 330 out of total 714 tokens. size: 0.0088 gb, cost 0.7331 ms, throughput: 12.0198 GB/s; offload_time: 0.6183 ms, put_time: 0.1148 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,542] LMCache INFO:[0m Reqid: chatcmpl-e15d77e8851e428d8be4e76c06fe460c, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,550] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-e15d77e8851e428d8be4e76c06fe460c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,551] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.3437 ms, throughput: 7.6132 GB/s; offload_time: 0.2873 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,574] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-004aa44f1f8b42fd8ceb792352356896 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,575] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3763 ms, throughput: 9.0839 GB/s; offload_time: 0.3115 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,581] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,582] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 0.4852 ms, throughput: 7.0444 GB/s; offload_time: 0.4207 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,596] LMCache INFO:[0m Storing KV cache for 128 out of 3584 tokens (skip_leading_tokens=3456) for request chatcmpl-9c75e3ecdba948d08dfabab5072fcfb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,598] LMCache INFO:[0m Stored 128 out of total 3584 tokens. size: 0.0034 gb, cost 2.0774 ms, throughput: 1.6453 GB/s; offload_time: 2.0147 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,598] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2054f3db1bbf4adfb4acd57d5639980b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,599] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6121 ms, throughput: 5.5840 GB/s; offload_time: 0.5619 ms, put_time: 0.0502 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,606] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-221922ebf5414c02aa19abbb4182a49a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,606] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3545 ms, throughput: 9.6418 GB/s; offload_time: 0.2978 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,620] LMCache INFO:[0m Reqid: chatcmpl-5f74ad699b6b4be2ae9dc3c212ee4e6d, Total tokens 783, LMCache hit tokens: 640, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,628] LMCache INFO:[0m Storing KV cache for 783 out of 783 tokens (skip_leading_tokens=0) for request chatcmpl-5f74ad699b6b4be2ae9dc3c212ee4e6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,629] LMCache INFO:[0m Stored 143 out of total 783 tokens. size: 0.0038 gb, cost 0.6231 ms, throughput: 6.1285 GB/s; offload_time: 0.5282 ms, put_time: 0.0949 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,632] LMCache INFO:[0m Reqid: chatcmpl-63459a813cc94b9b8312760e04be8bad, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,640] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-63459a813cc94b9b8312760e04be8bad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,641] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.3690 ms, throughput: 7.0201 GB/s; offload_time: 0.3055 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,641] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6fd24db452cf48c99b84a61aff9bec42 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,642] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6089 ms, throughput: 5.6131 GB/s; offload_time: 0.5569 ms, put_time: 0.0520 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,728] LMCache INFO:[0m Reqid: chatcmpl-19f774f9d24c4f2a960acdb4cb2263f6, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,737] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-19f774f9d24c4f2a960acdb4cb2263f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,737] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.3458 ms, throughput: 7.9527 GB/s; offload_time: 0.2872 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,749] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e15d77e8851e428d8be4e76c06fe460c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,750] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3433 ms, throughput: 9.9551 GB/s; offload_time: 0.2873 ms, put_time: 0.0560 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,778] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-af67f335988241c4b65fff638e46faa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,779] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3826 ms, throughput: 8.9324 GB/s; offload_time: 0.3252 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,837] LMCache INFO:[0m Reqid: chatcmpl-aed297bbdcd14a25b6c7cfd54272b1ae, Total tokens 773, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,845] LMCache INFO:[0m Storing KV cache for 773 out of 773 tokens (skip_leading_tokens=0) for request chatcmpl-aed297bbdcd14a25b6c7cfd54272b1ae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,846] LMCache INFO:[0m Stored 133 out of total 773 tokens. size: 0.0036 gb, cost 0.5986 ms, throughput: 5.9326 GB/s; offload_time: 0.5154 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,850] LMCache INFO:[0m Reqid: chatcmpl-8569107805034cc783e450c170373217, Total tokens 616, LMCache hit tokens: 512, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,858] LMCache INFO:[0m Storing KV cache for 616 out of 616 tokens (skip_leading_tokens=0) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,858] LMCache INFO:[0m Stored 104 out of total 616 tokens. size: 0.0028 gb, cost 0.4097 ms, throughput: 6.7783 GB/s; offload_time: 0.3528 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,865] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-85a6e674b5844c4f8811adb9ab9c0341 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,865] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4266 ms, throughput: 8.0120 GB/s; offload_time: 0.3691 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,873] LMCache INFO:[0m Reqid: chatcmpl-c45cdcf6c1844b7ea81e76f613df7432, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,873] LMCache INFO:[0m Reqid: chatcmpl-26cb6957b2f2439abdd00f21e46c9349, Total tokens 127, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,885] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-c45cdcf6c1844b7ea81e76f613df7432 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,886] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 0.5194 ms, throughput: 6.7865 GB/s; offload_time: 0.4324 ms, put_time: 0.0870 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,886] LMCache INFO:[0m Storing KV cache for 127 out of 127 tokens (skip_leading_tokens=0) for request chatcmpl-26cb6957b2f2439abdd00f21e46c9349 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,887] LMCache INFO:[0m Stored 127 out of total 127 tokens. size: 0.0034 gb, cost 0.7512 ms, throughput: 4.5145 GB/s; offload_time: 0.6889 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,894] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-26cb6957b2f2439abdd00f21e46c9349 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,895] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3450 ms, throughput: 9.9074 GB/s; offload_time: 0.2875 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,907] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-81786e680be44c6f935e8bf27c35f694 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,907] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3896 ms, throughput: 8.7735 GB/s; offload_time: 0.3266 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,910] LMCache INFO:[0m Reqid: chatcmpl-9fccc9483250480bacf8158c07e69920, Total tokens 791, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:36,923] LMCache INFO:[0m Storing KV cache for 791 out of 791 tokens (skip_leading_tokens=0) for request chatcmpl-9fccc9483250480bacf8158c07e69920 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,924] LMCache INFO:[0m Stored 407 out of total 791 tokens. size: 0.0109 gb, cost 0.9737 ms, throughput: 11.1615 GB/s; offload_time: 0.7716 ms, put_time: 0.2021 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,924] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1fc7d54d1071425286eb73d6a7ae94fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,926] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.9804 ms, throughput: 1.7259 GB/s; offload_time: 1.9283 ms, put_time: 0.0521 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,930] LMCache INFO:[0m Reqid: chatcmpl-0cc7dac52924420b939032d97582b913, Total tokens 638, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,931] LMCache INFO:[0m Reqid: chatcmpl-7bff557d41604d40b11f93c54cb3aefd, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,932] LMCache INFO:[0m Reqid: chatcmpl-765e15b7b5af4144888f8b24c9f86c25, Total tokens 360, LMCache hit tokens: 256, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,932] LMCache INFO:[0m Reqid: chatcmpl-2fb6e272b7ba437bb7bcf87763bfe302, Total tokens 129, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,943] LMCache INFO:[0m Storing KV cache for 638 out of 638 tokens (skip_leading_tokens=0) for request chatcmpl-0cc7dac52924420b939032d97582b913 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,943] LMCache INFO:[0m Stored 126 out of total 638 tokens. size: 0.0034 gb, cost 0.4293 ms, throughput: 7.8374 GB/s; offload_time: 0.3681 ms, put_time: 0.0611 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,943] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-7bff557d41604d40b11f93c54cb3aefd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,944] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.6809 ms, throughput: 4.4705 GB/s; offload_time: 0.6268 ms, put_time: 0.0541 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,944] LMCache INFO:[0m Storing KV cache for 360 out of 360 tokens (skip_leading_tokens=0) for request chatcmpl-765e15b7b5af4144888f8b24c9f86c25 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,945] LMCache INFO:[0m Stored 104 out of total 360 tokens. size: 0.0028 gb, cost 0.6598 ms, throughput: 4.2090 GB/s; offload_time: 0.6156 ms, put_time: 0.0442 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,945] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-2fb6e272b7ba437bb7bcf87763bfe302 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,946] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 0.7974 ms, throughput: 4.3196 GB/s; offload_time: 0.7300 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,947] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4aab1584ba7c4ed19c5ff2b17babf7f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,948] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9476 ms, throughput: 3.6070 GB/s; offload_time: 0.9017 ms, put_time: 0.0459 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,961] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0035d672065a4c6987729a5bc88b50e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,962] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3658 ms, throughput: 9.3446 GB/s; offload_time: 0.3039 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,962] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0cc7dac52924420b939032d97582b913 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,963] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3492 ms, throughput: 9.7868 GB/s; offload_time: 0.2948 ms, put_time: 0.0545 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,969] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9b8c1b001c964a708113bc49c8d274f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,970] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.3926 ms, throughput: 8.7058 GB/s; offload_time: 0.3359 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:36,970] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-df9a6ef0df034252bee9294eaddfa314 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:36,971] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4984 ms, throughput: 6.8579 GB/s; offload_time: 0.4511 ms, put_time: 0.0473 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,036] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7bff557d41604d40b11f93c54cb3aefd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,037] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3451 ms, throughput: 9.9057 GB/s; offload_time: 0.2890 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,039] LMCache INFO:[0m Reqid: chatcmpl-0dd829b0ae00402183b128f190dbec71, Total tokens 911, LMCache hit tokens: 896, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,048] LMCache INFO:[0m Storing KV cache for 911 out of 911 tokens (skip_leading_tokens=0) for request chatcmpl-0dd829b0ae00402183b128f190dbec71 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,048] LMCache INFO:[0m Stored 15 out of total 911 tokens. size: 0.0004 gb, cost 0.4501 ms, throughput: 0.8899 GB/s; offload_time: 0.3934 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,055] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c836a4699ea047098d94a8a311a1261b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,056] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.3936 ms, throughput: 8.6842 GB/s; offload_time: 0.3352 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,056] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,057] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5401 ms, throughput: 6.3288 GB/s; offload_time: 0.4925 ms, put_time: 0.0476 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,065] LMCache INFO:[0m Reqid: chatcmpl-3c9cb87005404e838de2eef66f3ca2f8, Total tokens 232, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,073] LMCache INFO:[0m Storing KV cache for 232 out of 232 tokens (skip_leading_tokens=0) for request chatcmpl-3c9cb87005404e838de2eef66f3ca2f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,073] LMCache INFO:[0m Stored 104 out of total 232 tokens. size: 0.0028 gb, cost 0.3882 ms, throughput: 7.1547 GB/s; offload_time: 0.3246 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,075] LMCache INFO:[0m Reqid: chatcmpl-1f5aa598d95546a68d551cc34a98a6a8, Total tokens 118, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,085] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-1f5aa598d95546a68d551cc34a98a6a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,085] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.3699 ms, throughput: 8.5175 GB/s; offload_time: 0.3049 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,118] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-765e15b7b5af4144888f8b24c9f86c25 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,119] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4865 ms, throughput: 7.0250 GB/s; offload_time: 0.4252 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,145] LMCache INFO:[0m Reqid: chatcmpl-c751eff8a979453b96b7ab2fef209062, Total tokens 1043, LMCache hit tokens: 1024, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,153] LMCache INFO:[0m Storing KV cache for 1043 out of 1043 tokens (skip_leading_tokens=0) for request chatcmpl-c751eff8a979453b96b7ab2fef209062 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,154] LMCache INFO:[0m Stored 19 out of total 1043 tokens. size: 0.0005 gb, cost 0.4791 ms, throughput: 1.0589 GB/s; offload_time: 0.4205 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,154] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1f5aa598d95546a68d551cc34a98a6a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,155] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7996 ms, throughput: 4.2747 GB/s; offload_time: 0.7494 ms, put_time: 0.0502 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,174] LMCache INFO:[0m Reqid: chatcmpl-a6abb0e7a4f742909f75e42dccfbcd04, Total tokens 285, LMCache hit tokens: 256, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,175] LMCache INFO:[0m Reqid: chatcmpl-15691b3e89334934855acd0762b8ba53, Total tokens 2473, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,222] LMCache INFO:[0m Storing KV cache for 285 out of 285 tokens (skip_leading_tokens=0) for request chatcmpl-a6abb0e7a4f742909f75e42dccfbcd04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,222] LMCache INFO:[0m Stored 29 out of total 285 tokens. size: 0.0008 gb, cost 0.4169 ms, throughput: 1.8574 GB/s; offload_time: 0.3598 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,223] LMCache INFO:[0m Storing KV cache for 2473 out of 2473 tokens (skip_leading_tokens=0) for request chatcmpl-15691b3e89334934855acd0762b8ba53 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,228] LMCache INFO:[0m Stored 2473 out of total 2473 tokens. size: 0.0660 gb, cost 5.2244 ms, throughput: 12.6399 GB/s; offload_time: 4.1120 ms, put_time: 1.1124 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,234] LMCache INFO:[0m Reqid: chatcmpl-6948304a16564d2c838ebf1c9b8bfbce, Total tokens 895, LMCache hit tokens: 768, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,236] LMCache INFO:[0m Reqid: chatcmpl-763140ce97684fedb868c19fccc7ab8c, Total tokens 739, LMCache hit tokens: 640, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,249] LMCache INFO:[0m Storing KV cache for 895 out of 895 tokens (skip_leading_tokens=0) for request chatcmpl-6948304a16564d2c838ebf1c9b8bfbce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,249] LMCache INFO:[0m Stored 127 out of total 895 tokens. size: 0.0034 gb, cost 0.4555 ms, throughput: 7.4457 GB/s; offload_time: 0.3970 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,250] LMCache INFO:[0m Storing KV cache for 739 out of 739 tokens (skip_leading_tokens=0) for request chatcmpl-763140ce97684fedb868c19fccc7ab8c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,250] LMCache INFO:[0m Stored 99 out of total 739 tokens. size: 0.0026 gb, cost 0.5409 ms, throughput: 4.8870 GB/s; offload_time: 0.4895 ms, put_time: 0.0514 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,253] LMCache INFO:[0m Reqid: chatcmpl-0e3cf575dd6248deb5d028c0ecb61dcc, Total tokens 341, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,253] LMCache INFO:[0m Reqid: chatcmpl-55b8138ac66d4d2e9d1537fe1ee64703, Total tokens 1928, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,255] LMCache INFO:[0m Reqid: chatcmpl-a93f7897edc448eba1d64068fc1c2ced, Total tokens 1095, LMCache hit tokens: 768, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,256] LMCache INFO:[0m Reqid: chatcmpl-abe77b637bf64de281192f24fa8d2146, Total tokens 940, LMCache hit tokens: 896, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,257] LMCache INFO:[0m Reqid: chatcmpl-6e9ec976fac8453aa225526896c820c9, Total tokens 176, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,257] LMCache INFO:[0m Reqid: chatcmpl-013ce2fdfe6a468a9479a53220840612, Total tokens 371, LMCache hit tokens: 256, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,302] LMCache INFO:[0m Storing KV cache for 341 out of 341 tokens (skip_leading_tokens=0) for request chatcmpl-0e3cf575dd6248deb5d028c0ecb61dcc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,302] LMCache INFO:[0m Stored 85 out of total 341 tokens. size: 0.0023 gb, cost 0.4031 ms, throughput: 5.6306 GB/s; offload_time: 0.3458 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,302] LMCache INFO:[0m Storing KV cache for 1928 out of 1928 tokens (skip_leading_tokens=0) for request chatcmpl-55b8138ac66d4d2e9d1537fe1ee64703 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,306] LMCache INFO:[0m Stored 1928 out of total 1928 tokens. size: 0.0515 gb, cost 3.9914 ms, throughput: 12.8987 GB/s; offload_time: 2.8351 ms, put_time: 1.1562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,307] LMCache INFO:[0m Storing KV cache for 1095 out of 1095 tokens (skip_leading_tokens=0) for request chatcmpl-a93f7897edc448eba1d64068fc1c2ced [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,312] LMCache INFO:[0m Stored 327 out of total 1095 tokens. size: 0.0087 gb, cost 4.7663 ms, throughput: 1.8320 GB/s; offload_time: 4.4209 ms, put_time: 0.3454 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,312] LMCache INFO:[0m Storing KV cache for 940 out of 940 tokens (skip_leading_tokens=0) for request chatcmpl-abe77b637bf64de281192f24fa8d2146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,316] LMCache INFO:[0m Stored 44 out of total 940 tokens. size: 0.0012 gb, cost 3.0162 ms, throughput: 0.3895 GB/s; offload_time: 2.8569 ms, put_time: 0.1593 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,316] LMCache INFO:[0m Storing KV cache for 176 out of 176 tokens (skip_leading_tokens=0) for request chatcmpl-6e9ec976fac8453aa225526896c820c9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,319] LMCache INFO:[0m Stored 48 out of total 176 tokens. size: 0.0013 gb, cost 2.2462 ms, throughput: 0.5706 GB/s; offload_time: 2.1517 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,320] LMCache INFO:[0m Storing KV cache for 371 out of 371 tokens (skip_leading_tokens=0) for request chatcmpl-013ce2fdfe6a468a9479a53220840612 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,320] LMCache INFO:[0m Stored 115 out of total 371 tokens. size: 0.0031 gb, cost 0.3349 ms, throughput: 9.1688 GB/s; offload_time: 0.2855 ms, put_time: 0.0494 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,320] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6948304a16564d2c838ebf1c9b8bfbce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,321] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4313 ms, throughput: 7.9256 GB/s; offload_time: 0.3844 ms, put_time: 0.0468 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,331] LMCache INFO:[0m Reqid: chatcmpl-d9e689a8cc464e6eb3196ea7738d2cf1, Total tokens 2767, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,382] LMCache INFO:[0m Storing KV cache for 2767 out of 2767 tokens (skip_leading_tokens=0) for request chatcmpl-d9e689a8cc464e6eb3196ea7738d2cf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,386] LMCache INFO:[0m Stored 2767 out of total 2767 tokens. size: 0.0739 gb, cost 3.8988 ms, throughput: 18.9510 GB/s; offload_time: 3.1737 ms, put_time: 0.7252 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,405] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-48b8726bc690466384837cba6c2c45ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,405] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4061 ms, throughput: 8.4164 GB/s; offload_time: 0.3468 ms, put_time: 0.0593 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,418] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ca6a8e6d1d4c42ac9212b7802604ed1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,419] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3782 ms, throughput: 9.0370 GB/s; offload_time: 0.3197 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,432] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3c9cb87005404e838de2eef66f3ca2f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,433] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3690 ms, throughput: 9.2629 GB/s; offload_time: 0.3094 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,446] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e724325689c54a7ca869d53a9f07fa61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,446] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3991 ms, throughput: 8.5649 GB/s; offload_time: 0.3341 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,466] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-cc4ec569811c49919600511ddde65072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,466] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4157 ms, throughput: 8.2225 GB/s; offload_time: 0.3600 ms, put_time: 0.0557 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,473] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-013ce2fdfe6a468a9479a53220840612 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,474] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3705 ms, throughput: 9.2252 GB/s; offload_time: 0.3131 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,501] LMCache INFO:[0m Reqid: chatcmpl-fb4768215aaf4978acf678350ba7bde3, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,510] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-fb4768215aaf4978acf678350ba7bde3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,511] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.3400 ms, throughput: 8.0905 GB/s; offload_time: 0.2819 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,555] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-28bf7ba223934532867000b25a88e25e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,556] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4156 ms, throughput: 8.2245 GB/s; offload_time: 0.3578 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,563] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-95dbd23d23bf4e4d99f387d875da3ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,564] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3782 ms, throughput: 9.0365 GB/s; offload_time: 0.3202 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,577] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-763140ce97684fedb868c19fccc7ab8c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,577] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4246 ms, throughput: 8.0491 GB/s; offload_time: 0.3592 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,580] LMCache INFO:[0m Reqid: chatcmpl-a9c2ccb580e448b28e55d84e11d9d6b0, Total tokens 642, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,589] LMCache INFO:[0m Storing KV cache for 642 out of 642 tokens (skip_leading_tokens=0) for request chatcmpl-a9c2ccb580e448b28e55d84e11d9d6b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,590] LMCache INFO:[0m Stored 130 out of total 642 tokens. size: 0.0035 gb, cost 0.5633 ms, throughput: 6.1631 GB/s; offload_time: 0.4785 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,614] LMCache INFO:[0m Reqid: chatcmpl-db402837bc77493996ac2efc17ca516e, Total tokens 123, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,623] LMCache INFO:[0m Storing KV cache for 123 out of 123 tokens (skip_leading_tokens=0) for request chatcmpl-db402837bc77493996ac2efc17ca516e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,624] LMCache INFO:[0m Stored 123 out of total 123 tokens. size: 0.0033 gb, cost 0.3460 ms, throughput: 9.4934 GB/s; offload_time: 0.2876 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,630] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5f74ad699b6b4be2ae9dc3c212ee4e6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,631] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4094 ms, throughput: 8.3486 GB/s; offload_time: 0.3465 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,656] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-db402837bc77493996ac2efc17ca516e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,656] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3591 ms, throughput: 9.5186 GB/s; offload_time: 0.3013 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,687] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,688] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 0.5211 ms, throughput: 6.5595 GB/s; offload_time: 0.4637 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,688] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0e3cf575dd6248deb5d028c0ecb61dcc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,689] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5233 ms, throughput: 6.5314 GB/s; offload_time: 0.4729 ms, put_time: 0.0504 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,689] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-fb4768215aaf4978acf678350ba7bde3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,690] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8130 ms, throughput: 4.2042 GB/s; offload_time: 0.4983 ms, put_time: 0.3147 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,704] LMCache INFO:[0m Reqid: chatcmpl-60191fce4fe245788131490f635c87df, Total tokens 414, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,712] LMCache INFO:[0m Storing KV cache for 414 out of 414 tokens (skip_leading_tokens=0) for request chatcmpl-60191fce4fe245788131490f635c87df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,713] LMCache INFO:[0m Stored 30 out of total 414 tokens. size: 0.0008 gb, cost 0.3832 ms, throughput: 2.0903 GB/s; offload_time: 0.3255 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,713] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-221922ebf5414c02aa19abbb4182a49a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,714] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5256 ms, throughput: 6.5032 GB/s; offload_time: 0.4698 ms, put_time: 0.0558 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,716] LMCache INFO:[0m Reqid: chatcmpl-78e9aa3f288c44a18895283e3e145204, Total tokens 241, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,725] LMCache INFO:[0m Storing KV cache for 241 out of 241 tokens (skip_leading_tokens=0) for request chatcmpl-78e9aa3f288c44a18895283e3e145204 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,725] LMCache INFO:[0m Stored 113 out of total 241 tokens. size: 0.0030 gb, cost 0.3703 ms, throughput: 8.1479 GB/s; offload_time: 0.3041 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,746] LMCache INFO:[0m Reqid: chatcmpl-660dd983facc472a9a61750a7053c30f, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,754] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-660dd983facc472a9a61750a7053c30f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,754] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3544 ms, throughput: 7.5352 GB/s; offload_time: 0.2840 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,755] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-d9e689a8cc464e6eb3196ea7738d2cf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,756] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 0.7745 ms, throughput: 4.4132 GB/s; offload_time: 0.7200 ms, put_time: 0.0545 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,758] LMCache INFO:[0m Reqid: chatcmpl-66cedc6215df4a94b17804b73de67126, Total tokens 235, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,767] LMCache INFO:[0m Storing KV cache for 235 out of 235 tokens (skip_leading_tokens=0) for request chatcmpl-66cedc6215df4a94b17804b73de67126 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,767] LMCache INFO:[0m Stored 107 out of total 235 tokens. size: 0.0029 gb, cost 0.3616 ms, throughput: 7.9008 GB/s; offload_time: 0.3035 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,787] LMCache INFO:[0m Reqid: chatcmpl-e1fd336f93b54a5b9d05f436c51647bf, Total tokens 191, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,795] LMCache INFO:[0m Storing KV cache for 191 out of 191 tokens (skip_leading_tokens=0) for request chatcmpl-e1fd336f93b54a5b9d05f436c51647bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,796] LMCache INFO:[0m Stored 63 out of total 191 tokens. size: 0.0017 gb, cost 0.3730 ms, throughput: 4.5105 GB/s; offload_time: 0.3093 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,816] LMCache INFO:[0m Reqid: chatcmpl-3b400afc71e245d6877d764fd9597b41, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,825] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-3b400afc71e245d6877d764fd9597b41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,826] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.3457 ms, throughput: 9.2692 GB/s; offload_time: 0.2889 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,839] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-78e9aa3f288c44a18895283e3e145204 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,839] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3618 ms, throughput: 9.4479 GB/s; offload_time: 0.3030 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,876] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3b400afc71e245d6877d764fd9597b41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,877] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3510 ms, throughput: 9.7372 GB/s; offload_time: 0.2943 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,884] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9fccc9483250480bacf8158c07e69920 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,884] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4038 ms, throughput: 8.4644 GB/s; offload_time: 0.3475 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,907] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-66cedc6215df4a94b17804b73de67126 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,908] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3651 ms, throughput: 9.3624 GB/s; offload_time: 0.3030 ms, put_time: 0.0621 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,939] LMCache INFO:[0m Reqid: chatcmpl-0d718211381f40c188c775c371eb8561, Total tokens 1386, LMCache hit tokens: 1024, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,951] LMCache INFO:[0m Storing KV cache for 1386 out of 1386 tokens (skip_leading_tokens=0) for request chatcmpl-0d718211381f40c188c775c371eb8561 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:37,952] LMCache INFO:[0m Stored 362 out of total 1386 tokens. size: 0.0097 gb, cost 0.7779 ms, throughput: 12.4271 GB/s; offload_time: 0.6799 ms, put_time: 0.0979 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,952] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-aed297bbdcd14a25b6c7cfd54272b1ae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,954] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.7305 ms, throughput: 1.9751 GB/s; offload_time: 1.6788 ms, put_time: 0.0517 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,956] LMCache INFO:[0m Reqid: chatcmpl-f237ee044a4948d881ecaef0dcdf9c74, Total tokens 404, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,970] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-f237ee044a4948d881ecaef0dcdf9c74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,971] LMCache INFO:[0m Stored 404 out of total 404 tokens. size: 0.0108 gb, cost 0.9602 ms, throughput: 11.2351 GB/s; offload_time: 0.7211 ms, put_time: 0.2391 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:37,997] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-abe77b637bf64de281192f24fa8d2146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:37,997] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4138 ms, throughput: 8.2591 GB/s; offload_time: 0.3575 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,010] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-85a6e674b5844c4f8811adb9ab9c0341 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,010] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4444 ms, throughput: 7.6914 GB/s; offload_time: 0.3857 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,024] LMCache INFO:[0m Reqid: chatcmpl-fa7cf8a9ca4447258e595f593d01f11b, Total tokens 502, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,035] LMCache INFO:[0m Storing KV cache for 502 out of 502 tokens (skip_leading_tokens=0) for request chatcmpl-fa7cf8a9ca4447258e595f593d01f11b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,036] LMCache INFO:[0m Stored 118 out of total 502 tokens. size: 0.0032 gb, cost 0.3855 ms, throughput: 8.1741 GB/s; offload_time: 0.3271 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,038] LMCache INFO:[0m Reqid: chatcmpl-3c478782684249cf8dae4cc7a4603bf9, Total tokens 251, LMCache hit tokens: 128, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,046] LMCache INFO:[0m Storing KV cache for 251 out of 251 tokens (skip_leading_tokens=0) for request chatcmpl-3c478782684249cf8dae4cc7a4603bf9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,046] LMCache INFO:[0m Stored 123 out of total 251 tokens. size: 0.0033 gb, cost 0.3561 ms, throughput: 9.2224 GB/s; offload_time: 0.2990 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,054] LMCache INFO:[0m Reqid: chatcmpl-b86ea8f37d4348249ef50a01057f1f7a, Total tokens 144, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,062] LMCache INFO:[0m Storing KV cache for 144 out of 144 tokens (skip_leading_tokens=0) for request chatcmpl-b86ea8f37d4348249ef50a01057f1f7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,062] LMCache INFO:[0m Stored 144 out of total 144 tokens. size: 0.0038 gb, cost 0.5037 ms, throughput: 7.6345 GB/s; offload_time: 0.4214 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,063] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1fc7d54d1071425286eb73d6a7ae94fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,064] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7645 ms, throughput: 4.4709 GB/s; offload_time: 0.7150 ms, put_time: 0.0495 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,064] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2fb6e272b7ba437bb7bcf87763bfe302 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,065] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7939 ms, throughput: 4.3052 GB/s; offload_time: 0.7472 ms, put_time: 0.0467 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,067] LMCache INFO:[0m Reqid: chatcmpl-de6abfecca274985b5ef9952f60cde7a, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,076] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-de6abfecca274985b5ef9952f60cde7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,076] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3459 ms, throughput: 8.0292 GB/s; offload_time: 0.2886 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,089] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0cc7dac52924420b939032d97582b913 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,090] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4074 ms, throughput: 8.3896 GB/s; offload_time: 0.3478 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,090] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3c478782684249cf8dae4cc7a4603bf9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,090] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5182 ms, throughput: 6.5953 GB/s; offload_time: 0.4614 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,114] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fa7cf8a9ca4447258e595f593d01f11b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,115] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3857 ms, throughput: 8.8618 GB/s; offload_time: 0.3276 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,118] LMCache INFO:[0m Reqid: chatcmpl-7de3663bc9a648bcbf8e8e51166151db, Total tokens 1406, LMCache hit tokens: 1280, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,126] LMCache INFO:[0m Storing KV cache for 1406 out of 1406 tokens (skip_leading_tokens=0) for request chatcmpl-7de3663bc9a648bcbf8e8e51166151db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,126] LMCache INFO:[0m Stored 126 out of total 1406 tokens. size: 0.0034 gb, cost 0.4776 ms, throughput: 7.0441 GB/s; offload_time: 0.4132 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,129] LMCache INFO:[0m Reqid: chatcmpl-5b800206f76b4905b78046bcf68305ba, Total tokens 309, LMCache hit tokens: 256, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,137] LMCache INFO:[0m Storing KV cache for 309 out of 309 tokens (skip_leading_tokens=0) for request chatcmpl-5b800206f76b4905b78046bcf68305ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,138] LMCache INFO:[0m Stored 53 out of total 309 tokens. size: 0.0014 gb, cost 0.3740 ms, throughput: 3.7842 GB/s; offload_time: 0.3160 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,145] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-7de3663bc9a648bcbf8e8e51166151db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,145] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4571 ms, throughput: 7.4771 GB/s; offload_time: 0.3984 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,148] LMCache INFO:[0m Reqid: chatcmpl-6e873e404cd243a58b8348674d863012, Total tokens 509, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,161] LMCache INFO:[0m Storing KV cache for 509 out of 509 tokens (skip_leading_tokens=0) for request chatcmpl-6e873e404cd243a58b8348674d863012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,163] LMCache INFO:[0m Stored 509 out of total 509 tokens. size: 0.0136 gb, cost 1.0014 ms, throughput: 13.5727 GB/s; offload_time: 0.7453 ms, put_time: 0.2561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,163] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c751eff8a979453b96b7ab2fef209062 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,165] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1083 ms, throughput: 3.0841 GB/s; offload_time: 1.0605 ms, put_time: 0.0478 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,184] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6e873e404cd243a58b8348674d863012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,185] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3878 ms, throughput: 8.8139 GB/s; offload_time: 0.3243 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,203] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c836a4699ea047098d94a8a311a1261b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,204] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4110 ms, throughput: 8.3158 GB/s; offload_time: 0.3538 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,204] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,205] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6965 ms, throughput: 4.9072 GB/s; offload_time: 0.6459 ms, put_time: 0.0506 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,220] LMCache INFO:[0m Reqid: chatcmpl-2cd4990bffa940a49d3a8bf94ee10473, Total tokens 1052, LMCache hit tokens: 896, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,229] LMCache INFO:[0m Storing KV cache for 1052 out of 1052 tokens (skip_leading_tokens=0) for request chatcmpl-2cd4990bffa940a49d3a8bf94ee10473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,229] LMCache INFO:[0m Stored 156 out of total 1052 tokens. size: 0.0042 gb, cost 0.6072 ms, throughput: 6.8605 GB/s; offload_time: 0.5196 ms, put_time: 0.0876 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,244] LMCache INFO:[0m Reqid: chatcmpl-3fff699dfd1a433e92460de3e8ff29cb, Total tokens 225, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,254] LMCache INFO:[0m Storing KV cache for 225 out of 225 tokens (skip_leading_tokens=0) for request chatcmpl-3fff699dfd1a433e92460de3e8ff29cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,255] LMCache INFO:[0m Stored 225 out of total 225 tokens. size: 0.0060 gb, cost 0.5232 ms, throughput: 11.4837 GB/s; offload_time: 0.4384 ms, put_time: 0.0847 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,268] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-765e15b7b5af4144888f8b24c9f86c25 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,269] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3835 ms, throughput: 8.9126 GB/s; offload_time: 0.3265 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,337] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6948304a16564d2c838ebf1c9b8bfbce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,337] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4229 ms, throughput: 8.0828 GB/s; offload_time: 0.3663 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,346] LMCache INFO:[0m Reqid: chatcmpl-d00923f9d71d4d1bbbb4b898c111f9c4, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,354] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-d00923f9d71d4d1bbbb4b898c111f9c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,354] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.3747 ms, throughput: 6.6992 GB/s; offload_time: 0.3056 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,361] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-48b8726bc690466384837cba6c2c45ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,362] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4048 ms, throughput: 8.4437 GB/s; offload_time: 0.3482 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,386] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3c9cb87005404e838de2eef66f3ca2f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,386] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3660 ms, throughput: 9.3393 GB/s; offload_time: 0.3099 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,398] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e724325689c54a7ca869d53a9f07fa61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,399] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3902 ms, throughput: 8.7595 GB/s; offload_time: 0.3334 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,450] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3fff699dfd1a433e92460de3e8ff29cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,450] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3636 ms, throughput: 9.3995 GB/s; offload_time: 0.2989 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,475] LMCache INFO:[0m Reqid: chatcmpl-13e5889d03624ed99faa57839f932f9f, Total tokens 259, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,483] LMCache INFO:[0m Storing KV cache for 259 out of 259 tokens (skip_leading_tokens=0) for request chatcmpl-13e5889d03624ed99faa57839f932f9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,484] LMCache INFO:[0m Stored 131 out of total 259 tokens. size: 0.0035 gb, cost 0.5801 ms, throughput: 6.0305 GB/s; offload_time: 0.4915 ms, put_time: 0.0886 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,498] LMCache INFO:[0m Reqid: chatcmpl-2622f617b2bd4930b3d4f241f895b494, Total tokens 216, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,506] LMCache INFO:[0m Storing KV cache for 216 out of 216 tokens (skip_leading_tokens=0) for request chatcmpl-2622f617b2bd4930b3d4f241f895b494 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,507] LMCache INFO:[0m Stored 88 out of total 216 tokens. size: 0.0023 gb, cost 0.3707 ms, throughput: 6.3397 GB/s; offload_time: 0.3116 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,513] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a9c2ccb580e448b28e55d84e11d9d6b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,513] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4061 ms, throughput: 8.4166 GB/s; offload_time: 0.3490 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,520] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-763140ce97684fedb868c19fccc7ab8c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,520] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4141 ms, throughput: 8.2532 GB/s; offload_time: 0.3560 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,529] LMCache INFO:[0m Reqid: chatcmpl-8a897502d7a44da28e1e6f0d0ec09939, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,536] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-8a897502d7a44da28e1e6f0d0ec09939 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,537] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3758 ms, throughput: 7.3900 GB/s; offload_time: 0.3156 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,560] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5f74ad699b6b4be2ae9dc3c212ee4e6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,561] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4191 ms, throughput: 8.1550 GB/s; offload_time: 0.3597 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,569] LMCache INFO:[0m Reqid: chatcmpl-22c20539f59945cdb8de970cd7b19c58, Total tokens 1024, LMCache hit tokens: 896, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,577] LMCache INFO:[0m Storing KV cache for 1024 out of 1024 tokens (skip_leading_tokens=0) for request chatcmpl-22c20539f59945cdb8de970cd7b19c58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,577] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4993 ms, throughput: 6.8460 GB/s; offload_time: 0.4376 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,578] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d00923f9d71d4d1bbbb4b898c111f9c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,578] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4907 ms, throughput: 6.9652 GB/s; offload_time: 0.4406 ms, put_time: 0.0501 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,588] LMCache INFO:[0m Reqid: chatcmpl-5deb8a9dff9d4fc796f412c7cf966e2b, Total tokens 1633, LMCache hit tokens: 1536, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,596] LMCache INFO:[0m Storing KV cache for 1633 out of 1633 tokens (skip_leading_tokens=0) for request chatcmpl-5deb8a9dff9d4fc796f412c7cf966e2b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,597] LMCache INFO:[0m Stored 97 out of total 1633 tokens. size: 0.0026 gb, cost 0.5334 ms, throughput: 4.8562 GB/s; offload_time: 0.4774 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,597] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-db402837bc77493996ac2efc17ca516e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,598] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7904 ms, throughput: 4.3243 GB/s; offload_time: 0.7402 ms, put_time: 0.0502 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,612] LMCache INFO:[0m Reqid: chatcmpl-582e82f39a0d48e3a9e63c20059628b7, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,621] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-582e82f39a0d48e3a9e63c20059628b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,622] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 0.5438 ms, throughput: 6.4822 GB/s; offload_time: 0.4574 ms, put_time: 0.0863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,636] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-95cd3443a930462eac505d4a8929b85e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,636] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 0.5308 ms, throughput: 6.4397 GB/s; offload_time: 0.4687 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,637] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0e3cf575dd6248deb5d028c0ecb61dcc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,637] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5065 ms, throughput: 6.7483 GB/s; offload_time: 0.4421 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,652] LMCache INFO:[0m Reqid: chatcmpl-b469720de04840399d15a6d42e5fc25f, Total tokens 353, LMCache hit tokens: 256, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,660] LMCache INFO:[0m Storing KV cache for 353 out of 353 tokens (skip_leading_tokens=0) for request chatcmpl-b469720de04840399d15a6d42e5fc25f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,660] LMCache INFO:[0m Stored 97 out of total 353 tokens. size: 0.0026 gb, cost 0.4097 ms, throughput: 6.3221 GB/s; offload_time: 0.3483 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,691] LMCache INFO:[0m Storing KV cache for 128 out of 2944 tokens (skip_leading_tokens=2816) for request chatcmpl-d9e689a8cc464e6eb3196ea7738d2cf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,691] LMCache INFO:[0m Stored 128 out of total 2944 tokens. size: 0.0034 gb, cost 0.5562 ms, throughput: 6.1450 GB/s; offload_time: 0.4984 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,709] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-8a897502d7a44da28e1e6f0d0ec09939 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,710] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3478 ms, throughput: 9.8272 GB/s; offload_time: 0.2898 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,744] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f237ee044a4948d881ecaef0dcdf9c74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,744] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3804 ms, throughput: 8.9852 GB/s; offload_time: 0.3200 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,756] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-78e9aa3f288c44a18895283e3e145204 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,757] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3644 ms, throughput: 9.3790 GB/s; offload_time: 0.3074 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,776] LMCache INFO:[0m Reqid: chatcmpl-0514827671e64d0f9df1bc3f7638498b, Total tokens 433, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,784] LMCache INFO:[0m Storing KV cache for 433 out of 433 tokens (skip_leading_tokens=0) for request chatcmpl-0514827671e64d0f9df1bc3f7638498b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,785] LMCache INFO:[0m Stored 49 out of total 433 tokens. size: 0.0013 gb, cost 0.4144 ms, throughput: 3.1574 GB/s; offload_time: 0.3571 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,785] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2622f617b2bd4930b3d4f241f895b494 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,786] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5626 ms, throughput: 6.0755 GB/s; offload_time: 0.4575 ms, put_time: 0.1051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,789] LMCache INFO:[0m Reqid: chatcmpl-52762327bf9d4358851bb8dbd011ada6, Total tokens 303, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,797] LMCache INFO:[0m Storing KV cache for 303 out of 303 tokens (skip_leading_tokens=0) for request chatcmpl-52762327bf9d4358851bb8dbd011ada6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,798] LMCache INFO:[0m Stored 47 out of total 303 tokens. size: 0.0013 gb, cost 0.4162 ms, throughput: 3.0156 GB/s; offload_time: 0.3562 ms, put_time: 0.0600 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,805] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3b400afc71e245d6877d764fd9597b41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,805] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3640 ms, throughput: 9.3892 GB/s; offload_time: 0.3012 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,813] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-9fccc9483250480bacf8158c07e69920 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,813] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4070 ms, throughput: 8.3986 GB/s; offload_time: 0.3508 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,813] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5deb8a9dff9d4fc796f412c7cf966e2b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,814] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6891 ms, throughput: 4.9600 GB/s; offload_time: 0.6353 ms, put_time: 0.0538 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,823] LMCache INFO:[0m Reqid: chatcmpl-347815118b36459699fde54fe80bb240, Total tokens 2114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,860] LMCache INFO:[0m Storing KV cache for 2114 out of 2114 tokens (skip_leading_tokens=0) for request chatcmpl-347815118b36459699fde54fe80bb240 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,864] LMCache INFO:[0m Stored 2114 out of total 2114 tokens. size: 0.0564 gb, cost 3.9949 ms, throughput: 14.1306 GB/s; offload_time: 2.7313 ms, put_time: 1.2635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,870] LMCache INFO:[0m Reqid: chatcmpl-84e797b89d0748eeba4c47d73e1d9d2a, Total tokens 656, LMCache hit tokens: 512, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,871] LMCache INFO:[0m Reqid: chatcmpl-b8db4c52b26c40e5acd320a2df5659b0, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,884] LMCache INFO:[0m Storing KV cache for 656 out of 656 tokens (skip_leading_tokens=0) for request chatcmpl-84e797b89d0748eeba4c47d73e1d9d2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,885] LMCache INFO:[0m Stored 144 out of total 656 tokens. size: 0.0038 gb, cost 0.8539 ms, throughput: 4.5032 GB/s; offload_time: 0.7682 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,885] LMCache INFO:[0m Storing KV cache for 115 out of 115 tokens (skip_leading_tokens=0) for request chatcmpl-b8db4c52b26c40e5acd320a2df5659b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,886] LMCache INFO:[0m Stored 115 out of total 115 tokens. size: 0.0031 gb, cost 0.5712 ms, throughput: 5.3759 GB/s; offload_time: 0.4059 ms, put_time: 0.1653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,918] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b469720de04840399d15a6d42e5fc25f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,919] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3672 ms, throughput: 9.3079 GB/s; offload_time: 0.3087 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,932] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-aed297bbdcd14a25b6c7cfd54272b1ae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,932] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4052 ms, throughput: 8.4359 GB/s; offload_time: 0.3472 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:38,963] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2cd4990bffa940a49d3a8bf94ee10473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:38,964] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4113 ms, throughput: 8.3108 GB/s; offload_time: 0.3551 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:38,996] LMCache INFO:[0m Reqid: chatcmpl-50daf61d41e341bb8c5f1cae1c81c666, Total tokens 1193, LMCache hit tokens: 1024, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,004] LMCache INFO:[0m Storing KV cache for 1193 out of 1193 tokens (skip_leading_tokens=0) for request chatcmpl-50daf61d41e341bb8c5f1cae1c81c666 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,005] LMCache INFO:[0m Stored 169 out of total 1193 tokens. size: 0.0045 gb, cost 0.6324 ms, throughput: 7.1360 GB/s; offload_time: 0.5510 ms, put_time: 0.0814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,007] LMCache INFO:[0m Reqid: chatcmpl-3c4677aa9e134c429cb7750289b9042e, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,017] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-3c4677aa9e134c429cb7750289b9042e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,017] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 0.3676 ms, throughput: 8.2077 GB/s; offload_time: 0.3045 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,041] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0cc7dac52924420b939032d97582b913 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,042] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4033 ms, throughput: 8.4759 GB/s; offload_time: 0.3453 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,042] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3c478782684249cf8dae4cc7a4603bf9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,043] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5943 ms, throughput: 5.7511 GB/s; offload_time: 0.5340 ms, put_time: 0.0603 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,090] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c751eff8a979453b96b7ab2fef209062 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,090] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4391 ms, throughput: 7.7839 GB/s; offload_time: 0.3821 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,099] LMCache INFO:[0m Reqid: chatcmpl-f762ee4991614b61b67a494f243da0ad, Total tokens 1040, LMCache hit tokens: 896, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,107] LMCache INFO:[0m Storing KV cache for 1040 out of 1040 tokens (skip_leading_tokens=0) for request chatcmpl-f762ee4991614b61b67a494f243da0ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,108] LMCache INFO:[0m Stored 144 out of total 1040 tokens. size: 0.0038 gb, cost 0.6630 ms, throughput: 5.7999 GB/s; offload_time: 0.5775 ms, put_time: 0.0855 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,115] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-6e873e404cd243a58b8348674d863012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,115] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3946 ms, throughput: 8.6624 GB/s; offload_time: 0.3323 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,118] LMCache INFO:[0m Reqid: chatcmpl-a1ec95ed1c974cca94e2d2deaa182ac1, Total tokens 892, LMCache hit tokens: 768, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,126] LMCache INFO:[0m Storing KV cache for 892 out of 892 tokens (skip_leading_tokens=0) for request chatcmpl-a1ec95ed1c974cca94e2d2deaa182ac1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,127] LMCache INFO:[0m Stored 124 out of total 892 tokens. size: 0.0033 gb, cost 0.4342 ms, throughput: 7.6265 GB/s; offload_time: 0.3718 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,140] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,140] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4005 ms, throughput: 8.5336 GB/s; offload_time: 0.3436 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,153] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a1ec95ed1c974cca94e2d2deaa182ac1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,153] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4142 ms, throughput: 8.2516 GB/s; offload_time: 0.3504 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,155] LMCache INFO:[0m Reqid: chatcmpl-d581e8c35f1342038c3a8be71f15861f, Total tokens 150, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,156] LMCache INFO:[0m Reqid: chatcmpl-0ec00c7df3004847b97667351a580c70, Total tokens 1707, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,187] LMCache INFO:[0m Storing KV cache for 150 out of 150 tokens (skip_leading_tokens=0) for request chatcmpl-d581e8c35f1342038c3a8be71f15861f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,188] LMCache INFO:[0m Stored 150 out of total 150 tokens. size: 0.0040 gb, cost 0.5267 ms, throughput: 7.6052 GB/s; offload_time: 0.4433 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,188] LMCache INFO:[0m Storing KV cache for 1707 out of 1707 tokens (skip_leading_tokens=0) for request chatcmpl-0ec00c7df3004847b97667351a580c70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,195] LMCache INFO:[0m Stored 1707 out of total 1707 tokens. size: 0.0456 gb, cost 5.1057 ms, throughput: 8.9277 GB/s; offload_time: 3.7972 ms, put_time: 1.3085 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,201] LMCache INFO:[0m Reqid: chatcmpl-0532861743ce4813953962a364a0d588, Total tokens 978, LMCache hit tokens: 896, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,203] LMCache INFO:[0m Reqid: chatcmpl-eca38d59e15b47fbb276bc68eed2bd08, Total tokens 661, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,205] LMCache INFO:[0m Reqid: chatcmpl-1b538356c54f4dbf9427b18d331bdd44, Total tokens 818, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,205] LMCache INFO:[0m Reqid: chatcmpl-c4a7e38486f34c4f8115b80646628583, Total tokens 1175, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,242] LMCache INFO:[0m Storing KV cache for 978 out of 978 tokens (skip_leading_tokens=0) for request chatcmpl-0532861743ce4813953962a364a0d588 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,243] LMCache INFO:[0m Stored 82 out of total 978 tokens. size: 0.0022 gb, cost 0.4776 ms, throughput: 4.5851 GB/s; offload_time: 0.4177 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,243] LMCache INFO:[0m Storing KV cache for 661 out of 661 tokens (skip_leading_tokens=0) for request chatcmpl-eca38d59e15b47fbb276bc68eed2bd08 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,244] LMCache INFO:[0m Stored 149 out of total 661 tokens. size: 0.0040 gb, cost 0.9852 ms, throughput: 4.0383 GB/s; offload_time: 0.9094 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,244] LMCache INFO:[0m Storing KV cache for 818 out of 818 tokens (skip_leading_tokens=0) for request chatcmpl-1b538356c54f4dbf9427b18d331bdd44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,247] LMCache INFO:[0m Stored 818 out of total 818 tokens. size: 0.0218 gb, cost 3.1651 ms, throughput: 6.9012 GB/s; offload_time: 1.8127 ms, put_time: 1.3524 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,248] LMCache INFO:[0m Storing KV cache for 1175 out of 1175 tokens (skip_leading_tokens=0) for request chatcmpl-c4a7e38486f34c4f8115b80646628583 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,252] LMCache INFO:[0m Stored 1175 out of total 1175 tokens. size: 0.0314 gb, cost 3.3576 ms, throughput: 9.3446 GB/s; offload_time: 2.7675 ms, put_time: 0.5901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,257] LMCache INFO:[0m Reqid: chatcmpl-1e469a718deb47ac8f32b958e5d8d6f6, Total tokens 391, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,272] LMCache INFO:[0m Storing KV cache for 391 out of 391 tokens (skip_leading_tokens=0) for request chatcmpl-1e469a718deb47ac8f32b958e5d8d6f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,273] LMCache INFO:[0m Stored 391 out of total 391 tokens. size: 0.0104 gb, cost 1.0507 ms, throughput: 9.9373 GB/s; offload_time: 0.7529 ms, put_time: 0.2978 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,361] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6948304a16564d2c838ebf1c9b8bfbce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,362] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4087 ms, throughput: 8.3624 GB/s; offload_time: 0.3510 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,393] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-347815118b36459699fde54fe80bb240 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,394] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.4854 ms, throughput: 7.0416 GB/s; offload_time: 0.4235 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,433] LMCache INFO:[0m Reqid: chatcmpl-5f3c3e22839b47d49f6f39b97e861b0c, Total tokens 910, LMCache hit tokens: 768, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,442] LMCache INFO:[0m Storing KV cache for 910 out of 910 tokens (skip_leading_tokens=0) for request chatcmpl-5f3c3e22839b47d49f6f39b97e861b0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,443] LMCache INFO:[0m Stored 142 out of total 910 tokens. size: 0.0038 gb, cost 0.6189 ms, throughput: 6.1265 GB/s; offload_time: 0.5377 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,475] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0514827671e64d0f9df1bc3f7638498b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,475] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3784 ms, throughput: 9.0315 GB/s; offload_time: 0.3203 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,478] LMCache INFO:[0m Reqid: chatcmpl-e159e48183a8472fa6f2343bd2baac98, Total tokens 754, LMCache hit tokens: 640, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,487] LMCache INFO:[0m Storing KV cache for 754 out of 754 tokens (skip_leading_tokens=0) for request chatcmpl-e159e48183a8472fa6f2343bd2baac98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,488] LMCache INFO:[0m Stored 114 out of total 754 tokens. size: 0.0030 gb, cost 0.4442 ms, throughput: 6.8529 GB/s; offload_time: 0.3845 ms, put_time: 0.0597 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,501] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-13e5889d03624ed99faa57839f932f9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,501] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3632 ms, throughput: 9.4098 GB/s; offload_time: 0.3073 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,503] LMCache INFO:[0m Reqid: chatcmpl-0770d2fb3e7a4c29959f3883674e2e1b, Total tokens 138, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,513] LMCache INFO:[0m Storing KV cache for 138 out of 138 tokens (skip_leading_tokens=0) for request chatcmpl-0770d2fb3e7a4c29959f3883674e2e1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,513] LMCache INFO:[0m Stored 138 out of total 138 tokens. size: 0.0037 gb, cost 0.5427 ms, throughput: 6.7901 GB/s; offload_time: 0.4595 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,529] LMCache INFO:[0m Reqid: chatcmpl-75dd595094c6494e9b9f6cd220c2b938, Total tokens 421, LMCache hit tokens: 256, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,538] LMCache INFO:[0m Storing KV cache for 421 out of 421 tokens (skip_leading_tokens=0) for request chatcmpl-75dd595094c6494e9b9f6cd220c2b938 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,539] LMCache INFO:[0m Stored 165 out of total 421 tokens. size: 0.0044 gb, cost 0.5713 ms, throughput: 7.7124 GB/s; offload_time: 0.4902 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,559] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a9c2ccb580e448b28e55d84e11d9d6b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,559] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4038 ms, throughput: 8.4644 GB/s; offload_time: 0.3458 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,562] LMCache INFO:[0m Reqid: chatcmpl-6310521bf90549ce89d49ab46903e4c9, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,570] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-6310521bf90549ce89d49ab46903e4c9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,570] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.3625 ms, throughput: 7.1444 GB/s; offload_time: 0.2924 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,589] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0532861743ce4813953962a364a0d588 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,590] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4091 ms, throughput: 8.3545 GB/s; offload_time: 0.3485 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,597] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e159e48183a8472fa6f2343bd2baac98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,598] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3942 ms, throughput: 8.6716 GB/s; offload_time: 0.3387 ms, put_time: 0.0554 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,611] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5f74ad699b6b4be2ae9dc3c212ee4e6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,611] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4176 ms, throughput: 8.1839 GB/s; offload_time: 0.3598 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,624] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d00923f9d71d4d1bbbb4b898c111f9c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,624] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3655 ms, throughput: 9.3504 GB/s; offload_time: 0.3012 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,625] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-22c20539f59945cdb8de970cd7b19c58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,625] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6417 ms, throughput: 5.3263 GB/s; offload_time: 0.5917 ms, put_time: 0.0500 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,632] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-582e82f39a0d48e3a9e63c20059628b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,632] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3607 ms, throughput: 9.4755 GB/s; offload_time: 0.2985 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,646] LMCache INFO:[0m Reqid: chatcmpl-384032b8580d4b9393d5d58ed58a5dd7, Total tokens 636, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,654] LMCache INFO:[0m Storing KV cache for 636 out of 636 tokens (skip_leading_tokens=0) for request chatcmpl-384032b8580d4b9393d5d58ed58a5dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,654] LMCache INFO:[0m Stored 124 out of total 636 tokens. size: 0.0033 gb, cost 0.4335 ms, throughput: 7.6382 GB/s; offload_time: 0.3724 ms, put_time: 0.0611 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,668] LMCache INFO:[0m Reqid: chatcmpl-f05df151e7f24cbb87dd6b2574a74a8f, Total tokens 412, LMCache hit tokens: 256, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,676] LMCache INFO:[0m Storing KV cache for 412 out of 412 tokens (skip_leading_tokens=0) for request chatcmpl-f05df151e7f24cbb87dd6b2574a74a8f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,677] LMCache INFO:[0m Stored 156 out of total 412 tokens. size: 0.0042 gb, cost 0.5477 ms, throughput: 7.6058 GB/s; offload_time: 0.4659 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,680] LMCache INFO:[0m Reqid: chatcmpl-7900d109964a4af3b098ecde73e63d5f, Total tokens 429, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,693] LMCache INFO:[0m Storing KV cache for 429 out of 429 tokens (skip_leading_tokens=0) for request chatcmpl-7900d109964a4af3b098ecde73e63d5f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,694] LMCache INFO:[0m Stored 429 out of total 429 tokens. size: 0.0115 gb, cost 0.8799 ms, throughput: 13.0197 GB/s; offload_time: 0.7620 ms, put_time: 0.1178 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,694] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-384032b8580d4b9393d5d58ed58a5dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,696] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2678 ms, throughput: 2.6961 GB/s; offload_time: 1.1925 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,705] LMCache INFO:[0m Reqid: chatcmpl-958e526dd3044e7fa0c20ddf8e661c32, Total tokens 1760, LMCache hit tokens: 1664, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,713] LMCache INFO:[0m Storing KV cache for 1760 out of 1760 tokens (skip_leading_tokens=0) for request chatcmpl-958e526dd3044e7fa0c20ddf8e661c32 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,714] LMCache INFO:[0m Stored 96 out of total 1760 tokens. size: 0.0026 gb, cost 0.5441 ms, throughput: 4.7113 GB/s; offload_time: 0.4853 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,732] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-50daf61d41e341bb8c5f1cae1c81c666 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,732] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4271 ms, throughput: 8.0022 GB/s; offload_time: 0.3657 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,744] LMCache INFO:[0m Storing KV cache for 128 out of 3072 tokens (skip_leading_tokens=2944) for request chatcmpl-d9e689a8cc464e6eb3196ea7738d2cf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,745] LMCache INFO:[0m Stored 128 out of total 3072 tokens. size: 0.0034 gb, cost 0.5609 ms, throughput: 6.0941 GB/s; offload_time: 0.4986 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,748] LMCache INFO:[0m Reqid: chatcmpl-90b6aefe1aab47c785f962545d03c741, Total tokens 1129, LMCache hit tokens: 1024, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,757] LMCache INFO:[0m Storing KV cache for 1129 out of 1129 tokens (skip_leading_tokens=0) for request chatcmpl-90b6aefe1aab47c785f962545d03c741 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,757] LMCache INFO:[0m Stored 105 out of total 1129 tokens. size: 0.0028 gb, cost 0.4541 ms, throughput: 6.1746 GB/s; offload_time: 0.3958 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,766] LMCache INFO:[0m Reqid: chatcmpl-ac4365e3b65742f5be661c1c6ab6b5bc, Total tokens 1146, LMCache hit tokens: 896, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,777] LMCache INFO:[0m Storing KV cache for 1146 out of 1146 tokens (skip_leading_tokens=0) for request chatcmpl-ac4365e3b65742f5be661c1c6ab6b5bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,777] LMCache INFO:[0m Stored 250 out of total 1146 tokens. size: 0.0067 gb, cost 0.7055 ms, throughput: 9.4623 GB/s; offload_time: 0.5877 ms, put_time: 0.1178 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,782] LMCache INFO:[0m Reqid: chatcmpl-c8795ffe2ac043fb9a833813bf848fa6, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,790] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-c8795ffe2ac043fb9a833813bf848fa6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,791] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.3441 ms, throughput: 8.3803 GB/s; offload_time: 0.2891 ms, put_time: 0.0551 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,793] LMCache INFO:[0m Reqid: chatcmpl-48b22ed6f1cf42f69660a70697fa00bc, Total tokens 425, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,794] LMCache INFO:[0m Reqid: chatcmpl-5e4c6fc9f86f45e5adbe3dfa395d1409, Total tokens 253, LMCache hit tokens: 128, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,804] LMCache INFO:[0m Storing KV cache for 425 out of 425 tokens (skip_leading_tokens=0) for request chatcmpl-48b22ed6f1cf42f69660a70697fa00bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,804] LMCache INFO:[0m Stored 41 out of total 425 tokens. size: 0.0011 gb, cost 0.3782 ms, throughput: 2.8945 GB/s; offload_time: 0.3209 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,804] LMCache INFO:[0m Storing KV cache for 253 out of 253 tokens (skip_leading_tokens=0) for request chatcmpl-5e4c6fc9f86f45e5adbe3dfa395d1409 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,805] LMCache INFO:[0m Stored 125 out of total 253 tokens. size: 0.0033 gb, cost 0.5445 ms, throughput: 6.1303 GB/s; offload_time: 0.4893 ms, put_time: 0.0552 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,825] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6310521bf90549ce89d49ab46903e4c9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,825] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3547 ms, throughput: 9.6372 GB/s; offload_time: 0.2969 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,826] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5e4c6fc9f86f45e5adbe3dfa395d1409 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,826] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7227 ms, throughput: 4.7293 GB/s; offload_time: 0.5691 ms, put_time: 0.1536 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,829] LMCache INFO:[0m Reqid: chatcmpl-9df2c2bb7e5c44f880573a7f1b6de705, Total tokens 1177, LMCache hit tokens: 1152, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,830] LMCache INFO:[0m Reqid: chatcmpl-be75938d7db9483d8ceb8482324b68b6, Total tokens 677, LMCache hit tokens: 512, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,831] LMCache INFO:[0m Reqid: chatcmpl-1b884ede932a48be904d2628def1c1d9, Total tokens 511, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,849] LMCache INFO:[0m Storing KV cache for 1177 out of 1177 tokens (skip_leading_tokens=0) for request chatcmpl-9df2c2bb7e5c44f880573a7f1b6de705 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,850] LMCache INFO:[0m Stored 25 out of total 1177 tokens. size: 0.0007 gb, cost 0.5053 ms, throughput: 1.3212 GB/s; offload_time: 0.4482 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,850] LMCache INFO:[0m Storing KV cache for 677 out of 677 tokens (skip_leading_tokens=0) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,851] LMCache INFO:[0m Stored 165 out of total 677 tokens. size: 0.0044 gb, cost 0.8013 ms, throughput: 5.4986 GB/s; offload_time: 0.7272 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,851] LMCache INFO:[0m Storing KV cache for 511 out of 511 tokens (skip_leading_tokens=0) for request chatcmpl-1b884ede932a48be904d2628def1c1d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,854] LMCache INFO:[0m Stored 511 out of total 511 tokens. size: 0.0136 gb, cost 2.3961 ms, throughput: 5.6947 GB/s; offload_time: 2.2018 ms, put_time: 0.1943 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,854] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ac4365e3b65742f5be661c1c6ab6b5bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,857] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.5502 ms, throughput: 1.3403 GB/s; offload_time: 2.4936 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,865] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1b884ede932a48be904d2628def1c1d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,865] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3828 ms, throughput: 8.9300 GB/s; offload_time: 0.3253 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,872] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-78e9aa3f288c44a18895283e3e145204 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,873] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3772 ms, throughput: 9.0623 GB/s; offload_time: 0.3199 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,899] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2622f617b2bd4930b3d4f241f895b494 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,899] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3634 ms, throughput: 9.4045 GB/s; offload_time: 0.3065 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,912] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3b400afc71e245d6877d764fd9597b41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,913] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3652 ms, throughput: 9.3579 GB/s; offload_time: 0.3083 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,920] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-9fccc9483250480bacf8158c07e69920 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,920] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4197 ms, throughput: 8.1435 GB/s; offload_time: 0.3567 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,957] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-90b6aefe1aab47c785f962545d03c741 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,957] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4140 ms, throughput: 8.2566 GB/s; offload_time: 0.3556 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,969] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b469720de04840399d15a6d42e5fc25f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,970] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3740 ms, throughput: 9.1399 GB/s; offload_time: 0.3161 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:39,973] LMCache INFO:[0m Reqid: chatcmpl-bc6212b6b9e14f6cb07e618f0e51c3b1, Total tokens 1364, LMCache hit tokens: 1280, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,982] LMCache INFO:[0m Storing KV cache for 1364 out of 1364 tokens (skip_leading_tokens=0) for request chatcmpl-bc6212b6b9e14f6cb07e618f0e51c3b1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:39,982] LMCache INFO:[0m Stored 84 out of total 1364 tokens. size: 0.0022 gb, cost 0.5001 ms, throughput: 4.4855 GB/s; offload_time: 0.4348 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:39,996] LMCache INFO:[0m Reqid: chatcmpl-b71d2dcd85d046dc8b6fb0cddcd016ad, Total tokens 91, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,003] LMCache INFO:[0m Storing KV cache for 91 out of 91 tokens (skip_leading_tokens=0) for request chatcmpl-b71d2dcd85d046dc8b6fb0cddcd016ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,004] LMCache INFO:[0m Stored 91 out of total 91 tokens. size: 0.0024 gb, cost 0.3550 ms, throughput: 6.8456 GB/s; offload_time: 0.2958 ms, put_time: 0.0592 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,021] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-2cd4990bffa940a49d3a8bf94ee10473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,022] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4179 ms, throughput: 8.1782 GB/s; offload_time: 0.3595 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,050] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f762ee4991614b61b67a494f243da0ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,051] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4178 ms, throughput: 8.1801 GB/s; offload_time: 0.3605 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,069] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-eca38d59e15b47fbb276bc68eed2bd08 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,069] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3890 ms, throughput: 8.7868 GB/s; offload_time: 0.3323 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,083] LMCache INFO:[0m Reqid: chatcmpl-92ed307e039c4488ab5ea9a3c78c3239, Total tokens 278, LMCache hit tokens: 256, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,090] LMCache INFO:[0m Storing KV cache for 278 out of 278 tokens (skip_leading_tokens=0) for request chatcmpl-92ed307e039c4488ab5ea9a3c78c3239 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,091] LMCache INFO:[0m Stored 22 out of total 278 tokens. size: 0.0006 gb, cost 0.3863 ms, throughput: 1.5207 GB/s; offload_time: 0.3221 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,091] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3c478782684249cf8dae4cc7a4603bf9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,092] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5539 ms, throughput: 6.1709 GB/s; offload_time: 0.5042 ms, put_time: 0.0497 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,122] LMCache INFO:[0m Reqid: chatcmpl-8a541dcb9dfc44b88350b622a41edc51, Total tokens 258, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,129] LMCache INFO:[0m Storing KV cache for 258 out of 258 tokens (skip_leading_tokens=0) for request chatcmpl-8a541dcb9dfc44b88350b622a41edc51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,129] LMCache INFO:[0m Stored 130 out of total 258 tokens. size: 0.0035 gb, cost 0.5443 ms, throughput: 6.3775 GB/s; offload_time: 0.4566 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,142] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c751eff8a979453b96b7ab2fef209062 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,143] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4401 ms, throughput: 7.7664 GB/s; offload_time: 0.3778 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,145] LMCache INFO:[0m Reqid: chatcmpl-2d123b0b8bfd43659e9fef30328ba8d7, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,152] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-2d123b0b8bfd43659e9fef30328ba8d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,153] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.3815 ms, throughput: 6.6487 GB/s; offload_time: 0.3104 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,165] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6e873e404cd243a58b8348674d863012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,165] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3905 ms, throughput: 8.7521 GB/s; offload_time: 0.3343 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,171] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1e469a718deb47ac8f32b958e5d8d6f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,172] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3752 ms, throughput: 9.1090 GB/s; offload_time: 0.3170 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,174] LMCache INFO:[0m Reqid: chatcmpl-742e504298124f1c8550c7616a265d54, Total tokens 143, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,181] LMCache INFO:[0m Storing KV cache for 143 out of 143 tokens (skip_leading_tokens=0) for request chatcmpl-742e504298124f1c8550c7616a265d54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,182] LMCache INFO:[0m Stored 143 out of total 143 tokens. size: 0.0038 gb, cost 0.5506 ms, throughput: 6.9354 GB/s; offload_time: 0.4594 ms, put_time: 0.0912 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,189] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,190] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4030 ms, throughput: 8.4803 GB/s; offload_time: 0.3446 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,197] LMCache INFO:[0m Reqid: chatcmpl-3cbd484a01284625aeca41b36ca997bf, Total tokens 350, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,205] LMCache INFO:[0m Storing KV cache for 350 out of 350 tokens (skip_leading_tokens=0) for request chatcmpl-3cbd484a01284625aeca41b36ca997bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,206] LMCache INFO:[0m Stored 94 out of total 350 tokens. size: 0.0025 gb, cost 0.3844 ms, throughput: 6.5291 GB/s; offload_time: 0.3243 ms, put_time: 0.0601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,208] LMCache INFO:[0m Reqid: chatcmpl-207f465e496944b9b713c6b038071645, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,216] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-207f465e496944b9b713c6b038071645 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,216] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.3705 ms, throughput: 6.7029 GB/s; offload_time: 0.3079 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,224] LMCache INFO:[0m Reqid: chatcmpl-5c238323463c4de188b7e361eb99f665, Total tokens 114, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,231] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-5c238323463c4de188b7e361eb99f665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,232] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.3633 ms, throughput: 8.3788 GB/s; offload_time: 0.3062 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,239] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-75dd595094c6494e9b9f6cd220c2b938 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,239] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3786 ms, throughput: 9.0280 GB/s; offload_time: 0.3219 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,266] LMCache INFO:[0m Reqid: chatcmpl-592f5d8822f54647a11522f3122f988d, Total tokens 1224, LMCache hit tokens: 1152, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,274] LMCache INFO:[0m Storing KV cache for 1224 out of 1224 tokens (skip_leading_tokens=0) for request chatcmpl-592f5d8822f54647a11522f3122f988d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,274] LMCache INFO:[0m Stored 72 out of total 1224 tokens. size: 0.0019 gb, cost 0.4934 ms, throughput: 3.8965 GB/s; offload_time: 0.4346 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,278] LMCache INFO:[0m Reqid: chatcmpl-ebdc9071fde940afa4682db56db12085, Total tokens 489, LMCache hit tokens: 384, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,286] LMCache INFO:[0m Storing KV cache for 489 out of 489 tokens (skip_leading_tokens=0) for request chatcmpl-ebdc9071fde940afa4682db56db12085 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,286] LMCache INFO:[0m Stored 105 out of total 489 tokens. size: 0.0028 gb, cost 0.4188 ms, throughput: 6.6947 GB/s; offload_time: 0.3613 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,293] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-bc6212b6b9e14f6cb07e618f0e51c3b1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,294] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5203 ms, throughput: 6.5690 GB/s; offload_time: 0.4636 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,296] LMCache INFO:[0m Reqid: chatcmpl-e3a377512ba84dc193e64df5fc8e6b0a, Total tokens 91, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,304] LMCache INFO:[0m Storing KV cache for 91 out of 91 tokens (skip_leading_tokens=0) for request chatcmpl-e3a377512ba84dc193e64df5fc8e6b0a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,304] LMCache INFO:[0m Stored 91 out of total 91 tokens. size: 0.0024 gb, cost 0.3690 ms, throughput: 6.5848 GB/s; offload_time: 0.3097 ms, put_time: 0.0593 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,323] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5f3c3e22839b47d49f6f39b97e861b0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,324] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4004 ms, throughput: 8.5360 GB/s; offload_time: 0.3444 ms, put_time: 0.0560 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,331] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7900d109964a4af3b098ecde73e63d5f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,331] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3728 ms, throughput: 9.1686 GB/s; offload_time: 0.3167 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,338] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-6948304a16564d2c838ebf1c9b8bfbce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,339] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4258 ms, throughput: 8.0268 GB/s; offload_time: 0.3677 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,339] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5c238323463c4de188b7e361eb99f665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,340] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6171 ms, throughput: 5.5387 GB/s; offload_time: 0.5624 ms, put_time: 0.0547 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,371] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-347815118b36459699fde54fe80bb240 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,371] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.4850 ms, throughput: 7.0467 GB/s; offload_time: 0.4276 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,379] LMCache INFO:[0m Reqid: chatcmpl-00adca1c58fb487cb871601528189fd1, Total tokens 194, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,387] LMCache INFO:[0m Storing KV cache for 194 out of 194 tokens (skip_leading_tokens=0) for request chatcmpl-00adca1c58fb487cb871601528189fd1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,388] LMCache INFO:[0m Stored 66 out of total 194 tokens. size: 0.0018 gb, cost 0.3908 ms, throughput: 4.5098 GB/s; offload_time: 0.3266 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,396] LMCache INFO:[0m Reqid: chatcmpl-7577306bc72c400c984bdf447e14b5de, Total tokens 157, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,407] LMCache INFO:[0m Storing KV cache for 157 out of 157 tokens (skip_leading_tokens=0) for request chatcmpl-7577306bc72c400c984bdf447e14b5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,408] LMCache INFO:[0m Stored 157 out of total 157 tokens. size: 0.0042 gb, cost 0.5373 ms, throughput: 7.8032 GB/s; offload_time: 0.4500 ms, put_time: 0.0873 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,408] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2d123b0b8bfd43659e9fef30328ba8d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,409] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0129 ms, throughput: 3.3744 GB/s; offload_time: 0.9181 ms, put_time: 0.0948 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,423] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0770d2fb3e7a4c29959f3883674e2e1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,423] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3674 ms, throughput: 9.3036 GB/s; offload_time: 0.3083 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,448] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-48b22ed6f1cf42f69660a70697fa00bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,448] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3864 ms, throughput: 8.8453 GB/s; offload_time: 0.3197 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,455] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ebdc9071fde940afa4682db56db12085 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,456] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3773 ms, throughput: 9.0593 GB/s; offload_time: 0.3198 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,462] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0514827671e64d0f9df1bc3f7638498b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,463] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3770 ms, throughput: 9.0653 GB/s; offload_time: 0.3193 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,463] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3cbd484a01284625aeca41b36ca997bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,464] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5561 ms, throughput: 6.1466 GB/s; offload_time: 0.5079 ms, put_time: 0.0482 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,490] LMCache INFO:[0m Reqid: chatcmpl-0631f4bc8bf34a63adb85675fe56f809, Total tokens 1237, LMCache hit tokens: 1024, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,500] LMCache INFO:[0m Storing KV cache for 1237 out of 1237 tokens (skip_leading_tokens=0) for request chatcmpl-0631f4bc8bf34a63adb85675fe56f809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,500] LMCache INFO:[0m Stored 213 out of total 1237 tokens. size: 0.0057 gb, cost 0.6286 ms, throughput: 9.0479 GB/s; offload_time: 0.5463 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,503] LMCache INFO:[0m Reqid: chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18, Total tokens 602, LMCache hit tokens: 512, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,512] LMCache INFO:[0m Storing KV cache for 602 out of 602 tokens (skip_leading_tokens=0) for request chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,512] LMCache INFO:[0m Stored 90 out of total 602 tokens. size: 0.0024 gb, cost 0.3871 ms, throughput: 6.2092 GB/s; offload_time: 0.3294 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,513] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,513] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5542 ms, throughput: 6.1671 GB/s; offload_time: 0.5039 ms, put_time: 0.0503 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,528] LMCache INFO:[0m Reqid: chatcmpl-83d13385103448a89f159803e1f443da, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,536] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-83d13385103448a89f159803e1f443da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,536] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.3702 ms, throughput: 7.7177 GB/s; offload_time: 0.3065 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,568] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0532861743ce4813953962a364a0d588 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,568] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4080 ms, throughput: 8.3772 GB/s; offload_time: 0.3506 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,588] LMCache INFO:[0m Reqid: chatcmpl-1961aa39d913426bb0f14df5e1d2614d, Total tokens 314, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,597] LMCache INFO:[0m Storing KV cache for 314 out of 314 tokens (skip_leading_tokens=0) for request chatcmpl-1961aa39d913426bb0f14df5e1d2614d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,598] LMCache INFO:[0m Stored 186 out of total 314 tokens. size: 0.0050 gb, cost 0.5621 ms, throughput: 8.8360 GB/s; offload_time: 0.4706 ms, put_time: 0.0915 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,598] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-9df2c2bb7e5c44f880573a7f1b6de705 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,599] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.9258 ms, throughput: 3.6919 GB/s; offload_time: 0.8765 ms, put_time: 0.0493 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,608] LMCache INFO:[0m Reqid: chatcmpl-4ea3b1ef89764410af979b1b0c0ad4fa, Total tokens 131, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,615] LMCache INFO:[0m Storing KV cache for 131 out of 131 tokens (skip_leading_tokens=0) for request chatcmpl-4ea3b1ef89764410af979b1b0c0ad4fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,616] LMCache INFO:[0m Stored 131 out of total 131 tokens. size: 0.0035 gb, cost 0.4957 ms, throughput: 7.0567 GB/s; offload_time: 0.4137 ms, put_time: 0.0820 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,637] LMCache INFO:[0m Reqid: chatcmpl-abbecf841aec4d898b065088df4f552e, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,645] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-abbecf841aec4d898b065088df4f552e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,646] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.3795 ms, throughput: 6.7549 GB/s; offload_time: 0.3156 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,664] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-384032b8580d4b9393d5d58ed58a5dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,665] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3866 ms, throughput: 8.8407 GB/s; offload_time: 0.3300 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,689] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-592f5d8822f54647a11522f3122f988d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,690] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4165 ms, throughput: 8.2070 GB/s; offload_time: 0.3552 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,716] LMCache INFO:[0m Reqid: chatcmpl-b5d93938fb294bf4812b0a50028ca439, Total tokens 856, LMCache hit tokens: 768, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,723] LMCache INFO:[0m Storing KV cache for 856 out of 856 tokens (skip_leading_tokens=0) for request chatcmpl-b5d93938fb294bf4812b0a50028ca439 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,724] LMCache INFO:[0m Stored 88 out of total 856 tokens. size: 0.0023 gb, cost 0.5547 ms, throughput: 4.2361 GB/s; offload_time: 0.4674 ms, put_time: 0.0873 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,727] LMCache INFO:[0m Reqid: chatcmpl-932cc20a601f45558862f07b7752ce96, Total tokens 578, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,735] LMCache INFO:[0m Storing KV cache for 578 out of 578 tokens (skip_leading_tokens=0) for request chatcmpl-932cc20a601f45558862f07b7752ce96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,736] LMCache INFO:[0m Stored 66 out of total 578 tokens. size: 0.0018 gb, cost 0.4237 ms, throughput: 4.1592 GB/s; offload_time: 0.3673 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,751] LMCache INFO:[0m Reqid: chatcmpl-9596c4845aff49df92fe56989aa0d210, Total tokens 163, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,763] LMCache INFO:[0m Storing KV cache for 163 out of 163 tokens (skip_leading_tokens=0) for request chatcmpl-9596c4845aff49df92fe56989aa0d210 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,764] LMCache INFO:[0m Stored 163 out of total 163 tokens. size: 0.0044 gb, cost 0.5219 ms, throughput: 8.3405 GB/s; offload_time: 0.4382 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,767] LMCache INFO:[0m Reqid: chatcmpl-c79bae4dd7c6431fa47a8522124d12f8, Total tokens 379, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,776] LMCache INFO:[0m Storing KV cache for 379 out of 379 tokens (skip_leading_tokens=0) for request chatcmpl-c79bae4dd7c6431fa47a8522124d12f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,777] LMCache INFO:[0m Stored 123 out of total 379 tokens. size: 0.0033 gb, cost 0.3680 ms, throughput: 8.9244 GB/s; offload_time: 0.3093 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,785] LMCache INFO:[0m Reqid: chatcmpl-e7b7fe05f5524eeebdb637b6abd33274, Total tokens 162, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,793] LMCache INFO:[0m Storing KV cache for 162 out of 162 tokens (skip_leading_tokens=0) for request chatcmpl-e7b7fe05f5524eeebdb637b6abd33274 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,793] LMCache INFO:[0m Stored 34 out of total 162 tokens. size: 0.0009 gb, cost 0.3685 ms, throughput: 2.4638 GB/s; offload_time: 0.3053 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,796] LMCache INFO:[0m Reqid: chatcmpl-5c1524d7610e40fd87dc6efc8a06bcd1, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,804] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-5c1524d7610e40fd87dc6efc8a06bcd1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,804] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.3482 ms, throughput: 7.0544 GB/s; offload_time: 0.2838 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,805] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-ac4365e3b65742f5be661c1c6ab6b5bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,806] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6674 ms, throughput: 5.1214 GB/s; offload_time: 0.6181 ms, put_time: 0.0493 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,813] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,814] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3976 ms, throughput: 8.5972 GB/s; offload_time: 0.3390 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,817] LMCache INFO:[0m Reqid: chatcmpl-db31b04c088f45c68d8faecffc74805f, Total tokens 568, LMCache hit tokens: 512, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,825] LMCache INFO:[0m Storing KV cache for 568 out of 568 tokens (skip_leading_tokens=0) for request chatcmpl-db31b04c088f45c68d8faecffc74805f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,825] LMCache INFO:[0m Stored 56 out of total 568 tokens. size: 0.0015 gb, cost 0.3940 ms, throughput: 3.7950 GB/s; offload_time: 0.3352 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,825] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c79bae4dd7c6431fa47a8522124d12f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,826] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5474 ms, throughput: 6.2445 GB/s; offload_time: 0.4942 ms, put_time: 0.0532 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,829] LMCache INFO:[0m Reqid: chatcmpl-d33de4ff868a4651b93edbdcf3e1ea1a, Total tokens 162, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,837] LMCache INFO:[0m Storing KV cache for 162 out of 162 tokens (skip_leading_tokens=0) for request chatcmpl-d33de4ff868a4651b93edbdcf3e1ea1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,837] LMCache INFO:[0m Stored 162 out of total 162 tokens. size: 0.0043 gb, cost 0.5143 ms, throughput: 8.4110 GB/s; offload_time: 0.4318 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,841] LMCache INFO:[0m Reqid: chatcmpl-9e6bbcbf86ba488e9ed94de38143dc50, Total tokens 608, LMCache hit tokens: 256, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,853] LMCache INFO:[0m Storing KV cache for 608 out of 608 tokens (skip_leading_tokens=0) for request chatcmpl-9e6bbcbf86ba488e9ed94de38143dc50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,854] LMCache INFO:[0m Stored 352 out of total 608 tokens. size: 0.0094 gb, cost 0.7271 ms, throughput: 12.9269 GB/s; offload_time: 0.6240 ms, put_time: 0.1031 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,861] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-0631f4bc8bf34a63adb85675fe56f809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,862] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4370 ms, throughput: 7.8206 GB/s; offload_time: 0.3738 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,869] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2622f617b2bd4930b3d4f241f895b494 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,870] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3891 ms, throughput: 8.7853 GB/s; offload_time: 0.3316 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,885] LMCache INFO:[0m Reqid: chatcmpl-876e99d66fa045f0bdfa1870a0812b26, Total tokens 1507, LMCache hit tokens: 1408, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,892] LMCache INFO:[0m Storing KV cache for 1507 out of 1507 tokens (skip_leading_tokens=0) for request chatcmpl-876e99d66fa045f0bdfa1870a0812b26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,893] LMCache INFO:[0m Stored 99 out of total 1507 tokens. size: 0.0026 gb, cost 0.4739 ms, throughput: 5.5780 GB/s; offload_time: 0.4101 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,896] LMCache INFO:[0m Reqid: chatcmpl-49a0a03a35d34b95bb8446ff8d08b481, Total tokens 696, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,904] LMCache INFO:[0m Storing KV cache for 696 out of 696 tokens (skip_leading_tokens=0) for request chatcmpl-49a0a03a35d34b95bb8446ff8d08b481 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,905] LMCache INFO:[0m Stored 56 out of total 696 tokens. size: 0.0015 gb, cost 0.4138 ms, throughput: 3.6137 GB/s; offload_time: 0.3493 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,913] LMCache INFO:[0m Reqid: chatcmpl-49d5ee127a8a4e518bacef22b280ff2a, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,922] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-49d5ee127a8a4e518bacef22b280ff2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,922] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.3412 ms, throughput: 8.5294 GB/s; offload_time: 0.2828 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,929] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-92ed307e039c4488ab5ea9a3c78c3239 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,930] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3778 ms, throughput: 9.0467 GB/s; offload_time: 0.3172 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,930] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-abbecf841aec4d898b065088df4f552e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,931] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6237 ms, throughput: 5.4805 GB/s; offload_time: 0.5484 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,944] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-90b6aefe1aab47c785f962545d03c741 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,944] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4293 ms, throughput: 7.9610 GB/s; offload_time: 0.3669 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:40,953] LMCache INFO:[0m Reqid: chatcmpl-61339d12413b4a60b5b6d75d308658a0, Total tokens 404, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,961] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-61339d12413b4a60b5b6d75d308658a0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,961] LMCache INFO:[0m Stored 20 out of total 404 tokens. size: 0.0005 gb, cost 0.3825 ms, throughput: 1.3962 GB/s; offload_time: 0.3164 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:40,961] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b469720de04840399d15a6d42e5fc25f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:40,962] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5947 ms, throughput: 5.7474 GB/s; offload_time: 0.5431 ms, put_time: 0.0516 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,006] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-2cd4990bffa940a49d3a8bf94ee10473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,006] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4377 ms, throughput: 7.8087 GB/s; offload_time: 0.3792 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,015] LMCache INFO:[0m Reqid: chatcmpl-3f3716bc5e5d4905b2c791528d769732, Total tokens 1321, LMCache hit tokens: 1280, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,023] LMCache INFO:[0m Storing KV cache for 1321 out of 1321 tokens (skip_leading_tokens=0) for request chatcmpl-3f3716bc5e5d4905b2c791528d769732 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,024] LMCache INFO:[0m Stored 41 out of total 1321 tokens. size: 0.0011 gb, cost 0.4507 ms, throughput: 2.4293 GB/s; offload_time: 0.3894 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,043] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f762ee4991614b61b67a494f243da0ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,044] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4265 ms, throughput: 8.0133 GB/s; offload_time: 0.3682 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,053] LMCache INFO:[0m Reqid: chatcmpl-e10e65100fcd469aaf6abe6ae99a8ebe, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,060] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-e10e65100fcd469aaf6abe6ae99a8ebe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,061] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.3343 ms, throughput: 7.6678 GB/s; offload_time: 0.2757 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,061] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-49d5ee127a8a4e518bacef22b280ff2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,062] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4492 ms, throughput: 7.6082 GB/s; offload_time: 0.3947 ms, put_time: 0.0545 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,069] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-b5d93938fb294bf4812b0a50028ca439 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,069] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4166 ms, throughput: 8.2046 GB/s; offload_time: 0.3541 ms, put_time: 0.0625 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,094] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5c1524d7610e40fd87dc6efc8a06bcd1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,094] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3585 ms, throughput: 9.5338 GB/s; offload_time: 0.3009 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,095] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9e6bbcbf86ba488e9ed94de38143dc50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,095] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5853 ms, throughput: 5.8396 GB/s; offload_time: 0.5317 ms, put_time: 0.0536 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,109] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-876e99d66fa045f0bdfa1870a0812b26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,109] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4415 ms, throughput: 7.7425 GB/s; offload_time: 0.3839 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,116] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8a541dcb9dfc44b88350b622a41edc51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,117] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3792 ms, throughput: 9.0129 GB/s; offload_time: 0.3222 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,138] LMCache INFO:[0m Reqid: chatcmpl-ff670be03b0143d7b6c5a79f793c5443, Total tokens 1351, LMCache hit tokens: 1280, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,146] LMCache INFO:[0m Storing KV cache for 1351 out of 1351 tokens (skip_leading_tokens=0) for request chatcmpl-ff670be03b0143d7b6c5a79f793c5443 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,147] LMCache INFO:[0m Stored 71 out of total 1351 tokens. size: 0.0019 gb, cost 0.4524 ms, throughput: 4.1911 GB/s; offload_time: 0.3943 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,156] LMCache INFO:[0m Reqid: chatcmpl-f54cf82070a840169e1a2944fb7f2a49, Total tokens 545, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,164] LMCache INFO:[0m Storing KV cache for 545 out of 545 tokens (skip_leading_tokens=0) for request chatcmpl-f54cf82070a840169e1a2944fb7f2a49 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,164] LMCache INFO:[0m Stored 161 out of total 545 tokens. size: 0.0043 gb, cost 0.5504 ms, throughput: 7.8117 GB/s; offload_time: 0.4634 ms, put_time: 0.0870 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,172] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6e873e404cd243a58b8348674d863012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,173] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4119 ms, throughput: 8.2977 GB/s; offload_time: 0.3550 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,180] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1e469a718deb47ac8f32b958e5d8d6f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,180] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3983 ms, throughput: 8.5805 GB/s; offload_time: 0.3401 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,183] LMCache INFO:[0m Reqid: chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba, Total tokens 691, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,191] LMCache INFO:[0m Storing KV cache for 691 out of 691 tokens (skip_leading_tokens=0) for request chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,192] LMCache INFO:[0m Stored 51 out of total 691 tokens. size: 0.0014 gb, cost 0.4028 ms, throughput: 3.3813 GB/s; offload_time: 0.3444 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,192] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7577306bc72c400c984bdf447e14b5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,193] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7664 ms, throughput: 4.4596 GB/s; offload_time: 0.7144 ms, put_time: 0.0520 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,200] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-8569107805034cc783e450c170373217 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,201] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4250 ms, throughput: 8.0427 GB/s; offload_time: 0.3667 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,209] LMCache INFO:[0m Reqid: chatcmpl-7e0ef3db76ac46bab37d59b7551ce1d3, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,218] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-7e0ef3db76ac46bab37d59b7551ce1d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,218] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.3379 ms, throughput: 8.6920 GB/s; offload_time: 0.2790 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,243] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-75dd595094c6494e9b9f6cd220c2b938 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,244] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3891 ms, throughput: 8.7833 GB/s; offload_time: 0.3321 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,244] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-932cc20a601f45558862f07b7752ce96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,245] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6688 ms, throughput: 5.1102 GB/s; offload_time: 0.6155 ms, put_time: 0.0534 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,314] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5f3c3e22839b47d49f6f39b97e861b0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,314] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4516 ms, throughput: 7.5684 GB/s; offload_time: 0.3872 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,324] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-7900d109964a4af3b098ecde73e63d5f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,325] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4616 ms, throughput: 7.4043 GB/s; offload_time: 0.4029 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,331] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5c238323463c4de188b7e361eb99f665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,332] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3613 ms, throughput: 9.4590 GB/s; offload_time: 0.3048 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,339] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7e0ef3db76ac46bab37d59b7551ce1d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,339] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3455 ms, throughput: 9.8930 GB/s; offload_time: 0.2889 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,364] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-347815118b36459699fde54fe80bb240 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,365] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.4842 ms, throughput: 7.0597 GB/s; offload_time: 0.4271 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,368] LMCache INFO:[0m Reqid: chatcmpl-293646dc4f75452491b5e40bc55a508b, Total tokens 1581, LMCache hit tokens: 1408, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,380] LMCache INFO:[0m Storing KV cache for 1581 out of 1581 tokens (skip_leading_tokens=0) for request chatcmpl-293646dc4f75452491b5e40bc55a508b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,381] LMCache INFO:[0m Stored 173 out of total 1581 tokens. size: 0.0046 gb, cost 0.6263 ms, throughput: 7.3765 GB/s; offload_time: 0.5427 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,381] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-db31b04c088f45c68d8faecffc74805f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,383] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8874 ms, throughput: 3.8515 GB/s; offload_time: 0.8362 ms, put_time: 0.0512 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,386] LMCache INFO:[0m Reqid: chatcmpl-debca6bc941449b0840f48c5e82b3d35, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,387] LMCache INFO:[0m Reqid: chatcmpl-3352b9a4ce924b4682f23ada288ee00d, Total tokens 435, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,388] LMCache INFO:[0m Reqid: chatcmpl-5af21303c2bf42dba43c2ef84246e571, Total tokens 1563, LMCache hit tokens: 1280, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,401] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-debca6bc941449b0840f48c5e82b3d35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,402] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.3709 ms, throughput: 7.2717 GB/s; offload_time: 0.3140 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,402] LMCache INFO:[0m Storing KV cache for 435 out of 435 tokens (skip_leading_tokens=0) for request chatcmpl-3352b9a4ce924b4682f23ada288ee00d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,403] LMCache INFO:[0m Stored 51 out of total 435 tokens. size: 0.0014 gb, cost 0.5727 ms, throughput: 2.3781 GB/s; offload_time: 0.5196 ms, put_time: 0.0530 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,403] LMCache INFO:[0m Storing KV cache for 1563 out of 1563 tokens (skip_leading_tokens=0) for request chatcmpl-5af21303c2bf42dba43c2ef84246e571 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,405] LMCache INFO:[0m Stored 283 out of total 1563 tokens. size: 0.0076 gb, cost 1.7376 ms, throughput: 4.3491 GB/s; offload_time: 1.5400 ms, put_time: 0.1976 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,415] LMCache INFO:[0m Reqid: chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb, Total tokens 126, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,415] LMCache INFO:[0m Reqid: chatcmpl-89797ac2dd5947c6a5c506ae271f03d6, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,427] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,427] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 0.3777 ms, throughput: 8.9092 GB/s; offload_time: 0.3088 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,428] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-89797ac2dd5947c6a5c506ae271f03d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,428] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.5785 ms, throughput: 5.5395 GB/s; offload_time: 0.5261 ms, put_time: 0.0524 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,442] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0770d2fb3e7a4c29959f3883674e2e1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,442] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3687 ms, throughput: 9.2704 GB/s; offload_time: 0.3114 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,443] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,443] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4303 ms, throughput: 7.9440 GB/s; offload_time: 0.3754 ms, put_time: 0.0549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,453] LMCache INFO:[0m Reqid: chatcmpl-9fdaba75c95c45219196c1a37ee520a2, Total tokens 1473, LMCache hit tokens: 1152, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,465] LMCache INFO:[0m Storing KV cache for 1473 out of 1473 tokens (skip_leading_tokens=0) for request chatcmpl-9fdaba75c95c45219196c1a37ee520a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,466] LMCache INFO:[0m Stored 321 out of total 1473 tokens. size: 0.0086 gb, cost 0.8328 ms, throughput: 10.2931 GB/s; offload_time: 0.7203 ms, put_time: 0.1125 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,474] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-49a0a03a35d34b95bb8446ff8d08b481 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,475] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3953 ms, throughput: 8.6461 GB/s; offload_time: 0.3381 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,494] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3cbd484a01284625aeca41b36ca997bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,495] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3726 ms, throughput: 9.1740 GB/s; offload_time: 0.3153 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,495] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-89797ac2dd5947c6a5c506ae271f03d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,496] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6364 ms, throughput: 5.3709 GB/s; offload_time: 0.5871 ms, put_time: 0.0492 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,522] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9596c4845aff49df92fe56989aa0d210 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,523] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3555 ms, throughput: 9.6157 GB/s; offload_time: 0.2999 ms, put_time: 0.0555 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,536] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,537] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4130 ms, throughput: 8.2756 GB/s; offload_time: 0.3490 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,539] LMCache INFO:[0m Reqid: chatcmpl-640980983184446d90fb77a0b2dd7003, Total tokens 444, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,548] LMCache INFO:[0m Storing KV cache for 444 out of 444 tokens (skip_leading_tokens=0) for request chatcmpl-640980983184446d90fb77a0b2dd7003 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,548] LMCache INFO:[0m Stored 60 out of total 444 tokens. size: 0.0016 gb, cost 0.3983 ms, throughput: 4.0223 GB/s; offload_time: 0.3418 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,556] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e7b7fe05f5524eeebdb637b6abd33274 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,556] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3616 ms, throughput: 9.4530 GB/s; offload_time: 0.2983 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,558] LMCache INFO:[0m Reqid: chatcmpl-2f61fee606704ea1a91ec5c44a18adff, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,567] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-2f61fee606704ea1a91ec5c44a18adff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,567] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.3698 ms, throughput: 6.7150 GB/s; offload_time: 0.3056 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,587] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d33de4ff868a4651b93edbdcf3e1ea1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,587] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3587 ms, throughput: 9.5299 GB/s; offload_time: 0.3017 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,601] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-0532861743ce4813953962a364a0d588 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,602] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4197 ms, throughput: 8.1447 GB/s; offload_time: 0.3595 ms, put_time: 0.0601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,609] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ff670be03b0143d7b6c5a79f793c5443 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,609] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4308 ms, throughput: 7.9331 GB/s; offload_time: 0.3694 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,623] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4ea3b1ef89764410af979b1b0c0ad4fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,623] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3591 ms, throughput: 9.5175 GB/s; offload_time: 0.2983 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,624] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-debca6bc941449b0840f48c5e82b3d35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,624] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4746 ms, throughput: 7.2017 GB/s; offload_time: 0.4209 ms, put_time: 0.0537 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,689] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-384032b8580d4b9393d5d58ed58a5dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,690] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4052 ms, throughput: 8.4360 GB/s; offload_time: 0.3439 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,697] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-3f3716bc5e5d4905b2c791528d769732 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,698] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4282 ms, throughput: 7.9821 GB/s; offload_time: 0.3710 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,717] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-592f5d8822f54647a11522f3122f988d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,718] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4501 ms, throughput: 7.5939 GB/s; offload_time: 0.3879 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,727] LMCache INFO:[0m Reqid: chatcmpl-2ad30dc3f92d4a4fa9bb16704b80d1cc, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,727] LMCache INFO:[0m Reqid: chatcmpl-19a09aa10bbb498bb9c7aa91b660f892, Total tokens 1003, LMCache hit tokens: 896, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,738] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-2ad30dc3f92d4a4fa9bb16704b80d1cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,738] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.3725 ms, throughput: 7.2407 GB/s; offload_time: 0.3055 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,738] LMCache INFO:[0m Storing KV cache for 1003 out of 1003 tokens (skip_leading_tokens=0) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,739] LMCache INFO:[0m Stored 107 out of total 1003 tokens. size: 0.0029 gb, cost 0.6571 ms, throughput: 4.3481 GB/s; offload_time: 0.6017 ms, put_time: 0.0554 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,767] LMCache INFO:[0m Reqid: chatcmpl-fe5f3d2ef7654c02bfe6f5b024fcdad2, Total tokens 487, LMCache hit tokens: 384, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO 07-11 15:20:41 [loggers.py:118] Engine 000: Avg prompt throughput: 12067.4 tokens/s, Avg generation throughput: 3568.4 tokens/s, Running: 42 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.9%, Prefix cache hit rate: 60.5%
[32;20m[2025-07-11 15:20:41,776] LMCache INFO:[0m Storing KV cache for 487 out of 487 tokens (skip_leading_tokens=0) for request chatcmpl-fe5f3d2ef7654c02bfe6f5b024fcdad2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,776] LMCache INFO:[0m Stored 103 out of total 487 tokens. size: 0.0028 gb, cost 0.3747 ms, throughput: 7.3394 GB/s; offload_time: 0.3185 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,790] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,790] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3882 ms, throughput: 8.8043 GB/s; offload_time: 0.3319 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,816] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,817] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4287 ms, throughput: 7.9737 GB/s; offload_time: 0.3700 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,817] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2f61fee606704ea1a91ec5c44a18adff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,818] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5702 ms, throughput: 5.9939 GB/s; offload_time: 0.5216 ms, put_time: 0.0486 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,840] LMCache INFO:[0m Reqid: chatcmpl-00097cfa980a428dbd839a4cbbe03dd7, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,840] LMCache INFO:[0m Reqid: chatcmpl-508aa5c2391b412694888a651ad90583, Total tokens 477, LMCache hit tokens: 384, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,850] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-00097cfa980a428dbd839a4cbbe03dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,850] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.3640 ms, throughput: 7.1153 GB/s; offload_time: 0.2993 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,850] LMCache INFO:[0m Storing KV cache for 477 out of 477 tokens (skip_leading_tokens=0) for request chatcmpl-508aa5c2391b412694888a651ad90583 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,851] LMCache INFO:[0m Stored 93 out of total 477 tokens. size: 0.0025 gb, cost 0.5406 ms, throughput: 4.5937 GB/s; offload_time: 0.4833 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,860] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2622f617b2bd4930b3d4f241f895b494 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,860] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4552 ms, throughput: 7.5086 GB/s; offload_time: 0.3888 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,894] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,894] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.3989 ms, throughput: 8.5688 GB/s; offload_time: 0.3419 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,901] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f54cf82070a840169e1a2944fb7f2a49 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,902] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3832 ms, throughput: 8.9193 GB/s; offload_time: 0.3240 ms, put_time: 0.0592 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,909] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-abbecf841aec4d898b065088df4f552e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,909] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3588 ms, throughput: 9.5262 GB/s; offload_time: 0.3031 ms, put_time: 0.0557 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,923] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-90b6aefe1aab47c785f962545d03c741 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,923] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4362 ms, throughput: 7.8354 GB/s; offload_time: 0.3795 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,931] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-9fdaba75c95c45219196c1a37ee520a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,931] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4437 ms, throughput: 7.7028 GB/s; offload_time: 0.3815 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,934] LMCache INFO:[0m Reqid: chatcmpl-d530bc50fd5b4440a14cf58828bfb28c, Total tokens 208, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,942] LMCache INFO:[0m Storing KV cache for 208 out of 208 tokens (skip_leading_tokens=0) for request chatcmpl-d530bc50fd5b4440a14cf58828bfb28c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,943] LMCache INFO:[0m Stored 80 out of total 208 tokens. size: 0.0021 gb, cost 0.3805 ms, throughput: 5.6148 GB/s; offload_time: 0.3170 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,943] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2ad30dc3f92d4a4fa9bb16704b80d1cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,943] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4826 ms, throughput: 7.0821 GB/s; offload_time: 0.4279 ms, put_time: 0.0548 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:41,965] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fe5f3d2ef7654c02bfe6f5b024fcdad2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,965] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3741 ms, throughput: 9.1360 GB/s; offload_time: 0.3158 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:41,974] LMCache INFO:[0m Reqid: chatcmpl-3a328806bc6e4c6782ffbf8d0023381f, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,982] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-3a328806bc6e4c6782ffbf8d0023381f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:41,983] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.3632 ms, throughput: 8.2351 GB/s; offload_time: 0.3056 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,027] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f762ee4991614b61b67a494f243da0ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,027] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4290 ms, throughput: 7.9680 GB/s; offload_time: 0.3672 ms, put_time: 0.0618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,028] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-293646dc4f75452491b5e40bc55a508b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,029] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.7485 ms, throughput: 4.5666 GB/s; offload_time: 0.6922 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,042] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-49d5ee127a8a4e518bacef22b280ff2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,042] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3585 ms, throughput: 9.5340 GB/s; offload_time: 0.3011 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,049] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-b5d93938fb294bf4812b0a50028ca439 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,050] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4037 ms, throughput: 8.4663 GB/s; offload_time: 0.3434 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,065] LMCache INFO:[0m Reqid: chatcmpl-c9a01a2a1b434d2aa64facd7bb356516, Total tokens 729, LMCache hit tokens: 640, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,066] LMCache INFO:[0m Reqid: chatcmpl-02545549ee9d408e976f49c3777b773b, Total tokens 500, LMCache hit tokens: 384, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,077] LMCache INFO:[0m Storing KV cache for 729 out of 729 tokens (skip_leading_tokens=0) for request chatcmpl-c9a01a2a1b434d2aa64facd7bb356516 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,078] LMCache INFO:[0m Stored 89 out of total 729 tokens. size: 0.0024 gb, cost 0.4410 ms, throughput: 5.3888 GB/s; offload_time: 0.3835 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,078] LMCache INFO:[0m Storing KV cache for 500 out of 500 tokens (skip_leading_tokens=0) for request chatcmpl-02545549ee9d408e976f49c3777b773b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,079] LMCache INFO:[0m Stored 116 out of total 500 tokens. size: 0.0031 gb, cost 0.7246 ms, throughput: 4.2750 GB/s; offload_time: 0.6702 ms, put_time: 0.0543 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,086] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9e6bbcbf86ba488e9ed94de38143dc50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,087] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3939 ms, throughput: 8.6775 GB/s; offload_time: 0.3325 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,087] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-00097cfa980a428dbd839a4cbbe03dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,087] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4404 ms, throughput: 7.7603 GB/s; offload_time: 0.3909 ms, put_time: 0.0495 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,101] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-876e99d66fa045f0bdfa1870a0812b26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,102] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4388 ms, throughput: 7.7887 GB/s; offload_time: 0.3815 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,102] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3a328806bc6e4c6782ffbf8d0023381f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,103] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5558 ms, throughput: 6.1492 GB/s; offload_time: 0.4979 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,106] LMCache INFO:[0m Reqid: chatcmpl-38fd208477b049b3819c15a9949f62cf, Total tokens 130, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,114] LMCache INFO:[0m Storing KV cache for 130 out of 130 tokens (skip_leading_tokens=0) for request chatcmpl-38fd208477b049b3819c15a9949f62cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,115] LMCache INFO:[0m Stored 130 out of total 130 tokens. size: 0.0035 gb, cost 0.5483 ms, throughput: 6.3315 GB/s; offload_time: 0.4667 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,125] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-508aa5c2391b412694888a651ad90583 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,126] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3867 ms, throughput: 8.8393 GB/s; offload_time: 0.3277 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,170] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1e469a718deb47ac8f32b958e5d8d6f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,171] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4092 ms, throughput: 8.3535 GB/s; offload_time: 0.3490 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,171] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-02545549ee9d408e976f49c3777b773b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,172] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7193 ms, throughput: 4.7517 GB/s; offload_time: 0.6693 ms, put_time: 0.0500 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,175] LMCache INFO:[0m Reqid: chatcmpl-b7f5039055cb4bc09b069e1484891735, Total tokens 155, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,183] LMCache INFO:[0m Storing KV cache for 155 out of 155 tokens (skip_leading_tokens=0) for request chatcmpl-b7f5039055cb4bc09b069e1484891735 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,183] LMCache INFO:[0m Stored 27 out of total 155 tokens. size: 0.0007 gb, cost 0.3569 ms, throughput: 2.0201 GB/s; offload_time: 0.2937 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,183] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7577306bc72c400c984bdf447e14b5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,184] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7736 ms, throughput: 4.4185 GB/s; offload_time: 0.7088 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,185] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5af21303c2bf42dba43c2ef84246e571 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,185] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6228 ms, throughput: 5.4881 GB/s; offload_time: 0.5655 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,219] LMCache INFO:[0m Reqid: chatcmpl-080f4b42db99407394c7f9610b29b6fc, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,228] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-080f4b42db99407394c7f9610b29b6fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,228] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.3436 ms, throughput: 8.4716 GB/s; offload_time: 0.2861 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,298] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d530bc50fd5b4440a14cf58828bfb28c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,299] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3559 ms, throughput: 9.6025 GB/s; offload_time: 0.2994 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,303] LMCache INFO:[0m Reqid: chatcmpl-e6c16dcfb92b4e8eabc3048649ed5597, Total tokens 1436, LMCache hit tokens: 1408, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,311] LMCache INFO:[0m Storing KV cache for 1436 out of 1436 tokens (skip_leading_tokens=0) for request chatcmpl-e6c16dcfb92b4e8eabc3048649ed5597 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,311] LMCache INFO:[0m Stored 28 out of total 1436 tokens. size: 0.0007 gb, cost 0.5076 ms, throughput: 1.4731 GB/s; offload_time: 0.4502 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,325] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5c238323463c4de188b7e361eb99f665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,325] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3717 ms, throughput: 9.1946 GB/s; offload_time: 0.3144 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,332] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7e0ef3db76ac46bab37d59b7551ce1d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,333] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3562 ms, throughput: 9.5958 GB/s; offload_time: 0.2928 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,342] LMCache INFO:[0m Reqid: chatcmpl-8448f605f9c34038a5140fe8fa73a711, Total tokens 175, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,349] LMCache INFO:[0m Storing KV cache for 175 out of 175 tokens (skip_leading_tokens=0) for request chatcmpl-8448f605f9c34038a5140fe8fa73a711 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,350] LMCache INFO:[0m Stored 47 out of total 175 tokens. size: 0.0013 gb, cost 0.3866 ms, throughput: 3.2461 GB/s; offload_time: 0.3296 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,364] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-080f4b42db99407394c7f9610b29b6fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,364] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3477 ms, throughput: 9.8312 GB/s; offload_time: 0.2861 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,371] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-db31b04c088f45c68d8faecffc74805f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,372] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3883 ms, throughput: 8.8022 GB/s; offload_time: 0.3312 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,372] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c9a01a2a1b434d2aa64facd7bb356516 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,373] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5719 ms, throughput: 5.9767 GB/s; offload_time: 0.5239 ms, put_time: 0.0480 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,405] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0770d2fb3e7a4c29959f3883674e2e1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,406] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3801 ms, throughput: 8.9914 GB/s; offload_time: 0.3213 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,406] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,407] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6269 ms, throughput: 5.4520 GB/s; offload_time: 0.5700 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,426] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-49a0a03a35d34b95bb8446ff8d08b481 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,426] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.3920 ms, throughput: 8.7187 GB/s; offload_time: 0.3356 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,429] LMCache INFO:[0m Reqid: chatcmpl-3ee53c4f32ad4d64910fc967d8efb9c9, Total tokens 776, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,437] LMCache INFO:[0m Storing KV cache for 776 out of 776 tokens (skip_leading_tokens=0) for request chatcmpl-3ee53c4f32ad4d64910fc967d8efb9c9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,437] LMCache INFO:[0m Stored 136 out of total 776 tokens. size: 0.0036 gb, cost 0.5881 ms, throughput: 6.1754 GB/s; offload_time: 0.5024 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,471] LMCache INFO:[0m Reqid: chatcmpl-de9c43c903b0457abba37378c61a589f, Total tokens 1062, LMCache hit tokens: 1024, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,479] LMCache INFO:[0m Storing KV cache for 1062 out of 1062 tokens (skip_leading_tokens=0) for request chatcmpl-de9c43c903b0457abba37378c61a589f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,480] LMCache INFO:[0m Stored 38 out of total 1062 tokens. size: 0.0010 gb, cost 0.4642 ms, throughput: 2.1862 GB/s; offload_time: 0.4070 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,480] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9596c4845aff49df92fe56989aa0d210 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,481] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6302 ms, throughput: 5.4234 GB/s; offload_time: 0.5814 ms, put_time: 0.0488 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,495] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,495] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4099 ms, throughput: 8.3384 GB/s; offload_time: 0.3537 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,508] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e7b7fe05f5524eeebdb637b6abd33274 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,509] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3760 ms, throughput: 9.0897 GB/s; offload_time: 0.3132 ms, put_time: 0.0628 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,511] LMCache INFO:[0m Reqid: chatcmpl-ccd61e2f691a45d48be1aaa98d508cfd, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,518] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-ccd61e2f691a45d48be1aaa98d508cfd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,519] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.3416 ms, throughput: 7.4266 GB/s; offload_time: 0.2846 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,538] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d33de4ff868a4651b93edbdcf3e1ea1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,538] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3699 ms, throughput: 9.2398 GB/s; offload_time: 0.3102 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,557] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-ff670be03b0143d7b6c5a79f793c5443 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,558] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4495 ms, throughput: 7.6046 GB/s; offload_time: 0.3890 ms, put_time: 0.0605 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,561] LMCache INFO:[0m Reqid: chatcmpl-56235a63605740ea9046dc0a819755dd, Total tokens 791, LMCache hit tokens: 640, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,568] LMCache INFO:[0m Storing KV cache for 791 out of 791 tokens (skip_leading_tokens=0) for request chatcmpl-56235a63605740ea9046dc0a819755dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,569] LMCache INFO:[0m Stored 151 out of total 791 tokens. size: 0.0040 gb, cost 0.6220 ms, throughput: 6.4828 GB/s; offload_time: 0.5350 ms, put_time: 0.0869 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,577] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4ea3b1ef89764410af979b1b0c0ad4fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,577] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3651 ms, throughput: 9.3625 GB/s; offload_time: 0.3078 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,577] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-debca6bc941449b0840f48c5e82b3d35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,578] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4515 ms, throughput: 7.5708 GB/s; offload_time: 0.4008 ms, put_time: 0.0506 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,645] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-3f3716bc5e5d4905b2c791528d769732 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,645] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4395 ms, throughput: 7.7767 GB/s; offload_time: 0.3799 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,648] LMCache INFO:[0m Reqid: chatcmpl-47eea33f43e14bbba095786944c91661, Total tokens 1515, LMCache hit tokens: 1408, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,656] LMCache INFO:[0m Storing KV cache for 1515 out of 1515 tokens (skip_leading_tokens=0) for request chatcmpl-47eea33f43e14bbba095786944c91661 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,657] LMCache INFO:[0m Stored 107 out of total 1515 tokens. size: 0.0029 gb, cost 0.5088 ms, throughput: 5.6160 GB/s; offload_time: 0.4481 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,696] LMCache INFO:[0m Reqid: chatcmpl-d1d7b8c651d248b880972360dfb661d2, Total tokens 1357, LMCache hit tokens: 1280, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,704] LMCache INFO:[0m Storing KV cache for 1357 out of 1357 tokens (skip_leading_tokens=0) for request chatcmpl-d1d7b8c651d248b880972360dfb661d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,704] LMCache INFO:[0m Stored 77 out of total 1357 tokens. size: 0.0021 gb, cost 0.4988 ms, throughput: 4.1223 GB/s; offload_time: 0.4406 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,713] LMCache INFO:[0m Reqid: chatcmpl-a9870e5d494b4501897f1d0dbe490653, Total tokens 1482, LMCache hit tokens: 1408, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,721] LMCache INFO:[0m Storing KV cache for 1482 out of 1482 tokens (skip_leading_tokens=0) for request chatcmpl-a9870e5d494b4501897f1d0dbe490653 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,721] LMCache INFO:[0m Stored 74 out of total 1482 tokens. size: 0.0020 gb, cost 0.4976 ms, throughput: 3.9712 GB/s; offload_time: 0.4335 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,740] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,741] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.3977 ms, throughput: 8.5953 GB/s; offload_time: 0.3389 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,766] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,767] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4008 ms, throughput: 8.5272 GB/s; offload_time: 0.3410 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,781] LMCache INFO:[0m Reqid: chatcmpl-0839afaba0ae4e7e82e66cd72952b1a8, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,789] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-0839afaba0ae4e7e82e66cd72952b1a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,789] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3557 ms, throughput: 7.8069 GB/s; offload_time: 0.2984 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,809] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-47eea33f43e14bbba095786944c91661 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,809] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4339 ms, throughput: 7.8766 GB/s; offload_time: 0.3742 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,819] LMCache INFO:[0m Reqid: chatcmpl-878edd68d7f84929ad4f320f2543c44c, Total tokens 1281, LMCache hit tokens: 1152, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,819] LMCache INFO:[0m Reqid: chatcmpl-9b3f83f7c0a841d29c8f21ffd6302ef6, Total tokens 197, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,829] LMCache INFO:[0m Storing KV cache for 1281 out of 1281 tokens (skip_leading_tokens=0) for request chatcmpl-878edd68d7f84929ad4f320f2543c44c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,829] LMCache INFO:[0m Stored 129 out of total 1281 tokens. size: 0.0034 gb, cost 0.6554 ms, throughput: 5.2557 GB/s; offload_time: 0.5655 ms, put_time: 0.0899 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,830] LMCache INFO:[0m Storing KV cache for 197 out of 197 tokens (skip_leading_tokens=0) for request chatcmpl-9b3f83f7c0a841d29c8f21ffd6302ef6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,831] LMCache INFO:[0m Stored 197 out of total 197 tokens. size: 0.0053 gb, cost 1.2055 ms, throughput: 4.3639 GB/s; offload_time: 1.0737 ms, put_time: 0.1317 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,846] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,846] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4157 ms, throughput: 8.2221 GB/s; offload_time: 0.3541 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,853] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f54cf82070a840169e1a2944fb7f2a49 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,854] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.3931 ms, throughput: 8.6946 GB/s; offload_time: 0.3369 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,857] LMCache INFO:[0m Reqid: chatcmpl-49fe7cc1701a4c379145bed974452bf1, Total tokens 862, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,866] LMCache INFO:[0m Storing KV cache for 862 out of 862 tokens (skip_leading_tokens=0) for request chatcmpl-49fe7cc1701a4c379145bed974452bf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,867] LMCache INFO:[0m Stored 222 out of total 862 tokens. size: 0.0059 gb, cost 0.6073 ms, throughput: 9.7619 GB/s; offload_time: 0.5252 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,892] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2ad30dc3f92d4a4fa9bb16704b80d1cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,893] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3637 ms, throughput: 9.3970 GB/s; offload_time: 0.3010 ms, put_time: 0.0628 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,908] LMCache INFO:[0m Reqid: chatcmpl-4963bcec1a464669a10ce5a7593dca01, Total tokens 1012, LMCache hit tokens: 896, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,916] LMCache INFO:[0m Storing KV cache for 1012 out of 1012 tokens (skip_leading_tokens=0) for request chatcmpl-4963bcec1a464669a10ce5a7593dca01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,916] LMCache INFO:[0m Stored 116 out of total 1012 tokens. size: 0.0031 gb, cost 0.4580 ms, throughput: 6.7638 GB/s; offload_time: 0.3935 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,923] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b7f5039055cb4bc09b069e1484891735 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,924] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3576 ms, throughput: 9.5569 GB/s; offload_time: 0.3017 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,946] LMCache INFO:[0m Reqid: chatcmpl-b190c95cc7794fbc8d667784c3e8a3fd, Total tokens 1637, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,953] LMCache INFO:[0m Storing KV cache for 1637 out of 1637 tokens (skip_leading_tokens=0) for request chatcmpl-b190c95cc7794fbc8d667784c3e8a3fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,954] LMCache INFO:[0m Stored 101 out of total 1637 tokens. size: 0.0027 gb, cost 0.5058 ms, throughput: 5.3323 GB/s; offload_time: 0.4450 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,969] LMCache INFO:[0m Reqid: chatcmpl-3ebf9f9583924e239b785f300fa37eb7, Total tokens 333, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,976] LMCache INFO:[0m Storing KV cache for 333 out of 333 tokens (skip_leading_tokens=0) for request chatcmpl-3ebf9f9583924e239b785f300fa37eb7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,976] LMCache INFO:[0m Stored 77 out of total 333 tokens. size: 0.0021 gb, cost 0.4069 ms, throughput: 5.0527 GB/s; offload_time: 0.3498 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:42,977] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-0839afaba0ae4e7e82e66cd72952b1a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,978] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6932 ms, throughput: 4.9306 GB/s; offload_time: 0.6426 ms, put_time: 0.0506 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:42,998] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-49d5ee127a8a4e518bacef22b280ff2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:42,998] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3597 ms, throughput: 9.5033 GB/s; offload_time: 0.3033 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,001] LMCache INFO:[0m Reqid: chatcmpl-82409e762a3e468284186f0362e3ec15, Total tokens 669, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,010] LMCache INFO:[0m Storing KV cache for 669 out of 669 tokens (skip_leading_tokens=0) for request chatcmpl-82409e762a3e468284186f0362e3ec15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,010] LMCache INFO:[0m Stored 157 out of total 669 tokens. size: 0.0042 gb, cost 0.6014 ms, throughput: 6.9712 GB/s; offload_time: 0.5132 ms, put_time: 0.0882 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,011] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4963bcec1a464669a10ce5a7593dca01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,012] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1872 ms, throughput: 2.8791 GB/s; offload_time: 1.1387 ms, put_time: 0.0485 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,038] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-00097cfa980a428dbd839a4cbbe03dd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,038] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3578 ms, throughput: 9.5524 GB/s; offload_time: 0.3011 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,045] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-38fd208477b049b3819c15a9949f62cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,046] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3560 ms, throughput: 9.6019 GB/s; offload_time: 0.3000 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,053] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-876e99d66fa045f0bdfa1870a0812b26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,053] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4555 ms, throughput: 7.5035 GB/s; offload_time: 0.3978 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,054] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3a328806bc6e4c6782ffbf8d0023381f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,054] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5189 ms, throughput: 6.5867 GB/s; offload_time: 0.4646 ms, put_time: 0.0543 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,055] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-e6c16dcfb92b4e8eabc3048649ed5597 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,056] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9766 ms, throughput: 3.4998 GB/s; offload_time: 0.9259 ms, put_time: 0.0508 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,059] LMCache INFO:[0m Reqid: chatcmpl-f557c8ed5ab54e3eab2bcc955c353eb5, Total tokens 882, LMCache hit tokens: 768, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,060] LMCache INFO:[0m Reqid: chatcmpl-f1307ae272ba43c1b80d9a3c034ffd4d, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,071] LMCache INFO:[0m Storing KV cache for 882 out of 882 tokens (skip_leading_tokens=0) for request chatcmpl-f557c8ed5ab54e3eab2bcc955c353eb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,072] LMCache INFO:[0m Stored 114 out of total 882 tokens. size: 0.0030 gb, cost 0.4259 ms, throughput: 7.1474 GB/s; offload_time: 0.3690 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,072] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-f1307ae272ba43c1b80d9a3c034ffd4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,073] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.5051 ms, throughput: 5.7101 GB/s; offload_time: 0.4570 ms, put_time: 0.0480 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,087] LMCache INFO:[0m Reqid: chatcmpl-9ee08b3f96af4874a2919f9e3bf5502e, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,095] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-9ee08b3f96af4874a2919f9e3bf5502e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,096] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.3645 ms, throughput: 7.8382 GB/s; offload_time: 0.3068 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,109] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-d1d7b8c651d248b880972360dfb661d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,110] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4250 ms, throughput: 8.0420 GB/s; offload_time: 0.3638 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,129] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-02545549ee9d408e976f49c3777b773b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,130] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3784 ms, throughput: 9.0331 GB/s; offload_time: 0.3217 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,130] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-49fe7cc1701a4c379145bed974452bf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,131] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7142 ms, throughput: 4.7860 GB/s; offload_time: 0.6638 ms, put_time: 0.0504 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,134] LMCache INFO:[0m Reqid: chatcmpl-1a58996c436445ff9bc5a5a841951cd2, Total tokens 953, LMCache hit tokens: 896, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,142] LMCache INFO:[0m Storing KV cache for 953 out of 953 tokens (skip_leading_tokens=0) for request chatcmpl-1a58996c436445ff9bc5a5a841951cd2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,143] LMCache INFO:[0m Stored 57 out of total 953 tokens. size: 0.0015 gb, cost 0.4400 ms, throughput: 3.4592 GB/s; offload_time: 0.3812 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,143] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7577306bc72c400c984bdf447e14b5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,144] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4955 ms, throughput: 6.8984 GB/s; offload_time: 0.4440 ms, put_time: 0.0514 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,144] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-a9870e5d494b4501897f1d0dbe490653 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,145] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5431 ms, throughput: 6.2939 GB/s; offload_time: 0.4942 ms, put_time: 0.0489 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,148] LMCache INFO:[0m Reqid: chatcmpl-1b96c188cb39479db87dbb9098a26508, Total tokens 443, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,156] LMCache INFO:[0m Storing KV cache for 443 out of 443 tokens (skip_leading_tokens=0) for request chatcmpl-1b96c188cb39479db87dbb9098a26508 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,157] LMCache INFO:[0m Stored 59 out of total 443 tokens. size: 0.0016 gb, cost 0.3821 ms, throughput: 4.1227 GB/s; offload_time: 0.3245 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,176] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-b190c95cc7794fbc8d667784c3e8a3fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,177] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4372 ms, throughput: 7.8176 GB/s; offload_time: 0.3793 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,184] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f557c8ed5ab54e3eab2bcc955c353eb5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,184] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4064 ms, throughput: 8.4111 GB/s; offload_time: 0.3443 ms, put_time: 0.0621 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,187] LMCache INFO:[0m Reqid: chatcmpl-8c51d25b6fe9480c97a626083e173060, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,195] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-8c51d25b6fe9480c97a626083e173060 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,195] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3634 ms, throughput: 7.3488 GB/s; offload_time: 0.3036 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,210] LMCache INFO:[0m Reqid: chatcmpl-56b4d226f3924abd9c7465b24d7ae64a, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,218] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-56b4d226f3924abd9c7465b24d7ae64a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,219] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.3715 ms, throughput: 7.2607 GB/s; offload_time: 0.3071 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,232] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f1307ae272ba43c1b80d9a3c034ffd4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,232] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3480 ms, throughput: 9.8207 GB/s; offload_time: 0.2834 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,242] LMCache INFO:[0m Reqid: chatcmpl-e4f3a1a001664122a15ed16bdb2f2492, Total tokens 650, LMCache hit tokens: 512, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,249] LMCache INFO:[0m Storing KV cache for 650 out of 650 tokens (skip_leading_tokens=0) for request chatcmpl-e4f3a1a001664122a15ed16bdb2f2492 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,250] LMCache INFO:[0m Stored 138 out of total 650 tokens. size: 0.0037 gb, cost 0.5873 ms, throughput: 6.2741 GB/s; offload_time: 0.5030 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,264] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9ee08b3f96af4874a2919f9e3bf5502e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,265] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3559 ms, throughput: 9.6028 GB/s; offload_time: 0.2980 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,274] LMCache INFO:[0m Reqid: chatcmpl-e64231d8ffd74ba3a9dff0dcb92416af, Total tokens 1882, LMCache hit tokens: 1664, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,284] LMCache INFO:[0m Storing KV cache for 1882 out of 1882 tokens (skip_leading_tokens=0) for request chatcmpl-e64231d8ffd74ba3a9dff0dcb92416af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,285] LMCache INFO:[0m Stored 218 out of total 1882 tokens. size: 0.0058 gb, cost 0.6807 ms, throughput: 8.5514 GB/s; offload_time: 0.5983 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,305] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5c238323463c4de188b7e361eb99f665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,306] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3747 ms, throughput: 9.1225 GB/s; offload_time: 0.3162 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,306] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9b3f83f7c0a841d29c8f21ffd6302ef6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,307] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6119 ms, throughput: 5.5860 GB/s; offload_time: 0.5569 ms, put_time: 0.0550 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,314] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7e0ef3db76ac46bab37d59b7551ce1d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,315] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3607 ms, throughput: 9.4759 GB/s; offload_time: 0.3052 ms, put_time: 0.0555 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,317] LMCache INFO:[0m Reqid: chatcmpl-de114038ae444f6bb87611f2623c01f1, Total tokens 342, LMCache hit tokens: 256, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,325] LMCache INFO:[0m Storing KV cache for 342 out of 342 tokens (skip_leading_tokens=0) for request chatcmpl-de114038ae444f6bb87611f2623c01f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,326] LMCache INFO:[0m Stored 86 out of total 342 tokens. size: 0.0023 gb, cost 0.4054 ms, throughput: 5.6650 GB/s; offload_time: 0.3479 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,345] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-080f4b42db99407394c7f9610b29b6fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,346] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3590 ms, throughput: 9.5218 GB/s; offload_time: 0.3016 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,348] LMCache INFO:[0m Reqid: chatcmpl-7d7b4e1dffc34523a5d759581ff6ccfa, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,356] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-7d7b4e1dffc34523a5d759581ff6ccfa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,357] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.3579 ms, throughput: 7.6857 GB/s; offload_time: 0.2922 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,364] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-3ee53c4f32ad4d64910fc967d8efb9c9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,365] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4056 ms, throughput: 8.4276 GB/s; offload_time: 0.3485 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,384] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-56235a63605740ea9046dc0a819755dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,385] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.3928 ms, throughput: 8.7016 GB/s; offload_time: 0.3354 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,392] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,393] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3659 ms, throughput: 9.3420 GB/s; offload_time: 0.3081 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,393] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3ebf9f9583924e239b785f300fa37eb7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,394] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6854 ms, throughput: 4.9868 GB/s; offload_time: 0.6356 ms, put_time: 0.0498 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,413] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-8c51d25b6fe9480c97a626083e173060 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,414] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3485 ms, throughput: 9.8064 GB/s; offload_time: 0.2902 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,416] LMCache INFO:[0m Reqid: chatcmpl-83c37b91dd4541baa8ddb4f0d7311f93, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,424] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-83c37b91dd4541baa8ddb4f0d7311f93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,424] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.3537 ms, throughput: 7.2478 GB/s; offload_time: 0.2851 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,432] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-56b4d226f3924abd9c7465b24d7ae64a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,432] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3491 ms, throughput: 9.7919 GB/s; offload_time: 0.2918 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,459] LMCache INFO:[0m Reqid: chatcmpl-82c53220ded74f2d9b4c47b97f8f490d, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,466] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-82c53220ded74f2d9b4c47b97f8f490d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,467] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3645 ms, throughput: 7.3251 GB/s; offload_time: 0.3039 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,467] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9596c4845aff49df92fe56989aa0d210 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,468] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5548 ms, throughput: 6.1606 GB/s; offload_time: 0.4995 ms, put_time: 0.0553 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,482] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,482] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4105 ms, throughput: 8.3255 GB/s; offload_time: 0.3521 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,521] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d33de4ff868a4651b93edbdcf3e1ea1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,522] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3782 ms, throughput: 9.0382 GB/s; offload_time: 0.3215 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,535] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7d7b4e1dffc34523a5d759581ff6ccfa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,535] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3452 ms, throughput: 9.9008 GB/s; offload_time: 0.2881 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,561] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-e64231d8ffd74ba3a9dff0dcb92416af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,561] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.4536 ms, throughput: 7.5347 GB/s; offload_time: 0.3977 ms, put_time: 0.0560 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,576] LMCache INFO:[0m Reqid: chatcmpl-29d59d6f972144309a3a5bdf6130c844, Total tokens 524, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,584] LMCache INFO:[0m Storing KV cache for 524 out of 524 tokens (skip_leading_tokens=0) for request chatcmpl-29d59d6f972144309a3a5bdf6130c844 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,584] LMCache INFO:[0m Stored 12 out of total 524 tokens. size: 0.0003 gb, cost 0.4064 ms, throughput: 0.7885 GB/s; offload_time: 0.3450 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,622] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-de114038ae444f6bb87611f2623c01f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,622] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3684 ms, throughput: 9.2787 GB/s; offload_time: 0.3103 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,629] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-3f3716bc5e5d4905b2c791528d769732 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,630] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5989 ms, throughput: 5.7075 GB/s; offload_time: 0.5400 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,633] LMCache INFO:[0m Reqid: chatcmpl-3b5205c18a18419181925d877b6ef5db, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,633] LMCache INFO:[0m Reqid: chatcmpl-21339de9458646819a904bc163cd3014, Total tokens 913, LMCache hit tokens: 768, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,645] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-3b5205c18a18419181925d877b6ef5db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,646] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.4553 ms, throughput: 7.0382 GB/s; offload_time: 0.3975 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,646] LMCache INFO:[0m Storing KV cache for 913 out of 913 tokens (skip_leading_tokens=0) for request chatcmpl-21339de9458646819a904bc163cd3014 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,647] LMCache INFO:[0m Stored 145 out of total 913 tokens. size: 0.0039 gb, cost 1.0053 ms, throughput: 3.8514 GB/s; offload_time: 0.9283 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,670] LMCache INFO:[0m Reqid: chatcmpl-24674921610540cb80599e79d1d05e57, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,677] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-24674921610540cb80599e79d1d05e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,678] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.4132 ms, throughput: 6.3335 GB/s; offload_time: 0.3518 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,678] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1b96c188cb39479db87dbb9098a26508 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,679] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.8348 ms, throughput: 4.0945 GB/s; offload_time: 0.7799 ms, put_time: 0.0549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,686] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1a58996c436445ff9bc5a5a841951cd2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,687] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4546 ms, throughput: 7.5187 GB/s; offload_time: 0.3965 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,705] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3b5205c18a18419181925d877b6ef5db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,706] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3871 ms, throughput: 8.8291 GB/s; offload_time: 0.3268 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,715] LMCache INFO:[0m Reqid: chatcmpl-eb995b0455974917a427a3621465486f, Total tokens 1032, LMCache hit tokens: 896, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,725] LMCache INFO:[0m Storing KV cache for 1032 out of 1032 tokens (skip_leading_tokens=0) for request chatcmpl-eb995b0455974917a427a3621465486f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,725] LMCache INFO:[0m Stored 136 out of total 1032 tokens. size: 0.0036 gb, cost 0.6282 ms, throughput: 5.7810 GB/s; offload_time: 0.5390 ms, put_time: 0.0891 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,733] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,734] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4466 ms, throughput: 7.6532 GB/s; offload_time: 0.3879 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,755] LMCache INFO:[0m Reqid: chatcmpl-44412fa677db46c3adfc498ecdd34e10, Total tokens 510, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,762] LMCache INFO:[0m Storing KV cache for 510 out of 510 tokens (skip_leading_tokens=0) for request chatcmpl-44412fa677db46c3adfc498ecdd34e10 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,763] LMCache INFO:[0m Stored 126 out of total 510 tokens. size: 0.0034 gb, cost 0.4475 ms, throughput: 7.5189 GB/s; offload_time: 0.3902 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,763] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4ec9528f14c44797a6bc6d1d07f95b18 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,764] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7692 ms, throughput: 4.4438 GB/s; offload_time: 0.7186 ms, put_time: 0.0505 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,778] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-82409e762a3e468284186f0362e3ec15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,778] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4401 ms, throughput: 7.7668 GB/s; offload_time: 0.3837 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,778] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-44412fa677db46c3adfc498ecdd34e10 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,779] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7633 ms, throughput: 4.4778 GB/s; offload_time: 0.7120 ms, put_time: 0.0514 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,805] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-47eea33f43e14bbba095786944c91661 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,806] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4900 ms, throughput: 6.9756 GB/s; offload_time: 0.4292 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,813] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-878edd68d7f84929ad4f320f2543c44c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,814] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5017 ms, throughput: 6.8122 GB/s; offload_time: 0.4440 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,816] LMCache INFO:[0m Reqid: chatcmpl-1d67be5e68704e14a4f10224c956611f, Total tokens 775, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,817] LMCache INFO:[0m Reqid: chatcmpl-61a1f79020744250874b13a3a7183652, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,827] LMCache INFO:[0m Storing KV cache for 775 out of 775 tokens (skip_leading_tokens=0) for request chatcmpl-1d67be5e68704e14a4f10224c956611f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,828] LMCache INFO:[0m Stored 135 out of total 775 tokens. size: 0.0036 gb, cost 0.6512 ms, throughput: 5.5360 GB/s; offload_time: 0.5627 ms, put_time: 0.0885 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,828] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-61a1f79020744250874b13a3a7183652 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,829] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.8773 ms, throughput: 3.0133 GB/s; offload_time: 0.6411 ms, put_time: 0.2362 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,843] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,844] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4523 ms, throughput: 7.5566 GB/s; offload_time: 0.3961 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,851] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f54cf82070a840169e1a2944fb7f2a49 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,851] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4423 ms, throughput: 7.7271 GB/s; offload_time: 0.3840 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,873] LMCache INFO:[0m Reqid: chatcmpl-0147d1e5cd264684beed656a0ec7076a, Total tokens 437, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,880] LMCache INFO:[0m Storing KV cache for 437 out of 437 tokens (skip_leading_tokens=0) for request chatcmpl-0147d1e5cd264684beed656a0ec7076a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,881] LMCache INFO:[0m Stored 53 out of total 437 tokens. size: 0.0014 gb, cost 0.4072 ms, throughput: 3.4753 GB/s; offload_time: 0.3490 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,889] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2ad30dc3f92d4a4fa9bb16704b80d1cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,889] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4145 ms, throughput: 8.2463 GB/s; offload_time: 0.3551 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,904] LMCache INFO:[0m Reqid: chatcmpl-e8ce6065c30c4884a74eaaba2476adaf, Total tokens 128, LMCache hit tokens: 0, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,912] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e8ce6065c30c4884a74eaaba2476adaf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,912] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3821 ms, throughput: 8.9442 GB/s; offload_time: 0.3249 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,912] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-24674921610540cb80599e79d1d05e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,913] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5181 ms, throughput: 6.5975 GB/s; offload_time: 0.4663 ms, put_time: 0.0518 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,920] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b7f5039055cb4bc09b069e1484891735 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,921] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4588 ms, throughput: 7.4496 GB/s; offload_time: 0.3970 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,929] LMCache INFO:[0m Reqid: chatcmpl-115fe3fd554e47c8972f456a54943a3f, Total tokens 562, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,942] LMCache INFO:[0m Storing KV cache for 562 out of 562 tokens (skip_leading_tokens=0) for request chatcmpl-115fe3fd554e47c8972f456a54943a3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,943] LMCache INFO:[0m Stored 434 out of total 562 tokens. size: 0.0116 gb, cost 1.0920 ms, throughput: 10.6123 GB/s; offload_time: 0.8375 ms, put_time: 0.2545 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:43,978] LMCache INFO:[0m Reqid: chatcmpl-24c6335346744f118acef4f3fe9b6c73, Total tokens 544, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,979] LMCache INFO:[0m Reqid: chatcmpl-564ef89f352e47d18dbd89abcb2f33ac, Total tokens 346, LMCache hit tokens: 256, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,990] LMCache INFO:[0m Storing KV cache for 544 out of 544 tokens (skip_leading_tokens=0) for request chatcmpl-24c6335346744f118acef4f3fe9b6c73 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,991] LMCache INFO:[0m Stored 32 out of total 544 tokens. size: 0.0009 gb, cost 0.4324 ms, throughput: 1.9763 GB/s; offload_time: 0.3736 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:43,991] LMCache INFO:[0m Storing KV cache for 346 out of 346 tokens (skip_leading_tokens=0) for request chatcmpl-564ef89f352e47d18dbd89abcb2f33ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:43,991] LMCache INFO:[0m Stored 90 out of total 346 tokens. size: 0.0024 gb, cost 0.6686 ms, throughput: 3.5943 GB/s; offload_time: 0.6119 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,001] LMCache INFO:[0m Reqid: chatcmpl-b13879b424ff4d5a88f4aa62abd175ba, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,009] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-b13879b424ff4d5a88f4aa62abd175ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,010] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.3816 ms, throughput: 7.3473 GB/s; offload_time: 0.3158 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,017] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-4963bcec1a464669a10ce5a7593dca01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,017] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4751 ms, throughput: 7.1947 GB/s; offload_time: 0.4095 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,038] LMCache INFO:[0m Reqid: chatcmpl-af577561c28d4f83bb32f2d19cc53a04, Total tokens 116, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,047] LMCache INFO:[0m Storing KV cache for 116 out of 116 tokens (skip_leading_tokens=0) for request chatcmpl-af577561c28d4f83bb32f2d19cc53a04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,048] LMCache INFO:[0m Stored 116 out of total 116 tokens. size: 0.0031 gb, cost 0.4325 ms, throughput: 7.1611 GB/s; offload_time: 0.3751 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,062] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-876e99d66fa045f0bdfa1870a0812b26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,062] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5450 ms, throughput: 6.2715 GB/s; offload_time: 0.4788 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,063] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3a328806bc6e4c6782ffbf8d0023381f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,063] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6411 ms, throughput: 5.3312 GB/s; offload_time: 0.5810 ms, put_time: 0.0601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,064] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-e6c16dcfb92b4e8eabc3048649ed5597 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,064] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.7627 ms, throughput: 4.4817 GB/s; offload_time: 0.7123 ms, put_time: 0.0503 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,065] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-61a1f79020744250874b13a3a7183652 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,066] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1488 ms, throughput: 2.9753 GB/s; offload_time: 1.0923 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,069] LMCache INFO:[0m Reqid: chatcmpl-575f908b2f3e4df39a2cbd9780c0bceb, Total tokens 164, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,078] LMCache INFO:[0m Storing KV cache for 164 out of 164 tokens (skip_leading_tokens=0) for request chatcmpl-575f908b2f3e4df39a2cbd9780c0bceb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,078] LMCache INFO:[0m Stored 36 out of total 164 tokens. size: 0.0010 gb, cost 0.3839 ms, throughput: 2.5040 GB/s; offload_time: 0.3233 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,106] LMCache INFO:[0m Reqid: chatcmpl-9cf6a545b78346dc93cc8ee4336c4382, Total tokens 131, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,114] LMCache INFO:[0m Storing KV cache for 131 out of 131 tokens (skip_leading_tokens=0) for request chatcmpl-9cf6a545b78346dc93cc8ee4336c4382 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,114] LMCache INFO:[0m Stored 131 out of total 131 tokens. size: 0.0035 gb, cost 0.6734 ms, throughput: 5.1946 GB/s; offload_time: 0.5887 ms, put_time: 0.0847 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,115] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d1d7b8c651d248b880972360dfb661d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,116] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5846 ms, throughput: 2.1570 GB/s; offload_time: 1.5291 ms, put_time: 0.0554 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,132] LMCache INFO:[0m Reqid: chatcmpl-0e0aaefe4ab84df5a51a025ec5f294cd, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,141] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-0e0aaefe4ab84df5a51a025ec5f294cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,142] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.3761 ms, throughput: 8.0948 GB/s; offload_time: 0.3131 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,142] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-49fe7cc1701a4c379145bed974452bf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,143] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7619 ms, throughput: 4.4863 GB/s; offload_time: 0.7099 ms, put_time: 0.0519 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,151] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-a9870e5d494b4501897f1d0dbe490653 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,152] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5755 ms, throughput: 5.9393 GB/s; offload_time: 0.5179 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,152] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-af577561c28d4f83bb32f2d19cc53a04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,153] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5946 ms, throughput: 5.7481 GB/s; offload_time: 0.5428 ms, put_time: 0.0519 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,179] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-b190c95cc7794fbc8d667784c3e8a3fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,180] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5189 ms, throughput: 6.5867 GB/s; offload_time: 0.4629 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,183] LMCache INFO:[0m Reqid: chatcmpl-447919478ff34a6bb79f45d8650135e4, Total tokens 382, LMCache hit tokens: 256, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,191] LMCache INFO:[0m Storing KV cache for 382 out of 382 tokens (skip_leading_tokens=0) for request chatcmpl-447919478ff34a6bb79f45d8650135e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,192] LMCache INFO:[0m Stored 126 out of total 382 tokens. size: 0.0034 gb, cost 0.4747 ms, throughput: 7.0882 GB/s; offload_time: 0.4110 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,199] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-b13879b424ff4d5a88f4aa62abd175ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,199] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4128 ms, throughput: 8.2807 GB/s; offload_time: 0.3559 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,206] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-447919478ff34a6bb79f45d8650135e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,207] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4391 ms, throughput: 7.7844 GB/s; offload_time: 0.3777 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,216] LMCache INFO:[0m Reqid: chatcmpl-ceba114606a941a1996faeddbb0919c0, Total tokens 198, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,223] LMCache INFO:[0m Storing KV cache for 198 out of 198 tokens (skip_leading_tokens=0) for request chatcmpl-ceba114606a941a1996faeddbb0919c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,224] LMCache INFO:[0m Stored 70 out of total 198 tokens. size: 0.0019 gb, cost 0.3924 ms, throughput: 4.7636 GB/s; offload_time: 0.3288 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,238] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f1307ae272ba43c1b80d9a3c034ffd4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,238] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4331 ms, throughput: 7.8916 GB/s; offload_time: 0.3726 ms, put_time: 0.0605 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,251] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-0e0aaefe4ab84df5a51a025ec5f294cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,252] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4112 ms, throughput: 8.3118 GB/s; offload_time: 0.3550 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,260] LMCache INFO:[0m Reqid: chatcmpl-f37e2ba2168b48d988fb195e04069dde, Total tokens 946, LMCache hit tokens: 896, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,269] LMCache INFO:[0m Storing KV cache for 946 out of 946 tokens (skip_leading_tokens=0) for request chatcmpl-f37e2ba2168b48d988fb195e04069dde [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,270] LMCache INFO:[0m Stored 50 out of total 946 tokens. size: 0.0013 gb, cost 0.6289 ms, throughput: 2.1229 GB/s; offload_time: 0.5682 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,278] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9ee08b3f96af4874a2919f9e3bf5502e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,278] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4350 ms, throughput: 7.8582 GB/s; offload_time: 0.3771 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,287] LMCache INFO:[0m Reqid: chatcmpl-06b8f41bafda4767b02a8fed53faa3b7, Total tokens 391, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,300] LMCache INFO:[0m Storing KV cache for 391 out of 391 tokens (skip_leading_tokens=0) for request chatcmpl-06b8f41bafda4767b02a8fed53faa3b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,301] LMCache INFO:[0m Stored 391 out of total 391 tokens. size: 0.0104 gb, cost 1.1790 ms, throughput: 8.8558 GB/s; offload_time: 0.9145 ms, put_time: 0.2645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,312] LMCache INFO:[0m Reqid: chatcmpl-282d830ef9974a31a2965a8a154cfc8e, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,321] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-282d830ef9974a31a2965a8a154cfc8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,322] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.4113 ms, throughput: 6.8816 GB/s; offload_time: 0.3522 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,322] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-564ef89f352e47d18dbd89abcb2f33ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,323] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7534 ms, throughput: 4.5368 GB/s; offload_time: 0.6921 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,369] LMCache INFO:[0m Reqid: chatcmpl-ff235ba6b2c24ec7bcdc390a3ffe9ee0, Total tokens 1042, LMCache hit tokens: 896, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,378] LMCache INFO:[0m Storing KV cache for 1042 out of 1042 tokens (skip_leading_tokens=0) for request chatcmpl-ff235ba6b2c24ec7bcdc390a3ffe9ee0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,379] LMCache INFO:[0m Stored 146 out of total 1042 tokens. size: 0.0039 gb, cost 0.7119 ms, throughput: 5.4764 GB/s; offload_time: 0.6226 ms, put_time: 0.0893 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,400] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-56235a63605740ea9046dc0a819755dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,400] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4827 ms, throughput: 7.0814 GB/s; offload_time: 0.4248 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,407] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-81c14f43287a47bdb6bd40150ff3e1eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,408] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4430 ms, throughput: 7.7152 GB/s; offload_time: 0.3847 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,408] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3ebf9f9583924e239b785f300fa37eb7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,409] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6063 ms, throughput: 5.6372 GB/s; offload_time: 0.5499 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,449] LMCache INFO:[0m Reqid: chatcmpl-da9d2bf49fd544229c69d85c7eee0c68, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,458] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-da9d2bf49fd544229c69d85c7eee0c68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,458] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3767 ms, throughput: 7.3717 GB/s; offload_time: 0.3168 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,478] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-282d830ef9974a31a2965a8a154cfc8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,479] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4127 ms, throughput: 8.2816 GB/s; offload_time: 0.3559 ms, put_time: 0.0568 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,492] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,493] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4977 ms, throughput: 6.8676 GB/s; offload_time: 0.4353 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,493] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0147d1e5cd264684beed656a0ec7076a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,494] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7522 ms, throughput: 4.5437 GB/s; offload_time: 0.6946 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,514] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-29d59d6f972144309a3a5bdf6130c844 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,514] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4553 ms, throughput: 7.5072 GB/s; offload_time: 0.3979 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,534] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-21339de9458646819a904bc163cd3014 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,535] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4901 ms, throughput: 6.9747 GB/s; offload_time: 0.4315 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,548] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7d7b4e1dffc34523a5d759581ff6ccfa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,549] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4258 ms, throughput: 8.0265 GB/s; offload_time: 0.3702 ms, put_time: 0.0556 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,562] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-115fe3fd554e47c8972f456a54943a3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,563] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4505 ms, throughput: 7.5870 GB/s; offload_time: 0.3947 ms, put_time: 0.0558 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,620] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-da9d2bf49fd544229c69d85c7eee0c68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,621] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4308 ms, throughput: 7.9339 GB/s; offload_time: 0.3654 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,640] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-3f3716bc5e5d4905b2c791528d769732 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,641] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5155 ms, throughput: 6.6299 GB/s; offload_time: 0.4592 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,655] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ceba114606a941a1996faeddbb0919c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,655] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4303 ms, throughput: 7.9437 GB/s; offload_time: 0.3689 ms, put_time: 0.0614 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,662] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-eb995b0455974917a427a3621465486f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,663] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4848 ms, throughput: 7.0500 GB/s; offload_time: 0.4277 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,676] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1b96c188cb39479db87dbb9098a26508 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,677] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4577 ms, throughput: 7.4680 GB/s; offload_time: 0.3957 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,680] LMCache INFO:[0m Reqid: chatcmpl-3e9c956e59fb45de932b3ad16fc228f6, Total tokens 261, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,687] LMCache INFO:[0m Storing KV cache for 261 out of 261 tokens (skip_leading_tokens=0) for request chatcmpl-3e9c956e59fb45de932b3ad16fc228f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,688] LMCache INFO:[0m Stored 133 out of total 261 tokens. size: 0.0036 gb, cost 0.8973 ms, throughput: 3.9579 GB/s; offload_time: 0.8141 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,689] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1a58996c436445ff9bc5a5a841951cd2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,690] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0722 ms, throughput: 3.1877 GB/s; offload_time: 1.0125 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,694] LMCache INFO:[0m Reqid: chatcmpl-2f85ef31846d41079f1b216cb2acbe09, Total tokens 1715, LMCache hit tokens: 1664, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,702] LMCache INFO:[0m Storing KV cache for 1715 out of 1715 tokens (skip_leading_tokens=0) for request chatcmpl-2f85ef31846d41079f1b216cb2acbe09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,702] LMCache INFO:[0m Stored 51 out of total 1715 tokens. size: 0.0014 gb, cost 0.4852 ms, throughput: 2.8070 GB/s; offload_time: 0.4220 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,716] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3b5205c18a18419181925d877b6ef5db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,716] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4364 ms, throughput: 7.8318 GB/s; offload_time: 0.3801 ms, put_time: 0.0563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,736] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-bb8c571a8d774a1aa16595164ec1c4ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,737] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4928 ms, throughput: 6.9356 GB/s; offload_time: 0.4367 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,737] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-24c6335346744f118acef4f3fe9b6c73 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,738] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5658 ms, throughput: 6.0407 GB/s; offload_time: 0.5058 ms, put_time: 0.0600 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,765] LMCache INFO:[0m Reqid: chatcmpl-25c95f602eb545159ffead8f41431eec, Total tokens 167, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,773] LMCache INFO:[0m Storing KV cache for 167 out of 167 tokens (skip_leading_tokens=0) for request chatcmpl-25c95f602eb545159ffead8f41431eec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,774] LMCache INFO:[0m Stored 39 out of total 167 tokens. size: 0.0010 gb, cost 0.4005 ms, throughput: 2.6004 GB/s; offload_time: 0.3349 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,774] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1d67be5e68704e14a4f10224c956611f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,775] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7005 ms, throughput: 4.8793 GB/s; offload_time: 0.6480 ms, put_time: 0.0525 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,783] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-82409e762a3e468284186f0362e3ec15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,783] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4695 ms, throughput: 7.2796 GB/s; offload_time: 0.4123 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,783] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-44412fa677db46c3adfc498ecdd34e10 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,784] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5223 ms, throughput: 6.5437 GB/s; offload_time: 0.4735 ms, put_time: 0.0488 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,784] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-575f908b2f3e4df39a2cbd9780c0bceb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,785] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4579 ms, throughput: 7.4637 GB/s; offload_time: 0.4115 ms, put_time: 0.0465 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,811] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-47eea33f43e14bbba095786944c91661 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,812] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5163 ms, throughput: 6.6206 GB/s; offload_time: 0.4591 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,819] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-878edd68d7f84929ad4f320f2543c44c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,819] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5180 ms, throughput: 6.5987 GB/s; offload_time: 0.4599 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,834] LMCache INFO:[0m Reqid: chatcmpl-03ca9ad3e61042f0a5ecd13639cbad27, Total tokens 356, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,846] LMCache INFO:[0m Storing KV cache for 356 out of 356 tokens (skip_leading_tokens=0) for request chatcmpl-03ca9ad3e61042f0a5ecd13639cbad27 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,847] LMCache INFO:[0m Stored 356 out of total 356 tokens. size: 0.0095 gb, cost 0.8411 ms, throughput: 11.3018 GB/s; offload_time: 0.7422 ms, put_time: 0.0989 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,847] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,849] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.4244 ms, throughput: 2.3996 GB/s; offload_time: 1.3742 ms, put_time: 0.0502 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,852] LMCache INFO:[0m Reqid: chatcmpl-48a55e0350954616ba6d4c6e3458d05a, Total tokens 483, LMCache hit tokens: 384, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,853] LMCache INFO:[0m Reqid: chatcmpl-566cd75d8ac2442dbc1a086ab1d13c7d, Total tokens 338, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,855] LMCache INFO:[0m Reqid: chatcmpl-e207450448434d6786665f82cb948a9a, Total tokens 1826, LMCache hit tokens: 1792, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,868] LMCache INFO:[0m Storing KV cache for 483 out of 483 tokens (skip_leading_tokens=0) for request chatcmpl-48a55e0350954616ba6d4c6e3458d05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,868] LMCache INFO:[0m Stored 99 out of total 483 tokens. size: 0.0026 gb, cost 0.4978 ms, throughput: 5.3101 GB/s; offload_time: 0.4351 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,868] LMCache INFO:[0m Storing KV cache for 338 out of 338 tokens (skip_leading_tokens=0) for request chatcmpl-566cd75d8ac2442dbc1a086ab1d13c7d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,870] LMCache INFO:[0m Stored 338 out of total 338 tokens. size: 0.0090 gb, cost 1.2422 ms, throughput: 7.2656 GB/s; offload_time: 1.1474 ms, put_time: 0.0948 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,870] LMCache INFO:[0m Storing KV cache for 1826 out of 1826 tokens (skip_leading_tokens=0) for request chatcmpl-e207450448434d6786665f82cb948a9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,873] LMCache INFO:[0m Stored 34 out of total 1826 tokens. size: 0.0009 gb, cost 2.6249 ms, throughput: 0.3459 GB/s; offload_time: 2.5256 ms, put_time: 0.0993 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,873] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f37e2ba2168b48d988fb195e04069dde [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,874] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9594 ms, throughput: 3.5626 GB/s; offload_time: 0.9043 ms, put_time: 0.0551 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,916] LMCache INFO:[0m Reqid: chatcmpl-69606084b13e4819ac7d4f88ece73a8b, Total tokens 1124, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,924] LMCache INFO:[0m Storing KV cache for 1124 out of 1124 tokens (skip_leading_tokens=0) for request chatcmpl-69606084b13e4819ac7d4f88ece73a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,924] LMCache INFO:[0m Stored 100 out of total 1124 tokens. size: 0.0027 gb, cost 0.5029 ms, throughput: 5.3095 GB/s; offload_time: 0.4450 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,932] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-24674921610540cb80599e79d1d05e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,932] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4327 ms, throughput: 7.8993 GB/s; offload_time: 0.3689 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,932] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e8ce6065c30c4884a74eaaba2476adaf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,933] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5454 ms, throughput: 6.2665 GB/s; offload_time: 0.4860 ms, put_time: 0.0595 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:44,941] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b7f5039055cb4bc09b069e1484891735 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,941] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4464 ms, throughput: 7.6573 GB/s; offload_time: 0.3891 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:44,963] LMCache INFO:[0m Reqid: chatcmpl-1b840dbb88a1403ea6ac02ba9289e6de, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,970] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-1b840dbb88a1403ea6ac02ba9289e6de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:44,971] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.3704 ms, throughput: 6.7759 GB/s; offload_time: 0.3115 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,059] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-03ca9ad3e61042f0a5ecd13639cbad27 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,059] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4399 ms, throughput: 7.7698 GB/s; offload_time: 0.3826 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,072] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9cf6a545b78346dc93cc8ee4336c4382 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,073] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4280 ms, throughput: 7.9850 GB/s; offload_time: 0.3712 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,073] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-48a55e0350954616ba6d4c6e3458d05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,074] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6226 ms, throughput: 5.4898 GB/s; offload_time: 0.5703 ms, put_time: 0.0523 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,084] LMCache INFO:[0m Reqid: chatcmpl-1b70c9ec277b4fd48a92268d49ce0dee, Total tokens 2169, LMCache hit tokens: 1920, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,095] LMCache INFO:[0m Storing KV cache for 2169 out of 2169 tokens (skip_leading_tokens=0) for request chatcmpl-1b70c9ec277b4fd48a92268d49ce0dee [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,096] LMCache INFO:[0m Stored 249 out of total 2169 tokens. size: 0.0066 gb, cost 0.8658 ms, throughput: 7.6797 GB/s; offload_time: 0.7739 ms, put_time: 0.0919 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,123] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-49fe7cc1701a4c379145bed974452bf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,123] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5123 ms, throughput: 6.6713 GB/s; offload_time: 0.4557 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,123] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-69606084b13e4819ac7d4f88ece73a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,124] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.8595 ms, throughput: 3.9765 GB/s; offload_time: 0.8074 ms, put_time: 0.0522 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,131] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-a9870e5d494b4501897f1d0dbe490653 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,132] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5546 ms, throughput: 6.1626 GB/s; offload_time: 0.4976 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,145] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-1b70c9ec277b4fd48a92268d49ce0dee [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,146] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5597 ms, throughput: 6.1068 GB/s; offload_time: 0.4958 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,148] LMCache INFO:[0m Reqid: chatcmpl-7e947ca32f9943d38144b121a1b4e747, Total tokens 338, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,161] LMCache INFO:[0m Storing KV cache for 338 out of 338 tokens (skip_leading_tokens=0) for request chatcmpl-7e947ca32f9943d38144b121a1b4e747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,162] LMCache INFO:[0m Stored 338 out of total 338 tokens. size: 0.0090 gb, cost 0.8325 ms, throughput: 10.8416 GB/s; offload_time: 0.7242 ms, put_time: 0.1083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,182] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b13879b424ff4d5a88f4aa62abd175ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,182] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4320 ms, throughput: 7.9121 GB/s; offload_time: 0.3758 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,189] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-447919478ff34a6bb79f45d8650135e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,190] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4596 ms, throughput: 7.4363 GB/s; offload_time: 0.3971 ms, put_time: 0.0625 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,203] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ff235ba6b2c24ec7bcdc390a3ffe9ee0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,204] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5055 ms, throughput: 6.7612 GB/s; offload_time: 0.4471 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,207] LMCache INFO:[0m Reqid: chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7, Total tokens 578, LMCache hit tokens: 512, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,215] LMCache INFO:[0m Storing KV cache for 578 out of 578 tokens (skip_leading_tokens=0) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,215] LMCache INFO:[0m Stored 66 out of total 578 tokens. size: 0.0018 gb, cost 0.4314 ms, throughput: 4.0850 GB/s; offload_time: 0.3715 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,215] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-06b8f41bafda4767b02a8fed53faa3b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,216] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5238 ms, throughput: 6.5258 GB/s; offload_time: 0.4708 ms, put_time: 0.0530 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,217] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-566cd75d8ac2442dbc1a086ab1d13c7d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,217] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5765 ms, throughput: 5.9289 GB/s; offload_time: 0.5013 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,225] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-f1307ae272ba43c1b80d9a3c034ffd4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,226] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4484 ms, throughput: 7.6234 GB/s; offload_time: 0.3854 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,226] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1b840dbb88a1403ea6ac02ba9289e6de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,227] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5356 ms, throughput: 6.3815 GB/s; offload_time: 0.4808 ms, put_time: 0.0548 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,241] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0e0aaefe4ab84df5a51a025ec5f294cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,241] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4420 ms, throughput: 7.7321 GB/s; offload_time: 0.3838 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,291] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-2f85ef31846d41079f1b216cb2acbe09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,292] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5304 ms, throughput: 6.4440 GB/s; offload_time: 0.4724 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,295] LMCache INFO:[0m Reqid: chatcmpl-cbfe4b4a78fa402da183d5d13a714d60, Total tokens 678, LMCache hit tokens: 640, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,303] LMCache INFO:[0m Storing KV cache for 678 out of 678 tokens (skip_leading_tokens=0) for request chatcmpl-cbfe4b4a78fa402da183d5d13a714d60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,303] LMCache INFO:[0m Stored 38 out of total 678 tokens. size: 0.0010 gb, cost 0.4401 ms, throughput: 2.3056 GB/s; offload_time: 0.3727 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,331] LMCache INFO:[0m Reqid: chatcmpl-bd2eebd0be3d47a28e0e04e508c2dac0, Total tokens 117, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,339] LMCache INFO:[0m Storing KV cache for 117 out of 117 tokens (skip_leading_tokens=0) for request chatcmpl-bd2eebd0be3d47a28e0e04e508c2dac0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,340] LMCache INFO:[0m Stored 117 out of total 117 tokens. size: 0.0031 gb, cost 0.4191 ms, throughput: 7.4542 GB/s; offload_time: 0.3557 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,360] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-56235a63605740ea9046dc0a819755dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,360] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5015 ms, throughput: 6.8161 GB/s; offload_time: 0.4358 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,381] LMCache INFO:[0m Reqid: chatcmpl-9d43391b216d40b6bc27db6fc435a970, Total tokens 510, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,389] LMCache INFO:[0m Storing KV cache for 510 out of 510 tokens (skip_leading_tokens=0) for request chatcmpl-9d43391b216d40b6bc27db6fc435a970 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,390] LMCache INFO:[0m Stored 126 out of total 510 tokens. size: 0.0034 gb, cost 0.4830 ms, throughput: 6.9663 GB/s; offload_time: 0.4251 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,403] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9d43391b216d40b6bc27db6fc435a970 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,403] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4697 ms, throughput: 7.2763 GB/s; offload_time: 0.4050 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,417] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-bd2eebd0be3d47a28e0e04e508c2dac0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,417] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4364 ms, throughput: 7.8314 GB/s; offload_time: 0.3728 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,420] LMCache INFO:[0m Reqid: chatcmpl-63677397f7c94275a837f45f5ee991c1, Total tokens 139, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,431] LMCache INFO:[0m Storing KV cache for 139 out of 139 tokens (skip_leading_tokens=0) for request chatcmpl-63677397f7c94275a837f45f5ee991c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,432] LMCache INFO:[0m Stored 139 out of total 139 tokens. size: 0.0037 gb, cost 0.6165 ms, throughput: 6.0208 GB/s; offload_time: 0.5305 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,459] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-be75938d7db9483d8ceb8482324b68b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,459] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5202 ms, throughput: 6.5707 GB/s; offload_time: 0.4479 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,460] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0147d1e5cd264684beed656a0ec7076a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,460] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6991 ms, throughput: 4.8891 GB/s; offload_time: 0.6418 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,461] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-25c95f602eb545159ffead8f41431eec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,461] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6124 ms, throughput: 5.5814 GB/s; offload_time: 0.5482 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,500] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-21339de9458646819a904bc163cd3014 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,500] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4999 ms, throughput: 6.8375 GB/s; offload_time: 0.4377 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,500] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7e947ca32f9943d38144b121a1b4e747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,501] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6829 ms, throughput: 5.0049 GB/s; offload_time: 0.6253 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,504] LMCache INFO:[0m Reqid: chatcmpl-9f43ba082b314eb882a39cd140f8e3b5, Total tokens 549, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,513] LMCache INFO:[0m Storing KV cache for 549 out of 549 tokens (skip_leading_tokens=0) for request chatcmpl-9f43ba082b314eb882a39cd140f8e3b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,513] LMCache INFO:[0m Stored 37 out of total 549 tokens. size: 0.0010 gb, cost 0.3998 ms, throughput: 2.4714 GB/s; offload_time: 0.3372 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,520] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7d7b4e1dffc34523a5d759581ff6ccfa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,521] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4507 ms, throughput: 7.5834 GB/s; offload_time: 0.3926 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,534] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-115fe3fd554e47c8972f456a54943a3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,535] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4736 ms, throughput: 7.2176 GB/s; offload_time: 0.4161 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,544] LMCache INFO:[0m Reqid: chatcmpl-e008e7a62e1b4364b81a33944eced376, Total tokens 206, LMCache hit tokens: 128, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,551] LMCache INFO:[0m Storing KV cache for 206 out of 206 tokens (skip_leading_tokens=0) for request chatcmpl-e008e7a62e1b4364b81a33944eced376 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,552] LMCache INFO:[0m Stored 78 out of total 206 tokens. size: 0.0021 gb, cost 0.3952 ms, throughput: 5.2708 GB/s; offload_time: 0.3324 ms, put_time: 0.0628 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,579] LMCache INFO:[0m Reqid: chatcmpl-c8b34c7aad1d4e679674196fbaadd7d6, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,579] LMCache INFO:[0m Reqid: chatcmpl-3ad6239c21d641b8bbc70398850a9413, Total tokens 165, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,588] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-c8b34c7aad1d4e679674196fbaadd7d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,589] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.4235 ms, throughput: 6.2425 GB/s; offload_time: 0.3664 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,589] LMCache INFO:[0m Storing KV cache for 165 out of 165 tokens (skip_leading_tokens=0) for request chatcmpl-3ad6239c21d641b8bbc70398850a9413 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,590] LMCache INFO:[0m Stored 165 out of total 165 tokens. size: 0.0044 gb, cost 0.9447 ms, throughput: 4.6640 GB/s; offload_time: 0.8604 ms, put_time: 0.0842 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,624] LMCache INFO:[0m Reqid: chatcmpl-75a72c07b1014cc5bc5f60eda19440d1, Total tokens 184, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,632] LMCache INFO:[0m Storing KV cache for 184 out of 184 tokens (skip_leading_tokens=0) for request chatcmpl-75a72c07b1014cc5bc5f60eda19440d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,632] LMCache INFO:[0m Stored 56 out of total 184 tokens. size: 0.0015 gb, cost 0.4537 ms, throughput: 3.2957 GB/s; offload_time: 0.3962 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,632] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3e9c956e59fb45de932b3ad16fc228f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,633] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6534 ms, throughput: 5.2310 GB/s; offload_time: 0.6009 ms, put_time: 0.0525 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,641] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ceba114606a941a1996faeddbb0919c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,642] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4601 ms, throughput: 7.4282 GB/s; offload_time: 0.4025 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,662] LMCache INFO:[0m Reqid: chatcmpl-66ff322ac5bc4ea38ce3e939039e19d2, Total tokens 528, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,669] LMCache INFO:[0m Storing KV cache for 528 out of 528 tokens (skip_leading_tokens=0) for request chatcmpl-66ff322ac5bc4ea38ce3e939039e19d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,670] LMCache INFO:[0m Stored 16 out of total 528 tokens. size: 0.0004 gb, cost 0.4320 ms, throughput: 0.9891 GB/s; offload_time: 0.3744 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,677] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,678] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4695 ms, throughput: 7.2803 GB/s; offload_time: 0.4086 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,692] LMCache INFO:[0m Reqid: chatcmpl-e49255cf1eca4b7bb34dc290c282446c, Total tokens 333, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,699] LMCache INFO:[0m Storing KV cache for 333 out of 333 tokens (skip_leading_tokens=0) for request chatcmpl-e49255cf1eca4b7bb34dc290c282446c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,700] LMCache INFO:[0m Stored 77 out of total 333 tokens. size: 0.0021 gb, cost 0.4110 ms, throughput: 5.0030 GB/s; offload_time: 0.3511 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,739] LMCache INFO:[0m Reqid: chatcmpl-2ee2ccb2c80746349c63fbb1d74dd7f7, Total tokens 1614, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,747] LMCache INFO:[0m Storing KV cache for 1614 out of 1614 tokens (skip_leading_tokens=0) for request chatcmpl-2ee2ccb2c80746349c63fbb1d74dd7f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,747] LMCache INFO:[0m Stored 78 out of total 1614 tokens. size: 0.0021 gb, cost 0.5568 ms, throughput: 3.7410 GB/s; offload_time: 0.4944 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,748] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1d67be5e68704e14a4f10224c956611f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,749] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8338 ms, throughput: 4.0993 GB/s; offload_time: 0.7756 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,756] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-575f908b2f3e4df39a2cbd9780c0bceb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,756] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4508 ms, throughput: 7.5818 GB/s; offload_time: 0.3935 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,771] LMCache INFO:[0m Reqid: chatcmpl-0c929daceb6b4e8e8b81866e07e8e9e2, Total tokens 341, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,782] LMCache INFO:[0m Storing KV cache for 341 out of 341 tokens (skip_leading_tokens=0) for request chatcmpl-0c929daceb6b4e8e8b81866e07e8e9e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,783] LMCache INFO:[0m Stored 213 out of total 341 tokens. size: 0.0057 gb, cost 0.6842 ms, throughput: 8.3128 GB/s; offload_time: 0.6008 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,802] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c8b34c7aad1d4e679674196fbaadd7d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,803] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4290 ms, throughput: 7.9676 GB/s; offload_time: 0.3701 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,805] LMCache INFO:[0m Reqid: chatcmpl-f496c5ff947d4ba58ad18a6fde623b1b, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,814] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-f496c5ff947d4ba58ad18a6fde623b1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,815] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.4556 ms, throughput: 6.6817 GB/s; offload_time: 0.3984 ms, put_time: 0.0572 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,822] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,822] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5237 ms, throughput: 6.5262 GB/s; offload_time: 0.4673 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,829] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f37e2ba2168b48d988fb195e04069dde [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,830] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5106 ms, throughput: 6.6943 GB/s; offload_time: 0.4555 ms, put_time: 0.0551 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,851] LMCache INFO:[0m Reqid: chatcmpl-7412268184b3421092ab451e1bb94ec6, Total tokens 1904, LMCache hit tokens: 1792, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,861] LMCache INFO:[0m Storing KV cache for 1904 out of 1904 tokens (skip_leading_tokens=0) for request chatcmpl-7412268184b3421092ab451e1bb94ec6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,861] LMCache INFO:[0m Stored 112 out of total 1904 tokens. size: 0.0030 gb, cost 0.5804 ms, throughput: 5.1529 GB/s; offload_time: 0.5204 ms, put_time: 0.0600 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,883] LMCache INFO:[0m Reqid: chatcmpl-3509698fc3174eacb50b660398993cfe, Total tokens 1195, LMCache hit tokens: 1152, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,891] LMCache INFO:[0m Storing KV cache for 1195 out of 1195 tokens (skip_leading_tokens=0) for request chatcmpl-3509698fc3174eacb50b660398993cfe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,892] LMCache INFO:[0m Stored 43 out of total 1195 tokens. size: 0.0011 gb, cost 0.4714 ms, throughput: 2.4358 GB/s; offload_time: 0.4138 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,917] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f496c5ff947d4ba58ad18a6fde623b1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,918] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4559 ms, throughput: 7.4965 GB/s; offload_time: 0.3980 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,925] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e008e7a62e1b4364b81a33944eced376 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,925] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4593 ms, throughput: 7.4409 GB/s; offload_time: 0.3978 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,941] LMCache INFO:[0m Reqid: chatcmpl-8c2b2136b0094e20b2f8a676f5258723, Total tokens 1250, LMCache hit tokens: 1152, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,949] LMCache INFO:[0m Storing KV cache for 1250 out of 1250 tokens (skip_leading_tokens=0) for request chatcmpl-8c2b2136b0094e20b2f8a676f5258723 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,949] LMCache INFO:[0m Stored 98 out of total 1250 tokens. size: 0.0026 gb, cost 0.4969 ms, throughput: 5.2668 GB/s; offload_time: 0.4393 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:45,975] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-cbfe4b4a78fa402da183d5d13a714d60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,975] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4805 ms, throughput: 7.1138 GB/s; offload_time: 0.4177 ms, put_time: 0.0628 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,976] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-7412268184b3421092ab451e1bb94ec6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,976] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.8540 ms, throughput: 4.0022 GB/s; offload_time: 0.7971 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:45,979] LMCache INFO:[0m Reqid: chatcmpl-2541cbf75e714453b94dad87c0714e42, Total tokens 224, LMCache hit tokens: 128, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,987] LMCache INFO:[0m Storing KV cache for 224 out of 224 tokens (skip_leading_tokens=0) for request chatcmpl-2541cbf75e714453b94dad87c0714e42 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:45,988] LMCache INFO:[0m Stored 96 out of total 224 tokens. size: 0.0026 gb, cost 0.4745 ms, throughput: 5.4028 GB/s; offload_time: 0.4172 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,021] LMCache INFO:[0m Reqid: chatcmpl-27015534e27b4e62b4b6bd10f8667a2b, Total tokens 782, LMCache hit tokens: 640, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,029] LMCache INFO:[0m Storing KV cache for 782 out of 782 tokens (skip_leading_tokens=0) for request chatcmpl-27015534e27b4e62b4b6bd10f8667a2b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,030] LMCache INFO:[0m Stored 142 out of total 782 tokens. size: 0.0038 gb, cost 0.6786 ms, throughput: 5.5877 GB/s; offload_time: 0.5807 ms, put_time: 0.0979 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,030] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-03ca9ad3e61042f0a5ecd13639cbad27 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,031] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2544 ms, throughput: 2.7247 GB/s; offload_time: 1.1689 ms, put_time: 0.0855 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,045] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9cf6a545b78346dc93cc8ee4336c4382 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,046] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4554 ms, throughput: 7.5051 GB/s; offload_time: 0.3976 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,046] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-48a55e0350954616ba6d4c6e3458d05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,047] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7581 ms, throughput: 4.5083 GB/s; offload_time: 0.7064 ms, put_time: 0.0518 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,056] LMCache INFO:[0m Reqid: chatcmpl-bbbac43bd5a2457e90c721c338adfde8, Total tokens 462, LMCache hit tokens: 384, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,063] LMCache INFO:[0m Storing KV cache for 462 out of 462 tokens (skip_leading_tokens=0) for request chatcmpl-bbbac43bd5a2457e90c721c338adfde8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,064] LMCache INFO:[0m Stored 78 out of total 462 tokens. size: 0.0021 gb, cost 0.4569 ms, throughput: 4.5584 GB/s; offload_time: 0.4007 ms, put_time: 0.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,083] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e49255cf1eca4b7bb34dc290c282446c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,084] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4589 ms, throughput: 7.4477 GB/s; offload_time: 0.4030 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,086] LMCache INFO:[0m Reqid: chatcmpl-e51a8461b58f43eb8cff7ec424f0e5b3, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,095] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-e51a8461b58f43eb8cff7ec424f0e5b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,095] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.3678 ms, throughput: 6.8252 GB/s; offload_time: 0.3114 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,095] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-49fe7cc1701a4c379145bed974452bf1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,096] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.7903 ms, throughput: 4.3248 GB/s; offload_time: 0.7320 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,096] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-69606084b13e4819ac7d4f88ece73a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,097] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.8747 ms, throughput: 3.9078 GB/s; offload_time: 0.8245 ms, put_time: 0.0502 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,105] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-a9870e5d494b4501897f1d0dbe490653 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,106] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5490 ms, throughput: 6.2256 GB/s; offload_time: 0.4916 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,113] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0c929daceb6b4e8e8b81866e07e8e9e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,113] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5041 ms, throughput: 6.7798 GB/s; offload_time: 0.4460 ms, put_time: 0.0581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,121] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-1b70c9ec277b4fd48a92268d49ce0dee [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,121] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.5705 ms, throughput: 5.9917 GB/s; offload_time: 0.5128 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,124] LMCache INFO:[0m Reqid: chatcmpl-688e3d2882004e73ab9566316a22eac5, Total tokens 439, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,137] LMCache INFO:[0m Storing KV cache for 439 out of 439 tokens (skip_leading_tokens=0) for request chatcmpl-688e3d2882004e73ab9566316a22eac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,138] LMCache INFO:[0m Stored 439 out of total 439 tokens. size: 0.0117 gb, cost 1.0990 ms, throughput: 10.6667 GB/s; offload_time: 0.9720 ms, put_time: 0.1269 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,146] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-2ee2ccb2c80746349c63fbb1d74dd7f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,147] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5454 ms, throughput: 6.2664 GB/s; offload_time: 0.4845 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,160] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b13879b424ff4d5a88f4aa62abd175ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,160] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4591 ms, throughput: 7.4443 GB/s; offload_time: 0.3947 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,167] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-447919478ff34a6bb79f45d8650135e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,168] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4777 ms, throughput: 7.1551 GB/s; offload_time: 0.4212 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,177] LMCache INFO:[0m Reqid: chatcmpl-b637e0743b7041e3bf19ff2ca771cdf6, Total tokens 1000, LMCache hit tokens: 896, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,185] LMCache INFO:[0m Storing KV cache for 1000 out of 1000 tokens (skip_leading_tokens=0) for request chatcmpl-b637e0743b7041e3bf19ff2ca771cdf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,185] LMCache INFO:[0m Stored 104 out of total 1000 tokens. size: 0.0028 gb, cost 0.5370 ms, throughput: 5.1712 GB/s; offload_time: 0.4797 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,193] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8c2b2136b0094e20b2f8a676f5258723 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,193] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4955 ms, throughput: 6.8975 GB/s; offload_time: 0.4406 ms, put_time: 0.0549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,196] LMCache INFO:[0m Reqid: chatcmpl-70f4e454fc614b629e4fc3d5c4bfe603, Total tokens 118, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,196] LMCache INFO:[0m Reqid: chatcmpl-2f1865868fc94eb0b25bbad428c68cd7, Total tokens 500, LMCache hit tokens: 384, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,208] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-70f4e454fc614b629e4fc3d5c4bfe603 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,209] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.4651 ms, throughput: 6.7741 GB/s; offload_time: 0.4075 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,209] LMCache INFO:[0m Storing KV cache for 500 out of 500 tokens (skip_leading_tokens=0) for request chatcmpl-2f1865868fc94eb0b25bbad428c68cd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,210] LMCache INFO:[0m Stored 116 out of total 500 tokens. size: 0.0031 gb, cost 0.8405 ms, throughput: 3.6855 GB/s; offload_time: 0.6820 ms, put_time: 0.1584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,224] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9f43ba082b314eb882a39cd140f8e3b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,225] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4723 ms, throughput: 7.2363 GB/s; offload_time: 0.4119 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,227] LMCache INFO:[0m Reqid: chatcmpl-5e2ca28e78a74b5daa6a9109e68b676d, Total tokens 530, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,235] LMCache INFO:[0m Storing KV cache for 530 out of 530 tokens (skip_leading_tokens=0) for request chatcmpl-5e2ca28e78a74b5daa6a9109e68b676d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,236] LMCache INFO:[0m Stored 146 out of total 530 tokens. size: 0.0039 gb, cost 0.6737 ms, throughput: 5.7869 GB/s; offload_time: 0.5805 ms, put_time: 0.0932 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,252] LMCache INFO:[0m Reqid: chatcmpl-3509cbfce32b441e9c4edf3d024d34f5, Total tokens 1926, LMCache hit tokens: 1792, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,260] LMCache INFO:[0m Storing KV cache for 1926 out of 1926 tokens (skip_leading_tokens=0) for request chatcmpl-3509cbfce32b441e9c4edf3d024d34f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,261] LMCache INFO:[0m Stored 134 out of total 1926 tokens. size: 0.0036 gb, cost 0.7376 ms, throughput: 4.8513 GB/s; offload_time: 0.6500 ms, put_time: 0.0876 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,262] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2541cbf75e714453b94dad87c0714e42 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,263] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1397 ms, throughput: 2.9991 GB/s; offload_time: 1.0626 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,290] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-2f85ef31846d41079f1b216cb2acbe09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,291] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5474 ms, throughput: 6.2441 GB/s; offload_time: 0.4886 ms, put_time: 0.0588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,291] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-70f4e454fc614b629e4fc3d5c4bfe603 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,292] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8928 ms, throughput: 3.8285 GB/s; offload_time: 0.8372 ms, put_time: 0.0556 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,294] LMCache INFO:[0m Reqid: chatcmpl-7234656f906b44dcb04cd95d6720777d, Total tokens 374, LMCache hit tokens: 256, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,302] LMCache INFO:[0m Storing KV cache for 374 out of 374 tokens (skip_leading_tokens=0) for request chatcmpl-7234656f906b44dcb04cd95d6720777d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,303] LMCache INFO:[0m Stored 118 out of total 374 tokens. size: 0.0032 gb, cost 0.4659 ms, throughput: 6.7627 GB/s; offload_time: 0.4009 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,310] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3ad6239c21d641b8bbc70398850a9413 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,310] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4502 ms, throughput: 7.5928 GB/s; offload_time: 0.3929 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,311] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2f1865868fc94eb0b25bbad428c68cd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,311] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5949 ms, throughput: 5.7451 GB/s; offload_time: 0.5369 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,320] LMCache INFO:[0m Reqid: chatcmpl-8eaf7703356346be9ac4089f02b9fe84, Total tokens 412, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,328] LMCache INFO:[0m Storing KV cache for 412 out of 412 tokens (skip_leading_tokens=0) for request chatcmpl-8eaf7703356346be9ac4089f02b9fe84 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,328] LMCache INFO:[0m Stored 28 out of total 412 tokens. size: 0.0007 gb, cost 0.3855 ms, throughput: 1.9396 GB/s; offload_time: 0.3269 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,338] LMCache INFO:[0m Reqid: chatcmpl-1326c48cda314ff3bca008e24fbbc1dc, Total tokens 443, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,345] LMCache INFO:[0m Storing KV cache for 443 out of 443 tokens (skip_leading_tokens=0) for request chatcmpl-1326c48cda314ff3bca008e24fbbc1dc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,346] LMCache INFO:[0m Stored 59 out of total 443 tokens. size: 0.0016 gb, cost 0.4617 ms, throughput: 3.4122 GB/s; offload_time: 0.4048 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,366] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-56235a63605740ea9046dc0a819755dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,366] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5108 ms, throughput: 6.6909 GB/s; offload_time: 0.4542 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,369] LMCache INFO:[0m Reqid: chatcmpl-bcf33c3a9d21443ab83ee3b39fb5cc62, Total tokens 679, LMCache hit tokens: 640, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,376] LMCache INFO:[0m Storing KV cache for 679 out of 679 tokens (skip_leading_tokens=0) for request chatcmpl-bcf33c3a9d21443ab83ee3b39fb5cc62 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,377] LMCache INFO:[0m Stored 39 out of total 679 tokens. size: 0.0010 gb, cost 0.4278 ms, throughput: 2.4346 GB/s; offload_time: 0.3700 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,384] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7234656f906b44dcb04cd95d6720777d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,385] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4490 ms, throughput: 7.6119 GB/s; offload_time: 0.3922 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,392] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-b637e0743b7041e3bf19ff2ca771cdf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,392] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4974 ms, throughput: 6.8710 GB/s; offload_time: 0.4368 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,395] LMCache INFO:[0m Reqid: chatcmpl-70f7201de81f4acb892d2b57d4ebe860, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,403] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-70f7201de81f4acb892d2b57d4ebe860 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,404] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.4188 ms, throughput: 6.6955 GB/s; offload_time: 0.3628 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,417] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9d43391b216d40b6bc27db6fc435a970 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,418] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4917 ms, throughput: 6.9513 GB/s; offload_time: 0.4271 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,427] LMCache INFO:[0m Reqid: chatcmpl-49b1911024fb4fdfa1573a1246e5d169, Total tokens 1218, LMCache hit tokens: 1152, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,435] LMCache INFO:[0m Storing KV cache for 1218 out of 1218 tokens (skip_leading_tokens=0) for request chatcmpl-49b1911024fb4fdfa1573a1246e5d169 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,436] LMCache INFO:[0m Stored 66 out of total 1218 tokens. size: 0.0018 gb, cost 0.4844 ms, throughput: 3.6381 GB/s; offload_time: 0.4184 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,452] LMCache INFO:[0m Reqid: chatcmpl-26bdfdea6bc84448b90af23883118fb7, Total tokens 215, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,461] LMCache INFO:[0m Storing KV cache for 215 out of 215 tokens (skip_leading_tokens=0) for request chatcmpl-26bdfdea6bc84448b90af23883118fb7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,461] LMCache INFO:[0m Stored 87 out of total 215 tokens. size: 0.0023 gb, cost 0.4660 ms, throughput: 4.9850 GB/s; offload_time: 0.4049 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,475] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0147d1e5cd264684beed656a0ec7076a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,475] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4783 ms, throughput: 7.1464 GB/s; offload_time: 0.4205 ms, put_time: 0.0578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,476] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-25c95f602eb545159ffead8f41431eec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,476] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6052 ms, throughput: 5.6475 GB/s; offload_time: 0.5477 ms, put_time: 0.0575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,489] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-bbbac43bd5a2457e90c721c338adfde8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,490] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4595 ms, throughput: 7.4381 GB/s; offload_time: 0.4036 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,511] LMCache INFO:[0m Reqid: chatcmpl-0401cef423ed4dd19a5c61d9691bb572, Total tokens 350, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,523] LMCache INFO:[0m Storing KV cache for 350 out of 350 tokens (skip_leading_tokens=0) for request chatcmpl-0401cef423ed4dd19a5c61d9691bb572 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,524] LMCache INFO:[0m Stored 222 out of total 350 tokens. size: 0.0059 gb, cost 0.7177 ms, throughput: 8.2602 GB/s; offload_time: 0.6357 ms, put_time: 0.0820 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,552] LMCache INFO:[0m Reqid: chatcmpl-ba1b18a8cef84e4e8e1672d7a5c9e0cf, Total tokens 144, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,563] LMCache INFO:[0m Storing KV cache for 144 out of 144 tokens (skip_leading_tokens=0) for request chatcmpl-ba1b18a8cef84e4e8e1672d7a5c9e0cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,564] LMCache INFO:[0m Stored 144 out of total 144 tokens. size: 0.0038 gb, cost 0.6268 ms, throughput: 6.1342 GB/s; offload_time: 0.5389 ms, put_time: 0.0880 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,572] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-66ff322ac5bc4ea38ce3e939039e19d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,573] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4812 ms, throughput: 7.1035 GB/s; offload_time: 0.4242 ms, put_time: 0.0569 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,586] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-3509698fc3174eacb50b660398993cfe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,587] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5068 ms, throughput: 6.7447 GB/s; offload_time: 0.4481 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,587] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-70f7201de81f4acb892d2b57d4ebe860 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,588] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8309 ms, throughput: 4.1136 GB/s; offload_time: 0.7756 ms, put_time: 0.0553 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,591] LMCache INFO:[0m Reqid: chatcmpl-81f13cfa70e448e99190372d1b2f936e, Total tokens 402, LMCache hit tokens: 256, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,599] LMCache INFO:[0m Storing KV cache for 402 out of 402 tokens (skip_leading_tokens=0) for request chatcmpl-81f13cfa70e448e99190372d1b2f936e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,600] LMCache INFO:[0m Stored 146 out of total 402 tokens. size: 0.0039 gb, cost 0.6489 ms, throughput: 6.0076 GB/s; offload_time: 0.5649 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,603] LMCache INFO:[0m Reqid: chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,612] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,612] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.4426 ms, throughput: 6.4550 GB/s; offload_time: 0.3844 ms, put_time: 0.0583 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,629] LMCache INFO:[0m Reqid: chatcmpl-edc2b011c1084cfb9ce0e234bf0ff657, Total tokens 1222, LMCache hit tokens: 1152, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,637] LMCache INFO:[0m Storing KV cache for 1222 out of 1222 tokens (skip_leading_tokens=0) for request chatcmpl-edc2b011c1084cfb9ce0e234bf0ff657 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,637] LMCache INFO:[0m Stored 70 out of total 1222 tokens. size: 0.0019 gb, cost 0.4919 ms, throughput: 3.7997 GB/s; offload_time: 0.4312 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,646] LMCache INFO:[0m Reqid: chatcmpl-71e13c29a8214bd3bd00bdd370a17307, Total tokens 368, LMCache hit tokens: 256, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,654] LMCache INFO:[0m Storing KV cache for 368 out of 368 tokens (skip_leading_tokens=0) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,655] LMCache INFO:[0m Stored 112 out of total 368 tokens. size: 0.0030 gb, cost 0.4839 ms, throughput: 6.1800 GB/s; offload_time: 0.4244 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,674] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ceba114606a941a1996faeddbb0919c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,675] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5330 ms, throughput: 6.4122 GB/s; offload_time: 0.4735 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,707] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,708] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5000 ms, throughput: 6.8360 GB/s; offload_time: 0.4423 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,717] LMCache INFO:[0m Reqid: chatcmpl-737ba3aeb2744f448eba6102cf86b27b, Total tokens 136, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,717] LMCache INFO:[0m Reqid: chatcmpl-cb205b7ac153471797a84151cb7b0e0f, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,726] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-737ba3aeb2744f448eba6102cf86b27b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,727] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 0.6336 ms, throughput: 5.7314 GB/s; offload_time: 0.5495 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,727] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-cb205b7ac153471797a84151cb7b0e0f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,728] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.4881 ms, throughput: 5.2520 GB/s; offload_time: 0.4230 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,742] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-688e3d2882004e73ab9566316a22eac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,743] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4910 ms, throughput: 6.9615 GB/s; offload_time: 0.4243 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,752] LMCache INFO:[0m Reqid: chatcmpl-76284f5af5b84f4487582cec2c33e5d5, Total tokens 915, LMCache hit tokens: 768, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,760] LMCache INFO:[0m Storing KV cache for 915 out of 915 tokens (skip_leading_tokens=0) for request chatcmpl-76284f5af5b84f4487582cec2c33e5d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,761] LMCache INFO:[0m Stored 147 out of total 915 tokens. size: 0.0039 gb, cost 0.7288 ms, throughput: 5.3863 GB/s; offload_time: 0.6405 ms, put_time: 0.0882 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,776] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,776] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4640 ms, throughput: 7.3667 GB/s; offload_time: 0.4068 ms, put_time: 0.0571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,777] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,778] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.8423 ms, throughput: 4.0577 GB/s; offload_time: 0.7883 ms, put_time: 0.0540 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,797] LMCache INFO:[0m Reqid: chatcmpl-c52d3da5e5214348bc24c97786eaf207, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,806] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-c52d3da5e5214348bc24c97786eaf207 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,806] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.3758 ms, throughput: 7.5310 GB/s; offload_time: 0.3109 ms, put_time: 0.0649 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,806] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0401cef423ed4dd19a5c61d9691bb572 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,807] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9264 ms, throughput: 3.6894 GB/s; offload_time: 0.8753 ms, put_time: 0.0511 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,842] LMCache INFO:[0m Reqid: chatcmpl-2e2acb3139c3411a8b54775e3a418699, Total tokens 726, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,853] LMCache INFO:[0m Storing KV cache for 726 out of 726 tokens (skip_leading_tokens=0) for request chatcmpl-2e2acb3139c3411a8b54775e3a418699 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,854] LMCache INFO:[0m Stored 342 out of total 726 tokens. size: 0.0091 gb, cost 0.9789 ms, throughput: 9.3288 GB/s; offload_time: 0.8688 ms, put_time: 0.1101 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,855] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c8b34c7aad1d4e679674196fbaadd7d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,856] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2114 ms, throughput: 2.8216 GB/s; offload_time: 1.1414 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,870] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,871] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6054 ms, throughput: 5.6459 GB/s; offload_time: 0.5463 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,880] LMCache INFO:[0m Reqid: chatcmpl-00ea0ba28c764cb78db9dd00aaf0568b, Total tokens 603, LMCache hit tokens: 512, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,888] LMCache INFO:[0m Storing KV cache for 603 out of 603 tokens (skip_leading_tokens=0) for request chatcmpl-00ea0ba28c764cb78db9dd00aaf0568b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,889] LMCache INFO:[0m Stored 91 out of total 603 tokens. size: 0.0024 gb, cost 0.4419 ms, throughput: 5.4990 GB/s; offload_time: 0.3792 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,909] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1326c48cda314ff3bca008e24fbbc1dc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,909] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4942 ms, throughput: 6.9162 GB/s; offload_time: 0.4329 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,912] LMCache INFO:[0m Reqid: chatcmpl-e18dc926b29d4a0797e19573e9cc2301, Total tokens 766, LMCache hit tokens: 640, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,921] LMCache INFO:[0m Storing KV cache for 766 out of 766 tokens (skip_leading_tokens=0) for request chatcmpl-e18dc926b29d4a0797e19573e9cc2301 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,922] LMCache INFO:[0m Stored 126 out of total 766 tokens. size: 0.0034 gb, cost 0.6075 ms, throughput: 5.5383 GB/s; offload_time: 0.5496 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,936] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e18dc926b29d4a0797e19573e9cc2301 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,936] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5367 ms, throughput: 6.3679 GB/s; offload_time: 0.4735 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,944] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-49b1911024fb4fdfa1573a1246e5d169 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,944] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5540 ms, throughput: 6.1691 GB/s; offload_time: 0.4897 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,960] LMCache INFO:[0m Reqid: chatcmpl-966ed7d36d0641ac97941003d6044044, Total tokens 1325, LMCache hit tokens: 1280, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,968] LMCache INFO:[0m Storing KV cache for 1325 out of 1325 tokens (skip_leading_tokens=0) for request chatcmpl-966ed7d36d0641ac97941003d6044044 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,969] LMCache INFO:[0m Stored 45 out of total 1325 tokens. size: 0.0012 gb, cost 0.5002 ms, throughput: 2.4024 GB/s; offload_time: 0.4403 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,977] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f496c5ff947d4ba58ad18a6fde623b1b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,978] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4951 ms, throughput: 6.9033 GB/s; offload_time: 0.4339 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,985] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e008e7a62e1b4364b81a33944eced376 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,986] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5268 ms, throughput: 6.4877 GB/s; offload_time: 0.4702 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,986] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-27015534e27b4e62b4b6bd10f8667a2b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,987] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9320 ms, throughput: 3.6674 GB/s; offload_time: 0.8767 ms, put_time: 0.0553 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:46,987] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c52d3da5e5214348bc24c97786eaf207 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:46,988] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6972 ms, throughput: 4.9021 GB/s; offload_time: 0.6427 ms, put_time: 0.0546 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:46,998] LMCache INFO:[0m Reqid: chatcmpl-2f1aced808384a88856b06377d8891ab, Total tokens 254, LMCache hit tokens: 128, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,006] LMCache INFO:[0m Storing KV cache for 254 out of 254 tokens (skip_leading_tokens=0) for request chatcmpl-2f1aced808384a88856b06377d8891ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,006] LMCache INFO:[0m Stored 126 out of total 254 tokens. size: 0.0034 gb, cost 0.5286 ms, throughput: 6.3654 GB/s; offload_time: 0.4650 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,020] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2f1aced808384a88856b06377d8891ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,021] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5058 ms, throughput: 6.7573 GB/s; offload_time: 0.4438 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,041] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-cbfe4b4a78fa402da183d5d13a714d60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,042] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5863 ms, throughput: 5.8300 GB/s; offload_time: 0.5261 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,042] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-7412268184b3421092ab451e1bb94ec6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,043] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.9255 ms, throughput: 3.6930 GB/s; offload_time: 0.8695 ms, put_time: 0.0560 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,078] LMCache INFO:[0m Reqid: chatcmpl-6d49a4a26fe74d0cb6062466b9a807e9, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,087] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-6d49a4a26fe74d0cb6062466b9a807e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,087] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3438 ms, throughput: 8.0781 GB/s; offload_time: 0.2811 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,094] LMCache INFO:[0m Reqid: chatcmpl-7c61a068befc41b793fae7c4ea3e45d9, Total tokens 324, LMCache hit tokens: 256, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,103] LMCache INFO:[0m Storing KV cache for 324 out of 324 tokens (skip_leading_tokens=0) for request chatcmpl-7c61a068befc41b793fae7c4ea3e45d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,104] LMCache INFO:[0m Stored 68 out of total 324 tokens. size: 0.0018 gb, cost 0.4331 ms, throughput: 4.1923 GB/s; offload_time: 0.3653 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,113] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-bcf33c3a9d21443ab83ee3b39fb5cc62 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,114] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6697 ms, throughput: 5.1038 GB/s; offload_time: 0.6014 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,115] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-edc2b011c1084cfb9ce0e234bf0ff657 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,115] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.7903 ms, throughput: 4.3251 GB/s; offload_time: 0.7270 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,125] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9cf6a545b78346dc93cc8ee4336c4382 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,125] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6277 ms, throughput: 5.4455 GB/s; offload_time: 0.5597 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,126] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-48a55e0350954616ba6d4c6e3458d05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,127] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8462 ms, throughput: 4.0391 GB/s; offload_time: 0.7777 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,139] LMCache INFO:[0m Reqid: chatcmpl-46e19d28ea09404c86bc2db011566ed9, Total tokens 424, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,147] LMCache INFO:[0m Storing KV cache for 424 out of 424 tokens (skip_leading_tokens=0) for request chatcmpl-46e19d28ea09404c86bc2db011566ed9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,148] LMCache INFO:[0m Stored 40 out of total 424 tokens. size: 0.0011 gb, cost 0.4482 ms, throughput: 2.3831 GB/s; offload_time: 0.3811 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,157] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-5e2ca28e78a74b5daa6a9109e68b676d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,158] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6818 ms, throughput: 5.0134 GB/s; offload_time: 0.6124 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,166] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8eaf7703356346be9ac4089f02b9fe84 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,167] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6472 ms, throughput: 5.2815 GB/s; offload_time: 0.5744 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,170] LMCache INFO:[0m Reqid: chatcmpl-803e581426084742863bdb844a47a998, Total tokens 1278, LMCache hit tokens: 1152, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,182] LMCache INFO:[0m Storing KV cache for 1278 out of 1278 tokens (skip_leading_tokens=0) for request chatcmpl-803e581426084742863bdb844a47a998 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,183] LMCache INFO:[0m Stored 126 out of total 1278 tokens. size: 0.0034 gb, cost 0.7818 ms, throughput: 4.3038 GB/s; offload_time: 0.7143 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,183] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e49255cf1eca4b7bb34dc290c282446c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,184] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0528 ms, throughput: 3.2466 GB/s; offload_time: 0.9912 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,193] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-69606084b13e4819ac7d4f88ece73a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,193] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7139 ms, throughput: 4.7880 GB/s; offload_time: 0.6425 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,201] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-803e581426084742863bdb844a47a998 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,202] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6964 ms, throughput: 4.9080 GB/s; offload_time: 0.6282 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,205] LMCache INFO:[0m Reqid: chatcmpl-21f96c8ff2b24683b9b0783304adf438, Total tokens 531, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,224] LMCache INFO:[0m Storing KV cache for 531 out of 531 tokens (skip_leading_tokens=0) for request chatcmpl-21f96c8ff2b24683b9b0783304adf438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,227] LMCache INFO:[0m Stored 531 out of total 531 tokens. size: 0.0142 gb, cost 2.2841 ms, throughput: 6.2078 GB/s; offload_time: 1.6535 ms, put_time: 0.6306 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,227] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0c929daceb6b4e8e8b81866e07e8e9e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,230] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.2507 ms, throughput: 1.5186 GB/s; offload_time: 2.0798 ms, put_time: 0.1709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,240] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-00ea0ba28c764cb78db9dd00aaf0568b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,241] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6670 ms, throughput: 5.1241 GB/s; offload_time: 0.5882 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,245] LMCache INFO:[0m Reqid: chatcmpl-1c556f345ab144f982c0929d2b30fb9a, Total tokens 1654, LMCache hit tokens: 1536, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,254] LMCache INFO:[0m Storing KV cache for 1654 out of 1654 tokens (skip_leading_tokens=0) for request chatcmpl-1c556f345ab144f982c0929d2b30fb9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,255] LMCache INFO:[0m Stored 118 out of total 1654 tokens. size: 0.0032 gb, cost 0.6254 ms, throughput: 5.0384 GB/s; offload_time: 0.5550 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,255] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2e2acb3139c3411a8b54775e3a418699 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,257] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0319 ms, throughput: 3.3123 GB/s; offload_time: 0.9676 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,260] LMCache INFO:[0m Reqid: chatcmpl-3d1ae723206049ad856004dc02677efe, Total tokens 237, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,271] LMCache INFO:[0m Storing KV cache for 237 out of 237 tokens (skip_leading_tokens=0) for request chatcmpl-3d1ae723206049ad856004dc02677efe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,272] LMCache INFO:[0m Stored 237 out of total 237 tokens. size: 0.0063 gb, cost 0.8433 ms, throughput: 7.5047 GB/s; offload_time: 0.7435 ms, put_time: 0.0998 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,272] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-2ee2ccb2c80746349c63fbb1d74dd7f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,275] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.9033 ms, throughput: 1.7958 GB/s; offload_time: 1.8364 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,287] LMCache INFO:[0m Reqid: chatcmpl-ce7f1a3dc38f4178a2b40c99dcf7a3d2, Total tokens 144, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,295] LMCache INFO:[0m Storing KV cache for 144 out of 144 tokens (skip_leading_tokens=0) for request chatcmpl-ce7f1a3dc38f4178a2b40c99dcf7a3d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,296] LMCache INFO:[0m Stored 144 out of total 144 tokens. size: 0.0038 gb, cost 0.8355 ms, throughput: 4.6022 GB/s; offload_time: 0.7227 ms, put_time: 0.1128 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,324] LMCache INFO:[0m Reqid: chatcmpl-2bd543897835488c9f0e3b7e7aa2fe90, Total tokens 1321, LMCache hit tokens: 1280, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,334] LMCache INFO:[0m Storing KV cache for 1321 out of 1321 tokens (skip_leading_tokens=0) for request chatcmpl-2bd543897835488c9f0e3b7e7aa2fe90 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,335] LMCache INFO:[0m Stored 41 out of total 1321 tokens. size: 0.0011 gb, cost 0.5501 ms, throughput: 1.9901 GB/s; offload_time: 0.4689 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,335] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-8c2b2136b0094e20b2f8a676f5258723 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,336] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3055 ms, throughput: 2.6181 GB/s; offload_time: 1.2341 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,340] LMCache INFO:[0m Reqid: chatcmpl-18ad681e55394068ab7c7402ff9792b5, Total tokens 473, LMCache hit tokens: 384, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,350] LMCache INFO:[0m Storing KV cache for 473 out of 473 tokens (skip_leading_tokens=0) for request chatcmpl-18ad681e55394068ab7c7402ff9792b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,350] LMCache INFO:[0m Stored 89 out of total 473 tokens. size: 0.0024 gb, cost 0.4649 ms, throughput: 5.1120 GB/s; offload_time: 0.3905 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,351] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-3509cbfce32b441e9c4edf3d024d34f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,352] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.1990 ms, throughput: 2.8507 GB/s; offload_time: 1.1300 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,364] LMCache INFO:[0m Reqid: chatcmpl-4b7691785e9b4ba997f5dd604410ddc1, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,374] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-4b7691785e9b4ba997f5dd604410ddc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,374] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.3974 ms, throughput: 6.5846 GB/s; offload_time: 0.3242 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,375] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9f43ba082b314eb882a39cd140f8e3b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,376] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8627 ms, throughput: 3.9619 GB/s; offload_time: 0.7952 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,376] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-1c556f345ab144f982c0929d2b30fb9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,377] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.9637 ms, throughput: 3.5467 GB/s; offload_time: 0.8979 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,381] LMCache INFO:[0m Reqid: chatcmpl-a6e3a97e0b0749119de28225f027ab1f, Total tokens 681, LMCache hit tokens: 640, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,390] LMCache INFO:[0m Storing KV cache for 681 out of 681 tokens (skip_leading_tokens=0) for request chatcmpl-a6e3a97e0b0749119de28225f027ab1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,391] LMCache INFO:[0m Stored 41 out of total 681 tokens. size: 0.0011 gb, cost 0.4818 ms, throughput: 2.2724 GB/s; offload_time: 0.4008 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,395] LMCache INFO:[0m Reqid: chatcmpl-4b99b2bf38bd4365958d134dab5292a4, Total tokens 665, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,406] LMCache INFO:[0m Storing KV cache for 665 out of 665 tokens (skip_leading_tokens=0) for request chatcmpl-4b99b2bf38bd4365958d134dab5292a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,408] LMCache INFO:[0m Stored 281 out of total 665 tokens. size: 0.0075 gb, cost 1.3882 ms, throughput: 5.4051 GB/s; offload_time: 1.0775 ms, put_time: 0.3108 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,413] LMCache INFO:[0m Reqid: chatcmpl-ec2ffd53ea744db5ab2412cf7c188048, Total tokens 822, LMCache hit tokens: 768, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,423] LMCache INFO:[0m Storing KV cache for 822 out of 822 tokens (skip_leading_tokens=0) for request chatcmpl-ec2ffd53ea744db5ab2412cf7c188048 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,424] LMCache INFO:[0m Stored 54 out of total 822 tokens. size: 0.0014 gb, cost 0.5397 ms, throughput: 2.6718 GB/s; offload_time: 0.4672 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,435] LMCache INFO:[0m Reqid: chatcmpl-2a423c9e1d9a4e3497cbd3391da8d017, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,444] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-2a423c9e1d9a4e3497cbd3391da8d017 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,444] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4610 ms, throughput: 5.3292 GB/s; offload_time: 0.3688 ms, put_time: 0.0922 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,449] LMCache INFO:[0m Reqid: chatcmpl-780d7fe374c54cf5a250807f3702c38a, Total tokens 757, LMCache hit tokens: 640, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,449] LMCache INFO:[0m Reqid: chatcmpl-31b912bf01e2414d87033408fa141fa5, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,459] LMCache INFO:[0m Storing KV cache for 757 out of 757 tokens (skip_leading_tokens=0) for request chatcmpl-780d7fe374c54cf5a250807f3702c38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,460] LMCache INFO:[0m Stored 117 out of total 757 tokens. size: 0.0031 gb, cost 0.7368 ms, throughput: 4.2401 GB/s; offload_time: 0.6633 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,461] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-31b912bf01e2414d87033408fa141fa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,461] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.6327 ms, throughput: 4.1784 GB/s; offload_time: 0.5639 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,466] LMCache INFO:[0m Reqid: chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,475] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,476] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.4438 ms, throughput: 5.8361 GB/s; offload_time: 0.3743 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,479] LMCache INFO:[0m Reqid: chatcmpl-4d285105f8704081af50fcb0ac18d012, Total tokens 137, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,489] LMCache INFO:[0m Storing KV cache for 137 out of 137 tokens (skip_leading_tokens=0) for request chatcmpl-4d285105f8704081af50fcb0ac18d012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,490] LMCache INFO:[0m Stored 137 out of total 137 tokens. size: 0.0037 gb, cost 0.8343 ms, throughput: 4.3849 GB/s; offload_time: 0.7254 ms, put_time: 0.1089 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,490] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-2f85ef31846d41079f1b216cb2acbe09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,492] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.7189 ms, throughput: 1.9885 GB/s; offload_time: 1.6512 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,509] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3ad6239c21d641b8bbc70398850a9413 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,510] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7068 ms, throughput: 4.8360 GB/s; offload_time: 0.6370 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,510] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2f1865868fc94eb0b25bbad428c68cd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,511] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7848 ms, throughput: 4.3553 GB/s; offload_time: 0.7224 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,511] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3d1ae723206049ad856004dc02677efe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,512] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7345 ms, throughput: 4.6533 GB/s; offload_time: 0.6715 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,567] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-780d7fe374c54cf5a250807f3702c38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,567] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7193 ms, throughput: 4.7521 GB/s; offload_time: 0.6489 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,584] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7234656f906b44dcb04cd95d6720777d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,585] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7335 ms, throughput: 4.6597 GB/s; offload_time: 0.6630 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,593] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b637e0743b7041e3bf19ff2ca771cdf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,594] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.7239 ms, throughput: 4.7217 GB/s; offload_time: 0.6527 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,613] LMCache INFO:[0m Reqid: chatcmpl-b98a8caf53884197b702668cb47af02f, Total tokens 563, LMCache hit tokens: 512, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,622] LMCache INFO:[0m Storing KV cache for 563 out of 563 tokens (skip_leading_tokens=0) for request chatcmpl-b98a8caf53884197b702668cb47af02f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,623] LMCache INFO:[0m Stored 51 out of total 563 tokens. size: 0.0014 gb, cost 0.4982 ms, throughput: 2.7336 GB/s; offload_time: 0.4309 ms, put_time: 0.0673 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,638] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ba1b18a8cef84e4e8e1672d7a5c9e0cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,639] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7089 ms, throughput: 4.8216 GB/s; offload_time: 0.6279 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,655] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-81f13cfa70e448e99190372d1b2f936e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,656] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7175 ms, throughput: 4.7635 GB/s; offload_time: 0.6419 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,660] LMCache INFO:[0m Reqid: chatcmpl-17157e42aba248a68bfb5e36402eabd4, Total tokens 1373, LMCache hit tokens: 1280, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,661] LMCache INFO:[0m Reqid: chatcmpl-c509a6d4c2a146fc91249aff39cf24da, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,672] LMCache INFO:[0m Storing KV cache for 1373 out of 1373 tokens (skip_leading_tokens=0) for request chatcmpl-17157e42aba248a68bfb5e36402eabd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,673] LMCache INFO:[0m Stored 93 out of total 1373 tokens. size: 0.0025 gb, cost 0.5336 ms, throughput: 4.6540 GB/s; offload_time: 0.4644 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,673] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-c509a6d4c2a146fc91249aff39cf24da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,674] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.7927 ms, throughput: 3.6046 GB/s; offload_time: 0.7315 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,691] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-4b7691785e9b4ba997f5dd604410ddc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,692] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7002 ms, throughput: 4.8812 GB/s; offload_time: 0.6243 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,695] LMCache INFO:[0m Reqid: chatcmpl-fa746e461d9c482da99d2475fd9ffd0e, Total tokens 354, LMCache hit tokens: 256, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,705] LMCache INFO:[0m Storing KV cache for 354 out of 354 tokens (skip_leading_tokens=0) for request chatcmpl-fa746e461d9c482da99d2475fd9ffd0e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,706] LMCache INFO:[0m Stored 98 out of total 354 tokens. size: 0.0026 gb, cost 0.6390 ms, throughput: 4.0953 GB/s; offload_time: 0.5676 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,726] LMCache INFO:[0m Reqid: chatcmpl-552c79dc696840dab2dd840e2cb72338, Total tokens 1384, LMCache hit tokens: 1280, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,728] LMCache INFO:[0m Reqid: chatcmpl-e45f27c9c3954c8d8d83981cda4d4687, Total tokens 1431, LMCache hit tokens: 1408, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,729] LMCache INFO:[0m Reqid: chatcmpl-3b57fdbd7bf34d8486653363b4713f99, Total tokens 511, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,729] LMCache INFO:[0m Reqid: chatcmpl-091be6538e7c443dbb08f3ae6d7e63bc, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,744] LMCache INFO:[0m Storing KV cache for 1384 out of 1384 tokens (skip_leading_tokens=0) for request chatcmpl-552c79dc696840dab2dd840e2cb72338 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,745] LMCache INFO:[0m Stored 104 out of total 1384 tokens. size: 0.0028 gb, cost 0.7187 ms, throughput: 3.8641 GB/s; offload_time: 0.6446 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,745] LMCache INFO:[0m Storing KV cache for 1431 out of 1431 tokens (skip_leading_tokens=0) for request chatcmpl-e45f27c9c3954c8d8d83981cda4d4687 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,746] LMCache INFO:[0m Stored 23 out of total 1431 tokens. size: 0.0006 gb, cost 0.9519 ms, throughput: 0.6452 GB/s; offload_time: 0.8840 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,747] LMCache INFO:[0m Storing KV cache for 511 out of 511 tokens (skip_leading_tokens=0) for request chatcmpl-3b57fdbd7bf34d8486653363b4713f99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,748] LMCache INFO:[0m Stored 255 out of total 511 tokens. size: 0.0068 gb, cost 1.3072 ms, throughput: 5.2091 GB/s; offload_time: 1.2136 ms, put_time: 0.0936 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,749] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-091be6538e7c443dbb08f3ae6d7e63bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,750] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 1.4574 ms, throughput: 1.8322 GB/s; offload_time: 1.3871 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,755] LMCache INFO:[0m Reqid: chatcmpl-f8c00cfdecd148fd820afb379411c3c1, Total tokens 621, LMCache hit tokens: 512, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,765] LMCache INFO:[0m Storing KV cache for 621 out of 621 tokens (skip_leading_tokens=0) for request chatcmpl-f8c00cfdecd148fd820afb379411c3c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,766] LMCache INFO:[0m Stored 109 out of total 621 tokens. size: 0.0029 gb, cost 0.4650 ms, throughput: 6.2596 GB/s; offload_time: 0.3965 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,766] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3b57fdbd7bf34d8486653363b4713f99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,767] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.8809 ms, throughput: 3.8803 GB/s; offload_time: 0.8186 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,771] LMCache INFO:[0m Reqid: chatcmpl-6598ffe4710d4fa2b17ac37052f9a2f3, Total tokens 484, LMCache hit tokens: 384, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,781] LMCache INFO:[0m Storing KV cache for 484 out of 484 tokens (skip_leading_tokens=0) for request chatcmpl-6598ffe4710d4fa2b17ac37052f9a2f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,782] LMCache INFO:[0m Stored 100 out of total 484 tokens. size: 0.0027 gb, cost 0.6428 ms, throughput: 4.1538 GB/s; offload_time: 0.5719 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,791] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-18ad681e55394068ab7c7402ff9792b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,791] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7355 ms, throughput: 4.6471 GB/s; offload_time: 0.6614 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,800] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,801] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6138 ms, throughput: 5.5685 GB/s; offload_time: 0.5390 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,822] LMCache INFO:[0m Reqid: chatcmpl-0ae8da1052cc44b28028ac6af3846a08, Total tokens 1845, LMCache hit tokens: 1792, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,832] LMCache INFO:[0m Storing KV cache for 1845 out of 1845 tokens (skip_leading_tokens=0) for request chatcmpl-0ae8da1052cc44b28028ac6af3846a08 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,833] LMCache INFO:[0m Stored 53 out of total 1845 tokens. size: 0.0014 gb, cost 0.6834 ms, throughput: 2.0709 GB/s; offload_time: 0.6092 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,837] LMCache INFO:[0m Reqid: chatcmpl-c650ad97d54c458cb7307cad5006042e, Total tokens 240, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,846] LMCache INFO:[0m Storing KV cache for 240 out of 240 tokens (skip_leading_tokens=0) for request chatcmpl-c650ad97d54c458cb7307cad5006042e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,847] LMCache INFO:[0m Stored 112 out of total 240 tokens. size: 0.0030 gb, cost 0.6272 ms, throughput: 4.7681 GB/s; offload_time: 0.5535 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,871] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-966ed7d36d0641ac97941003d6044044 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,872] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7990 ms, throughput: 4.2781 GB/s; offload_time: 0.7165 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,881] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-76284f5af5b84f4487582cec2c33e5d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,882] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6901 ms, throughput: 4.9528 GB/s; offload_time: 0.6164 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,893] LMCache INFO:[0m Reqid: chatcmpl-d667dce780f445459c36281ffab4eb80, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,903] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-d667dce780f445459c36281ffab4eb80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,904] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.6006 ms, throughput: 4.8910 GB/s; offload_time: 0.5250 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,913] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c509a6d4c2a146fc91249aff39cf24da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,914] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6366 ms, throughput: 5.3690 GB/s; offload_time: 0.5566 ms, put_time: 0.0800 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,926] LMCache INFO:[0m Reqid: chatcmpl-8bb4f1b3909c48bf88752cfbfe9c0ea1, Total tokens 324, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,937] LMCache INFO:[0m Storing KV cache for 324 out of 324 tokens (skip_leading_tokens=0) for request chatcmpl-8bb4f1b3909c48bf88752cfbfe9c0ea1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,938] LMCache INFO:[0m Stored 196 out of total 324 tokens. size: 0.0052 gb, cost 0.8771 ms, throughput: 5.9669 GB/s; offload_time: 0.7741 ms, put_time: 0.1031 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:47,959] LMCache INFO:[0m Reqid: chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c, Total tokens 529, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,973] LMCache INFO:[0m Storing KV cache for 529 out of 529 tokens (skip_leading_tokens=0) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,975] LMCache INFO:[0m Stored 529 out of total 529 tokens. size: 0.0141 gb, cost 1.8228 ms, throughput: 7.7496 GB/s; offload_time: 1.6276 ms, put_time: 0.1952 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:47,976] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f8c00cfdecd148fd820afb379411c3c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:47,979] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 2.8009 ms, throughput: 1.2203 GB/s; offload_time: 2.0177 ms, put_time: 0.7832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,000] LMCache INFO:[0m Reqid: chatcmpl-2c7e094553a24ecab88f0094126779cb, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,000] LMCache INFO:[0m Reqid: chatcmpl-4650dc048fb14dfa856a5b91bbe4066c, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,014] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-2c7e094553a24ecab88f0094126779cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,015] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.6273 ms, throughput: 3.9586 GB/s; offload_time: 0.5580 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,015] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-4650dc048fb14dfa856a5b91bbe4066c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,016] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.6397 ms, throughput: 3.9241 GB/s; offload_time: 0.5789 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,025] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-552c79dc696840dab2dd840e2cb72338 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,026] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7221 ms, throughput: 4.7336 GB/s; offload_time: 0.6432 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,027] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c650ad97d54c458cb7307cad5006042e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,028] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6137 ms, throughput: 5.5692 GB/s; offload_time: 0.5446 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,037] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,038] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6764 ms, throughput: 5.0534 GB/s; offload_time: 0.6062 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,041] LMCache INFO:[0m Reqid: chatcmpl-db65296e72084a06b06ad5df4d76e091, Total tokens 352, LMCache hit tokens: 256, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,042] LMCache INFO:[0m Reqid: chatcmpl-5d831e078d63485caa5a332b596396ad, Total tokens 847, LMCache hit tokens: 768, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,043] LMCache INFO:[0m Reqid: chatcmpl-5fee936ba3ec4e5ea189bfea265d7353, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,054] LMCache INFO:[0m Storing KV cache for 352 out of 352 tokens (skip_leading_tokens=0) for request chatcmpl-db65296e72084a06b06ad5df4d76e091 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,055] LMCache INFO:[0m Stored 96 out of total 352 tokens. size: 0.0026 gb, cost 0.6185 ms, throughput: 4.1445 GB/s; offload_time: 0.5476 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,056] LMCache INFO:[0m Storing KV cache for 847 out of 847 tokens (skip_leading_tokens=0) for request chatcmpl-5d831e078d63485caa5a332b596396ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,057] LMCache INFO:[0m Stored 79 out of total 847 tokens. size: 0.0021 gb, cost 0.8490 ms, throughput: 2.4848 GB/s; offload_time: 0.7800 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,057] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-5fee936ba3ec4e5ea189bfea265d7353 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,058] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.6391 ms, throughput: 4.0111 GB/s; offload_time: 0.5747 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,068] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-fa746e461d9c482da99d2475fd9ffd0e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,069] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6417 ms, throughput: 5.3265 GB/s; offload_time: 0.5746 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,078] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-091be6538e7c443dbb08f3ae6d7e63bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,079] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6327 ms, throughput: 5.4024 GB/s; offload_time: 0.5580 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,083] LMCache INFO:[0m Reqid: chatcmpl-7b6e300698d34cbd899f567d88f87036, Total tokens 744, LMCache hit tokens: 640, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,084] LMCache INFO:[0m Reqid: chatcmpl-80d129e6e90d44beb6d1838e6b2c837e, Total tokens 711, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,099] LMCache INFO:[0m Storing KV cache for 744 out of 744 tokens (skip_leading_tokens=0) for request chatcmpl-7b6e300698d34cbd899f567d88f87036 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,100] LMCache INFO:[0m Stored 104 out of total 744 tokens. size: 0.0028 gb, cost 0.6923 ms, throughput: 4.0116 GB/s; offload_time: 0.6227 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,100] LMCache INFO:[0m Storing KV cache for 711 out of 711 tokens (skip_leading_tokens=0) for request chatcmpl-80d129e6e90d44beb6d1838e6b2c837e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,103] LMCache INFO:[0m Stored 327 out of total 711 tokens. size: 0.0087 gb, cost 2.5302 ms, throughput: 3.4511 GB/s; offload_time: 1.6591 ms, put_time: 0.8711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,104] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-17157e42aba248a68bfb5e36402eabd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,105] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.1081 ms, throughput: 3.0846 GB/s; offload_time: 1.0442 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,119] LMCache INFO:[0m Reqid: chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c, Total tokens 820, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,140] LMCache INFO:[0m Storing KV cache for 820 out of 820 tokens (skip_leading_tokens=0) for request chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,143] LMCache INFO:[0m Stored 820 out of total 820 tokens. size: 0.0219 gb, cost 2.6379 ms, throughput: 8.3005 GB/s; offload_time: 2.4003 ms, put_time: 0.2376 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,156] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d667dce780f445459c36281ffab4eb80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,157] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7207 ms, throughput: 4.7423 GB/s; offload_time: 0.6377 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,166] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,167] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7133 ms, throughput: 4.7920 GB/s; offload_time: 0.6408 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,167] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,168] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1201 ms, throughput: 3.0515 GB/s; offload_time: 1.0490 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,188] LMCache INFO:[0m Reqid: chatcmpl-7651e1cbcb75403faecdbcd438cc59cc, Total tokens 2091, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,230] LMCache INFO:[0m Storing KV cache for 2091 out of 2091 tokens (skip_leading_tokens=0) for request chatcmpl-7651e1cbcb75403faecdbcd438cc59cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,241] LMCache INFO:[0m Stored 2091 out of total 2091 tokens. size: 0.0558 gb, cost 10.4566 ms, throughput: 5.3398 GB/s; offload_time: 5.9637 ms, put_time: 4.4929 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,241] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-46e19d28ea09404c86bc2db011566ed9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,244] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.0890 ms, throughput: 1.6361 GB/s; offload_time: 1.9843 ms, put_time: 0.1047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,297] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c8b34c7aad1d4e679674196fbaadd7d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,298] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7934 ms, throughput: 4.3078 GB/s; offload_time: 0.7203 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,308] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ec2ffd53ea744db5ab2412cf7c188048 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,309] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7473 ms, throughput: 4.5735 GB/s; offload_time: 0.6694 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,318] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-19a09aa10bbb498bb9c7aa91b660f892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,319] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.8183 ms, throughput: 4.1770 GB/s; offload_time: 0.7408 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,366] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-2bd543897835488c9f0e3b7e7aa2fe90 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,367] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.8202 ms, throughput: 4.1673 GB/s; offload_time: 0.7463 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,392] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-7b6e300698d34cbd899f567d88f87036 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,393] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8136 ms, throughput: 4.2010 GB/s; offload_time: 0.7341 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,402] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a6e3a97e0b0749119de28225f027ab1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,402] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7359 ms, throughput: 4.6445 GB/s; offload_time: 0.6606 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,406] LMCache INFO:[0m Reqid: chatcmpl-13b80fbdad5548a49eb01a612344216b, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,417] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-13b80fbdad5548a49eb01a612344216b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,417] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.4604 ms, throughput: 5.6835 GB/s; offload_time: 0.3852 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,434] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-4650dc048fb14dfa856a5b91bbe4066c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,435] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7610 ms, throughput: 4.4917 GB/s; offload_time: 0.6873 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,440] LMCache INFO:[0m Reqid: chatcmpl-5359baeada88444bb4212fe45807ac1d, Total tokens 1014, LMCache hit tokens: 896, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,450] LMCache INFO:[0m Storing KV cache for 1014 out of 1014 tokens (skip_leading_tokens=0) for request chatcmpl-5359baeada88444bb4212fe45807ac1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,451] LMCache INFO:[0m Stored 118 out of total 1014 tokens. size: 0.0032 gb, cost 0.5346 ms, throughput: 5.8936 GB/s; offload_time: 0.4588 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,451] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e008e7a62e1b4364b81a33944eced376 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,452] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0560 ms, throughput: 3.2368 GB/s; offload_time: 0.9718 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,453] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-27015534e27b4e62b4b6bd10f8667a2b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,454] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0491 ms, throughput: 3.2579 GB/s; offload_time: 0.9788 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,454] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2c7e094553a24ecab88f0094126779cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,455] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9109 ms, throughput: 3.7521 GB/s; offload_time: 0.8472 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,456] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-db65296e72084a06b06ad5df4d76e091 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,458] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.0333 ms, throughput: 1.6810 GB/s; offload_time: 1.9608 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,458] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5fee936ba3ec4e5ea189bfea265d7353 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,459] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7549 ms, throughput: 4.5276 GB/s; offload_time: 0.6934 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,488] LMCache INFO:[0m Reqid: chatcmpl-6c4715cbc3fe4a3f86dec7008ad9ede9, Total tokens 290, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,498] LMCache INFO:[0m Storing KV cache for 290 out of 290 tokens (skip_leading_tokens=0) for request chatcmpl-6c4715cbc3fe4a3f86dec7008ad9ede9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,499] LMCache INFO:[0m Stored 34 out of total 290 tokens. size: 0.0009 gb, cost 0.5191 ms, throughput: 1.7489 GB/s; offload_time: 0.4443 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,499] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2f1aced808384a88856b06377d8891ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,500] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9357 ms, throughput: 3.6528 GB/s; offload_time: 0.8556 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,504] LMCache INFO:[0m Reqid: chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1, Total tokens 189, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,516] LMCache INFO:[0m Storing KV cache for 189 out of 189 tokens (skip_leading_tokens=0) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,517] LMCache INFO:[0m Stored 189 out of total 189 tokens. size: 0.0050 gb, cost 0.9925 ms, throughput: 5.0852 GB/s; offload_time: 0.8683 ms, put_time: 0.1241 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,517] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-21f96c8ff2b24683b9b0783304adf438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,519] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6537 ms, throughput: 2.0669 GB/s; offload_time: 1.4451 ms, put_time: 0.2086 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,538] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-7412268184b3421092ab451e1bb94ec6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,539] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.8987 ms, throughput: 3.8032 GB/s; offload_time: 0.8226 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,542] LMCache INFO:[0m Reqid: chatcmpl-2c322609891244b7801086d36cdd9a3e, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,553] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-2c322609891244b7801086d36cdd9a3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,554] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.4242 ms, throughput: 6.9240 GB/s; offload_time: 0.3472 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,554] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b98a8caf53884197b702668cb47af02f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,556] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0613 ms, throughput: 3.2205 GB/s; offload_time: 0.9864 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,573] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5359baeada88444bb4212fe45807ac1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,574] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8765 ms, throughput: 3.8997 GB/s; offload_time: 0.7926 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,599] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4b99b2bf38bd4365958d134dab5292a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,600] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7743 ms, throughput: 4.4141 GB/s; offload_time: 0.6945 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,619] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-bcf33c3a9d21443ab83ee3b39fb5cc62 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,620] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.8002 ms, throughput: 4.2716 GB/s; offload_time: 0.7236 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,620] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-edc2b011c1084cfb9ce0e234bf0ff657 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,621] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.0157 ms, throughput: 3.3651 GB/s; offload_time: 0.9408 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,626] LMCache INFO:[0m Reqid: chatcmpl-b905bc06642d4595ad868024a5f2b4a9, Total tokens 907, LMCache hit tokens: 768, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,637] LMCache INFO:[0m Storing KV cache for 907 out of 907 tokens (skip_leading_tokens=0) for request chatcmpl-b905bc06642d4595ad868024a5f2b4a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,638] LMCache INFO:[0m Stored 139 out of total 907 tokens. size: 0.0037 gb, cost 1.0166 ms, throughput: 3.6512 GB/s; offload_time: 0.9049 ms, put_time: 0.1116 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,639] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9cf6a545b78346dc93cc8ee4336c4382 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,641] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3323 ms, throughput: 2.5654 GB/s; offload_time: 1.1608 ms, put_time: 0.1715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,650] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5d831e078d63485caa5a332b596396ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,651] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7960 ms, throughput: 4.2939 GB/s; offload_time: 0.7181 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,664] LMCache INFO:[0m Reqid: chatcmpl-e3f787905047424792b7d4db9e138940, Total tokens 714, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,677] LMCache INFO:[0m Storing KV cache for 714 out of 714 tokens (skip_leading_tokens=0) for request chatcmpl-e3f787905047424792b7d4db9e138940 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,678] LMCache INFO:[0m Stored 74 out of total 714 tokens. size: 0.0020 gb, cost 0.5021 ms, throughput: 3.9354 GB/s; offload_time: 0.4259 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,682] LMCache INFO:[0m Reqid: chatcmpl-3120cc8a93ce4037b0cb87f9517e5904, Total tokens 240, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,694] LMCache INFO:[0m Storing KV cache for 240 out of 240 tokens (skip_leading_tokens=0) for request chatcmpl-3120cc8a93ce4037b0cb87f9517e5904 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,695] LMCache INFO:[0m Stored 240 out of total 240 tokens. size: 0.0064 gb, cost 0.9804 ms, throughput: 6.5366 GB/s; offload_time: 0.8634 ms, put_time: 0.1170 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,695] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8eaf7703356346be9ac4089f02b9fe84 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,698] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 2.0050 ms, throughput: 1.7047 GB/s; offload_time: 1.9320 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,708] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e49255cf1eca4b7bb34dc290c282446c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,709] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7774 ms, throughput: 4.3968 GB/s; offload_time: 0.6947 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,719] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-69606084b13e4819ac7d4f88ece73a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,720] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.8364 ms, throughput: 4.0866 GB/s; offload_time: 0.7609 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,724] LMCache INFO:[0m Reqid: chatcmpl-0855730d93a245be87e474200347989b, Total tokens 639, LMCache hit tokens: 512, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,725] LMCache INFO:[0m Reqid: chatcmpl-400068e3a03d46088efe28fd74eadf54, Total tokens 400, LMCache hit tokens: 256, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,725] LMCache INFO:[0m Reqid: chatcmpl-dd6bbed8d6234054add81cf06bb7dc16, Total tokens 161, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,726] LMCache INFO:[0m Reqid: chatcmpl-bee71b4578d6403984bca220bb7f94f9, Total tokens 148, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,740] LMCache INFO:[0m Storing KV cache for 639 out of 639 tokens (skip_leading_tokens=0) for request chatcmpl-0855730d93a245be87e474200347989b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,741] LMCache INFO:[0m Stored 127 out of total 639 tokens. size: 0.0034 gb, cost 0.8023 ms, throughput: 4.2268 GB/s; offload_time: 0.7252 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,741] LMCache INFO:[0m Storing KV cache for 400 out of 400 tokens (skip_leading_tokens=0) for request chatcmpl-400068e3a03d46088efe28fd74eadf54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,743] LMCache INFO:[0m Stored 144 out of total 400 tokens. size: 0.0038 gb, cost 1.2694 ms, throughput: 3.0292 GB/s; offload_time: 1.1681 ms, put_time: 0.1013 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,743] LMCache INFO:[0m Storing KV cache for 161 out of 161 tokens (skip_leading_tokens=0) for request chatcmpl-dd6bbed8d6234054add81cf06bb7dc16 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,745] LMCache INFO:[0m Stored 33 out of total 161 tokens. size: 0.0009 gb, cost 1.0705 ms, throughput: 0.8232 GB/s; offload_time: 1.0102 ms, put_time: 0.0603 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,745] LMCache INFO:[0m Storing KV cache for 148 out of 148 tokens (skip_leading_tokens=0) for request chatcmpl-bee71b4578d6403984bca220bb7f94f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,747] LMCache INFO:[0m Stored 148 out of total 148 tokens. size: 0.0040 gb, cost 1.5194 ms, throughput: 2.6010 GB/s; offload_time: 1.4092 ms, put_time: 0.1103 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,747] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-803e581426084742863bdb844a47a998 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,750] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.4326 ms, throughput: 1.4051 GB/s; offload_time: 2.1439 ms, put_time: 0.2888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,761] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0c929daceb6b4e8e8b81866e07e8e9e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,762] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8168 ms, throughput: 4.1844 GB/s; offload_time: 0.7444 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,762] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-0ae8da1052cc44b28028ac6af3846a08 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,763] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.8358 ms, throughput: 4.0896 GB/s; offload_time: 0.7733 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,763] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0855730d93a245be87e474200347989b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,764] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8468 ms, throughput: 4.0363 GB/s; offload_time: 0.7839 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,775] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-00ea0ba28c764cb78db9dd00aaf0568b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,776] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8409 ms, throughput: 4.0649 GB/s; offload_time: 0.7683 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,793] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-13b80fbdad5548a49eb01a612344216b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,794] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7382 ms, throughput: 4.6303 GB/s; offload_time: 0.6609 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,803] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-80d129e6e90d44beb6d1838e6b2c837e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,804] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7803 ms, throughput: 4.3804 GB/s; offload_time: 0.7081 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,853] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-3509cbfce32b441e9c4edf3d024d34f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,854] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.9151 ms, throughput: 3.7353 GB/s; offload_time: 0.8419 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,857] LMCache INFO:[0m Reqid: chatcmpl-cfe2a72c06aa4989bae6f65e6e915d37, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,869] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-cfe2a72c06aa4989bae6f65e6e915d37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,869] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.4642 ms, throughput: 5.5225 GB/s; offload_time: 0.3841 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,870] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4d285105f8704081af50fcb0ac18d012 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,871] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1413 ms, throughput: 2.9947 GB/s; offload_time: 1.0698 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,882] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9f43ba082b314eb882a39cd140f8e3b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,883] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.8408 ms, throughput: 4.0653 GB/s; offload_time: 0.7677 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,883] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-1c556f345ab144f982c0929d2b30fb9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,884] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.9813 ms, throughput: 3.4830 GB/s; offload_time: 0.9087 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,884] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3120cc8a93ce4037b0cb87f9517e5904 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,885] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8920 ms, throughput: 3.8319 GB/s; offload_time: 0.8287 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,966] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2f1865868fc94eb0b25bbad428c68cd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,967] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7973 ms, throughput: 4.2867 GB/s; offload_time: 0.7248 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,967] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3d1ae723206049ad856004dc02677efe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,968] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9182 ms, throughput: 3.7223 GB/s; offload_time: 0.8390 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:48,993] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:48,994] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9428 ms, throughput: 3.6253 GB/s; offload_time: 0.8702 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:48,998] LMCache INFO:[0m Reqid: chatcmpl-8fc5338d9ef441a9a2548fe4edad81b6, Total tokens 671, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,008] LMCache INFO:[0m Storing KV cache for 671 out of 671 tokens (skip_leading_tokens=0) for request chatcmpl-8fc5338d9ef441a9a2548fe4edad81b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,009] LMCache INFO:[0m Stored 31 out of total 671 tokens. size: 0.0008 gb, cost 0.4918 ms, throughput: 1.6830 GB/s; offload_time: 0.4206 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,028] LMCache INFO:[0m Reqid: chatcmpl-803861d08f7a42889b707c59820de43f, Total tokens 121, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,041] LMCache INFO:[0m Storing KV cache for 121 out of 121 tokens (skip_leading_tokens=0) for request chatcmpl-803861d08f7a42889b707c59820de43f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,042] LMCache INFO:[0m Stored 121 out of total 121 tokens. size: 0.0032 gb, cost 0.4284 ms, throughput: 7.5427 GB/s; offload_time: 0.3520 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,042] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-780d7fe374c54cf5a250807f3702c38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,044] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1084 ms, throughput: 3.0836 GB/s; offload_time: 1.0421 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,069] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b637e0743b7041e3bf19ff2ca771cdf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,070] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.9464 ms, throughput: 3.6115 GB/s; offload_time: 0.8751 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,097] LMCache INFO:[0m Reqid: chatcmpl-88aa257dbc5f4763bf12580cb630e4ce, Total tokens 231, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,107] LMCache INFO:[0m Storing KV cache for 231 out of 231 tokens (skip_leading_tokens=0) for request chatcmpl-88aa257dbc5f4763bf12580cb630e4ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,107] LMCache INFO:[0m Stored 103 out of total 231 tokens. size: 0.0028 gb, cost 0.5018 ms, throughput: 5.4816 GB/s; offload_time: 0.4281 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,108] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-803861d08f7a42889b707c59820de43f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,109] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9753 ms, throughput: 3.5046 GB/s; offload_time: 0.9107 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,112] LMCache INFO:[0m Reqid: chatcmpl-3283d9e7130d40d68831a3fb70e3bfbe, Total tokens 199, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,123] LMCache INFO:[0m Storing KV cache for 199 out of 199 tokens (skip_leading_tokens=0) for request chatcmpl-3283d9e7130d40d68831a3fb70e3bfbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,124] LMCache INFO:[0m Stored 71 out of total 199 tokens. size: 0.0019 gb, cost 0.4624 ms, throughput: 4.1002 GB/s; offload_time: 0.3913 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,141] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-81f13cfa70e448e99190372d1b2f936e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,142] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8534 ms, throughput: 4.0052 GB/s; offload_time: 0.7762 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,143] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-7651e1cbcb75403faecdbcd438cc59cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,144] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.0440 ms, throughput: 3.2738 GB/s; offload_time: 0.9733 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,164] LMCache INFO:[0m Reqid: chatcmpl-4506111fd00a45e980fd4338d92b7b63, Total tokens 167, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,175] LMCache INFO:[0m Storing KV cache for 167 out of 167 tokens (skip_leading_tokens=0) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,176] LMCache INFO:[0m Stored 167 out of total 167 tokens. size: 0.0045 gb, cost 1.0352 ms, throughput: 4.3079 GB/s; offload_time: 0.9168 ms, put_time: 0.1184 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,187] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-cfe2a72c06aa4989bae6f65e6e915d37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,188] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7848 ms, throughput: 4.3554 GB/s; offload_time: 0.7070 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,192] LMCache INFO:[0m Reqid: chatcmpl-988b1d0092df45a0b34b3bd46b359a37, Total tokens 597, LMCache hit tokens: 512, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,203] LMCache INFO:[0m Storing KV cache for 597 out of 597 tokens (skip_leading_tokens=0) for request chatcmpl-988b1d0092df45a0b34b3bd46b359a37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,203] LMCache INFO:[0m Stored 85 out of total 597 tokens. size: 0.0023 gb, cost 0.5408 ms, throughput: 4.1970 GB/s; offload_time: 0.4542 ms, put_time: 0.0866 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,223] LMCache INFO:[0m Reqid: chatcmpl-1f5876c17f54453884c160f6d67bd4af, Total tokens 906, LMCache hit tokens: 768, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,237] LMCache INFO:[0m Storing KV cache for 906 out of 906 tokens (skip_leading_tokens=0) for request chatcmpl-1f5876c17f54453884c160f6d67bd4af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,239] LMCache INFO:[0m Stored 138 out of total 906 tokens. size: 0.0037 gb, cost 1.0797 ms, throughput: 3.4129 GB/s; offload_time: 0.9663 ms, put_time: 0.1135 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,239] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-3b57fdbd7bf34d8486653363b4713f99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,241] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.8726 ms, throughput: 1.8253 GB/s; offload_time: 1.7976 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,246] LMCache INFO:[0m Reqid: chatcmpl-3e0827abfe1c4dd3b13a1370134a883c, Total tokens 452, LMCache hit tokens: 384, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,255] LMCache INFO:[0m Storing KV cache for 452 out of 452 tokens (skip_leading_tokens=0) for request chatcmpl-3e0827abfe1c4dd3b13a1370134a883c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,256] LMCache INFO:[0m Stored 68 out of total 452 tokens. size: 0.0018 gb, cost 0.4713 ms, throughput: 3.8531 GB/s; offload_time: 0.3940 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,256] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,258] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0217 ms, throughput: 3.3452 GB/s; offload_time: 0.9497 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,261] LMCache INFO:[0m Reqid: chatcmpl-ce6ffd91955d4c979cdc4d44fffb80c6, Total tokens 126, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,275] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-ce6ffd91955d4c979cdc4d44fffb80c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,276] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 0.4534 ms, throughput: 7.4210 GB/s; offload_time: 0.3775 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,276] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-18ad681e55394068ab7c7402ff9792b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,278] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1659 ms, throughput: 2.9315 GB/s; offload_time: 1.0888 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,278] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,279] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0850 ms, throughput: 3.1501 GB/s; offload_time: 0.9618 ms, put_time: 0.1232 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,279] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e3f787905047424792b7d4db9e138940 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,281] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2700 ms, throughput: 2.6912 GB/s; offload_time: 1.1914 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,286] LMCache INFO:[0m Reqid: chatcmpl-27c130ce29884b3999d356a2060b3a6a, Total tokens 1528, LMCache hit tokens: 1408, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,297] LMCache INFO:[0m Storing KV cache for 1528 out of 1528 tokens (skip_leading_tokens=0) for request chatcmpl-27c130ce29884b3999d356a2060b3a6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,298] LMCache INFO:[0m Stored 120 out of total 1528 tokens. size: 0.0032 gb, cost 0.6059 ms, throughput: 5.2883 GB/s; offload_time: 0.5260 ms, put_time: 0.0800 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,298] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,300] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1452 ms, throughput: 2.9846 GB/s; offload_time: 1.0642 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,304] LMCache INFO:[0m Reqid: chatcmpl-ba115843b7ee43859c96c05ab19516b8, Total tokens 1159, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,307] LMCache INFO:[0m Reqid: chatcmpl-3bf673d1c4bb4940a7643dd9fb798e6b, Total tokens 708, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,308] LMCache INFO:[0m Reqid: chatcmpl-3b0ae74dd92b42eea4484bd20ed69afa, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,308] LMCache INFO:[0m Reqid: chatcmpl-10ec1f6df96340a591a8b9ade9326a2e, Total tokens 706, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,309] LMCache INFO:[0m Reqid: chatcmpl-028aa45d2d344d2184ac06b1e39f3837, Total tokens 203, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,321] LMCache INFO:[0m Storing KV cache for 1159 out of 1159 tokens (skip_leading_tokens=0) for request chatcmpl-ba115843b7ee43859c96c05ab19516b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,323] LMCache INFO:[0m Stored 135 out of total 1159 tokens. size: 0.0036 gb, cost 1.1243 ms, throughput: 3.2063 GB/s; offload_time: 1.0166 ms, put_time: 0.1077 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,323] LMCache INFO:[0m Storing KV cache for 708 out of 708 tokens (skip_leading_tokens=0) for request chatcmpl-3bf673d1c4bb4940a7643dd9fb798e6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,324] LMCache INFO:[0m Stored 68 out of total 708 tokens. size: 0.0018 gb, cost 1.3201 ms, throughput: 1.3755 GB/s; offload_time: 1.2459 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,325] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-3b0ae74dd92b42eea4484bd20ed69afa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,326] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.9390 ms, throughput: 2.8154 GB/s; offload_time: 0.8640 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,326] LMCache INFO:[0m Storing KV cache for 706 out of 706 tokens (skip_leading_tokens=0) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,327] LMCache INFO:[0m Stored 66 out of total 706 tokens. size: 0.0018 gb, cost 0.6360 ms, throughput: 2.7710 GB/s; offload_time: 0.5751 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,328] LMCache INFO:[0m Storing KV cache for 203 out of 203 tokens (skip_leading_tokens=0) for request chatcmpl-028aa45d2d344d2184ac06b1e39f3837 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,329] LMCache INFO:[0m Stored 75 out of total 203 tokens. size: 0.0020 gb, cost 1.0695 ms, throughput: 1.8725 GB/s; offload_time: 0.6321 ms, put_time: 0.4374 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,329] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-ce6ffd91955d4c979cdc4d44fffb80c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,330] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1289 ms, throughput: 3.0277 GB/s; offload_time: 1.0595 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,388] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-27c130ce29884b3999d356a2060b3a6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,389] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9748 ms, throughput: 3.5065 GB/s; offload_time: 0.8871 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,413] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-88aa257dbc5f4763bf12580cb630e4ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,414] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8411 ms, throughput: 4.0635 GB/s; offload_time: 0.7690 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,417] LMCache INFO:[0m Reqid: chatcmpl-934af0b3e1c644fe961af0553b4cb804, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,427] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-934af0b3e1c644fe961af0553b4cb804 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,428] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.4147 ms, throughput: 6.6964 GB/s; offload_time: 0.3442 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,459] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f8c00cfdecd148fd820afb379411c3c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,460] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8598 ms, throughput: 3.9751 GB/s; offload_time: 0.7807 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,489] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-552c79dc696840dab2dd840e2cb72338 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,490] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9953 ms, throughput: 3.4341 GB/s; offload_time: 0.9106 ms, put_time: 0.0847 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,499] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,500] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8488 ms, throughput: 4.0271 GB/s; offload_time: 0.7754 ms, put_time: 0.0734 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,523] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-091be6538e7c443dbb08f3ae6d7e63bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,524] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8035 ms, throughput: 4.2541 GB/s; offload_time: 0.7223 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,532] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-17157e42aba248a68bfb5e36402eabd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,533] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9557 ms, throughput: 3.5764 GB/s; offload_time: 0.8694 ms, put_time: 0.0863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,563] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,564] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.8952 ms, throughput: 3.8183 GB/s; offload_time: 0.8218 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,564] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,565] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0994 ms, throughput: 3.1091 GB/s; offload_time: 1.0334 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,573] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3b0ae74dd92b42eea4484bd20ed69afa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,574] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8239 ms, throughput: 4.1485 GB/s; offload_time: 0.7516 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,585] LMCache INFO:[0m Reqid: chatcmpl-1793f2dedabc4368b9dd1e9dec00efdd, Total tokens 976, LMCache hit tokens: 896, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,594] LMCache INFO:[0m Storing KV cache for 976 out of 976 tokens (skip_leading_tokens=0) for request chatcmpl-1793f2dedabc4368b9dd1e9dec00efdd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,595] LMCache INFO:[0m Stored 80 out of total 976 tokens. size: 0.0021 gb, cost 0.5405 ms, throughput: 3.9522 GB/s; offload_time: 0.4680 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,595] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-46e19d28ea09404c86bc2db011566ed9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,597] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2462 ms, throughput: 2.7427 GB/s; offload_time: 1.1741 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,614] LMCache INFO:[0m Reqid: chatcmpl-9263784267624de28c41419b48636072, Total tokens 971, LMCache hit tokens: 896, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,623] LMCache INFO:[0m Storing KV cache for 971 out of 971 tokens (skip_leading_tokens=0) for request chatcmpl-9263784267624de28c41419b48636072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,624] LMCache INFO:[0m Stored 75 out of total 971 tokens. size: 0.0020 gb, cost 0.5766 ms, throughput: 3.4736 GB/s; offload_time: 0.5025 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,632] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-934af0b3e1c644fe961af0553b4cb804 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,633] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8143 ms, throughput: 4.1972 GB/s; offload_time: 0.7347 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,641] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-988b1d0092df45a0b34b3bd46b359a37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,642] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8678 ms, throughput: 3.9387 GB/s; offload_time: 0.7908 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,646] LMCache INFO:[0m Reqid: chatcmpl-c4d14bbfbe1c483fac6fe980ad978b6a, Total tokens 846, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,660] LMCache INFO:[0m Storing KV cache for 846 out of 846 tokens (skip_leading_tokens=0) for request chatcmpl-c4d14bbfbe1c483fac6fe980ad978b6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,663] LMCache INFO:[0m Stored 462 out of total 846 tokens. size: 0.0123 gb, cost 2.2182 ms, throughput: 5.5616 GB/s; offload_time: 1.9000 ms, put_time: 0.3182 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,689] LMCache INFO:[0m Reqid: chatcmpl-5fda769b64cb472ab208cb01b73b0f1a, Total tokens 866, LMCache hit tokens: 768, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,699] LMCache INFO:[0m Storing KV cache for 866 out of 866 tokens (skip_leading_tokens=0) for request chatcmpl-5fda769b64cb472ab208cb01b73b0f1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,699] LMCache INFO:[0m Stored 98 out of total 866 tokens. size: 0.0026 gb, cost 0.5790 ms, throughput: 4.5198 GB/s; offload_time: 0.4997 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,702] LMCache INFO:[0m Reqid: chatcmpl-10f1776a54d847b78fd0cdcc5e86e289, Total tokens 145, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,716] LMCache INFO:[0m Storing KV cache for 145 out of 145 tokens (skip_leading_tokens=0) for request chatcmpl-10f1776a54d847b78fd0cdcc5e86e289 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,717] LMCache INFO:[0m Stored 145 out of total 145 tokens. size: 0.0039 gb, cost 1.0399 ms, throughput: 3.7234 GB/s; offload_time: 0.9320 ms, put_time: 0.1079 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,721] LMCache INFO:[0m Reqid: chatcmpl-df15d138f25942948a266e81edd0f7ef, Total tokens 261, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,730] LMCache INFO:[0m Storing KV cache for 261 out of 261 tokens (skip_leading_tokens=0) for request chatcmpl-df15d138f25942948a266e81edd0f7ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,732] LMCache INFO:[0m Stored 133 out of total 261 tokens. size: 0.0036 gb, cost 1.0447 ms, throughput: 3.3996 GB/s; offload_time: 0.9317 ms, put_time: 0.1130 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,732] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-dd6bbed8d6234054add81cf06bb7dc16 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,735] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.6834 ms, throughput: 1.2737 GB/s; offload_time: 2.5506 ms, put_time: 0.1328 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,735] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3283d9e7130d40d68831a3fb70e3bfbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,737] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4249 ms, throughput: 2.3987 GB/s; offload_time: 1.3502 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,740] LMCache INFO:[0m Reqid: chatcmpl-96457a71cce4465f8b637ddfcb29d497, Total tokens 155, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,750] LMCache INFO:[0m Storing KV cache for 155 out of 155 tokens (skip_leading_tokens=0) for request chatcmpl-96457a71cce4465f8b637ddfcb29d497 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,750] LMCache INFO:[0m Stored 27 out of total 155 tokens. size: 0.0007 gb, cost 0.4659 ms, throughput: 1.5475 GB/s; offload_time: 0.3932 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,754] LMCache INFO:[0m Reqid: chatcmpl-b7a62f19d1314cbc9da585d66867ecc2, Total tokens 509, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,763] LMCache INFO:[0m Storing KV cache for 509 out of 509 tokens (skip_leading_tokens=0) for request chatcmpl-b7a62f19d1314cbc9da585d66867ecc2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,764] LMCache INFO:[0m Stored 125 out of total 509 tokens. size: 0.0033 gb, cost 0.9467 ms, throughput: 3.5256 GB/s; offload_time: 0.8724 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,783] LMCache INFO:[0m Reqid: chatcmpl-0053d25795454952a90053bceb9c01d2, Total tokens 331, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,784] LMCache INFO:[0m Reqid: chatcmpl-d0dc7804d30d401cb67ac01a492d5851, Total tokens 912, LMCache hit tokens: 768, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,786] LMCache INFO:[0m Reqid: chatcmpl-8613da46fc5f4e9a9aab0ed745801f41, Total tokens 5317, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,792] LMCache INFO:[0m Reqid: chatcmpl-b518e1ea97a84730990dc72721723669, Total tokens 1129, LMCache hit tokens: 768, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,793] LMCache INFO:[0m Reqid: chatcmpl-538d29312f0046f9a18747b20f5fee54, Total tokens 503, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,793] LMCache INFO:[0m Reqid: chatcmpl-28732df8529c41d990f3ab126864725f, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,794] LMCache INFO:[0m Reqid: chatcmpl-2a7d4e2b19894b38b268e56132b2919b, Total tokens 498, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,902] LMCache INFO:[0m Storing KV cache for 331 out of 331 tokens (skip_leading_tokens=0) for request chatcmpl-0053d25795454952a90053bceb9c01d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,902] LMCache INFO:[0m Stored 75 out of total 331 tokens. size: 0.0020 gb, cost 0.4896 ms, throughput: 4.0909 GB/s; offload_time: 0.4173 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,903] LMCache INFO:[0m Storing KV cache for 912 out of 912 tokens (skip_leading_tokens=0) for request chatcmpl-d0dc7804d30d401cb67ac01a492d5851 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,904] LMCache INFO:[0m Stored 144 out of total 912 tokens. size: 0.0038 gb, cost 1.6099 ms, throughput: 2.3884 GB/s; offload_time: 1.5062 ms, put_time: 0.1038 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,904] LMCache INFO:[0m Storing KV cache for 5317 out of 5317 tokens (skip_leading_tokens=0) for request chatcmpl-8613da46fc5f4e9a9aab0ed745801f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:49,933] LMCache INFO:[0m Stored 5317 out of total 5317 tokens. size: 0.1420 gb, cost 28.0422 ms, throughput: 5.0630 GB/s; offload_time: 22.3233 ms, put_time: 5.7190 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,933] LMCache INFO:[0m Storing KV cache for 1129 out of 1129 tokens (skip_leading_tokens=0) for request chatcmpl-b518e1ea97a84730990dc72721723669 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,940] LMCache INFO:[0m Stored 361 out of total 1129 tokens. size: 0.0096 gb, cost 6.7391 ms, throughput: 1.4304 GB/s; offload_time: 5.9636 ms, put_time: 0.7755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,941] LMCache INFO:[0m Storing KV cache for 503 out of 503 tokens (skip_leading_tokens=0) for request chatcmpl-538d29312f0046f9a18747b20f5fee54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,944] LMCache INFO:[0m Stored 119 out of total 503 tokens. size: 0.0032 gb, cost 2.9872 ms, throughput: 1.0637 GB/s; offload_time: 2.8478 ms, put_time: 0.1394 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,945] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-28732df8529c41d990f3ab126864725f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,947] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 2.2942 ms, throughput: 1.1290 GB/s; offload_time: 2.2142 ms, put_time: 0.0800 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,947] LMCache INFO:[0m Storing KV cache for 498 out of 498 tokens (skip_leading_tokens=0) for request chatcmpl-2a7d4e2b19894b38b268e56132b2919b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,954] LMCache INFO:[0m Stored 114 out of total 498 tokens. size: 0.0030 gb, cost 4.7818 ms, throughput: 0.6366 GB/s; offload_time: 4.6337 ms, put_time: 0.1481 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,954] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b7a62f19d1314cbc9da585d66867ecc2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,956] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9306 ms, throughput: 3.6730 GB/s; offload_time: 0.8633 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,959] LMCache INFO:[0m Reqid: chatcmpl-761ce30e498840778533b335ddc77665, Total tokens 1012, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,960] LMCache INFO:[0m Reqid: chatcmpl-617ab7aea7404b858c585367aabea74d, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,988] LMCache INFO:[0m Storing KV cache for 1012 out of 1012 tokens (skip_leading_tokens=0) for request chatcmpl-761ce30e498840778533b335ddc77665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,993] LMCache INFO:[0m Stored 1012 out of total 1012 tokens. size: 0.0270 gb, cost 5.2627 ms, throughput: 5.1349 GB/s; offload_time: 4.3727 ms, put_time: 0.8900 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:49,994] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-617ab7aea7404b858c585367aabea74d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:49,996] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 2.1813 ms, throughput: 1.1752 GB/s; offload_time: 2.1115 ms, put_time: 0.0698 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,033] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-028aa45d2d344d2184ac06b1e39f3837 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,034] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9714 ms, throughput: 3.5188 GB/s; offload_time: 0.8977 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,063] LMCache INFO:[0m Reqid: chatcmpl-b745acdc6e01416488eb93018aecc488, Total tokens 5760, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,171] LMCache INFO:[0m Storing KV cache for 5760 out of 5760 tokens (skip_leading_tokens=0) for request chatcmpl-b745acdc6e01416488eb93018aecc488 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,200] LMCache INFO:[0m Stored 5760 out of total 5760 tokens. size: 0.1538 gb, cost 28.3946 ms, throughput: 5.4168 GB/s; offload_time: 26.5978 ms, put_time: 1.7968 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,201] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2f1aced808384a88856b06377d8891ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,204] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.7377 ms, throughput: 1.2485 GB/s; offload_time: 2.3533 ms, put_time: 0.3844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,205] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-538d29312f0046f9a18747b20f5fee54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,209] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 3.7639 ms, throughput: 0.9081 GB/s; offload_time: 3.5672 ms, put_time: 0.1967 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,227] LMCache INFO:[0m Reqid: chatcmpl-025956baa6a04abfb954de9237039495, Total tokens 1586, LMCache hit tokens: 1536, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,228] LMCache INFO:[0m Reqid: chatcmpl-578057c72dbb475e845aab10ef53ae93, Total tokens 995, LMCache hit tokens: 896, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,230] LMCache INFO:[0m Reqid: chatcmpl-186a6471a56f405fba550440abd4e213, Total tokens 720, LMCache hit tokens: 640, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,230] LMCache INFO:[0m Reqid: chatcmpl-b460100d80ee4679af8ea7ff66eb4ce8, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,230] LMCache INFO:[0m Reqid: chatcmpl-d0e75e7f9c894f33b186537fff08e200, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,248] LMCache INFO:[0m Storing KV cache for 1586 out of 1586 tokens (skip_leading_tokens=0) for request chatcmpl-025956baa6a04abfb954de9237039495 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,249] LMCache INFO:[0m Stored 50 out of total 1586 tokens. size: 0.0013 gb, cost 0.6373 ms, throughput: 2.0949 GB/s; offload_time: 0.5617 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,249] LMCache INFO:[0m Storing KV cache for 995 out of 995 tokens (skip_leading_tokens=0) for request chatcmpl-578057c72dbb475e845aab10ef53ae93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,250] LMCache INFO:[0m Stored 99 out of total 995 tokens. size: 0.0026 gb, cost 0.8714 ms, throughput: 3.0339 GB/s; offload_time: 0.7977 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,250] LMCache INFO:[0m Storing KV cache for 720 out of 720 tokens (skip_leading_tokens=0) for request chatcmpl-186a6471a56f405fba550440abd4e213 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,251] LMCache INFO:[0m Stored 80 out of total 720 tokens. size: 0.0021 gb, cost 0.6419 ms, throughput: 3.3282 GB/s; offload_time: 0.5748 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,251] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-b460100d80ee4679af8ea7ff66eb4ce8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,252] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.5303 ms, throughput: 5.6393 GB/s; offload_time: 0.4726 ms, put_time: 0.0577 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,253] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-d0e75e7f9c894f33b186537fff08e200 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,254] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.8383 ms, throughput: 3.2174 GB/s; offload_time: 0.7302 ms, put_time: 0.1081 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,254] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-b905bc06642d4595ad868024a5f2b4a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,256] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7256 ms, throughput: 1.9808 GB/s; offload_time: 1.6604 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,277] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-7412268184b3421092ab451e1bb94ec6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,279] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.2284 ms, throughput: 2.7825 GB/s; offload_time: 1.1534 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,279] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-3bf673d1c4bb4940a7643dd9fb798e6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,280] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1870 ms, throughput: 2.8796 GB/s; offload_time: 1.1117 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,290] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b98a8caf53884197b702668cb47af02f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,292] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1171 ms, throughput: 3.0596 GB/s; offload_time: 1.0370 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,292] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-761ce30e498840778533b335ddc77665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,293] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1885 ms, throughput: 2.8760 GB/s; offload_time: 1.1180 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,306] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,307] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1348 ms, throughput: 3.0120 GB/s; offload_time: 1.0626 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,308] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2a7d4e2b19894b38b268e56132b2919b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,309] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3096 ms, throughput: 2.6099 GB/s; offload_time: 1.2439 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,319] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5359baeada88444bb4212fe45807ac1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,320] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1392 ms, throughput: 3.0004 GB/s; offload_time: 1.0608 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,345] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4b99b2bf38bd4365958d134dab5292a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,346] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1326 ms, throughput: 3.0177 GB/s; offload_time: 1.0599 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,363] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-bcf33c3a9d21443ab83ee3b39fb5cc62 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,364] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1170 ms, throughput: 3.0600 GB/s; offload_time: 1.0397 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,377] LMCache INFO:[0m Reqid: chatcmpl-1dec1adcde914eb4aaaa0418aee68e03, Total tokens 1663, LMCache hit tokens: 1536, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,390] LMCache INFO:[0m Storing KV cache for 1663 out of 1663 tokens (skip_leading_tokens=0) for request chatcmpl-1dec1adcde914eb4aaaa0418aee68e03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,392] LMCache INFO:[0m Stored 127 out of total 1663 tokens. size: 0.0034 gb, cost 1.2477 ms, throughput: 2.7180 GB/s; offload_time: 1.1753 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,402] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5fda769b64cb472ab208cb01b73b0f1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,404] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2140 ms, throughput: 2.8155 GB/s; offload_time: 1.1356 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,404] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b518e1ea97a84730990dc72721723669 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,406] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3646 ms, throughput: 2.5047 GB/s; offload_time: 1.2974 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,406] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-1dec1adcde914eb4aaaa0418aee68e03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,408] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.5197 ms, throughput: 2.2491 GB/s; offload_time: 1.4546 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,412] LMCache INFO:[0m Reqid: chatcmpl-c85647c6aac94cbf8c1e6afb67c9ed6f, Total tokens 381, LMCache hit tokens: 256, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,412] LMCache INFO:[0m Reqid: chatcmpl-0de9f4e5cd424f11989181b49b84491d, Total tokens 204, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,427] LMCache INFO:[0m Storing KV cache for 381 out of 381 tokens (skip_leading_tokens=0) for request chatcmpl-c85647c6aac94cbf8c1e6afb67c9ed6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,428] LMCache INFO:[0m Stored 125 out of total 381 tokens. size: 0.0033 gb, cost 0.4947 ms, throughput: 6.7470 GB/s; offload_time: 0.4230 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,428] LMCache INFO:[0m Storing KV cache for 204 out of 204 tokens (skip_leading_tokens=0) for request chatcmpl-0de9f4e5cd424f11989181b49b84491d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,429] LMCache INFO:[0m Stored 204 out of total 204 tokens. size: 0.0054 gb, cost 0.8584 ms, throughput: 6.3456 GB/s; offload_time: 0.7640 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,430] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8fc5338d9ef441a9a2548fe4edad81b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,432] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.8862 ms, throughput: 1.8121 GB/s; offload_time: 1.7794 ms, put_time: 0.1069 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,450] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-b460100d80ee4679af8ea7ff66eb4ce8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,451] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1390 ms, throughput: 3.0008 GB/s; offload_time: 1.0711 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,454] LMCache INFO:[0m Reqid: chatcmpl-71a071c75ddd478cafc4911050fdae57, Total tokens 805, LMCache hit tokens: 768, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,469] LMCache INFO:[0m Storing KV cache for 805 out of 805 tokens (skip_leading_tokens=0) for request chatcmpl-71a071c75ddd478cafc4911050fdae57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,469] LMCache INFO:[0m Stored 37 out of total 805 tokens. size: 0.0010 gb, cost 0.5517 ms, throughput: 1.7907 GB/s; offload_time: 0.4793 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,470] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c85647c6aac94cbf8c1e6afb67c9ed6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,471] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3565 ms, throughput: 2.5197 GB/s; offload_time: 1.2552 ms, put_time: 0.1013 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,475] LMCache INFO:[0m Reqid: chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9, Total tokens 892, LMCache hit tokens: 768, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,476] LMCache INFO:[0m Reqid: chatcmpl-27f30a3de01c4c248f8aa083ca37c31d, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,476] LMCache INFO:[0m Reqid: chatcmpl-80a3cb5731f34b8f89bff06427e4ed0c, Total tokens 325, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,478] LMCache INFO:[0m Reqid: chatcmpl-41be9aa406124661b1fa7de310a356e0, Total tokens 288, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,493] LMCache INFO:[0m Storing KV cache for 892 out of 892 tokens (skip_leading_tokens=0) for request chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,493] LMCache INFO:[0m Stored 124 out of total 892 tokens. size: 0.0033 gb, cost 0.5300 ms, throughput: 6.2472 GB/s; offload_time: 0.4593 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,494] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-27f30a3de01c4c248f8aa083ca37c31d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,494] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.6314 ms, throughput: 4.2294 GB/s; offload_time: 0.5635 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,495] LMCache INFO:[0m Storing KV cache for 325 out of 325 tokens (skip_leading_tokens=0) for request chatcmpl-80a3cb5731f34b8f89bff06427e4ed0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,496] LMCache INFO:[0m Stored 69 out of total 325 tokens. size: 0.0018 gb, cost 1.4464 ms, throughput: 1.2739 GB/s; offload_time: 1.3692 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,497] LMCache INFO:[0m Storing KV cache for 288 out of 288 tokens (skip_leading_tokens=0) for request chatcmpl-41be9aa406124661b1fa7de310a356e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,498] LMCache INFO:[0m Stored 32 out of total 288 tokens. size: 0.0009 gb, cost 0.6818 ms, throughput: 1.2533 GB/s; offload_time: 0.6207 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,498] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-803e581426084742863bdb844a47a998 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,501] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 2.5200 ms, throughput: 1.3563 GB/s; offload_time: 2.4490 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,510] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0855730d93a245be87e474200347989b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,511] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1320 ms, throughput: 3.0193 GB/s; offload_time: 1.0613 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,529] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1793f2dedabc4368b9dd1e9dec00efdd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,530] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2358 ms, throughput: 2.7657 GB/s; offload_time: 1.1641 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,531] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-28732df8529c41d990f3ab126864725f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,532] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4084 ms, throughput: 2.4268 GB/s; offload_time: 1.3396 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,542] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,543] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0793 ms, throughput: 3.1667 GB/s; offload_time: 1.0069 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,543] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,545] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3738 ms, throughput: 2.4879 GB/s; offload_time: 1.3082 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,586] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d0e75e7f9c894f33b186537fff08e200 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,587] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0990 ms, throughput: 3.1100 GB/s; offload_time: 1.0245 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,604] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-9263784267624de28c41419b48636072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,606] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3103 ms, throughput: 2.6086 GB/s; offload_time: 1.2386 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,606] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-578057c72dbb475e845aab10ef53ae93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,608] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3244 ms, throughput: 2.5807 GB/s; offload_time: 1.2588 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,612] LMCache INFO:[0m Reqid: chatcmpl-85f28010137a480f9273afa1409d5c94, Total tokens 849, LMCache hit tokens: 768, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,626] LMCache INFO:[0m Storing KV cache for 849 out of 849 tokens (skip_leading_tokens=0) for request chatcmpl-85f28010137a480f9273afa1409d5c94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,627] LMCache INFO:[0m Stored 81 out of total 849 tokens. size: 0.0022 gb, cost 0.5019 ms, throughput: 4.3095 GB/s; offload_time: 0.4289 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,631] LMCache INFO:[0m Reqid: chatcmpl-6904d1a609c240ed839c47e98b9737fd, Total tokens 947, LMCache hit tokens: 768, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,649] LMCache INFO:[0m Storing KV cache for 947 out of 947 tokens (skip_leading_tokens=0) for request chatcmpl-6904d1a609c240ed839c47e98b9737fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,651] LMCache INFO:[0m Stored 179 out of total 947 tokens. size: 0.0048 gb, cost 1.5314 ms, throughput: 3.1213 GB/s; offload_time: 1.4290 ms, put_time: 0.1024 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,651] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-1c556f345ab144f982c0929d2b30fb9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,653] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 2.3979 ms, throughput: 1.4254 GB/s; offload_time: 2.3336 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,658] LMCache INFO:[0m Reqid: chatcmpl-e6dfcf404dbe467fb25a085b56a24902, Total tokens 308, LMCache hit tokens: 256, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,672] LMCache INFO:[0m Storing KV cache for 308 out of 308 tokens (skip_leading_tokens=0) for request chatcmpl-e6dfcf404dbe467fb25a085b56a24902 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,673] LMCache INFO:[0m Stored 52 out of total 308 tokens. size: 0.0014 gb, cost 0.4427 ms, throughput: 3.1368 GB/s; offload_time: 0.3733 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,677] LMCache INFO:[0m Reqid: chatcmpl-a235ce0d3d9c447d862a74939efd7d21, Total tokens 1888, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,720] LMCache INFO:[0m Storing KV cache for 1888 out of 1888 tokens (skip_leading_tokens=0) for request chatcmpl-a235ce0d3d9c447d862a74939efd7d21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,730] LMCache INFO:[0m Stored 1888 out of total 1888 tokens. size: 0.0504 gb, cost 9.8931 ms, throughput: 5.0960 GB/s; offload_time: 9.5052 ms, put_time: 0.3879 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,779] LMCache INFO:[0m Reqid: chatcmpl-c9d6cfdd5630445493cca8616a5353a5, Total tokens 1052, LMCache hit tokens: 896, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,795] LMCache INFO:[0m Storing KV cache for 1052 out of 1052 tokens (skip_leading_tokens=0) for request chatcmpl-c9d6cfdd5630445493cca8616a5353a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,796] LMCache INFO:[0m Stored 156 out of total 1052 tokens. size: 0.0042 gb, cost 1.4154 ms, throughput: 2.9431 GB/s; offload_time: 1.2982 ms, put_time: 0.1172 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,801] LMCache INFO:[0m Reqid: chatcmpl-40f73d1226db470f810310a770cd9268, Total tokens 238, LMCache hit tokens: 128, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,802] LMCache INFO:[0m Reqid: chatcmpl-03e7426d6a25487d8bd7c54746c23330, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,819] LMCache INFO:[0m Storing KV cache for 238 out of 238 tokens (skip_leading_tokens=0) for request chatcmpl-40f73d1226db470f810310a770cd9268 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,820] LMCache INFO:[0m Stored 110 out of total 238 tokens. size: 0.0029 gb, cost 0.4542 ms, throughput: 6.4675 GB/s; offload_time: 0.3828 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,820] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-03e7426d6a25487d8bd7c54746c23330 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,821] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.8034 ms, throughput: 3.2240 GB/s; offload_time: 0.7293 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,840] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3d1ae723206049ad856004dc02677efe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,842] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1741 ms, throughput: 2.9112 GB/s; offload_time: 1.0983 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,861] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0053d25795454952a90053bceb9c01d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,862] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0899 ms, throughput: 3.1360 GB/s; offload_time: 1.0144 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,872] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,873] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1686 ms, throughput: 2.9250 GB/s; offload_time: 1.0881 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,892] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-27f30a3de01c4c248f8aa083ca37c31d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,893] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0507 ms, throughput: 3.2532 GB/s; offload_time: 0.9769 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:50,913] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-186a6471a56f405fba550440abd4e213 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,914] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1809 ms, throughput: 2.8945 GB/s; offload_time: 1.1042 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,919] LMCache INFO:[0m Reqid: chatcmpl-e3a6ec68051e4e9a9b9e903ec77a3e3d, Total tokens 756, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,934] LMCache INFO:[0m Storing KV cache for 756 out of 756 tokens (skip_leading_tokens=0) for request chatcmpl-e3a6ec68051e4e9a9b9e903ec77a3e3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,934] LMCache INFO:[0m Stored 116 out of total 756 tokens. size: 0.0031 gb, cost 0.5053 ms, throughput: 6.1301 GB/s; offload_time: 0.4297 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:50,935] LMCache INFO:[0m Storing KV cache for 128 out of 5376 tokens (skip_leading_tokens=5248) for request chatcmpl-8613da46fc5f4e9a9aab0ed745801f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:50,937] LMCache INFO:[0m Stored 128 out of total 5376 tokens. size: 0.0034 gb, cost 1.8287 ms, throughput: 1.8690 GB/s; offload_time: 1.7576 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,000] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1f5876c17f54453884c160f6d67bd4af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,002] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1553 ms, throughput: 2.9586 GB/s; offload_time: 1.0817 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,011] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-40f73d1226db470f810310a770cd9268 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,013] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1213 ms, throughput: 3.0483 GB/s; offload_time: 1.0370 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,017] LMCache INFO:[0m Reqid: chatcmpl-ce9024e05d7241f195d49a58ff5473d7, Total tokens 584, LMCache hit tokens: 512, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,031] LMCache INFO:[0m Storing KV cache for 584 out of 584 tokens (skip_leading_tokens=0) for request chatcmpl-ce9024e05d7241f195d49a58ff5473d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,032] LMCache INFO:[0m Stored 72 out of total 584 tokens. size: 0.0019 gb, cost 0.4805 ms, throughput: 4.0015 GB/s; offload_time: 0.4059 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,032] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-81f13cfa70e448e99190372d1b2f936e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,033] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4012 ms, throughput: 2.4394 GB/s; offload_time: 1.3178 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,034] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-7651e1cbcb75403faecdbcd438cc59cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,035] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.4058 ms, throughput: 2.4314 GB/s; offload_time: 1.3297 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,058] LMCache INFO:[0m Reqid: chatcmpl-f21d3e9f90e34429b6c818595ea3c867, Total tokens 1208, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,089] LMCache INFO:[0m Storing KV cache for 1208 out of 1208 tokens (skip_leading_tokens=0) for request chatcmpl-f21d3e9f90e34429b6c818595ea3c867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,097] LMCache INFO:[0m Stored 1208 out of total 1208 tokens. size: 0.0323 gb, cost 7.4340 ms, throughput: 4.3391 GB/s; offload_time: 6.3232 ms, put_time: 1.1109 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,097] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e3a6ec68051e4e9a9b9e903ec77a3e3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,102] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 4.8099 ms, throughput: 0.7106 GB/s; offload_time: 4.7202 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,111] LMCache INFO:[0m Reqid: chatcmpl-e22e721017df446abe045aa64e4b1409, Total tokens 1684, LMCache hit tokens: 1536, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,112] LMCache INFO:[0m Reqid: chatcmpl-c52f0c0ecb344617902804d03669b0cf, Total tokens 584, LMCache hit tokens: 512, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,113] LMCache INFO:[0m Reqid: chatcmpl-f4393462fed0493490a1f3488e126190, Total tokens 494, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,136] LMCache INFO:[0m Storing KV cache for 1684 out of 1684 tokens (skip_leading_tokens=0) for request chatcmpl-e22e721017df446abe045aa64e4b1409 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,138] LMCache INFO:[0m Stored 148 out of total 1684 tokens. size: 0.0040 gb, cost 1.5931 ms, throughput: 2.4807 GB/s; offload_time: 1.3356 ms, put_time: 0.2575 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,138] LMCache INFO:[0m Storing KV cache for 584 out of 584 tokens (skip_leading_tokens=0) for request chatcmpl-c52f0c0ecb344617902804d03669b0cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,140] LMCache INFO:[0m Stored 72 out of total 584 tokens. size: 0.0019 gb, cost 1.3042 ms, throughput: 1.4741 GB/s; offload_time: 1.2111 ms, put_time: 0.0932 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,140] LMCache INFO:[0m Storing KV cache for 494 out of 494 tokens (skip_leading_tokens=0) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,144] LMCache INFO:[0m Stored 494 out of total 494 tokens. size: 0.0132 gb, cost 4.3364 ms, throughput: 3.0420 GB/s; offload_time: 3.7086 ms, put_time: 0.6279 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,156] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-ba115843b7ee43859c96c05ab19516b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,157] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.1451 ms, throughput: 2.9850 GB/s; offload_time: 1.0715 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,177] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-a235ce0d3d9c447d862a74939efd7d21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,178] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2753 ms, throughput: 2.6802 GB/s; offload_time: 1.1869 ms, put_time: 0.0884 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,190] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-3b57fdbd7bf34d8486653363b4713f99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,191] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1280 ms, throughput: 3.0301 GB/s; offload_time: 1.0444 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,201] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,202] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0906 ms, throughput: 3.1341 GB/s; offload_time: 1.0103 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,206] LMCache INFO:[0m Reqid: chatcmpl-5753d9be27bd44379feb9804a9da881a, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,223] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-5753d9be27bd44379feb9804a9da881a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,224] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.4146 ms, throughput: 7.2127 GB/s; offload_time: 0.3416 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,224] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,226] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5260 ms, throughput: 2.2399 GB/s; offload_time: 1.4537 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,227] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e3f787905047424792b7d4db9e138940 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,228] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3503 ms, throughput: 2.5312 GB/s; offload_time: 1.2877 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,239] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,240] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0816 ms, throughput: 3.1600 GB/s; offload_time: 1.0066 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,312] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-27c130ce29884b3999d356a2060b3a6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,313] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1618 ms, throughput: 2.9420 GB/s; offload_time: 1.0807 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,313] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-85f28010137a480f9273afa1409d5c94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,315] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3965 ms, throughput: 2.4475 GB/s; offload_time: 1.3189 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,326] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-025956baa6a04abfb954de9237039495 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,327] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1725 ms, throughput: 2.9151 GB/s; offload_time: 1.0997 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,331] LMCache INFO:[0m Reqid: chatcmpl-37064537dacc4d17a6e62fc94501627c, Total tokens 135, LMCache hit tokens: 0, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,344] LMCache INFO:[0m Storing KV cache for 135 out of 135 tokens (skip_leading_tokens=0) for request chatcmpl-37064537dacc4d17a6e62fc94501627c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,346] LMCache INFO:[0m Stored 135 out of total 135 tokens. size: 0.0036 gb, cost 1.2538 ms, throughput: 2.8752 GB/s; offload_time: 1.1455 ms, put_time: 0.1083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,350] LMCache INFO:[0m Reqid: chatcmpl-3a841bcb75a34d7a9321b4df7593734e, Total tokens 167, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,366] LMCache INFO:[0m Storing KV cache for 167 out of 167 tokens (skip_leading_tokens=0) for request chatcmpl-3a841bcb75a34d7a9321b4df7593734e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,367] LMCache INFO:[0m Stored 167 out of total 167 tokens. size: 0.0045 gb, cost 1.3158 ms, throughput: 3.3892 GB/s; offload_time: 1.2036 ms, put_time: 0.1121 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,368] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,370] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5490 ms, throughput: 2.2066 GB/s; offload_time: 1.4714 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,393] LMCache INFO:[0m Reqid: chatcmpl-ceffd19728d54bc19582dd1f61e13709, Total tokens 622, LMCache hit tokens: 512, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,394] LMCache INFO:[0m Reqid: chatcmpl-d40b48e782d640ac9d152bba83457f31, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,409] LMCache INFO:[0m Storing KV cache for 622 out of 622 tokens (skip_leading_tokens=0) for request chatcmpl-ceffd19728d54bc19582dd1f61e13709 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,409] LMCache INFO:[0m Stored 110 out of total 622 tokens. size: 0.0029 gb, cost 0.4747 ms, throughput: 6.1883 GB/s; offload_time: 0.4020 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,410] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-d40b48e782d640ac9d152bba83457f31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,411] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.6671 ms, throughput: 4.2432 GB/s; offload_time: 0.5991 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,421] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5753d9be27bd44379feb9804a9da881a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,423] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1497 ms, throughput: 2.9729 GB/s; offload_time: 1.0748 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,478] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,479] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1601 ms, throughput: 2.9462 GB/s; offload_time: 1.0857 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,506] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-091be6538e7c443dbb08f3ae6d7e63bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,508] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1348 ms, throughput: 3.0119 GB/s; offload_time: 1.0607 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,519] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-17157e42aba248a68bfb5e36402eabd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,520] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1905 ms, throughput: 2.8711 GB/s; offload_time: 1.1123 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,555] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-aedd85f3a3b34571b7a0595a5eaa7a4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,556] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1706 ms, throughput: 2.9197 GB/s; offload_time: 1.0943 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,556] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,558] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4700 ms, throughput: 2.3252 GB/s; offload_time: 1.4006 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,572] LMCache INFO:[0m Reqid: chatcmpl-4d5a6c5c916e4a26929caa62b1728253, Total tokens 1076, LMCache hit tokens: 1024, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,586] LMCache INFO:[0m Storing KV cache for 1076 out of 1076 tokens (skip_leading_tokens=0) for request chatcmpl-4d5a6c5c916e4a26929caa62b1728253 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,587] LMCache INFO:[0m Stored 52 out of total 1076 tokens. size: 0.0014 gb, cost 0.5262 ms, throughput: 2.6386 GB/s; offload_time: 0.4520 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,598] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ceffd19728d54bc19582dd1f61e13709 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,600] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1356 ms, throughput: 3.0098 GB/s; offload_time: 1.0564 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,603] LMCache INFO:[0m Reqid: chatcmpl-297a23f3438d43bb9a19ee0f4cac63b7, Total tokens 635, LMCache hit tokens: 512, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,618] LMCache INFO:[0m Storing KV cache for 635 out of 635 tokens (skip_leading_tokens=0) for request chatcmpl-297a23f3438d43bb9a19ee0f4cac63b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,618] LMCache INFO:[0m Stored 123 out of total 635 tokens. size: 0.0033 gb, cost 0.4901 ms, throughput: 6.7013 GB/s; offload_time: 0.4134 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,618] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-d0dc7804d30d401cb67ac01a492d5851 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,620] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4955 ms, throughput: 2.2855 GB/s; offload_time: 1.4216 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,642] LMCache INFO:[0m Reqid: chatcmpl-2f893861755f4cbcbafa173402d97d27, Total tokens 272, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,642] LMCache INFO:[0m Reqid: chatcmpl-16fb5d8e989547fabd102acaca6b0b69, Total tokens 333, LMCache hit tokens: 128, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,643] LMCache INFO:[0m Reqid: chatcmpl-73b0d359a2584c11b57c10498737c2c5, Total tokens 235, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,644] LMCache INFO:[0m Reqid: chatcmpl-f0af4aa916724ab68fbda351fa2df0d3, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,644] LMCache INFO:[0m Reqid: chatcmpl-3d8eb88cac0744d0be53b037d48be801, Total tokens 131, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,663] LMCache INFO:[0m Storing KV cache for 272 out of 272 tokens (skip_leading_tokens=0) for request chatcmpl-2f893861755f4cbcbafa173402d97d27 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,664] LMCache INFO:[0m Stored 144 out of total 272 tokens. size: 0.0038 gb, cost 1.3271 ms, throughput: 2.8975 GB/s; offload_time: 1.2119 ms, put_time: 0.1152 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,665] LMCache INFO:[0m Storing KV cache for 333 out of 333 tokens (skip_leading_tokens=0) for request chatcmpl-16fb5d8e989547fabd102acaca6b0b69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,667] LMCache INFO:[0m Stored 205 out of total 333 tokens. size: 0.0055 gb, cost 2.5461 ms, throughput: 2.1500 GB/s; offload_time: 2.2873 ms, put_time: 0.2588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,668] LMCache INFO:[0m Storing KV cache for 235 out of 235 tokens (skip_leading_tokens=0) for request chatcmpl-73b0d359a2584c11b57c10498737c2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,669] LMCache INFO:[0m Stored 107 out of total 235 tokens. size: 0.0029 gb, cost 0.8021 ms, throughput: 3.5623 GB/s; offload_time: 0.7291 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,669] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-f0af4aa916724ab68fbda351fa2df0d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,670] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.5118 ms, throughput: 5.1132 GB/s; offload_time: 0.4388 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,670] LMCache INFO:[0m Storing KV cache for 131 out of 131 tokens (skip_leading_tokens=0) for request chatcmpl-3d8eb88cac0744d0be53b037d48be801 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,673] LMCache INFO:[0m Stored 131 out of total 131 tokens. size: 0.0035 gb, cost 2.5400 ms, throughput: 1.3772 GB/s; offload_time: 2.3646 ms, put_time: 0.1754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,673] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d40b48e782d640ac9d152bba83457f31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,676] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.8585 ms, throughput: 1.8391 GB/s; offload_time: 1.5523 ms, put_time: 0.3061 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,688] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-988b1d0092df45a0b34b3bd46b359a37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,689] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1608 ms, throughput: 2.9445 GB/s; offload_time: 1.0847 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,700] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-297a23f3438d43bb9a19ee0f4cac63b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,701] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1579 ms, throughput: 2.9519 GB/s; offload_time: 1.0816 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,713] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-71a071c75ddd478cafc4911050fdae57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,715] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1758 ms, throughput: 2.9069 GB/s; offload_time: 1.1006 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,715] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6904d1a609c240ed839c47e98b9737fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,716] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4234 ms, throughput: 2.4014 GB/s; offload_time: 1.3488 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,717] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e6dfcf404dbe467fb25a085b56a24902 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,719] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.8074 ms, throughput: 1.8911 GB/s; offload_time: 1.7196 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,750] LMCache INFO:[0m Reqid: chatcmpl-e969f4204b364a278465ec0b5e9dd92b, Total tokens 119, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,767] LMCache INFO:[0m Storing KV cache for 119 out of 119 tokens (skip_leading_tokens=0) for request chatcmpl-e969f4204b364a278465ec0b5e9dd92b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,768] LMCache INFO:[0m Stored 119 out of total 119 tokens. size: 0.0032 gb, cost 0.4283 ms, throughput: 7.4197 GB/s; offload_time: 0.3439 ms, put_time: 0.0844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO 07-11 15:20:51 [loggers.py:118] Engine 000: Avg prompt throughput: 15191.9 tokens/s, Avg generation throughput: 4968.5 tokens/s, Running: 71 reqs, Waiting: 0 reqs, GPU KV cache usage: 96.6%, Prefix cache hit rate: 70.0%
[32;20m[2025-07-11 15:20:51,780] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dd6bbed8d6234054add81cf06bb7dc16 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,781] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2163 ms, throughput: 2.8100 GB/s; offload_time: 1.1395 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,781] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3283d9e7130d40d68831a3fb70e3bfbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,783] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3905 ms, throughput: 2.4580 GB/s; offload_time: 1.1215 ms, put_time: 0.2690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,795] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-41be9aa406124661b1fa7de310a356e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,796] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1904 ms, throughput: 2.8714 GB/s; offload_time: 1.1127 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,840] LMCache INFO:[0m Reqid: chatcmpl-4f8504ffe1174db08e47a4dab245f94f, Total tokens 858, LMCache hit tokens: 768, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,858] LMCache INFO:[0m Storing KV cache for 858 out of 858 tokens (skip_leading_tokens=0) for request chatcmpl-4f8504ffe1174db08e47a4dab245f94f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,859] LMCache INFO:[0m Stored 90 out of total 858 tokens. size: 0.0024 gb, cost 0.5198 ms, throughput: 4.6233 GB/s; offload_time: 0.4405 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,880] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e969f4204b364a278465ec0b5e9dd92b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,881] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0847 ms, throughput: 3.1512 GB/s; offload_time: 1.0094 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,906] LMCache INFO:[0m Reqid: chatcmpl-d1dcfca07ed44c05ae13275a5e7184cc, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,923] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-d1dcfca07ed44c05ae13275a5e7184cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,924] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.4168 ms, throughput: 7.0478 GB/s; offload_time: 0.3411 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,946] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-73b0d359a2584c11b57c10498737c2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,948] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1437 ms, throughput: 2.9886 GB/s; offload_time: 1.0682 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,961] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2f1aced808384a88856b06377d8891ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,962] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1866 ms, throughput: 2.8806 GB/s; offload_time: 1.1064 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,962] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-538d29312f0046f9a18747b20f5fee54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,964] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4732 ms, throughput: 2.3200 GB/s; offload_time: 1.4013 ms, put_time: 0.0719 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:51,964] LMCache INFO:[0m Storing KV cache for 128 out of 5888 tokens (skip_leading_tokens=5760) for request chatcmpl-b745acdc6e01416488eb93018aecc488 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,966] LMCache INFO:[0m Stored 128 out of total 5888 tokens. size: 0.0034 gb, cost 1.9253 ms, throughput: 1.7753 GB/s; offload_time: 1.8485 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:51,981] LMCache INFO:[0m Reqid: chatcmpl-28e8bd7100154660a537dcf7ec02a038, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,996] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-28e8bd7100154660a537dcf7ec02a038 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:51,996] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.4116 ms, throughput: 6.5521 GB/s; offload_time: 0.3365 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,008] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-3bf673d1c4bb4940a7643dd9fb798e6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,009] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2269 ms, throughput: 2.7858 GB/s; offload_time: 1.1503 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,021] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-761ce30e498840778533b335ddc77665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,022] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2111 ms, throughput: 2.8221 GB/s; offload_time: 1.1337 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,034] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,035] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1520 ms, throughput: 2.9669 GB/s; offload_time: 1.0738 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,039] LMCache INFO:[0m Reqid: chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a, Total tokens 1242, LMCache hit tokens: 1024, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,057] LMCache INFO:[0m Storing KV cache for 1242 out of 1242 tokens (skip_leading_tokens=0) for request chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,058] LMCache INFO:[0m Stored 218 out of total 1242 tokens. size: 0.0058 gb, cost 1.5809 ms, throughput: 3.6821 GB/s; offload_time: 1.4716 ms, put_time: 0.1093 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,059] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-5359baeada88444bb4212fe45807ac1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,061] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.3117 ms, throughput: 1.4786 GB/s; offload_time: 2.2362 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,061] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f21d3e9f90e34429b6c818595ea3c867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,063] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5016 ms, throughput: 2.2762 GB/s; offload_time: 1.3522 ms, put_time: 0.1495 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,068] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,079] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,088] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f0af4aa916724ab68fbda351fa2df0d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,089] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1276 ms, throughput: 3.0311 GB/s; offload_time: 1.0500 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,093] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 384 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,104] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,115] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 496 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,124] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c9d6cfdd5630445493cca8616a5353a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,125] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1969 ms, throughput: 2.8557 GB/s; offload_time: 1.1190 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,129] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,151] LMCache INFO:[0m Reqid: chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a, Total tokens 1249, LMCache hit tokens: 1242, need to load: 122 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,160] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5fda769b64cb472ab208cb01b73b0f1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,162] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2087 ms, throughput: 2.8279 GB/s; offload_time: 1.1328 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,162] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b518e1ea97a84730990dc72721723669 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,164] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5772 ms, throughput: 2.1671 GB/s; offload_time: 1.5095 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,164] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-1dec1adcde914eb4aaaa0418aee68e03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,166] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5716 ms, throughput: 2.1748 GB/s; offload_time: 1.4979 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,170] LMCache INFO:[0m Reqid: chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a, Total tokens 1249, LMCache hit tokens: 1242, need to load: 282 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,180] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8fc5338d9ef441a9a2548fe4edad81b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,181] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2669 ms, throughput: 2.6978 GB/s; offload_time: 1.1810 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,182] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d1dcfca07ed44c05ae13275a5e7184cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,183] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3618 ms, throughput: 2.5099 GB/s; offload_time: 1.2870 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,188] LMCache INFO:[0m Reqid: chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a, Total tokens 1249, LMCache hit tokens: 1242, need to load: 378 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,189] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 674, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,190] LMCache INFO:[0m Reqid: chatcmpl-992e209f52964869813d86407c1d8c3c, Total tokens 950, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,216] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b460100d80ee4679af8ea7ff66eb4ce8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,218] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1316 ms, throughput: 3.0206 GB/s; offload_time: 1.0559 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,222] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,230] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c85647c6aac94cbf8c1e6afb67c9ed6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,232] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1969 ms, throughput: 2.8556 GB/s; offload_time: 1.1195 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,236] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,247] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,255] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0855730d93a245be87e474200347989b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,257] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2008 ms, throughput: 2.8465 GB/s; offload_time: 1.1248 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,261] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,272] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,279] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1793f2dedabc4368b9dd1e9dec00efdd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,280] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2313 ms, throughput: 2.7758 GB/s; offload_time: 1.1567 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,284] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 384 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,292] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,293] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1421 ms, throughput: 2.9928 GB/s; offload_time: 1.0679 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,294] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,295] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4106 ms, throughput: 2.4231 GB/s; offload_time: 1.3401 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,299] LMCache INFO:[0m Reqid: chatcmpl-bda4e18cbd9d4a128a84649f60bcf02c, Total tokens 675, LMCache hit tokens: 640, need to load: 448 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,300] LMCache INFO:[0m Reqid: chatcmpl-992e209f52964869813d86407c1d8c3c, Total tokens 950, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,317] LMCache INFO:[0m Reqid: chatcmpl-992e209f52964869813d86407c1d8c3c, Total tokens 950, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,318] LMCache INFO:[0m Reqid: chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a, Total tokens 760, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,346] LMCache INFO:[0m Storing KV cache for 950 out of 950 tokens (skip_leading_tokens=0) for request chatcmpl-992e209f52964869813d86407c1d8c3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,352] LMCache INFO:[0m Stored 950 out of total 950 tokens. size: 0.0254 gb, cost 5.8396 ms, throughput: 4.3441 GB/s; offload_time: 5.3533 ms, put_time: 0.4863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,359] LMCache INFO:[0m Reqid: chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a, Total tokens 760, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,370] LMCache INFO:[0m Reqid: chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a, Total tokens 760, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,371] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,396] LMCache INFO:[0m Storing KV cache for 760 out of 760 tokens (skip_leading_tokens=0) for request chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,401] LMCache INFO:[0m Stored 760 out of total 760 tokens. size: 0.0203 gb, cost 4.2115 ms, throughput: 4.8188 GB/s; offload_time: 3.9889 ms, put_time: 0.2225 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,408] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,416] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d0e75e7f9c894f33b186537fff08e200 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,418] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1545 ms, throughput: 2.9607 GB/s; offload_time: 1.0765 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,421] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,429] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-16fb5d8e989547fabd102acaca6b0b69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,430] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1476 ms, throughput: 2.9784 GB/s; offload_time: 1.0710 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,434] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,442] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-9263784267624de28c41419b48636072 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,443] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2288 ms, throughput: 2.7816 GB/s; offload_time: 1.1532 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,444] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-578057c72dbb475e845aab10ef53ae93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,445] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4174 ms, throughput: 2.4114 GB/s; offload_time: 1.3426 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,446] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4f8504ffe1174db08e47a4dab245f94f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,447] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3729 ms, throughput: 2.4897 GB/s; offload_time: 1.3025 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,452] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,462] LMCache INFO:[0m Reqid: chatcmpl-7cab1e91d91446d5acd8f0e2bdcb7119, Total tokens 1046, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,463] LMCache INFO:[0m Reqid: chatcmpl-5453f9e9492c4981a752689017e41ff4, Total tokens 1085, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,479] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-1c556f345ab144f982c0929d2b30fb9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,480] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.2661 ms, throughput: 2.6996 GB/s; offload_time: 1.1897 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,484] LMCache INFO:[0m Reqid: chatcmpl-5453f9e9492c4981a752689017e41ff4, Total tokens 1085, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,494] LMCache INFO:[0m Reqid: chatcmpl-5453f9e9492c4981a752689017e41ff4, Total tokens 1085, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,503] LMCache INFO:[0m Reqid: chatcmpl-5453f9e9492c4981a752689017e41ff4, Total tokens 1085, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,510] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,512] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1676 ms, throughput: 2.9275 GB/s; offload_time: 1.0902 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,516] LMCache INFO:[0m Reqid: chatcmpl-5453f9e9492c4981a752689017e41ff4, Total tokens 1085, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,517] LMCache INFO:[0m Reqid: chatcmpl-f627593677594a468dcca8545fafa375, Total tokens 215, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,517] LMCache INFO:[0m Reqid: chatcmpl-bf60f8d88e494529a43d9b897fe8ef8f, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,550] LMCache INFO:[0m Storing KV cache for 1085 out of 1085 tokens (skip_leading_tokens=0) for request chatcmpl-5453f9e9492c4981a752689017e41ff4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,556] LMCache INFO:[0m Stored 1085 out of total 1085 tokens. size: 0.0290 gb, cost 6.3727 ms, throughput: 4.5464 GB/s; offload_time: 5.8599 ms, put_time: 0.5128 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,556] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-bf60f8d88e494529a43d9b897fe8ef8f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,560] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 2.5039 ms, throughput: 1.0771 GB/s; offload_time: 2.4250 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,625] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-3d1ae723206049ad856004dc02677efe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,627] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1937 ms, throughput: 2.8634 GB/s; offload_time: 1.1104 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,627] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3a841bcb75a34d7a9321b4df7593734e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,629] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5163 ms, throughput: 2.2541 GB/s; offload_time: 1.3885 ms, put_time: 0.1278 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,641] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-e22e721017df446abe045aa64e4b1409 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,642] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2454 ms, throughput: 2.7444 GB/s; offload_time: 1.1618 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,653] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0053d25795454952a90053bceb9c01d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,655] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1546 ms, throughput: 2.9604 GB/s; offload_time: 1.0735 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,665] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,667] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2159 ms, throughput: 2.8111 GB/s; offload_time: 1.1408 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,687] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-27f30a3de01c4c248f8aa083ca37c31d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,689] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1406 ms, throughput: 2.9967 GB/s; offload_time: 1.0541 ms, put_time: 0.0865 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,689] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-d2edd1b5e967416ea962d4b1ef2d377a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,691] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5868 ms, throughput: 2.1540 GB/s; offload_time: 1.3219 ms, put_time: 0.2650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,711] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-186a6471a56f405fba550440abd4e213 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,712] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1787 ms, throughput: 2.8997 GB/s; offload_time: 1.1047 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,712] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-4d5a6c5c916e4a26929caa62b1728253 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,714] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5971 ms, throughput: 2.1402 GB/s; offload_time: 1.5239 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,727] LMCache INFO:[0m Storing KV cache for 128 out of 5504 tokens (skip_leading_tokens=5376) for request chatcmpl-8613da46fc5f4e9a9aab0ed745801f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,728] LMCache INFO:[0m Stored 128 out of total 5504 tokens. size: 0.0034 gb, cost 1.4855 ms, throughput: 2.3008 GB/s; offload_time: 1.4087 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,800] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-40f73d1226db470f810310a770cd9268 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,801] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1358 ms, throughput: 3.0092 GB/s; offload_time: 1.0594 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,812] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-81f13cfa70e448e99190372d1b2f936e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,814] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1991 ms, throughput: 2.8506 GB/s; offload_time: 1.1207 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,814] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-7651e1cbcb75403faecdbcd438cc59cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,816] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.5083 ms, throughput: 2.2662 GB/s; offload_time: 1.4378 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,839] LMCache INFO:[0m Reqid: chatcmpl-896fbaeba2c2429b92373f316d86bfd9, Total tokens 914, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,857] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e3a6ec68051e4e9a9b9e903ec77a3e3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,857] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4831 ms, throughput: 7.0755 GB/s; offload_time: 0.4098 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,876] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ba115843b7ee43859c96c05ab19516b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,877] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2357 ms, throughput: 2.7660 GB/s; offload_time: 1.1546 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,896] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-a235ce0d3d9c447d862a74939efd7d21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,897] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.2735 ms, throughput: 2.6840 GB/s; offload_time: 1.1914 ms, put_time: 0.0820 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,910] LMCache INFO:[0m Reqid: chatcmpl-290597f094274a72aceef73a067b350b, Total tokens 1316, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,911] LMCache INFO:[0m Reqid: chatcmpl-30c20879342e4cbeb993f8d903e25b74, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,932] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-30c20879342e4cbeb993f8d903e25b74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,933] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.3840 ms, throughput: 7.5791 GB/s; offload_time: 0.3129 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,933] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,934] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.8927 ms, throughput: 3.8288 GB/s; offload_time: 0.8161 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,945] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,946] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1782 ms, throughput: 2.9010 GB/s; offload_time: 1.0898 ms, put_time: 0.0883 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,947] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-e3f787905047424792b7d4db9e138940 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,948] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4857 ms, throughput: 2.3005 GB/s; offload_time: 1.4137 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:52,959] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:52,961] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3019 ms, throughput: 2.6254 GB/s; offload_time: 1.2258 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:52,964] LMCache INFO:[0m Reqid: chatcmpl-60ad3b2e9cfc48fb9b02a577ddc90892, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,007] LMCache INFO:[0m Reqid: chatcmpl-f099b6e043144e39b444d15946896ed8, Total tokens 861, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,029] LMCache INFO:[0m Storing KV cache for 861 out of 861 tokens (skip_leading_tokens=0) for request chatcmpl-f099b6e043144e39b444d15946896ed8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,033] LMCache INFO:[0m Stored 861 out of total 861 tokens. size: 0.0230 gb, cost 3.7411 ms, throughput: 6.1456 GB/s; offload_time: 3.5056 ms, put_time: 0.2355 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,039] LMCache INFO:[0m Reqid: chatcmpl-85019a4004134ff1a291070c6a9d51e2, Total tokens 184, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,052] LMCache INFO:[0m Storing KV cache for 184 out of 184 tokens (skip_leading_tokens=0) for request chatcmpl-85019a4004134ff1a291070c6a9d51e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,054] LMCache INFO:[0m Stored 184 out of total 184 tokens. size: 0.0049 gb, cost 1.3299 ms, throughput: 3.6946 GB/s; offload_time: 1.2157 ms, put_time: 0.1142 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,068] LMCache INFO:[0m Reqid: chatcmpl-83fc63c6771d4afd837e8473a0e65240, Total tokens 1109, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,086] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f627593677594a468dcca8545fafa375 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,087] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4448 ms, throughput: 7.6847 GB/s; offload_time: 0.3607 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,092] LMCache INFO:[0m Reqid: chatcmpl-63bb8bfe215448ba89d98866c31c5790, Total tokens 2098, LMCache hit tokens: 2048, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,093] LMCache INFO:[0m Reqid: chatcmpl-02f958d42eb64bb7ab05ae7a62ebef6f, Total tokens 437, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,094] LMCache INFO:[0m Reqid: chatcmpl-e85bdb31c34b4d898882440297764e83, Total tokens 690, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,117] LMCache INFO:[0m Storing KV cache for 2098 out of 2098 tokens (skip_leading_tokens=0) for request chatcmpl-63bb8bfe215448ba89d98866c31c5790 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,118] LMCache INFO:[0m Stored 50 out of total 2098 tokens. size: 0.0013 gb, cost 0.6512 ms, throughput: 2.0501 GB/s; offload_time: 0.5681 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,118] LMCache INFO:[0m Storing KV cache for 690 out of 690 tokens (skip_leading_tokens=0) for request chatcmpl-e85bdb31c34b4d898882440297764e83 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,124] LMCache INFO:[0m Stored 690 out of total 690 tokens. size: 0.0184 gb, cost 6.2524 ms, throughput: 2.9469 GB/s; offload_time: 4.4597 ms, put_time: 1.7927 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,125] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-27c130ce29884b3999d356a2060b3a6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,128] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 2.4070 ms, throughput: 1.4200 GB/s; offload_time: 2.3320 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,128] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-85f28010137a480f9273afa1409d5c94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,131] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 2.6380 ms, throughput: 1.2956 GB/s; offload_time: 2.5638 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,136] LMCache INFO:[0m Reqid: chatcmpl-f010231db8eb4de7b2462d0e5004771e, Total tokens 1209, LMCache hit tokens: 1152, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,137] LMCache INFO:[0m Reqid: chatcmpl-2517285f540c4b82930eca8a22500210, Total tokens 160, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,138] LMCache INFO:[0m Reqid: chatcmpl-f20ca34d0da740929651983f46c9aef1, Total tokens 1855, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,139] LMCache INFO:[0m Reqid: chatcmpl-10a0c9ea1c784f52bb022901bbdabfca, Total tokens 1104, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,140] LMCache INFO:[0m Reqid: chatcmpl-db3f95fac1ce4a1983c118109a213937, Total tokens 151, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,141] LMCache INFO:[0m Reqid: chatcmpl-761679abdcf24947b2c82ab5ef4ef37f, Total tokens 1365, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,170] LMCache INFO:[0m Storing KV cache for 160 out of 160 tokens (skip_leading_tokens=0) for request chatcmpl-2517285f540c4b82930eca8a22500210 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,171] LMCache INFO:[0m Stored 160 out of total 160 tokens. size: 0.0043 gb, cost 0.6251 ms, throughput: 6.8349 GB/s; offload_time: 0.5158 ms, put_time: 0.1093 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,171] LMCache INFO:[0m Storing KV cache for 191 out of 1855 tokens (skip_leading_tokens=1664) for request chatcmpl-f20ca34d0da740929651983f46c9aef1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,173] LMCache INFO:[0m Stored 191 out of total 1855 tokens. size: 0.0051 gb, cost 1.3919 ms, throughput: 3.6642 GB/s; offload_time: 1.2977 ms, put_time: 0.0942 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,173] LMCache INFO:[0m Storing KV cache for 151 out of 151 tokens (skip_leading_tokens=0) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,177] LMCache INFO:[0m Stored 151 out of total 151 tokens. size: 0.0040 gb, cost 2.2623 ms, throughput: 1.7824 GB/s; offload_time: 2.0921 ms, put_time: 0.1701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,177] LMCache INFO:[0m Storing KV cache for 1365 out of 1365 tokens (skip_leading_tokens=0) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,178] LMCache INFO:[0m Stored 85 out of total 1365 tokens. size: 0.0023 gb, cost 1.2646 ms, throughput: 1.7949 GB/s; offload_time: 1.1926 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,184] LMCache INFO:[0m Reqid: chatcmpl-add556b5fc584b77aa886147d22e3f07, Total tokens 934, LMCache hit tokens: 896, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,185] LMCache INFO:[0m Reqid: chatcmpl-91e0aa14e3ce4249a665345e4f0ecd4c, Total tokens 1394, LMCache hit tokens: 1280, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,186] LMCache INFO:[0m Reqid: chatcmpl-6fd536347643404fa9889712c24859f0, Total tokens 752, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,187] LMCache INFO:[0m Reqid: chatcmpl-9709d35e83874f5e9b5e24c3b5fcc38d, Total tokens 118, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,202] LMCache INFO:[0m Storing KV cache for 934 out of 934 tokens (skip_leading_tokens=0) for request chatcmpl-add556b5fc584b77aa886147d22e3f07 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,203] LMCache INFO:[0m Stored 38 out of total 934 tokens. size: 0.0010 gb, cost 0.5547 ms, throughput: 1.8294 GB/s; offload_time: 0.4784 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,203] LMCache INFO:[0m Storing KV cache for 1394 out of 1394 tokens (skip_leading_tokens=0) for request chatcmpl-91e0aa14e3ce4249a665345e4f0ecd4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,204] LMCache INFO:[0m Stored 114 out of total 1394 tokens. size: 0.0030 gb, cost 0.7659 ms, throughput: 3.9747 GB/s; offload_time: 0.7013 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,204] LMCache INFO:[0m Storing KV cache for 752 out of 752 tokens (skip_leading_tokens=0) for request chatcmpl-6fd536347643404fa9889712c24859f0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,205] LMCache INFO:[0m Stored 112 out of total 752 tokens. size: 0.0030 gb, cost 0.4129 ms, throughput: 7.2431 GB/s; offload_time: 0.3519 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,206] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-9709d35e83874f5e9b5e24c3b5fcc38d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,206] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.6110 ms, throughput: 5.1569 GB/s; offload_time: 0.5480 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,219] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,220] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1546 ms, throughput: 2.9603 GB/s; offload_time: 1.0705 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,256] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5753d9be27bd44379feb9804a9da881a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,257] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0452 ms, throughput: 3.2703 GB/s; offload_time: 0.9719 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,277] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-30c20879342e4cbeb993f8d903e25b74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,278] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0694 ms, throughput: 3.1962 GB/s; offload_time: 0.9887 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,291] LMCache INFO:[0m Reqid: chatcmpl-55e50ea0e0c04822a649ca35461e556f, Total tokens 1000, LMCache hit tokens: 896, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,303] LMCache INFO:[0m Storing KV cache for 1000 out of 1000 tokens (skip_leading_tokens=0) for request chatcmpl-55e50ea0e0c04822a649ca35461e556f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,304] LMCache INFO:[0m Stored 104 out of total 1000 tokens. size: 0.0028 gb, cost 0.5352 ms, throughput: 5.1886 GB/s; offload_time: 0.4613 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,315] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2f893861755f4cbcbafa173402d97d27 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,316] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0692 ms, throughput: 3.1966 GB/s; offload_time: 0.9947 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,316] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9709d35e83874f5e9b5e24c3b5fcc38d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,318] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2753 ms, throughput: 2.6802 GB/s; offload_time: 1.2043 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,329] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-52e5cf83e0894c4ab5c5f4d8192f5ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,330] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.1314 ms, throughput: 3.0209 GB/s; offload_time: 1.0559 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,359] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-91e0aa14e3ce4249a665345e4f0ecd4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,360] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.1716 ms, throughput: 2.9173 GB/s; offload_time: 1.0894 ms, put_time: 0.0822 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,380] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6fd536347643404fa9889712c24859f0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,381] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1163 ms, throughput: 3.0617 GB/s; offload_time: 1.0438 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,402] LMCache INFO:[0m Reqid: chatcmpl-1707c03314254f4bb45b578eea2406e3, Total tokens 256, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,417] LMCache INFO:[0m Storing KV cache for 256 out of 256 tokens (skip_leading_tokens=0) for request chatcmpl-1707c03314254f4bb45b578eea2406e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,419] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0068 gb, cost 1.8422 ms, throughput: 3.7107 GB/s; offload_time: 1.7300 ms, put_time: 0.1122 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,419] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-71e13c29a8214bd3bd00bdd370a17307 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,421] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.7370 ms, throughput: 1.9678 GB/s; offload_time: 1.5230 ms, put_time: 0.2139 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,422] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-992e209f52964869813d86407c1d8c3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,423] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0629 ms, throughput: 3.2157 GB/s; offload_time: 0.9931 ms, put_time: 0.0698 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,428] LMCache INFO:[0m Reqid: chatcmpl-2c3261a0109146d98e2426332d67a5b9, Total tokens 136, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,439] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-2c3261a0109146d98e2426332d67a5b9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,441] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 1.2738 ms, throughput: 2.8509 GB/s; offload_time: 1.1628 ms, put_time: 0.1110 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,470] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3d8eb88cac0744d0be53b037d48be801 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,471] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0879 ms, throughput: 3.1419 GB/s; offload_time: 1.0061 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,471] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5453f9e9492c4981a752689017e41ff4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,473] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5674 ms, throughput: 2.1806 GB/s; offload_time: 1.4945 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,516] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-297a23f3438d43bb9a19ee0f4cac63b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,518] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1450 ms, throughput: 2.9850 GB/s; offload_time: 1.0656 ms, put_time: 0.0794 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,523] LMCache INFO:[0m Reqid: chatcmpl-7eac64dced654cb7879ed31cc70882bc, Total tokens 895, LMCache hit tokens: 768, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,534] LMCache INFO:[0m Storing KV cache for 895 out of 895 tokens (skip_leading_tokens=0) for request chatcmpl-7eac64dced654cb7879ed31cc70882bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,535] LMCache INFO:[0m Stored 127 out of total 895 tokens. size: 0.0034 gb, cost 0.6532 ms, throughput: 5.1918 GB/s; offload_time: 0.4730 ms, put_time: 0.1802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,535] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-71a071c75ddd478cafc4911050fdae57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,537] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.9626 ms, throughput: 1.7415 GB/s; offload_time: 1.8839 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,538] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6904d1a609c240ed839c47e98b9737fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,540] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.2326 ms, throughput: 1.5309 GB/s; offload_time: 2.1340 ms, put_time: 0.0986 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,541] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e6dfcf404dbe467fb25a085b56a24902 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,542] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5373 ms, throughput: 2.2233 GB/s; offload_time: 1.4621 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,543] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f099b6e043144e39b444d15946896ed8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,544] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4779 ms, throughput: 2.3127 GB/s; offload_time: 1.3955 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,549] LMCache INFO:[0m Reqid: chatcmpl-e9ac66d7d01845b6bfcbaea978377f56, Total tokens 1152, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,561] LMCache INFO:[0m Storing KV cache for 1152 out of 1152 tokens (skip_leading_tokens=0) for request chatcmpl-e9ac66d7d01845b6bfcbaea978377f56 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,563] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2227 ms, throughput: 2.7954 GB/s; offload_time: 1.1449 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,563] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7eac64dced654cb7879ed31cc70882bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,565] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5951 ms, throughput: 2.1428 GB/s; offload_time: 1.5203 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,586] LMCache INFO:[0m Reqid: chatcmpl-33878c764ab2403886e819580b9be330, Total tokens 536, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,606] LMCache INFO:[0m Storing KV cache for 536 out of 536 tokens (skip_leading_tokens=0) for request chatcmpl-33878c764ab2403886e819580b9be330 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,610] LMCache INFO:[0m Stored 536 out of total 536 tokens. size: 0.0143 gb, cost 3.7197 ms, throughput: 3.8478 GB/s; offload_time: 3.1320 ms, put_time: 0.5877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,612] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-55e50ea0e0c04822a649ca35461e556f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,614] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7392 ms, throughput: 1.9652 GB/s; offload_time: 1.6597 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,620] LMCache INFO:[0m Reqid: chatcmpl-b1f2f03a6b58470fbd7820cbe5477707, Total tokens 671, LMCache hit tokens: 512, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,633] LMCache INFO:[0m Storing KV cache for 671 out of 671 tokens (skip_leading_tokens=0) for request chatcmpl-b1f2f03a6b58470fbd7820cbe5477707 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,634] LMCache INFO:[0m Stored 159 out of total 671 tokens. size: 0.0042 gb, cost 1.3844 ms, throughput: 3.0668 GB/s; offload_time: 1.2744 ms, put_time: 0.1100 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,634] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-dd6bbed8d6234054add81cf06bb7dc16 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,637] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.0072 ms, throughput: 1.7028 GB/s; offload_time: 1.9025 ms, put_time: 0.1047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,642] LMCache INFO:[0m Reqid: chatcmpl-45f07ae31ae7484287ab31fca2554071, Total tokens 555, LMCache hit tokens: 384, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,642] LMCache INFO:[0m Reqid: chatcmpl-8237c292f1564640afc553db8b74e39d, Total tokens 186, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,643] LMCache INFO:[0m Reqid: chatcmpl-0db4f82f7c1f40eca711209c66ddce75, Total tokens 415, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,644] LMCache INFO:[0m Reqid: chatcmpl-d8436790e9f74c3ab30c43772c370c09, Total tokens 1376, LMCache hit tokens: 1152, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,661] LMCache INFO:[0m Storing KV cache for 555 out of 555 tokens (skip_leading_tokens=0) for request chatcmpl-45f07ae31ae7484287ab31fca2554071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,662] LMCache INFO:[0m Stored 171 out of total 555 tokens. size: 0.0046 gb, cost 1.4599 ms, throughput: 3.1277 GB/s; offload_time: 1.3397 ms, put_time: 0.1202 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,663] LMCache INFO:[0m Storing KV cache for 186 out of 186 tokens (skip_leading_tokens=0) for request chatcmpl-8237c292f1564640afc553db8b74e39d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,665] LMCache INFO:[0m Stored 186 out of total 186 tokens. size: 0.0050 gb, cost 1.7327 ms, throughput: 2.8664 GB/s; offload_time: 1.5803 ms, put_time: 0.1525 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,665] LMCache INFO:[0m Storing KV cache for 415 out of 415 tokens (skip_leading_tokens=0) for request chatcmpl-0db4f82f7c1f40eca711209c66ddce75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,667] LMCache INFO:[0m Stored 31 out of total 415 tokens. size: 0.0008 gb, cost 1.0448 ms, throughput: 0.7923 GB/s; offload_time: 0.9781 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,667] LMCache INFO:[0m Storing KV cache for 1376 out of 1376 tokens (skip_leading_tokens=0) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,670] LMCache INFO:[0m Stored 224 out of total 1376 tokens. size: 0.0060 gb, cost 2.5810 ms, throughput: 2.3175 GB/s; offload_time: 2.4093 ms, put_time: 0.1718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,684] LMCache INFO:[0m Reqid: chatcmpl-6601e0cb1fa54b4abe95b609242bfa80, Total tokens 935, LMCache hit tokens: 896, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,685] LMCache INFO:[0m Reqid: chatcmpl-28f55046a57f42c88d42f285aea2c33b, Total tokens 725, LMCache hit tokens: 640, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,686] LMCache INFO:[0m Reqid: chatcmpl-04c11aa4f3b64768ac50b7597ed1e300, Total tokens 1415, LMCache hit tokens: 1024, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,688] LMCache INFO:[0m Reqid: chatcmpl-b71185f8dd2d493498dc8c1321021c52, Total tokens 1926, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,735] LMCache INFO:[0m Storing KV cache for 935 out of 935 tokens (skip_leading_tokens=0) for request chatcmpl-6601e0cb1fa54b4abe95b609242bfa80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,736] LMCache INFO:[0m Stored 39 out of total 935 tokens. size: 0.0010 gb, cost 0.5284 ms, throughput: 1.9710 GB/s; offload_time: 0.4555 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,736] LMCache INFO:[0m Storing KV cache for 725 out of 725 tokens (skip_leading_tokens=0) for request chatcmpl-28f55046a57f42c88d42f285aea2c33b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,737] LMCache INFO:[0m Stored 85 out of total 725 tokens. size: 0.0023 gb, cost 0.6209 ms, throughput: 3.6557 GB/s; offload_time: 0.5552 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,737] LMCache INFO:[0m Storing KV cache for 1415 out of 1415 tokens (skip_leading_tokens=0) for request chatcmpl-04c11aa4f3b64768ac50b7597ed1e300 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,742] LMCache INFO:[0m Stored 391 out of total 1415 tokens. size: 0.0104 gb, cost 4.7332 ms, throughput: 2.2059 GB/s; offload_time: 3.5122 ms, put_time: 1.2210 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,743] LMCache INFO:[0m Storing KV cache for 1926 out of 1926 tokens (skip_leading_tokens=0) for request chatcmpl-b71185f8dd2d493498dc8c1321021c52 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,756] LMCache INFO:[0m Stored 1926 out of total 1926 tokens. size: 0.0514 gb, cost 13.5329 ms, throughput: 3.8003 GB/s; offload_time: 11.7706 ms, put_time: 1.7623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,791] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-83fc63c6771d4afd837e8473a0e65240 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,792] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1618 ms, throughput: 2.9421 GB/s; offload_time: 1.0863 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,812] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e969f4204b364a278465ec0b5e9dd92b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,813] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0924 ms, throughput: 3.1287 GB/s; offload_time: 1.0163 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,813] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,815] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6495 ms, throughput: 2.0721 GB/s; offload_time: 1.5686 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,861] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-73b0d359a2584c11b57c10498737c2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,863] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1328 ms, throughput: 3.0172 GB/s; offload_time: 1.0483 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,863] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-60ad3b2e9cfc48fb9b02a577ddc90892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,865] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5573 ms, throughput: 2.1949 GB/s; offload_time: 1.4860 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,910] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-761ce30e498840778533b335ddc77665 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,911] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.1403 ms, throughput: 2.9973 GB/s; offload_time: 1.0661 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,922] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,923] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1275 ms, throughput: 3.0315 GB/s; offload_time: 1.0503 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,949] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f0af4aa916724ab68fbda351fa2df0d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,950] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0808 ms, throughput: 3.1624 GB/s; offload_time: 1.0051 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:53,977] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c9d6cfdd5630445493cca8616a5353a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,979] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.1894 ms, throughput: 2.8738 GB/s; offload_time: 1.1158 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:53,984] LMCache INFO:[0m Reqid: chatcmpl-798980311fef479884656c10f41e6be0, Total tokens 1198, LMCache hit tokens: 1152, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,995] LMCache INFO:[0m Storing KV cache for 1198 out of 1198 tokens (skip_leading_tokens=0) for request chatcmpl-798980311fef479884656c10f41e6be0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:53,996] LMCache INFO:[0m Stored 46 out of total 1198 tokens. size: 0.0012 gb, cost 0.5951 ms, throughput: 2.0642 GB/s; offload_time: 0.5175 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,015] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-1dec1adcde914eb4aaaa0418aee68e03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,017] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2852 ms, throughput: 2.6595 GB/s; offload_time: 1.2089 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,027] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-8fc5338d9ef441a9a2548fe4edad81b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,028] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1720 ms, throughput: 2.9163 GB/s; offload_time: 1.0832 ms, put_time: 0.0888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,029] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d1dcfca07ed44c05ae13275a5e7184cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,030] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3115 ms, throughput: 2.6062 GB/s; offload_time: 1.0755 ms, put_time: 0.2359 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,041] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-f20ca34d0da740929651983f46c9aef1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,043] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2548 ms, throughput: 2.7239 GB/s; offload_time: 1.1780 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,047] LMCache INFO:[0m Reqid: chatcmpl-cb4c8d8c81b648f39d8e3292bbe7c5fd, Total tokens 800, LMCache hit tokens: 768, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,059] LMCache INFO:[0m Storing KV cache for 800 out of 800 tokens (skip_leading_tokens=0) for request chatcmpl-cb4c8d8c81b648f39d8e3292bbe7c5fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,060] LMCache INFO:[0m Stored 32 out of total 800 tokens. size: 0.0009 gb, cost 0.5529 ms, throughput: 1.5455 GB/s; offload_time: 0.4698 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,060] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b460100d80ee4679af8ea7ff66eb4ce8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,061] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3771 ms, throughput: 2.4820 GB/s; offload_time: 1.3056 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,081] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-85019a4004134ff1a291070c6a9d51e2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,082] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1496 ms, throughput: 2.9732 GB/s; offload_time: 1.0718 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,083] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,084] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5439 ms, throughput: 2.2139 GB/s; offload_time: 1.4637 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,089] LMCache INFO:[0m Reqid: chatcmpl-9e2e18cc23504ea8ba13bc6318a88728, Total tokens 1859, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,129] LMCache INFO:[0m Storing KV cache for 1859 out of 1859 tokens (skip_leading_tokens=0) for request chatcmpl-9e2e18cc23504ea8ba13bc6318a88728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,141] LMCache INFO:[0m Stored 1859 out of total 1859 tokens. size: 0.0496 gb, cost 11.5264 ms, throughput: 4.3067 GB/s; offload_time: 10.4390 ms, put_time: 1.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,158] LMCache INFO:[0m Reqid: chatcmpl-f48dfb37b7274044bffe7b533a36921b, Total tokens 534, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,159] LMCache INFO:[0m Reqid: chatcmpl-97073a95aa9c4340ae0555ca2729b88c, Total tokens 830, LMCache hit tokens: 768, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,160] LMCache INFO:[0m Reqid: chatcmpl-5e76d035f1804af985f87422d602855e, Total tokens 1828, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,161] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,203] LMCache INFO:[0m Storing KV cache for 830 out of 830 tokens (skip_leading_tokens=0) for request chatcmpl-97073a95aa9c4340ae0555ca2729b88c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,204] LMCache INFO:[0m Stored 62 out of total 830 tokens. size: 0.0017 gb, cost 0.5528 ms, throughput: 2.9948 GB/s; offload_time: 0.4697 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,204] LMCache INFO:[0m Storing KV cache for 1828 out of 1828 tokens (skip_leading_tokens=0) for request chatcmpl-5e76d035f1804af985f87422d602855e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,219] LMCache INFO:[0m Stored 1828 out of total 1828 tokens. size: 0.0488 gb, cost 14.2432 ms, throughput: 3.4271 GB/s; offload_time: 10.8210 ms, put_time: 3.4221 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,227] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,234] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f010231db8eb4de7b2462d0e5004771e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,236] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3213 ms, throughput: 2.5869 GB/s; offload_time: 1.2441 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,240] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,247] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,248] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1340 ms, throughput: 3.0140 GB/s; offload_time: 1.0598 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,249] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,250] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4238 ms, throughput: 2.4007 GB/s; offload_time: 1.3518 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,255] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,268] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,275] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-02f958d42eb64bb7ab05ae7a62ebef6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,276] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1925 ms, throughput: 2.8663 GB/s; offload_time: 1.1190 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,280] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,290] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,300] LMCache INFO:[0m Reqid: chatcmpl-562c9a96535840d4854aefe92416c61d, Total tokens 789, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,301] LMCache INFO:[0m Reqid: chatcmpl-c227c494ebfa43c0a4dbc7ec99786a6c, Total tokens 782, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,302] LMCache INFO:[0m Reqid: chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,321] LMCache INFO:[0m Storing KV cache for 149 out of 789 tokens (skip_leading_tokens=640) for request chatcmpl-562c9a96535840d4854aefe92416c61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,322] LMCache INFO:[0m Stored 149 out of total 789 tokens. size: 0.0040 gb, cost 0.6978 ms, throughput: 5.7019 GB/s; offload_time: 0.5935 ms, put_time: 0.1042 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,323] LMCache INFO:[0m Storing KV cache for 142 out of 782 tokens (skip_leading_tokens=640) for request chatcmpl-c227c494ebfa43c0a4dbc7ec99786a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,325] LMCache INFO:[0m Stored 142 out of total 782 tokens. size: 0.0038 gb, cost 2.3814 ms, throughput: 1.5923 GB/s; offload_time: 2.2044 ms, put_time: 0.1769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,326] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d0e75e7f9c894f33b186537fff08e200 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,328] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.9444 ms, throughput: 1.7578 GB/s; offload_time: 1.6013 ms, put_time: 0.3431 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,328] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-63bb8bfe215448ba89d98866c31c5790 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,330] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.8349 ms, throughput: 1.8628 GB/s; offload_time: 1.7604 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,335] LMCache INFO:[0m Reqid: chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,336] LMCache INFO:[0m Reqid: chatcmpl-d52f389ba8b14e328442cbd877ac1d38, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,337] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,351] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,351] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.4338 ms, throughput: 6.0943 GB/s; offload_time: 0.3600 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,352] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-16fb5d8e989547fabd102acaca6b0b69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,353] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4107 ms, throughput: 2.4228 GB/s; offload_time: 1.3403 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,358] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,366] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4f8504ffe1174db08e47a4dab245f94f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,367] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2239 ms, throughput: 2.7926 GB/s; offload_time: 1.1496 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,371] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,382] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,389] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-290597f094274a72aceef73a067b350b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,390] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2333 ms, throughput: 2.7713 GB/s; offload_time: 1.1587 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,391] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-28f55046a57f42c88d42f285aea2c33b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,393] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4889 ms, throughput: 2.2956 GB/s; offload_time: 1.4128 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,398] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,407] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,417] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,424] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,425] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2476 ms, throughput: 2.7396 GB/s; offload_time: 1.1644 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,430] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,440] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,451] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1540, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,452] LMCache INFO:[0m Reqid: chatcmpl-adbd992e32be4235a5a3fdfd7ffa5379, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,452] LMCache INFO:[0m Reqid: chatcmpl-a1a8a9e683d3428e9105853463a10589, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,472] LMCache INFO:[0m Storing KV cache for 132 out of 1540 tokens (skip_leading_tokens=1408) for request chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,473] LMCache INFO:[0m Stored 132 out of total 1540 tokens. size: 0.0035 gb, cost 0.7878 ms, throughput: 4.4744 GB/s; offload_time: 0.6809 ms, put_time: 0.1069 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,473] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-adbd992e32be4235a5a3fdfd7ffa5379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,475] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 1.4315 ms, throughput: 2.0705 GB/s; offload_time: 1.3304 ms, put_time: 0.1011 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,475] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-a1a8a9e683d3428e9105853463a10589 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,476] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 0.7511 ms, throughput: 4.0527 GB/s; offload_time: 0.6872 ms, put_time: 0.0640 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,515] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-add556b5fc584b77aa886147d22e3f07 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,516] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1646 ms, throughput: 2.9349 GB/s; offload_time: 1.0910 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,521] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1544, LMCache hit tokens: 1540, need to load: 116 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,531] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1544, LMCache hit tokens: 1540, need to load: 180 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,538] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-896fbaeba2c2429b92373f316d86bfd9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,540] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2032 ms, throughput: 2.8409 GB/s; offload_time: 1.1291 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,545] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1544, LMCache hit tokens: 1540, need to load: 244 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,552] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-d9de87dcaa2642e1a20a06a12f9c971c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,553] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2116 ms, throughput: 2.8211 GB/s; offload_time: 1.1359 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,558] LMCache INFO:[0m Reqid: chatcmpl-c5ccba2a1b8d40a786d1f954e7ae2c04, Total tokens 1544, LMCache hit tokens: 1540, need to load: 340 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,559] LMCache INFO:[0m Reqid: chatcmpl-adbd992e32be4235a5a3fdfd7ffa5379, Total tokens 114, LMCache hit tokens: 111, need to load: 63 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,559] LMCache INFO:[0m Reqid: chatcmpl-a1a8a9e683d3428e9105853463a10589, Total tokens 116, LMCache hit tokens: 114, need to load: 66 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,560] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,574] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,576] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,592] LMCache INFO:[0m Storing KV cache for 143 out of 1295 tokens (skip_leading_tokens=1152) for request chatcmpl-597def71c0994eebafdcf99bc2516f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,593] LMCache INFO:[0m Stored 143 out of total 1295 tokens. size: 0.0038 gb, cost 0.7763 ms, throughput: 4.9189 GB/s; offload_time: 0.6577 ms, put_time: 0.1186 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,599] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,609] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,616] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-186a6471a56f405fba550440abd4e213 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,618] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1781 ms, throughput: 2.9012 GB/s; offload_time: 1.1023 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,618] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-4d5a6c5c916e4a26929caa62b1728253 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,620] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.7517 ms, throughput: 1.9513 GB/s; offload_time: 1.6788 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,625] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,635] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,644] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,654] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,664] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,674] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,684] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,691] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,692] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1343 ms, throughput: 3.0133 GB/s; offload_time: 1.0596 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,703] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8237c292f1564640afc553db8b74e39d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,705] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1310 ms, throughput: 3.0221 GB/s; offload_time: 1.0562 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,709] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1305, LMCache hit tokens: 1295, need to load: 79 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,717] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-40f73d1226db470f810310a770cd9268 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,718] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2008 ms, throughput: 2.8464 GB/s; offload_time: 1.1227 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,718] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,720] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4208 ms, throughput: 2.4056 GB/s; offload_time: 1.2254 ms, put_time: 0.1954 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,720] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a1a8a9e683d3428e9105853463a10589 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,722] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2668 ms, throughput: 2.6981 GB/s; offload_time: 1.2009 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,728] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1305, LMCache hit tokens: 1295, need to load: 191 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,736] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-7651e1cbcb75403faecdbcd438cc59cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,739] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 3.5074 ms, throughput: 0.9745 GB/s; offload_time: 3.4262 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,744] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1305, LMCache hit tokens: 1295, need to load: 239 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,751] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-adbd992e32be4235a5a3fdfd7ffa5379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,753] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0966 ms, throughput: 3.1170 GB/s; offload_time: 1.0225 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,757] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1305, LMCache hit tokens: 1295, need to load: 319 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,768] LMCache INFO:[0m Reqid: chatcmpl-597def71c0994eebafdcf99bc2516f21, Total tokens 1305, LMCache hit tokens: 1295, need to load: 415 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,769] LMCache INFO:[0m Reqid: chatcmpl-f09dd15a2500429fb571baf76f19c84c, Total tokens 1288, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,770] LMCache INFO:[0m Reqid: chatcmpl-1ad7856396ef4c9cbe70418014ff30d2, Total tokens 139, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,771] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1325, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,787] LMCache INFO:[0m Storing KV cache for 136 out of 1288 tokens (skip_leading_tokens=1152) for request chatcmpl-f09dd15a2500429fb571baf76f19c84c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,789] LMCache INFO:[0m Stored 136 out of total 1288 tokens. size: 0.0036 gb, cost 1.4394 ms, throughput: 2.5230 GB/s; offload_time: 1.3230 ms, put_time: 0.1164 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,790] LMCache INFO:[0m Storing KV cache for 139 out of 139 tokens (skip_leading_tokens=0) for request chatcmpl-1ad7856396ef4c9cbe70418014ff30d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,792] LMCache INFO:[0m Stored 139 out of total 139 tokens. size: 0.0037 gb, cost 2.0195 ms, throughput: 1.8379 GB/s; offload_time: 1.9094 ms, put_time: 0.1101 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,792] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-e3a6ec68051e4e9a9b9e903ec77a3e3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,795] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 2.6805 ms, throughput: 1.2751 GB/s; offload_time: 2.6013 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,800] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1325, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,801] LMCache INFO:[0m Reqid: chatcmpl-89ac10c46c514beb93d8091e85b96191, Total tokens 148, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,802] LMCache INFO:[0m Reqid: chatcmpl-936f02186fd349c8ab10941d00edbb66, Total tokens 1231, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:54,834] LMCache INFO:[0m Storing KV cache for 148 out of 148 tokens (skip_leading_tokens=0) for request chatcmpl-89ac10c46c514beb93d8091e85b96191 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,835] LMCache INFO:[0m Stored 148 out of total 148 tokens. size: 0.0040 gb, cost 0.6642 ms, throughput: 5.9505 GB/s; offload_time: 0.5558 ms, put_time: 0.1083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,841] LMCache INFO:[0m Reqid: chatcmpl-936f02186fd349c8ab10941d00edbb66, Total tokens 1231, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,849] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-ba115843b7ee43859c96c05ab19516b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,849] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5585 ms, throughput: 6.1198 GB/s; offload_time: 0.4753 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,853] LMCache INFO:[0m Reqid: chatcmpl-936f02186fd349c8ab10941d00edbb66, Total tokens 1231, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,884] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,891] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,891] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6425 ms, throughput: 5.3201 GB/s; offload_time: 0.5617 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,896] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,903] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,904] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5489 ms, throughput: 6.2265 GB/s; offload_time: 0.4739 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,909] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,916] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-45ce5e1bb6614f7a9f3569d0a4672069 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,917] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4962 ms, throughput: 6.8888 GB/s; offload_time: 0.4231 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,922] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,932] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,939] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-45f07ae31ae7484287ab31fca2554071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,940] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5026 ms, throughput: 6.8000 GB/s; offload_time: 0.4262 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,944] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,954] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,964] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,971] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d52f389ba8b14e328442cbd877ac1d38 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,972] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4667 ms, throughput: 7.3234 GB/s; offload_time: 0.3923 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,976] LMCache INFO:[0m Reqid: chatcmpl-517ad14976524a108bef1fd686a40071, Total tokens 1329, LMCache hit tokens: 1280, need to load: 528 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,978] LMCache INFO:[0m Reqid: chatcmpl-89ac10c46c514beb93d8091e85b96191, Total tokens 151, LMCache hit tokens: 148, need to load: 100 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,979] LMCache INFO:[0m Reqid: chatcmpl-936f02186fd349c8ab10941d00edbb66, Total tokens 1231, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,979] LMCache INFO:[0m Reqid: chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,980] LMCache INFO:[0m Reqid: chatcmpl-70f4ad521ea746ce90b47dd57ee930b9, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,997] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,998] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.4169 ms, throughput: 6.9820 GB/s; offload_time: 0.3364 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:54,998] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-70f4ad521ea746ce90b47dd57ee930b9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:54,999] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.6537 ms, throughput: 4.2072 GB/s; offload_time: 0.5870 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,020] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-27c130ce29884b3999d356a2060b3a6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,021] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6192 ms, throughput: 5.5204 GB/s; offload_time: 0.5456 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,021] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-85f28010137a480f9273afa1409d5c94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,022] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.8187 ms, throughput: 4.1749 GB/s; offload_time: 0.7515 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,022] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6601e0cb1fa54b4abe95b609242bfa80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,025] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 2.2965 ms, throughput: 1.4883 GB/s; offload_time: 2.1716 ms, put_time: 0.1249 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,039] LMCache INFO:[0m Reqid: chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3, Total tokens 112, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,039] LMCache INFO:[0m Reqid: chatcmpl-70f4ad521ea746ce90b47dd57ee930b9, Total tokens 106, LMCache hit tokens: 103, need to load: 55 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,041] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,055] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,062] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,064] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2528 ms, throughput: 2.7282 GB/s; offload_time: 1.1732 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,064] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-9e2e18cc23504ea8ba13bc6318a88728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,066] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.6229 ms, throughput: 2.1061 GB/s; offload_time: 1.5536 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,071] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,081] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,087] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b1f2f03a6b58470fbd7820cbe5477707 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,089] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1716 ms, throughput: 2.9174 GB/s; offload_time: 1.0966 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,094] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,101] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0db4f82f7c1f40eca711209c66ddce75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,102] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1392 ms, throughput: 3.0004 GB/s; offload_time: 1.0629 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,107] LMCache INFO:[0m Reqid: chatcmpl-9fde83d53acd4a7da229acd7f5102751, Total tokens 1321, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,108] LMCache INFO:[0m Reqid: chatcmpl-dc3eb2f5a5bb4a94a6afdf2f0c58c8e9, Total tokens 149, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,145] LMCache INFO:[0m Reqid: chatcmpl-acd21cdfcef04cb8a172ff32c358b38a, Total tokens 343, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,160] LMCache INFO:[0m Storing KV cache for 343 out of 343 tokens (skip_leading_tokens=0) for request chatcmpl-acd21cdfcef04cb8a172ff32c358b38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,161] LMCache INFO:[0m Stored 343 out of total 343 tokens. size: 0.0092 gb, cost 0.8700 ms, throughput: 10.5281 GB/s; offload_time: 0.7265 ms, put_time: 0.1435 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,166] LMCache INFO:[0m Reqid: chatcmpl-da1332fe30304f4cb89c84732225da4d, Total tokens 228, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,168] LMCache INFO:[0m Reqid: chatcmpl-0e4dd1ede1b94e88bc0e331d61c182f6, Total tokens 665, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,188] LMCache INFO:[0m Storing KV cache for 228 out of 228 tokens (skip_leading_tokens=0) for request chatcmpl-da1332fe30304f4cb89c84732225da4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,189] LMCache INFO:[0m Stored 228 out of total 228 tokens. size: 0.0061 gb, cost 0.6667 ms, throughput: 9.1316 GB/s; offload_time: 0.5576 ms, put_time: 0.1091 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,189] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-97073a95aa9c4340ae0555ca2729b88c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,191] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.7965 ms, throughput: 1.9026 GB/s; offload_time: 1.7181 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,196] LMCache INFO:[0m Reqid: chatcmpl-635dc91559d34c8abfe83967691d416c, Total tokens 352, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,197] LMCache INFO:[0m Reqid: chatcmpl-974e39d17edb4f498043afcd0784ab7f, Total tokens 116, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,212] LMCache INFO:[0m Storing KV cache for 116 out of 116 tokens (skip_leading_tokens=0) for request chatcmpl-974e39d17edb4f498043afcd0784ab7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,213] LMCache INFO:[0m Stored 116 out of total 116 tokens. size: 0.0031 gb, cost 0.4419 ms, throughput: 7.0093 GB/s; offload_time: 0.3531 ms, put_time: 0.0888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,223] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-33878c764ab2403886e819580b9be330 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,224] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4853 ms, throughput: 7.0430 GB/s; offload_time: 0.4057 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,235] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9709d35e83874f5e9b5e24c3b5fcc38d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,235] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4483 ms, throughput: 7.6249 GB/s; offload_time: 0.3747 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,255] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2c3261a0109146d98e2426332d67a5b9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,255] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4533 ms, throughput: 7.5395 GB/s; offload_time: 0.3786 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,293] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,293] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4391 ms, throughput: 7.7834 GB/s; offload_time: 0.3633 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,329] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-974e39d17edb4f498043afcd0784ab7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,331] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1344 ms, throughput: 3.0130 GB/s; offload_time: 1.0608 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,335] LMCache INFO:[0m Reqid: chatcmpl-bdb93e150aed445b92bc14bc6c9514a7, Total tokens 1076, LMCache hit tokens: 1024, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,366] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3d8eb88cac0744d0be53b037d48be801 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,367] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1481 ms, throughput: 2.9771 GB/s; offload_time: 1.0754 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,367] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-5453f9e9492c4981a752689017e41ff4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,369] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.6046 ms, throughput: 2.1301 GB/s; offload_time: 1.5357 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,373] LMCache INFO:[0m Reqid: chatcmpl-1ccc811f6733427495d527bf240057a0, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,395] LMCache INFO:[0m Reqid: chatcmpl-6545793934e2456bb2a8e2f6aae823a6, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,406] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-6545793934e2456bb2a8e2f6aae823a6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,407] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.4220 ms, throughput: 6.4541 GB/s; offload_time: 0.3492 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,429] LMCache INFO:[0m Reqid: chatcmpl-44a32f8e47c44173ab89c9fc909e4d99, Total tokens 1196, LMCache hit tokens: 1152, need to load: 528 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,453] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-71a071c75ddd478cafc4911050fdae57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,453] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5785 ms, throughput: 5.9087 GB/s; offload_time: 0.4998 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,454] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-6904d1a609c240ed839c47e98b9737fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,456] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.8656 ms, throughput: 1.8321 GB/s; offload_time: 1.7862 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,456] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e6dfcf404dbe467fb25a085b56a24902 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,458] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5938 ms, throughput: 2.1445 GB/s; offload_time: 1.4100 ms, put_time: 0.1838 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,458] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f099b6e043144e39b444d15946896ed8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,460] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1407 ms, throughput: 2.9964 GB/s; offload_time: 1.0750 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,471] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-7eac64dced654cb7879ed31cc70882bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,472] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1895 ms, throughput: 2.8735 GB/s; offload_time: 1.1142 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,473] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-04c11aa4f3b64768ac50b7597ed1e300 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,475] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5457 ms, throughput: 2.2113 GB/s; offload_time: 1.4700 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,479] LMCache INFO:[0m Reqid: chatcmpl-0697b242db254501a3bf111e43922ae8, Total tokens 598, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,497] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-b71185f8dd2d493498dc8c1321021c52 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,498] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.6138 ms, throughput: 5.5688 GB/s; offload_time: 0.5408 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,503] LMCache INFO:[0m Reqid: chatcmpl-e3f3139484c74312b7761ea1a837e066, Total tokens 1560, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,534] LMCache INFO:[0m Storing KV cache for 1176 out of 1560 tokens (skip_leading_tokens=384) for request chatcmpl-e3f3139484c74312b7761ea1a837e066 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,541] LMCache INFO:[0m Stored 1176 out of total 1560 tokens. size: 0.0314 gb, cost 6.4510 ms, throughput: 4.8678 GB/s; offload_time: 6.1394 ms, put_time: 0.3117 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,553] LMCache INFO:[0m Reqid: chatcmpl-8d86fcdcf29d4ff8915a50613c7f3116, Total tokens 367, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,553] LMCache INFO:[0m Reqid: chatcmpl-8dcbb3bb18544b3eb4efba7534636222, Total tokens 362, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,554] LMCache INFO:[0m Reqid: chatcmpl-3ea97cfaa05840d69b64813e90eca619, Total tokens 297, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,554] LMCache INFO:[0m Reqid: chatcmpl-4e8f4bbe95ed4feb9039fcf055832eaf, Total tokens 154, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,555] LMCache INFO:[0m Reqid: chatcmpl-c006b308542242ac99bbfb52fd7fe51e, Total tokens 206, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,555] LMCache INFO:[0m Reqid: chatcmpl-ea9e06d9a3ae4cf483db224b2e270c2d, Total tokens 129, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,556] LMCache INFO:[0m Reqid: chatcmpl-e31f7b903b8347d7a470dacb3b6c0eaa, Total tokens 150, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,582] LMCache INFO:[0m Storing KV cache for 154 out of 154 tokens (skip_leading_tokens=0) for request chatcmpl-4e8f4bbe95ed4feb9039fcf055832eaf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,583] LMCache INFO:[0m Stored 154 out of total 154 tokens. size: 0.0041 gb, cost 0.6352 ms, throughput: 6.4738 GB/s; offload_time: 0.5202 ms, put_time: 0.1150 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,583] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-ea9e06d9a3ae4cf483db224b2e270c2d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,585] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 1.9620 ms, throughput: 1.7557 GB/s; offload_time: 1.8556 ms, put_time: 0.1063 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,586] LMCache INFO:[0m Storing KV cache for 150 out of 150 tokens (skip_leading_tokens=0) for request chatcmpl-e31f7b903b8347d7a470dacb3b6c0eaa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,588] LMCache INFO:[0m Stored 150 out of total 150 tokens. size: 0.0040 gb, cost 2.4463 ms, throughput: 1.6373 GB/s; offload_time: 2.3075 ms, put_time: 0.1388 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,590] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-55e50ea0e0c04822a649ca35461e556f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,592] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7521 ms, throughput: 1.9508 GB/s; offload_time: 1.6106 ms, put_time: 0.1416 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,592] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-cb4c8d8c81b648f39d8e3292bbe7c5fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,594] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5617 ms, throughput: 2.1887 GB/s; offload_time: 1.4952 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,594] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-5e76d035f1804af985f87422d602855e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,596] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.9302 ms, throughput: 1.7708 GB/s; offload_time: 1.8634 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,602] LMCache INFO:[0m Reqid: chatcmpl-04b4f4b275d840a0a33df6c78879c122, Total tokens 1605, LMCache hit tokens: 1536, need to load: 768 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,603] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 784 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,629] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 816 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,635] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-da1332fe30304f4cb89c84732225da4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,636] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4600 ms, throughput: 7.4310 GB/s; offload_time: 0.3843 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,640] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 928 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,650] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,660] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,670] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,680] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,687] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-635dc91559d34c8abfe83967691d416c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,687] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4786 ms, throughput: 7.1416 GB/s; offload_time: 0.4016 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,691] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,701] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,709] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e969f4204b364a278465ec0b5e9dd92b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,709] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4732 ms, throughput: 7.2230 GB/s; offload_time: 0.3960 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,709] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,711] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.6847 ms, throughput: 2.0288 GB/s; offload_time: 1.6008 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,716] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,726] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,742] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-936f02186fd349c8ab10941d00edbb66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,743] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2035 ms, throughput: 2.8401 GB/s; offload_time: 1.1232 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,748] LMCache INFO:[0m Reqid: chatcmpl-04b4f4b275d840a0a33df6c78879c122, Total tokens 1616, LMCache hit tokens: 1536, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,758] LMCache INFO:[0m Reqid: chatcmpl-04b4f4b275d840a0a33df6c78879c122, Total tokens 1616, LMCache hit tokens: 1536, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,759] LMCache INFO:[0m Reqid: chatcmpl-f561f579230b4daaaad850e5e7abb3b3, Total tokens 1138, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,760] LMCache INFO:[0m Reqid: chatcmpl-e34f4c6fac094c64bd6ea6be3ac3e9e3, Total tokens 1062, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,780] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-60ad3b2e9cfc48fb9b02a577ddc90892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,780] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4987 ms, throughput: 6.8544 GB/s; offload_time: 0.4207 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,781] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f48dfb37b7274044bffe7b533a36921b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,782] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8735 ms, throughput: 3.9127 GB/s; offload_time: 0.8056 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,782] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-acd21cdfcef04cb8a172ff32c358b38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,784] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4654 ms, throughput: 2.3325 GB/s; offload_time: 1.3874 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,788] LMCache INFO:[0m Reqid: chatcmpl-e34f4c6fac094c64bd6ea6be3ac3e9e3, Total tokens 1062, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,790] LMCache INFO:[0m Reqid: chatcmpl-06a36efde0ef4ec186f662b84a485cc7, Total tokens 1508, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,791] LMCache INFO:[0m Reqid: chatcmpl-6e42a35d7e2d46d3a32f47206f225597, Total tokens 1045, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,839] LMCache INFO:[0m Storing KV cache for 1062 out of 1062 tokens (skip_leading_tokens=0) for request chatcmpl-e34f4c6fac094c64bd6ea6be3ac3e9e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,845] LMCache INFO:[0m Stored 1062 out of total 1062 tokens. size: 0.0284 gb, cost 5.1375 ms, throughput: 5.5199 GB/s; offload_time: 1.6740 ms, put_time: 3.4635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,852] LMCache INFO:[0m Reqid: chatcmpl-6e42a35d7e2d46d3a32f47206f225597, Total tokens 1045, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,854] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,879] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,885] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8d86fcdcf29d4ff8915a50613c7f3116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,886] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4569 ms, throughput: 7.4811 GB/s; offload_time: 0.3808 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,890] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,900] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,909] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,916] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,917] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5178 ms, throughput: 6.6013 GB/s; offload_time: 0.4412 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,921] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,930] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1373, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,931] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,963] LMCache INFO:[0m Storing KV cache for 1373 out of 1373 tokens (skip_leading_tokens=0) for request chatcmpl-ca6b38396828423691d00590bc3281ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,969] LMCache INFO:[0m Stored 1373 out of total 1373 tokens. size: 0.0367 gb, cost 5.8650 ms, throughput: 6.2511 GB/s; offload_time: 5.2920 ms, put_time: 0.5730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,970] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-562c9a96535840d4854aefe92416c61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,975] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 5.0336 ms, throughput: 0.6790 GB/s; offload_time: 4.9588 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:55,975] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8dcbb3bb18544b3eb4efba7534636222 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,977] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.8126 ms, throughput: 1.8857 GB/s; offload_time: 1.4632 ms, put_time: 0.3494 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:55,985] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:55,995] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,004] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,020] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c9d6cfdd5630445493cca8616a5353a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,021] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2234 ms, throughput: 2.7939 GB/s; offload_time: 1.1474 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,026] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 109 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,035] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 205 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,042] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f561f579230b4daaaad850e5e7abb3b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,044] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2541 ms, throughput: 2.7254 GB/s; offload_time: 1.1728 ms, put_time: 0.0814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,048] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 269 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,056] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-1dec1adcde914eb4aaaa0418aee68e03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,057] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3897 ms, throughput: 2.4595 GB/s; offload_time: 1.3061 ms, put_time: 0.0837 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,058] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c227c494ebfa43c0a4dbc7ec99786a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,059] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5646 ms, throughput: 2.1846 GB/s; offload_time: 1.4894 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,064] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 381 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,074] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 461 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,081] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-f20ca34d0da740929651983f46c9aef1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,082] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.2361 ms, throughput: 2.7652 GB/s; offload_time: 1.1595 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,086] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 541 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,096] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 637 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,106] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 669 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,113] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,115] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2184 ms, throughput: 2.8054 GB/s; offload_time: 1.1433 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,119] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 765 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,128] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 797 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,138] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 861 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,145] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f010231db8eb4de7b2462d0e5004771e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,146] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2285 ms, throughput: 2.7822 GB/s; offload_time: 1.1479 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,150] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 893 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,158] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,159] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1397 ms, throughput: 2.9990 GB/s; offload_time: 1.0574 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,159] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-7cf330b9c8ea4f368da68bdc7bb1f2e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,161] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5399 ms, throughput: 2.2196 GB/s; offload_time: 1.4716 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,165] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 973 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,175] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 1053 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,182] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-02f958d42eb64bb7ab05ae7a62ebef6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,184] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1417 ms, throughput: 2.9939 GB/s; offload_time: 1.0649 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,184] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0697b242db254501a3bf111e43922ae8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,186] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3685 ms, throughput: 2.4975 GB/s; offload_time: 1.2993 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,190] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 1117 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,200] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 1213 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,207] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-517ad14976524a108bef1fd686a40071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,209] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2389 ms, throughput: 2.7589 GB/s; offload_time: 1.1607 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,213] LMCache INFO:[0m Reqid: chatcmpl-ca6b38396828423691d00590bc3281ad, Total tokens 1377, LMCache hit tokens: 1373, need to load: 1277 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,214] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,225] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-06a36efde0ef4ec186f662b84a485cc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,227] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2314 ms, throughput: 2.7757 GB/s; offload_time: 1.1518 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,230] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,240] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,247] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-4f8504ffe1174db08e47a4dab245f94f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,248] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1671 ms, throughput: 2.9286 GB/s; offload_time: 1.0907 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,252] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,261] LMCache INFO:[0m Reqid: chatcmpl-44d7db6362c74f4ea3debb6933118465, Total tokens 532, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,262] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 454, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,263] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,288] LMCache INFO:[0m Storing KV cache for 148 out of 532 tokens (skip_leading_tokens=384) for request chatcmpl-44d7db6362c74f4ea3debb6933118465 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,289] LMCache INFO:[0m Stored 148 out of total 532 tokens. size: 0.0040 gb, cost 0.6754 ms, throughput: 5.8517 GB/s; offload_time: 0.5703 ms, put_time: 0.1051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,289] LMCache INFO:[0m Storing KV cache for 454 out of 454 tokens (skip_leading_tokens=0) for request chatcmpl-46b060b3472e4193a3d8f37c83c7b051 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,293] LMCache INFO:[0m Stored 454 out of total 454 tokens. size: 0.0121 gb, cost 3.8590 ms, throughput: 3.1415 GB/s; offload_time: 3.4507 ms, put_time: 0.4083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,293] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-28f55046a57f42c88d42f285aea2c33b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,296] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 2.8893 ms, throughput: 1.1830 GB/s; offload_time: 2.8131 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,302] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,311] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,318] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1ccc811f6733427495d527bf240057a0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,320] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2239 ms, throughput: 2.7928 GB/s; offload_time: 1.1476 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,324] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,331] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,333] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2011 ms, throughput: 2.8458 GB/s; offload_time: 1.1233 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,333] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c006b308542242ac99bbfb52fd7fe51e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,335] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4023 ms, throughput: 2.4374 GB/s; offload_time: 1.3252 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,348] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,355] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-597def71c0994eebafdcf99bc2516f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,356] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2349 ms, throughput: 2.7678 GB/s; offload_time: 1.1552 ms, put_time: 0.0797 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,360] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 118 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,369] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 150 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,378] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 230 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,388] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 310 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,397] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 374 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,403] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-add556b5fc584b77aa886147d22e3f07 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,405] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1803 ms, throughput: 2.8959 GB/s; offload_time: 1.1016 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,409] LMCache INFO:[0m Reqid: chatcmpl-46b060b3472e4193a3d8f37c83c7b051, Total tokens 458, LMCache hit tokens: 454, need to load: 406 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,410] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,423] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,430] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-896fbaeba2c2429b92373f316d86bfd9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,432] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1965 ms, throughput: 2.8566 GB/s; offload_time: 1.1156 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,432] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-9fde83d53acd4a7da229acd7f5102751 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,434] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5311 ms, throughput: 2.2324 GB/s; offload_time: 1.4594 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,438] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,448] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,457] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,464] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-04b4f4b275d840a0a33df6c78879c122 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,466] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2426 ms, throughput: 2.7507 GB/s; offload_time: 1.1620 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,470] LMCache INFO:[0m Reqid: chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c, Total tokens 1157, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,472] LMCache INFO:[0m Reqid: chatcmpl-43df6b936ba347acbc426068ddddc496, Total tokens 1674, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,473] LMCache INFO:[0m Reqid: chatcmpl-c9d8468fdbd34c51aff88edefa28c886, Total tokens 671, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,497] LMCache INFO:[0m Storing KV cache for 133 out of 1157 tokens (skip_leading_tokens=1024) for request chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,498] LMCache INFO:[0m Stored 133 out of total 1157 tokens. size: 0.0036 gb, cost 0.6880 ms, throughput: 5.1623 GB/s; offload_time: 0.5780 ms, put_time: 0.1099 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,498] LMCache INFO:[0m Storing KV cache for 138 out of 1674 tokens (skip_leading_tokens=1536) for request chatcmpl-43df6b936ba347acbc426068ddddc496 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,501] LMCache INFO:[0m Stored 138 out of total 1674 tokens. size: 0.0037 gb, cost 2.1909 ms, throughput: 1.6820 GB/s; offload_time: 2.0861 ms, put_time: 0.1047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,506] LMCache INFO:[0m Reqid: chatcmpl-c9d8468fdbd34c51aff88edefa28c886, Total tokens 671, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,513] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-bdb93e150aed445b92bc14bc6c9514a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,514] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1919 ms, throughput: 2.8677 GB/s; offload_time: 1.1114 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,528] LMCache INFO:[0m Reqid: chatcmpl-43df6b936ba347acbc426068ddddc496, Total tokens 1676, LMCache hit tokens: 1674, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,529] LMCache INFO:[0m Reqid: chatcmpl-c9d8468fdbd34c51aff88edefa28c886, Total tokens 671, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,529] LMCache INFO:[0m Reqid: chatcmpl-a29531ad2ddb4ec5879e12186e9bd39b, Total tokens 690, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,546] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1ad7856396ef4c9cbe70418014ff30d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,546] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4377 ms, throughput: 7.8086 GB/s; offload_time: 0.3644 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,550] LMCache INFO:[0m Reqid: chatcmpl-a29531ad2ddb4ec5879e12186e9bd39b, Total tokens 690, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,551] LMCache INFO:[0m Reqid: chatcmpl-abbdfe5c7638410c9677719ce7979f4c, Total tokens 587, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,552] LMCache INFO:[0m Reqid: chatcmpl-38b7303763b143959d35ba1aab9fb63a, Total tokens 679, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,553] LMCache INFO:[0m Reqid: chatcmpl-cb7d995f18c14444b55023f7463b33c2, Total tokens 1113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,554] LMCache INFO:[0m Reqid: chatcmpl-4b5c765ffe204495a4450af74865a4b4, Total tokens 1407, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,597] LMCache INFO:[0m Storing KV cache for 690 out of 690 tokens (skip_leading_tokens=0) for request chatcmpl-a29531ad2ddb4ec5879e12186e9bd39b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,601] LMCache INFO:[0m Stored 690 out of total 690 tokens. size: 0.0184 gb, cost 3.0163 ms, throughput: 6.1085 GB/s; offload_time: 2.8148 ms, put_time: 0.2016 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,601] LMCache INFO:[0m Storing KV cache for 167 out of 679 tokens (skip_leading_tokens=512) for request chatcmpl-38b7303763b143959d35ba1aab9fb63a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,607] LMCache INFO:[0m Stored 167 out of total 679 tokens. size: 0.0045 gb, cost 6.1069 ms, throughput: 0.7302 GB/s; offload_time: 5.8270 ms, put_time: 0.2798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,608] LMCache INFO:[0m Storing KV cache for 1113 out of 1113 tokens (skip_leading_tokens=0) for request chatcmpl-cb7d995f18c14444b55023f7463b33c2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,617] LMCache INFO:[0m Stored 1113 out of total 1113 tokens. size: 0.0297 gb, cost 9.4310 ms, throughput: 3.1513 GB/s; offload_time: 8.6924 ms, put_time: 0.7386 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,625] LMCache INFO:[0m Reqid: chatcmpl-4b5c765ffe204495a4450af74865a4b4, Total tokens 1407, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,627] LMCache INFO:[0m Reqid: chatcmpl-facd9e4ddfda4930ae6125bb1f248977, Total tokens 1114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,658] LMCache INFO:[0m Storing KV cache for 1407 out of 1407 tokens (skip_leading_tokens=0) for request chatcmpl-4b5c765ffe204495a4450af74865a4b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,665] LMCache INFO:[0m Stored 1407 out of total 1407 tokens. size: 0.0376 gb, cost 7.5045 ms, throughput: 5.0064 GB/s; offload_time: 7.1684 ms, put_time: 0.3361 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,666] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-89ac10c46c514beb93d8091e85b96191 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,669] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.7174 ms, throughput: 1.2578 GB/s; offload_time: 2.5524 ms, put_time: 0.1650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,677] LMCache INFO:[0m Reqid: chatcmpl-facd9e4ddfda4930ae6125bb1f248977, Total tokens 1114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,685] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f09dd15a2500429fb571baf76f19c84c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,687] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2038 ms, throughput: 2.8392 GB/s; offload_time: 1.1301 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,687] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-4b5c765ffe204495a4450af74865a4b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,689] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.4748 ms, throughput: 2.3175 GB/s; offload_time: 1.4006 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,693] LMCache INFO:[0m Reqid: chatcmpl-facd9e4ddfda4930ae6125bb1f248977, Total tokens 1114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,703] LMCache INFO:[0m Reqid: chatcmpl-facd9e4ddfda4930ae6125bb1f248977, Total tokens 1114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,710] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,711] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0954 ms, throughput: 3.1202 GB/s; offload_time: 1.0209 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,715] LMCache INFO:[0m Reqid: chatcmpl-facd9e4ddfda4930ae6125bb1f248977, Total tokens 1114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,717] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,743] LMCache INFO:[0m Storing KV cache for 1114 out of 1114 tokens (skip_leading_tokens=0) for request chatcmpl-facd9e4ddfda4930ae6125bb1f248977 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,749] LMCache INFO:[0m Stored 1114 out of total 1114 tokens. size: 0.0297 gb, cost 6.2612 ms, throughput: 4.7510 GB/s; offload_time: 5.7696 ms, put_time: 0.4916 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,750] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8237c292f1564640afc553db8b74e39d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,754] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 3.6508 ms, throughput: 0.9362 GB/s; offload_time: 3.2890 ms, put_time: 0.3618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,761] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,768] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,769] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1258 ms, throughput: 3.0361 GB/s; offload_time: 1.0525 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,773] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,780] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ca6b38396828423691d00590bc3281ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,781] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.0096 ms, throughput: 3.3855 GB/s; offload_time: 0.9431 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,785] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,794] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,803] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,809] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0e4dd1ede1b94e88bc0e331d61c182f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,810] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.9863 ms, throughput: 3.4655 GB/s; offload_time: 0.9243 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,813] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,823] LMCache INFO:[0m Reqid: chatcmpl-b7e96390384c432e9e0d0cbe49caba51, Total tokens 1219, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,823] LMCache INFO:[0m Reqid: chatcmpl-9c8083efa8a94012ae3b4a3df7b0a832, Total tokens 753, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,842] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-44a32f8e47c44173ab89c9fc909e4d99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,843] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4271 ms, throughput: 8.0024 GB/s; offload_time: 0.3644 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,847] LMCache INFO:[0m Reqid: chatcmpl-9c8083efa8a94012ae3b4a3df7b0a832, Total tokens 753, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,856] LMCache INFO:[0m Reqid: chatcmpl-9c8083efa8a94012ae3b4a3df7b0a832, Total tokens 753, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,865] LMCache INFO:[0m Reqid: chatcmpl-9c8083efa8a94012ae3b4a3df7b0a832, Total tokens 753, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,865] LMCache INFO:[0m Reqid: chatcmpl-eb4fa744bdfa43fb8f3cf6a720d7066d, Total tokens 793, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,866] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,896] LMCache INFO:[0m Storing KV cache for 753 out of 753 tokens (skip_leading_tokens=0) for request chatcmpl-9c8083efa8a94012ae3b4a3df7b0a832 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,899] LMCache INFO:[0m Stored 753 out of total 753 tokens. size: 0.0201 gb, cost 2.9604 ms, throughput: 6.7920 GB/s; offload_time: 2.7950 ms, put_time: 0.1654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,899] LMCache INFO:[0m Storing KV cache for 793 out of 793 tokens (skip_leading_tokens=0) for request chatcmpl-eb4fa744bdfa43fb8f3cf6a720d7066d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,907] LMCache INFO:[0m Stored 793 out of total 793 tokens. size: 0.0212 gb, cost 7.2695 ms, throughput: 2.9129 GB/s; offload_time: 6.3088 ms, put_time: 0.9608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,915] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,922] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-fa29bad7bbd04667b64cff1b4300f9e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,923] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.9997 ms, throughput: 3.4191 GB/s; offload_time: 0.9343 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,926] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,933] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,934] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0144 ms, throughput: 3.3695 GB/s; offload_time: 0.9493 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,937] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,946] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:56,955] LMCache INFO:[0m Reqid: chatcmpl-87b30922fb74455ba7ee77637b6dd1e9, Total tokens 982, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,956] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,973] LMCache INFO:[0m Storing KV cache for 214 out of 982 tokens (skip_leading_tokens=768) for request chatcmpl-87b30922fb74455ba7ee77637b6dd1e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,974] LMCache INFO:[0m Stored 214 out of total 982 tokens. size: 0.0057 gb, cost 0.5917 ms, throughput: 9.6582 GB/s; offload_time: 0.4908 ms, put_time: 0.1008 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,974] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-45f07ae31ae7484287ab31fca2554071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,976] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3615 ms, throughput: 2.5104 GB/s; offload_time: 1.3024 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,976] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3ea97cfaa05840d69b64813e90eca619 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,977] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2674 ms, throughput: 2.6968 GB/s; offload_time: 1.1894 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:56,982] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:56,991] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,000] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,007] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d52f389ba8b14e328442cbd877ac1d38 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,008] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9487 ms, throughput: 3.6029 GB/s; offload_time: 0.8829 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,012] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,021] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,031] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,037] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6601e0cb1fa54b4abe95b609242bfa80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,038] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.9937 ms, throughput: 3.4395 GB/s; offload_time: 0.9219 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,042] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1885, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,043] LMCache INFO:[0m Reqid: chatcmpl-a72ef362dffc40bd9397793851ea5ff5, Total tokens 744, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,070] LMCache INFO:[0m Storing KV cache for 861 out of 1885 tokens (skip_leading_tokens=1024) for request chatcmpl-be5dda2454654ea6baf15516337a12e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,074] LMCache INFO:[0m Stored 861 out of total 1885 tokens. size: 0.0230 gb, cost 3.8952 ms, throughput: 5.9025 GB/s; offload_time: 3.6930 ms, put_time: 0.2022 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,080] LMCache INFO:[0m Reqid: chatcmpl-a72ef362dffc40bd9397793851ea5ff5, Total tokens 744, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,091] LMCache INFO:[0m Reqid: chatcmpl-a72ef362dffc40bd9397793851ea5ff5, Total tokens 744, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,098] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,099] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0175 ms, throughput: 3.3592 GB/s; offload_time: 0.9529 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,100] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-9e2e18cc23504ea8ba13bc6318a88728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,101] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3580 ms, throughput: 2.5170 GB/s; offload_time: 1.2972 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,115] LMCache INFO:[0m Reqid: chatcmpl-be5dda2454654ea6baf15516337a12e4, Total tokens 1888, LMCache hit tokens: 1885, need to load: 141 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,116] LMCache INFO:[0m Reqid: chatcmpl-a72ef362dffc40bd9397793851ea5ff5, Total tokens 744, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,117] LMCache INFO:[0m Reqid: chatcmpl-8ee5d4ca17414524abe67bf485068441, Total tokens 1436, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,137] LMCache INFO:[0m Storing KV cache for 744 out of 744 tokens (skip_leading_tokens=0) for request chatcmpl-a72ef362dffc40bd9397793851ea5ff5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,141] LMCache INFO:[0m Stored 744 out of total 744 tokens. size: 0.0199 gb, cost 3.6781 ms, throughput: 5.4014 GB/s; offload_time: 3.2730 ms, put_time: 0.4051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,146] LMCache INFO:[0m Reqid: chatcmpl-8ee5d4ca17414524abe67bf485068441, Total tokens 1436, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,157] LMCache INFO:[0m Reqid: chatcmpl-8ee5d4ca17414524abe67bf485068441, Total tokens 1436, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,166] LMCache INFO:[0m Reqid: chatcmpl-8ee5d4ca17414524abe67bf485068441, Total tokens 1436, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,175] LMCache INFO:[0m Reqid: chatcmpl-8ee5d4ca17414524abe67bf485068441, Total tokens 1436, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,176] LMCache INFO:[0m Reqid: chatcmpl-01a6ba503e0e473099b56f28b67ac44f, Total tokens 292, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,176] LMCache INFO:[0m Reqid: chatcmpl-5507698dea584e2a9496cfd597d3e06b, Total tokens 150, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,177] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,197] LMCache INFO:[0m Storing KV cache for 156 out of 1436 tokens (skip_leading_tokens=1280) for request chatcmpl-8ee5d4ca17414524abe67bf485068441 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,197] LMCache INFO:[0m Stored 156 out of total 1436 tokens. size: 0.0042 gb, cost 0.6104 ms, throughput: 6.8240 GB/s; offload_time: 0.5158 ms, put_time: 0.0946 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,198] LMCache INFO:[0m Storing KV cache for 164 out of 292 tokens (skip_leading_tokens=128) for request chatcmpl-01a6ba503e0e473099b56f28b67ac44f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,201] LMCache INFO:[0m Stored 164 out of total 292 tokens. size: 0.0044 gb, cost 2.6632 ms, throughput: 1.6444 GB/s; offload_time: 2.4977 ms, put_time: 0.1655 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,201] LMCache INFO:[0m Storing KV cache for 150 out of 150 tokens (skip_leading_tokens=0) for request chatcmpl-5507698dea584e2a9496cfd597d3e06b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,203] LMCache INFO:[0m Stored 150 out of total 150 tokens. size: 0.0040 gb, cost 1.9236 ms, throughput: 2.0822 GB/s; offload_time: 1.8347 ms, put_time: 0.0890 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,214] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,221] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-e3f3139484c74312b7761ea1a837e066 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,223] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2680 ms, throughput: 2.6955 GB/s; offload_time: 1.2024 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,227] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,234] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-33878c764ab2403886e819580b9be330 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,236] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.9921 ms, throughput: 3.4453 GB/s; offload_time: 0.9213 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,239] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,249] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,255] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e31f7b903b8347d7a470dacb3b6c0eaa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,256] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9361 ms, throughput: 3.6512 GB/s; offload_time: 0.8694 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,260] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,267] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2c3261a0109146d98e2426332d67a5b9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,268] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9593 ms, throughput: 3.5628 GB/s; offload_time: 0.8942 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,272] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,281] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,290] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,299] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,306] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,307] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9545 ms, throughput: 3.5810 GB/s; offload_time: 0.8885 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,311] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,318] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-46b060b3472e4193a3d8f37c83c7b051 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,319] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9866 ms, throughput: 3.4643 GB/s; offload_time: 0.9160 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,322] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,332] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,341] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1715, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,343] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,359] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-974e39d17edb4f498043afcd0784ab7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,359] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3587 ms, throughput: 9.5282 GB/s; offload_time: 0.2948 ms, put_time: 0.0640 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,365] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,374] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,391] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-5453f9e9492c4981a752689017e41ff4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,392] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2417 ms, throughput: 2.7527 GB/s; offload_time: 1.1639 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,396] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1718, LMCache hit tokens: 1664, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,407] LMCache INFO:[0m Reqid: chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60, Total tokens 1718, LMCache hit tokens: 1664, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,408] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,419] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-abbdfe5c7638410c9677719ce7979f4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,420] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2034 ms, throughput: 2.8403 GB/s; offload_time: 1.1244 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,425] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,435] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,441] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a72ef362dffc40bd9397793851ea5ff5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,443] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2089 ms, throughput: 2.8272 GB/s; offload_time: 1.1320 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,447] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,456] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,466] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,473] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-7eac64dced654cb7879ed31cc70882bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,474] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1946 ms, throughput: 2.8611 GB/s; offload_time: 1.1135 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,478] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,486] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-b71185f8dd2d493498dc8c1321021c52 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,487] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.2621 ms, throughput: 2.7081 GB/s; offload_time: 1.1873 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,491] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,499] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ea9e06d9a3ae4cf483db224b2e270c2d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,500] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1053 ms, throughput: 3.0923 GB/s; offload_time: 1.0281 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,504] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,511] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-5e76d035f1804af985f87422d602855e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,513] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.2576 ms, throughput: 2.7179 GB/s; offload_time: 1.1760 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,517] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,524] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-87b30922fb74455ba7ee77637b6dd1e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,525] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1524 ms, throughput: 2.9660 GB/s; offload_time: 1.0756 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,529] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,537] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-da1332fe30304f4cb89c84732225da4d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,538] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1474 ms, throughput: 2.9788 GB/s; offload_time: 1.0701 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,539] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-be5dda2454654ea6baf15516337a12e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,540] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4317 ms, throughput: 2.3873 GB/s; offload_time: 1.3628 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,544] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,554] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,563] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,573] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,582] LMCache INFO:[0m Reqid: chatcmpl-6f0e5426eb134086a204350cbb6b609a, Total tokens 1733, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,584] LMCache INFO:[0m Reqid: chatcmpl-2addbe7be40044b0989509dff97eaf98, Total tokens 1128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,618] LMCache INFO:[0m Storing KV cache for 1733 out of 1733 tokens (skip_leading_tokens=0) for request chatcmpl-6f0e5426eb134086a204350cbb6b609a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,630] LMCache INFO:[0m Stored 1733 out of total 1733 tokens. size: 0.0463 gb, cost 12.4269 ms, throughput: 3.7239 GB/s; offload_time: 9.0754 ms, put_time: 3.3516 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,631] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-635dc91559d34c8abfe83967691d416c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,633] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.5542 ms, throughput: 1.3382 GB/s; offload_time: 2.4693 ms, put_time: 0.0849 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,642] LMCache INFO:[0m Reqid: chatcmpl-2addbe7be40044b0989509dff97eaf98, Total tokens 1128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,652] LMCache INFO:[0m Reqid: chatcmpl-2addbe7be40044b0989509dff97eaf98, Total tokens 1128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,653] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2008, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,654] LMCache INFO:[0m Reqid: chatcmpl-e27a8116bf8347dbb4555a40d8d51ef2, Total tokens 785, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,710] LMCache INFO:[0m Storing KV cache for 1128 out of 1128 tokens (skip_leading_tokens=0) for request chatcmpl-2addbe7be40044b0989509dff97eaf98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,716] LMCache INFO:[0m Stored 1128 out of total 1128 tokens. size: 0.0301 gb, cost 6.1605 ms, throughput: 4.8893 GB/s; offload_time: 5.8750 ms, put_time: 0.2856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,717] LMCache INFO:[0m Storing KV cache for 2008 out of 2008 tokens (skip_leading_tokens=0) for request chatcmpl-9a43f9e659c94a91854f0ef95b51cad3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,739] LMCache INFO:[0m Stored 2008 out of total 2008 tokens. size: 0.0536 gb, cost 21.4407 ms, throughput: 2.5008 GB/s; offload_time: 16.5524 ms, put_time: 4.8883 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,740] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,747] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 5.1782 ms, throughput: 0.6601 GB/s; offload_time: 4.9379 ms, put_time: 0.2403 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,751] LMCache INFO:[0m Reqid: chatcmpl-e27a8116bf8347dbb4555a40d8d51ef2, Total tokens 785, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,761] LMCache INFO:[0m Reqid: chatcmpl-e27a8116bf8347dbb4555a40d8d51ef2, Total tokens 785, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,777] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b7e96390384c432e9e0d0cbe49caba51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,778] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2352 ms, throughput: 2.7671 GB/s; offload_time: 1.1595 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,782] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,792] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,799] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-60ad3b2e9cfc48fb9b02a577ddc90892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,801] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1377 ms, throughput: 3.0042 GB/s; offload_time: 1.0618 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,801] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f48dfb37b7274044bffe7b533a36921b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,802] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4034 ms, throughput: 2.4355 GB/s; offload_time: 1.2829 ms, put_time: 0.1205 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,803] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-acd21cdfcef04cb8a172ff32c358b38a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,804] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3569 ms, throughput: 2.5190 GB/s; offload_time: 1.1819 ms, put_time: 0.1750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,809] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 184 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,819] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 264 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,829] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,836] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8d86fcdcf29d4ff8915a50613c7f3116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,837] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1389 ms, throughput: 3.0012 GB/s; offload_time: 1.0658 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,837] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a29531ad2ddb4ec5879e12186e9bd39b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,839] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1211 ms, throughput: 3.0488 GB/s; offload_time: 1.0523 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,844] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 440 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,854] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 568 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,863] LMCache INFO:[0m Reqid: chatcmpl-9a43f9e659c94a91854f0ef95b51cad3, Total tokens 2011, LMCache hit tokens: 2008, need to load: 600 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,864] LMCache INFO:[0m Reqid: chatcmpl-e27a8116bf8347dbb4555a40d8d51ef2, Total tokens 785, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,865] LMCache INFO:[0m Reqid: chatcmpl-3be445a3f58749528495ec030ed797ef, Total tokens 1357, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,888] LMCache INFO:[0m Storing KV cache for 785 out of 785 tokens (skip_leading_tokens=0) for request chatcmpl-e27a8116bf8347dbb4555a40d8d51ef2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,893] LMCache INFO:[0m Stored 785 out of total 785 tokens. size: 0.0210 gb, cost 4.8387 ms, throughput: 4.3321 GB/s; offload_time: 4.4563 ms, put_time: 0.3824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,893] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,897] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.8901 ms, throughput: 1.1827 GB/s; offload_time: 2.8237 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,903] LMCache INFO:[0m Reqid: chatcmpl-3be445a3f58749528495ec030ed797ef, Total tokens 1357, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,913] LMCache INFO:[0m Reqid: chatcmpl-3be445a3f58749528495ec030ed797ef, Total tokens 1357, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,914] LMCache INFO:[0m Reqid: chatcmpl-33cb5c0d2aab44f9bf5bf8ee259bbd55, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,940] LMCache INFO:[0m Storing KV cache for 461 out of 1357 tokens (skip_leading_tokens=896) for request chatcmpl-3be445a3f58749528495ec030ed797ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,942] LMCache INFO:[0m Stored 461 out of total 1357 tokens. size: 0.0123 gb, cost 1.9523 ms, throughput: 6.3055 GB/s; offload_time: 1.5893 ms, put_time: 0.3630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,943] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-562c9a96535840d4854aefe92416c61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,947] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 3.2677 ms, throughput: 1.0460 GB/s; offload_time: 3.0647 ms, put_time: 0.2030 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,947] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8dcbb3bb18544b3eb4efba7534636222 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,949] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8278 ms, throughput: 1.8700 GB/s; offload_time: 1.6222 ms, put_time: 0.2056 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:57,954] LMCache INFO:[0m Reqid: chatcmpl-33cb5c0d2aab44f9bf5bf8ee259bbd55, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,956] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1457, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:57,988] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1457, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:57,989] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,013] LMCache INFO:[0m Storing KV cache for 817 out of 1457 tokens (skip_leading_tokens=640) for request chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,015] LMCache INFO:[0m Stored 817 out of total 1457 tokens. size: 0.0218 gb, cost 1.5682 ms, throughput: 13.9114 GB/s; offload_time: 1.3517 ms, put_time: 0.2165 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,024] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,033] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,049] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-44d7db6362c74f4ea3debb6933118465 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,050] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4895 ms, throughput: 6.9822 GB/s; offload_time: 0.4166 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,054] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 113 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,061] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f561f579230b4daaaad850e5e7abb3b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,062] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5265 ms, throughput: 6.4923 GB/s; offload_time: 0.4549 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,062] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-38b7303763b143959d35ba1aab9fb63a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,063] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2418 ms, throughput: 2.7525 GB/s; offload_time: 1.1759 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,068] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 161 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,075] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c227c494ebfa43c0a4dbc7ec99786a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,077] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2012 ms, throughput: 2.8454 GB/s; offload_time: 1.1269 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,081] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 209 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,090] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 289 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,100] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 353 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,109] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 449 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,119] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 497 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,126] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,127] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2535 ms, throughput: 2.7266 GB/s; offload_time: 1.1818 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,131] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 641 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,138] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c9d8468fdbd34c51aff88edefa28c886 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,140] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1425 ms, throughput: 2.9917 GB/s; offload_time: 1.0710 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,143] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 689 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,153] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 753 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,163] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 753 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,170] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,171] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1651 ms, throughput: 2.9335 GB/s; offload_time: 1.0908 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,175] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 817 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,185] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 881 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,192] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0697b242db254501a3bf111e43922ae8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,193] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1633 ms, throughput: 2.9382 GB/s; offload_time: 1.0856 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,197] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 945 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,207] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1025 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,214] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-517ad14976524a108bef1fd686a40071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,215] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2343 ms, throughput: 2.7691 GB/s; offload_time: 1.1584 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,220] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1121 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,227] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-06a36efde0ef4ec186f662b84a485cc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,228] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2296 ms, throughput: 2.7796 GB/s; offload_time: 1.1541 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,232] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1185 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,242] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1233 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,251] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1281 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,261] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1361 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,267] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-28f55046a57f42c88d42f285aea2c33b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,269] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1775 ms, throughput: 2.9028 GB/s; offload_time: 1.1024 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,273] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1460, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,274] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,287] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,293] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-1ccc811f6733427495d527bf240057a0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,295] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2196 ms, throughput: 2.8025 GB/s; offload_time: 1.1432 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,298] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,305] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-464e79ebf16e4b3e9844c467ff6dca9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,307] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2496 ms, throughput: 2.7353 GB/s; offload_time: 1.1666 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,307] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c006b308542242ac99bbfb52fd7fe51e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,309] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4280 ms, throughput: 2.3936 GB/s; offload_time: 1.3585 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,322] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 129 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,329] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-597def71c0994eebafdcf99bc2516f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,330] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2185 ms, throughput: 2.8050 GB/s; offload_time: 1.1384 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,334] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 193 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,344] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 193 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,353] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 257 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,362] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 321 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,371] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 385 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,378] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-add556b5fc584b77aa886147d22e3f07 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,379] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2744 ms, throughput: 2.6821 GB/s; offload_time: 1.1972 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,380] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-9a43f9e659c94a91854f0ef95b51cad3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,381] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5810 ms, throughput: 2.1619 GB/s; offload_time: 1.5015 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,386] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 465 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,393] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,395] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2091 ms, throughput: 2.8268 GB/s; offload_time: 1.1277 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,399] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 545 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,406] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-9fde83d53acd4a7da229acd7f5102751 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,407] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2270 ms, throughput: 2.7857 GB/s; offload_time: 1.1436 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,412] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 609 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,421] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 657 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,430] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 705 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:51988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,437] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-04b4f4b275d840a0a33df6c78879c122 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,439] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2737 ms, throughput: 2.6835 GB/s; offload_time: 1.1993 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,443] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 785 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,453] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 849 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,460] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-bdb93e150aed445b92bc14bc6c9514a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,461] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2356 ms, throughput: 2.7663 GB/s; offload_time: 1.1585 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,465] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 913 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,475] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 961 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,482] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1ad7856396ef4c9cbe70418014ff30d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,483] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1707 ms, throughput: 2.9195 GB/s; offload_time: 1.0885 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,484] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,485] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2712 ms, throughput: 2.6887 GB/s; offload_time: 1.1887 ms, put_time: 0.0826 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,491] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1089 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,500] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1137 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,506] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-89ac10c46c514beb93d8091e85b96191 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,507] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1448 ms, throughput: 2.9858 GB/s; offload_time: 1.0639 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,511] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1201 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,521] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1201 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,530] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1265 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,536] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,537] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1572 ms, throughput: 2.9536 GB/s; offload_time: 1.0804 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,541] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1329 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,549] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8237c292f1564640afc553db8b74e39d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,550] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1559 ms, throughput: 2.9571 GB/s; offload_time: 1.0788 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,554] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1393 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,561] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-efb168ae3afd47cc8ec3b928c6409bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,562] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1737 ms, throughput: 2.9121 GB/s; offload_time: 1.0920 ms, put_time: 0.0817 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,563] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-3be445a3f58749528495ec030ed797ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,564] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3637 ms, throughput: 2.5064 GB/s; offload_time: 1.2959 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,568] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,575] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-8ee5d4ca17414524abe67bf485068441 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,577] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2105 ms, throughput: 2.8237 GB/s; offload_time: 1.1317 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,581] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,590] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,599] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,605] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0e4dd1ede1b94e88bc0e331d61c182f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,606] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2010 ms, throughput: 2.8459 GB/s; offload_time: 1.1226 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,610] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,620] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,626] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-44a32f8e47c44173ab89c9fc909e4d99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,628] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2316 ms, throughput: 2.7753 GB/s; offload_time: 1.1567 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,632] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,641] LMCache INFO:[0m Reqid: chatcmpl-8a8e62fcc9f74ba696cdf486d5d4396c, Total tokens 1463, LMCache hit tokens: 1457, need to load: 1409 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,642] LMCache INFO:[0m Reqid: chatcmpl-3d73690ff5154c75a9a8aec99da8713f, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,643] LMCache INFO:[0m Reqid: chatcmpl-6d9370e9905b4cef9dee76381d76b5b5, Total tokens 392, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,643] LMCache INFO:[0m Reqid: chatcmpl-4755115eb4a64739b253ad9d50764be2, Total tokens 560, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,667] LMCache INFO:[0m Storing KV cache for 392 out of 392 tokens (skip_leading_tokens=0) for request chatcmpl-6d9370e9905b4cef9dee76381d76b5b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,669] LMCache INFO:[0m Stored 392 out of total 392 tokens. size: 0.0105 gb, cost 1.7279 ms, throughput: 6.0579 GB/s; offload_time: 1.5591 ms, put_time: 0.1688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,676] LMCache INFO:[0m Reqid: chatcmpl-4755115eb4a64739b253ad9d50764be2, Total tokens 560, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,683] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-33cb5c0d2aab44f9bf5bf8ee259bbd55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,684] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2331 ms, throughput: 2.7718 GB/s; offload_time: 1.1584 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,688] LMCache INFO:[0m Reqid: chatcmpl-4755115eb4a64739b253ad9d50764be2, Total tokens 560, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,689] LMCache INFO:[0m Reqid: chatcmpl-b18fa09bfa314997b410c483913f261e, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,709] LMCache INFO:[0m Storing KV cache for 560 out of 560 tokens (skip_leading_tokens=0) for request chatcmpl-4755115eb4a64739b253ad9d50764be2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,713] LMCache INFO:[0m Stored 560 out of total 560 tokens. size: 0.0150 gb, cost 4.2785 ms, throughput: 3.4950 GB/s; offload_time: 3.3049 ms, put_time: 0.9736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,721] LMCache INFO:[0m Reqid: chatcmpl-b18fa09bfa314997b410c483913f261e, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,722] LMCache INFO:[0m Reqid: chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe, Total tokens 505, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,745] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f6a4b64c6c1443c1aa22260c9061fb4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,745] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5228 ms, throughput: 6.5382 GB/s; offload_time: 0.4483 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,758] LMCache INFO:[0m Reqid: chatcmpl-b18fa09bfa314997b410c483913f261e, Total tokens 1251, LMCache hit tokens: 1152, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52032 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,768] LMCache INFO:[0m Reqid: chatcmpl-b18fa09bfa314997b410c483913f261e, Total tokens 1251, LMCache hit tokens: 1152, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,774] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-45f07ae31ae7484287ab31fca2554071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,775] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5185 ms, throughput: 6.5917 GB/s; offload_time: 0.4431 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,779] LMCache INFO:[0m Reqid: chatcmpl-b18fa09bfa314997b410c483913f261e, Total tokens 1251, LMCache hit tokens: 1152, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,780] LMCache INFO:[0m Reqid: chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe, Total tokens 505, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,781] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,802] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,811] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,817] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3d73690ff5154c75a9a8aec99da8713f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,818] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4775 ms, throughput: 7.1586 GB/s; offload_time: 0.4034 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,822] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,831] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,840] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,847] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-6601e0cb1fa54b4abe95b609242bfa80 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,847] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5484 ms, throughput: 6.2326 GB/s; offload_time: 0.4727 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,852] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,861] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,867] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,868] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4750 ms, throughput: 7.1964 GB/s; offload_time: 0.4013 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,872] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,879] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f4393462fed0493490a1f3488e126190 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,881] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2347 ms, throughput: 2.7682 GB/s; offload_time: 1.1586 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,881] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-9e2e18cc23504ea8ba13bc6318a88728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,882] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.3150 ms, throughput: 2.5991 GB/s; offload_time: 1.2479 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,888] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,897] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,915] LMCache INFO:[0m Reqid: chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe, Total tokens 516, LMCache hit tokens: 384, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,924] LMCache INFO:[0m Reqid: chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe, Total tokens 516, LMCache hit tokens: 384, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,932] LMCache INFO:[0m Reqid: chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe, Total tokens 516, LMCache hit tokens: 384, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,934] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:58,949] LMCache INFO:[0m Reqid: chatcmpl-dee5a8f21af7478c9e67518e33f67ad0, Total tokens 1437, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,951] LMCache INFO:[0m Reqid: chatcmpl-dad030cdb93646fd867d4bc19b51a205, Total tokens 1528, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,972] LMCache INFO:[0m Storing KV cache for 157 out of 1437 tokens (skip_leading_tokens=1280) for request chatcmpl-dee5a8f21af7478c9e67518e33f67ad0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,973] LMCache INFO:[0m Stored 157 out of total 1437 tokens. size: 0.0042 gb, cost 0.7268 ms, throughput: 5.7681 GB/s; offload_time: 0.6191 ms, put_time: 0.1077 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,973] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-e3f3139484c74312b7761ea1a837e066 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,975] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.7594 ms, throughput: 1.9427 GB/s; offload_time: 1.6874 ms, put_time: 0.0719 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:58,981] LMCache INFO:[0m Reqid: chatcmpl-dad030cdb93646fd867d4bc19b51a205, Total tokens 1528, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,982] LMCache INFO:[0m Reqid: chatcmpl-1570f713c8924a969f86f2d06a6bce9b, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,982] LMCache INFO:[0m Reqid: chatcmpl-5314929076464685ba8d6de4fe2ce123, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:58,983] LMCache INFO:[0m Reqid: chatcmpl-288cb4434b4e4d1fb85e477a08e73f47, Total tokens 1187, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,004] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-1570f713c8924a969f86f2d06a6bce9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,004] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4007 ms, throughput: 6.1310 GB/s; offload_time: 0.3234 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,004] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-5314929076464685ba8d6de4fe2ce123 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,005] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.4467 ms, throughput: 5.7387 GB/s; offload_time: 0.3770 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,010] LMCache INFO:[0m Reqid: chatcmpl-288cb4434b4e4d1fb85e477a08e73f47, Total tokens 1187, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,011] LMCache INFO:[0m Reqid: chatcmpl-7860033fdd2c40cbb603e1dd3598ce78, Total tokens 125, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,012] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,031] LMCache INFO:[0m Storing KV cache for 291 out of 1187 tokens (skip_leading_tokens=896) for request chatcmpl-288cb4434b4e4d1fb85e477a08e73f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,033] LMCache INFO:[0m Stored 291 out of total 1187 tokens. size: 0.0078 gb, cost 1.0750 ms, throughput: 7.2285 GB/s; offload_time: 0.7633 ms, put_time: 0.3117 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,033] LMCache INFO:[0m Storing KV cache for 125 out of 125 tokens (skip_leading_tokens=0) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,035] LMCache INFO:[0m Stored 125 out of total 125 tokens. size: 0.0033 gb, cost 2.0287 ms, throughput: 1.6453 GB/s; offload_time: 1.0879 ms, put_time: 0.9408 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,040] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,048] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e31f7b903b8347d7a470dacb3b6c0eaa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,049] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4627 ms, throughput: 7.3868 GB/s; offload_time: 0.3889 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,053] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,062] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,068] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,070] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1369 ms, throughput: 3.0063 GB/s; offload_time: 1.0565 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,073] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,082] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,091] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,098] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,099] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1352 ms, throughput: 3.0108 GB/s; offload_time: 1.0574 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,103] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,113] LMCache INFO:[0m Reqid: chatcmpl-a4329ef4197c4e2ab18630786fc7a18a, Total tokens 1360, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,114] LMCache INFO:[0m Reqid: chatcmpl-25b9d7977eec4d67a9a5f1a554453b93, Total tokens 1762, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,116] LMCache INFO:[0m Reqid: chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e, Total tokens 2222, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,140] LMCache INFO:[0m Storing KV cache for 592 out of 1360 tokens (skip_leading_tokens=768) for request chatcmpl-a4329ef4197c4e2ab18630786fc7a18a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,144] LMCache INFO:[0m Stored 592 out of total 1360 tokens. size: 0.0158 gb, cost 3.4402 ms, throughput: 4.5952 GB/s; offload_time: 3.2538 ms, put_time: 0.1864 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,153] LMCache INFO:[0m Reqid: chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e, Total tokens 2222, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,162] LMCache INFO:[0m Reqid: chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e, Total tokens 2222, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,171] LMCache INFO:[0m Reqid: chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e, Total tokens 2222, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,181] LMCache INFO:[0m Reqid: chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e, Total tokens 2222, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,182] LMCache INFO:[0m Reqid: chatcmpl-f7ddda6ef95e4f1c8531254b4357bb69, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,183] LMCache INFO:[0m Reqid: chatcmpl-412a5bf4f3dc44369ac37ea72c4f3c1d, Total tokens 265, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,184] LMCache INFO:[0m Reqid: chatcmpl-3f0722d12d1e48458104edb98002bd1e, Total tokens 1501, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,230] LMCache INFO:[0m Storing KV cache for 174 out of 2222 tokens (skip_leading_tokens=2048) for request chatcmpl-0c6c9e65cd5947a8bd017ce5a3871d3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,231] LMCache INFO:[0m Stored 174 out of total 2222 tokens. size: 0.0046 gb, cost 0.7671 ms, throughput: 6.0571 GB/s; offload_time: 0.6581 ms, put_time: 0.1090 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,231] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-f7ddda6ef95e4f1c8531254b4357bb69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,232] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.9185 ms, throughput: 2.9363 GB/s; offload_time: 0.8381 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,233] LMCache INFO:[0m Storing KV cache for 265 out of 265 tokens (skip_leading_tokens=0) for request chatcmpl-412a5bf4f3dc44369ac37ea72c4f3c1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,235] LMCache INFO:[0m Stored 265 out of total 265 tokens. size: 0.0071 gb, cost 1.3741 ms, throughput: 5.1498 GB/s; offload_time: 1.1515 ms, put_time: 0.2225 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,236] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b18fa09bfa314997b410c483913f261e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,238] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5536 ms, throughput: 2.2000 GB/s; offload_time: 1.4710 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,244] LMCache INFO:[0m Reqid: chatcmpl-3f0722d12d1e48458104edb98002bd1e, Total tokens 1501, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,251] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-5453f9e9492c4981a752689017e41ff4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,252] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5698 ms, throughput: 5.9989 GB/s; offload_time: 0.4944 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,256] LMCache INFO:[0m Reqid: chatcmpl-3f0722d12d1e48458104edb98002bd1e, Total tokens 1501, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52078 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,266] LMCache INFO:[0m Reqid: chatcmpl-3f0722d12d1e48458104edb98002bd1e, Total tokens 1501, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,276] LMCache INFO:[0m Reqid: chatcmpl-3f0722d12d1e48458104edb98002bd1e, Total tokens 1501, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,277] LMCache INFO:[0m Reqid: chatcmpl-40f8c509c1554f5ead2247f898fb99ff, Total tokens 810, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,278] LMCache INFO:[0m Reqid: chatcmpl-4a474137dae3476ba1468f179e9f6f3d, Total tokens 1396, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,312] LMCache INFO:[0m Reqid: chatcmpl-4a474137dae3476ba1468f179e9f6f3d, Total tokens 1396, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,318] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a72ef362dffc40bd9397793851ea5ff5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,319] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5037 ms, throughput: 6.7861 GB/s; offload_time: 0.4230 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,323] LMCache INFO:[0m Reqid: chatcmpl-4a474137dae3476ba1468f179e9f6f3d, Total tokens 1396, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,333] LMCache INFO:[0m Reqid: chatcmpl-4a474137dae3476ba1468f179e9f6f3d, Total tokens 1396, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,342] LMCache INFO:[0m Reqid: chatcmpl-4a474137dae3476ba1468f179e9f6f3d, Total tokens 1396, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,344] LMCache INFO:[0m Reqid: chatcmpl-13a97cbaad6345edb557a3f077ad7e99, Total tokens 373, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,344] LMCache INFO:[0m Reqid: chatcmpl-1530f0fabc084e18baac9f7ffaccc50e, Total tokens 480, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,345] LMCache INFO:[0m Reqid: chatcmpl-fff1145508ee445086bf39d9a90e9920, Total tokens 247, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,373] LMCache INFO:[0m Storing KV cache for 372 out of 1396 tokens (skip_leading_tokens=1024) for request chatcmpl-4a474137dae3476ba1468f179e9f6f3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,374] LMCache INFO:[0m Stored 372 out of total 1396 tokens. size: 0.0099 gb, cost 1.0532 ms, throughput: 9.4317 GB/s; offload_time: 0.7923 ms, put_time: 0.2609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,374] LMCache INFO:[0m Storing KV cache for 480 out of 480 tokens (skip_leading_tokens=0) for request chatcmpl-1530f0fabc084e18baac9f7ffaccc50e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,377] LMCache INFO:[0m Stored 480 out of total 480 tokens. size: 0.0128 gb, cost 2.6437 ms, throughput: 4.8482 GB/s; offload_time: 2.4897 ms, put_time: 0.1540 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,385] LMCache INFO:[0m Reqid: chatcmpl-fff1145508ee445086bf39d9a90e9920, Total tokens 247, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,385] LMCache INFO:[0m Reqid: chatcmpl-b5334654c47e4fadaac02aeceebc28de, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,398] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-b71185f8dd2d493498dc8c1321021c52 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,399] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.6169 ms, throughput: 5.5405 GB/s; offload_time: 0.5435 ms, put_time: 0.0734 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,403] LMCache INFO:[0m Reqid: chatcmpl-b5334654c47e4fadaac02aeceebc28de, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,410] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ea9e06d9a3ae4cf483db224b2e270c2d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,410] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4864 ms, throughput: 7.0276 GB/s; offload_time: 0.4007 ms, put_time: 0.0857 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,421] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-5e76d035f1804af985f87422d602855e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,421] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5910 ms, throughput: 5.7837 GB/s; offload_time: 0.5144 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,425] LMCache INFO:[0m Reqid: chatcmpl-fff1145508ee445086bf39d9a90e9920, Total tokens 249, LMCache hit tokens: 128, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,426] LMCache INFO:[0m Reqid: chatcmpl-b5334654c47e4fadaac02aeceebc28de, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,426] LMCache INFO:[0m Reqid: chatcmpl-275ce2c21fa24d9a899b9a82136a4e9b, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,427] LMCache INFO:[0m Reqid: chatcmpl-fad4f1b6a9be400187c1f0ccb3d701f5, Total tokens 622, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,428] LMCache INFO:[0m Reqid: chatcmpl-1763283e3bb54538afc6003083aea068, Total tokens 450, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,429] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,455] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-b5334654c47e4fadaac02aeceebc28de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,456] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 0.6258 ms, throughput: 6.2723 GB/s; offload_time: 0.5149 ms, put_time: 0.1110 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,456] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-275ce2c21fa24d9a899b9a82136a4e9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,458] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.9203 ms, throughput: 2.7856 GB/s; offload_time: 0.8490 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,458] LMCache INFO:[0m Storing KV cache for 450 out of 450 tokens (skip_leading_tokens=0) for request chatcmpl-1763283e3bb54538afc6003083aea068 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,461] LMCache INFO:[0m Stored 450 out of total 450 tokens. size: 0.0120 gb, cost 2.6905 ms, throughput: 4.4662 GB/s; offload_time: 2.5297 ms, put_time: 0.1608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,462] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-87b30922fb74455ba7ee77637b6dd1e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,464] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.2457 ms, throughput: 1.5220 GB/s; offload_time: 2.1707 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,470] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,477] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-be5dda2454654ea6baf15516337a12e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,478] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.2714 ms, throughput: 2.6884 GB/s; offload_time: 1.1939 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,483] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,493] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,503] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,520] LMCache INFO:[0m Reqid: chatcmpl-1763283e3bb54538afc6003083aea068, Total tokens 455, LMCache hit tokens: 450, need to load: 50 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,527] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-635dc91559d34c8abfe83967691d416c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,528] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1469 ms, throughput: 2.9801 GB/s; offload_time: 1.0727 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,532] LMCache INFO:[0m Reqid: chatcmpl-1763283e3bb54538afc6003083aea068, Total tokens 455, LMCache hit tokens: 450, need to load: 98 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,534] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,545] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5314929076464685ba8d6de4fe2ce123 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,546] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1003 ms, throughput: 3.1065 GB/s; offload_time: 1.0246 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,546] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-13a97cbaad6345edb557a3f077ad7e99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,548] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4071 ms, throughput: 2.4292 GB/s; offload_time: 1.3345 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,548] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fff1145508ee445086bf39d9a90e9920 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,550] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3428 ms, throughput: 2.5454 GB/s; offload_time: 1.2737 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,554] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,562] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,563] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2162 ms, throughput: 2.8103 GB/s; offload_time: 1.1408 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,563] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-4a474137dae3476ba1468f179e9f6f3d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,565] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5289 ms, throughput: 2.2355 GB/s; offload_time: 1.4548 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,569] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,579] LMCache INFO:[0m Reqid: chatcmpl-781ef4583ced4ef6ae85e31f4318265a, Total tokens 1385, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,580] LMCache INFO:[0m Reqid: chatcmpl-8083b1287d8945ff9fba99860e0102dd, Total tokens 502, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,581] LMCache INFO:[0m Reqid: chatcmpl-1f0240bab9e043cd839ed7a44a0a74a9, Total tokens 906, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,581] LMCache INFO:[0m Reqid: chatcmpl-0b34eddc735c4338ac161f1e5f217b23, Total tokens 553, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,624] LMCache INFO:[0m Storing KV cache for 873 out of 1385 tokens (skip_leading_tokens=512) for request chatcmpl-781ef4583ced4ef6ae85e31f4318265a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,629] LMCache INFO:[0m Stored 873 out of total 1385 tokens. size: 0.0233 gb, cost 5.6025 ms, throughput: 4.1609 GB/s; offload_time: 2.0762 ms, put_time: 3.5263 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,630] LMCache INFO:[0m Storing KV cache for 502 out of 502 tokens (skip_leading_tokens=0) for request chatcmpl-8083b1287d8945ff9fba99860e0102dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,635] LMCache INFO:[0m Stored 502 out of total 502 tokens. size: 0.0134 gb, cost 4.3012 ms, throughput: 3.1165 GB/s; offload_time: 4.1306 ms, put_time: 0.1706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,635] LMCache INFO:[0m Storing KV cache for 138 out of 906 tokens (skip_leading_tokens=768) for request chatcmpl-1f0240bab9e043cd839ed7a44a0a74a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,640] LMCache INFO:[0m Stored 138 out of total 906 tokens. size: 0.0037 gb, cost 4.4586 ms, throughput: 0.8265 GB/s; offload_time: 4.3043 ms, put_time: 0.1543 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,646] LMCache INFO:[0m Reqid: chatcmpl-0b34eddc735c4338ac161f1e5f217b23, Total tokens 553, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,655] LMCache INFO:[0m Reqid: chatcmpl-0b34eddc735c4338ac161f1e5f217b23, Total tokens 553, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,671] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-60ad3b2e9cfc48fb9b02a577ddc90892 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,672] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1405 ms, throughput: 2.9968 GB/s; offload_time: 1.0655 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,673] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f48dfb37b7274044bffe7b533a36921b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,674] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2617 ms, throughput: 2.7091 GB/s; offload_time: 1.1954 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,679] LMCache INFO:[0m Reqid: chatcmpl-1f0240bab9e043cd839ed7a44a0a74a9, Total tokens 909, LMCache hit tokens: 906, need to load: 90 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,686] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-25b9d7977eec4d67a9a5f1a554453b93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,687] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2590 ms, throughput: 2.7148 GB/s; offload_time: 1.1821 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,692] LMCache INFO:[0m Reqid: chatcmpl-1f0240bab9e043cd839ed7a44a0a74a9, Total tokens 909, LMCache hit tokens: 906, need to load: 186 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,693] LMCache INFO:[0m Reqid: chatcmpl-0b34eddc735c4338ac161f1e5f217b23, Total tokens 553, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,693] LMCache INFO:[0m Reqid: chatcmpl-19d4ab5d858946ed8ab8a77fe2561f47, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,694] LMCache INFO:[0m Reqid: chatcmpl-83abc45ae8b349e59782b3e4503402db, Total tokens 1326, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,696] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,725] LMCache INFO:[0m Storing KV cache for 169 out of 553 tokens (skip_leading_tokens=384) for request chatcmpl-0b34eddc735c4338ac161f1e5f217b23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,725] LMCache INFO:[0m Stored 169 out of total 553 tokens. size: 0.0045 gb, cost 0.6509 ms, throughput: 6.9326 GB/s; offload_time: 0.5365 ms, put_time: 0.1144 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,726] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-19d4ab5d858946ed8ab8a77fe2561f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,727] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.8909 ms, throughput: 3.1473 GB/s; offload_time: 0.8021 ms, put_time: 0.0887 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,727] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f7ddda6ef95e4f1c8531254b4357bb69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,728] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7824 ms, throughput: 4.3688 GB/s; offload_time: 0.7095 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,734] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,741] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8d86fcdcf29d4ff8915a50613c7f3116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,741] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4959 ms, throughput: 6.8924 GB/s; offload_time: 0.4208 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,746] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,756] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,762] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-fad4f1b6a9be400187c1f0ccb3d701f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,763] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4951 ms, throughput: 6.9041 GB/s; offload_time: 0.4158 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,767] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,774] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,775] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5615 ms, throughput: 6.0869 GB/s; offload_time: 0.4850 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,779] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,786] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8083b1287d8945ff9fba99860e0102dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,787] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1861 ms, throughput: 2.8817 GB/s; offload_time: 1.1096 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,792] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,799] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-562c9a96535840d4854aefe92416c61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,800] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1849 ms, throughput: 2.8847 GB/s; offload_time: 1.1004 ms, put_time: 0.0844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,804] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,814] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,824] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,834] LMCache INFO:[0m Reqid: chatcmpl-e43b48309c2c466695b490fdb3e8da51, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,835] LMCache INFO:[0m Reqid: chatcmpl-1fe64bf0a9804c7d9c4872b2a2130ffe, Total tokens 195, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,836] LMCache INFO:[0m Reqid: chatcmpl-ccdd3a778ba846bab1ca6987a12f4e89, Total tokens 1384, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,837] LMCache INFO:[0m Reqid: chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,887] LMCache INFO:[0m Storing KV cache for 195 out of 195 tokens (skip_leading_tokens=0) for request chatcmpl-1fe64bf0a9804c7d9c4872b2a2130ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:20:59,888] LMCache INFO:[0m Stored 195 out of total 195 tokens. size: 0.0052 gb, cost 0.9179 ms, throughput: 5.6727 GB/s; offload_time: 0.8038 ms, put_time: 0.1141 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,903] LMCache INFO:[0m Reqid: chatcmpl-ccdd3a778ba846bab1ca6987a12f4e89, Total tokens 1385, LMCache hit tokens: 1280, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,904] LMCache INFO:[0m Reqid: chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,905] LMCache INFO:[0m Reqid: chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,906] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,926] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,926] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 0.6102 ms, throughput: 6.4324 GB/s; offload_time: 0.5017 ms, put_time: 0.1085 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,927] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f561f579230b4daaaad850e5e7abb3b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,928] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7006 ms, throughput: 4.8787 GB/s; offload_time: 0.6344 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,928] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-38b7303763b143959d35ba1aab9fb63a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,930] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0484 ms, throughput: 3.2601 GB/s; offload_time: 0.9723 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,930] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-3f0722d12d1e48458104edb98002bd1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,931] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7171 ms, throughput: 4.7666 GB/s; offload_time: 0.6493 ms, put_time: 0.0677 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,936] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,944] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c227c494ebfa43c0a4dbc7ec99786a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,944] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5246 ms, throughput: 6.5151 GB/s; offload_time: 0.4436 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,945] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1530f0fabc084e18baac9f7ffaccc50e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,945] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5764 ms, throughput: 5.9303 GB/s; offload_time: 0.5064 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,950] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,959] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,977] LMCache INFO:[0m Reqid: chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242, Total tokens 1331, LMCache hit tokens: 1280, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,984] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-a4329ef4197c4e2ab18630786fc7a18a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,985] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5486 ms, throughput: 6.2302 GB/s; offload_time: 0.4695 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,985] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-275ce2c21fa24d9a899b9a82136a4e9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,986] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6399 ms, throughput: 5.3418 GB/s; offload_time: 0.5709 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,991] LMCache INFO:[0m Reqid: chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242, Total tokens 1331, LMCache hit tokens: 1280, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,998] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:20:59,999] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5653 ms, throughput: 6.0465 GB/s; offload_time: 0.4874 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:20:59,999] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-781ef4583ced4ef6ae85e31f4318265a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,000] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7967 ms, throughput: 4.2903 GB/s; offload_time: 0.7183 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,005] LMCache INFO:[0m Reqid: chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242, Total tokens 1331, LMCache hit tokens: 1280, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,006] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,018] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c9d8468fdbd34c51aff88edefa28c886 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,019] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5773 ms, throughput: 5.9207 GB/s; offload_time: 0.4958 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,023] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,024] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,039] LMCache INFO:[0m Storing KV cache for 270 out of 270 tokens (skip_leading_tokens=0) for request chatcmpl-3fed1313a3094d009ea3532ec22ee87e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,041] LMCache INFO:[0m Stored 270 out of total 270 tokens. size: 0.0072 gb, cost 2.2351 ms, throughput: 3.2257 GB/s; offload_time: 1.9690 ms, put_time: 0.2661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,053] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,062] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,070] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4506111fd00a45e980fd4338d92b7b63 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,071] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5003 ms, throughput: 2.2782 GB/s; offload_time: 1.4244 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,075] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,086] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,093] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0697b242db254501a3bf111e43922ae8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,094] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2197 ms, throughput: 2.8022 GB/s; offload_time: 1.1436 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,107] LMCache INFO:[0m Reqid: chatcmpl-3fed1313a3094d009ea3532ec22ee87e, Total tokens 275, LMCache hit tokens: 270, need to load: 78 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,108] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,119] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-517ad14976524a108bef1fd686a40071 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,120] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2657 ms, throughput: 2.7004 GB/s; offload_time: 1.1895 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,125] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,135] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,144] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,155] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,164] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,171] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-28f55046a57f42c88d42f285aea2c33b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,173] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2308 ms, throughput: 2.7771 GB/s; offload_time: 1.1555 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,177] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,186] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,196] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,205] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,212] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ccdd3a778ba846bab1ca6987a12f4e89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,213] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2134 ms, throughput: 2.8168 GB/s; offload_time: 1.1327 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,218] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,225] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-597def71c0994eebafdcf99bc2516f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,226] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2140 ms, throughput: 2.8155 GB/s; offload_time: 1.1375 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,230] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,240] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,249] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,258] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,267] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,277] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,283] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1601c3c30f2e4382bf0883eaf4d7a64c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,285] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2388 ms, throughput: 2.7590 GB/s; offload_time: 1.1572 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,289] LMCache INFO:[0m Reqid: chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830, Total tokens 1551, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,291] LMCache INFO:[0m Reqid: chatcmpl-76602b5b34cc431ead3c4cea29ad8dc6, Total tokens 943, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,311] LMCache INFO:[0m Storing KV cache for 143 out of 1551 tokens (skip_leading_tokens=1408) for request chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,312] LMCache INFO:[0m Stored 143 out of total 1551 tokens. size: 0.0038 gb, cost 0.7871 ms, throughput: 4.8513 GB/s; offload_time: 0.6754 ms, put_time: 0.1117 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,313] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-9fde83d53acd4a7da229acd7f5102751 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,314] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.3465 ms, throughput: 2.5385 GB/s; offload_time: 1.2739 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,319] LMCache INFO:[0m Reqid: chatcmpl-76602b5b34cc431ead3c4cea29ad8dc6, Total tokens 943, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,321] LMCache INFO:[0m Reqid: chatcmpl-88a2992bf3e044c684249bd631d7cd9b, Total tokens 1725, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,322] LMCache INFO:[0m Reqid: chatcmpl-44d237387a8c4ace924756b6b6a00b5e, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,323] LMCache INFO:[0m Reqid: chatcmpl-c8b1bd8f9c0c4fb4a5a1367d92054633, Total tokens 1472, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,364] LMCache INFO:[0m Storing KV cache for 175 out of 943 tokens (skip_leading_tokens=768) for request chatcmpl-76602b5b34cc431ead3c4cea29ad8dc6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,365] LMCache INFO:[0m Stored 175 out of total 943 tokens. size: 0.0047 gb, cost 0.7324 ms, throughput: 6.3808 GB/s; offload_time: 0.6214 ms, put_time: 0.1109 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,365] LMCache INFO:[0m Storing KV cache for 957 out of 1725 tokens (skip_leading_tokens=768) for request chatcmpl-88a2992bf3e044c684249bd631d7cd9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,370] LMCache INFO:[0m Stored 957 out of total 1725 tokens. size: 0.0256 gb, cost 4.4375 ms, throughput: 5.7587 GB/s; offload_time: 3.8848 ms, put_time: 0.5527 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,371] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-44d237387a8c4ace924756b6b6a00b5e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,373] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 1.4662 ms, throughput: 1.6755 GB/s; offload_time: 1.3625 ms, put_time: 0.1037 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,382] LMCache INFO:[0m Reqid: chatcmpl-c8b1bd8f9c0c4fb4a5a1367d92054633, Total tokens 1472, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,392] LMCache INFO:[0m Reqid: chatcmpl-c8b1bd8f9c0c4fb4a5a1367d92054633, Total tokens 1472, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,393] LMCache INFO:[0m Reqid: chatcmpl-1934df6070c94aa1a200276c12a36da8, Total tokens 973, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,417] LMCache INFO:[0m Reqid: chatcmpl-1934df6070c94aa1a200276c12a36da8, Total tokens 973, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,426] LMCache INFO:[0m Reqid: chatcmpl-1934df6070c94aa1a200276c12a36da8, Total tokens 973, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,427] LMCache INFO:[0m Reqid: chatcmpl-579ac96a414c462da4daca8dee72773e, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,450] LMCache INFO:[0m Reqid: chatcmpl-579ac96a414c462da4daca8dee72773e, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,456] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1763283e3bb54538afc6003083aea068 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,457] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4536 ms, throughput: 7.5346 GB/s; offload_time: 0.3814 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,461] LMCache INFO:[0m Reqid: chatcmpl-579ac96a414c462da4daca8dee72773e, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,468] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-55383ef2680b42ae9f4aa08be5e2ae60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,469] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5799 ms, throughput: 5.8937 GB/s; offload_time: 0.5048 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,473] LMCache INFO:[0m Reqid: chatcmpl-579ac96a414c462da4daca8dee72773e, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,491] LMCache INFO:[0m Reqid: chatcmpl-1934df6070c94aa1a200276c12a36da8, Total tokens 977, LMCache hit tokens: 896, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,492] LMCache INFO:[0m Reqid: chatcmpl-579ac96a414c462da4daca8dee72773e, Total tokens 456, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,493] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 777, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,493] LMCache INFO:[0m Reqid: chatcmpl-f264153a307d46e3a31d810e15b3246f, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,519] LMCache INFO:[0m Storing KV cache for 137 out of 777 tokens (skip_leading_tokens=640) for request chatcmpl-c700b225736a44458efa75aeb5e63fd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,520] LMCache INFO:[0m Stored 137 out of total 777 tokens. size: 0.0037 gb, cost 0.7044 ms, throughput: 5.1936 GB/s; offload_time: 0.5940 ms, put_time: 0.1104 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,525] LMCache INFO:[0m Reqid: chatcmpl-f264153a307d46e3a31d810e15b3246f, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,532] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-288cb4434b4e4d1fb85e477a08e73f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,533] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5424 ms, throughput: 6.3018 GB/s; offload_time: 0.4614 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,543] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,544] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4908 ms, throughput: 6.9634 GB/s; offload_time: 0.4148 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,548] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 779, LMCache hit tokens: 777, need to load: 105 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,554] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8237c292f1564640afc553db8b74e39d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,555] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4874 ms, throughput: 7.0126 GB/s; offload_time: 0.4138 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,559] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 779, LMCache hit tokens: 777, need to load: 153 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,560] LMCache INFO:[0m Reqid: chatcmpl-f264153a307d46e3a31d810e15b3246f, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,561] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,573] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-f264153a307d46e3a31d810e15b3246f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,574] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.4298 ms, throughput: 6.4615 GB/s; offload_time: 0.3547 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,574] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-3be445a3f58749528495ec030ed797ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,575] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.1963 ms, throughput: 2.8572 GB/s; offload_time: 1.1236 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,580] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,587] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-e43b48309c2c466695b490fdb3e8da51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,589] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2908 ms, throughput: 2.6478 GB/s; offload_time: 1.2084 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,593] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,603] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,612] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,619] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0e4dd1ede1b94e88bc0e331d61c182f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,621] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2199 ms, throughput: 2.8018 GB/s; offload_time: 1.1422 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,633] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 73 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,640] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-44a32f8e47c44173ab89c9fc909e4d99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,641] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2258 ms, throughput: 2.7884 GB/s; offload_time: 1.1484 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,642] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-40f8c509c1554f5ead2247f898fb99ff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,644] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.8147 ms, throughput: 1.8835 GB/s; offload_time: 1.7360 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,648] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 185 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,657] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 249 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,666] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 329 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,673] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-33cb5c0d2aab44f9bf5bf8ee259bbd55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,674] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2226 ms, throughput: 2.7957 GB/s; offload_time: 1.1361 ms, put_time: 0.0864 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,679] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 425 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,688] LMCache INFO:[0m Reqid: chatcmpl-c700b225736a44458efa75aeb5e63fd8, Total tokens 784, LMCache hit tokens: 777, need to load: 473 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,688] LMCache INFO:[0m Reqid: chatcmpl-f264153a307d46e3a31d810e15b3246f, Total tokens 109, LMCache hit tokens: 104, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,690] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,703] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,712] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,722] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,728] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1fe64bf0a9804c7d9c4872b2a2130ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,730] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1773 ms, throughput: 2.9031 GB/s; offload_time: 1.0999 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,734] LMCache INFO:[0m Reqid: chatcmpl-f9a9d934bc4947389154fc6545f5e0d9, Total tokens 1850, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,736] LMCache INFO:[0m Reqid: chatcmpl-625492c99616493cb41e804bc5a74ce4, Total tokens 1372, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,776] LMCache INFO:[0m Reqid: chatcmpl-625492c99616493cb41e804bc5a74ce4, Total tokens 1372, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,785] LMCache INFO:[0m Reqid: chatcmpl-625492c99616493cb41e804bc5a74ce4, Total tokens 1372, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,786] LMCache INFO:[0m Reqid: chatcmpl-026b3d35b4fc46ea8dc667c27b7b0dc1, Total tokens 374, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,787] LMCache INFO:[0m Reqid: chatcmpl-e77b230bd38e4202bcc962f3900f4672, Total tokens 751, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,788] LMCache INFO:[0m Reqid: chatcmpl-c632f9c3405144a69a39c34e4839f9c1, Total tokens 632, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,821] LMCache INFO:[0m Storing KV cache for 374 out of 374 tokens (skip_leading_tokens=0) for request chatcmpl-026b3d35b4fc46ea8dc667c27b7b0dc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,822] LMCache INFO:[0m Stored 374 out of total 374 tokens. size: 0.0100 gb, cost 0.8953 ms, throughput: 11.1553 GB/s; offload_time: 0.7582 ms, put_time: 0.1370 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,823] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-3d73690ff5154c75a9a8aec99da8713f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,824] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7131 ms, throughput: 1.9952 GB/s; offload_time: 1.6483 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,828] LMCache INFO:[0m Reqid: chatcmpl-c632f9c3405144a69a39c34e4839f9c1, Total tokens 632, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,830] LMCache INFO:[0m Reqid: chatcmpl-5d341d7135c14a6d994aaa0f29ad58ee, Total tokens 299, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,831] LMCache INFO:[0m Reqid: chatcmpl-f5d302be5704490bb22fbd3ee15f2b91, Total tokens 524, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,832] LMCache INFO:[0m Reqid: chatcmpl-581208a665894023b6fc52762f40e2ca, Total tokens 331, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,833] LMCache INFO:[0m Reqid: chatcmpl-ede0feb939204ad9ac28337175f96c75, Total tokens 643, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,834] LMCache INFO:[0m Reqid: chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745, Total tokens 1586, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52170 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,871] LMCache INFO:[0m Storing KV cache for 140 out of 524 tokens (skip_leading_tokens=384) for request chatcmpl-f5d302be5704490bb22fbd3ee15f2b91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,872] LMCache INFO:[0m Stored 140 out of total 524 tokens. size: 0.0037 gb, cost 0.7168 ms, throughput: 5.2157 GB/s; offload_time: 0.6081 ms, put_time: 0.1087 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,872] LMCache INFO:[0m Storing KV cache for 331 out of 331 tokens (skip_leading_tokens=0) for request chatcmpl-581208a665894023b6fc52762f40e2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,876] LMCache INFO:[0m Stored 331 out of total 331 tokens. size: 0.0088 gb, cost 1.3943 ms, throughput: 6.3392 GB/s; offload_time: 1.2601 ms, put_time: 0.1342 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,877] LMCache INFO:[0m Storing KV cache for 259 out of 643 tokens (skip_leading_tokens=384) for request chatcmpl-ede0feb939204ad9ac28337175f96c75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,878] LMCache INFO:[0m Stored 259 out of total 643 tokens. size: 0.0069 gb, cost 1.4977 ms, throughput: 4.6178 GB/s; offload_time: 1.3733 ms, put_time: 0.1244 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,886] LMCache INFO:[0m Reqid: chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745, Total tokens 1586, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,887] LMCache INFO:[0m Reqid: chatcmpl-5bb3eea6e86d44e995efdc33c849997a, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,888] LMCache INFO:[0m Reqid: chatcmpl-0ab59ca3e51d457aacf8725031932734, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,888] LMCache INFO:[0m Reqid: chatcmpl-2904e2ab38e747bf8285c9c312ed4d98, Total tokens 944, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,889] LMCache INFO:[0m Reqid: chatcmpl-421c198ea03a4e3389bdfb7222c7bb98, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,890] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,932] LMCache INFO:[0m Storing KV cache for 135 out of 135 tokens (skip_leading_tokens=0) for request chatcmpl-5bb3eea6e86d44e995efdc33c849997a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,932] LMCache INFO:[0m Stored 135 out of total 135 tokens. size: 0.0036 gb, cost 0.6790 ms, throughput: 5.3092 GB/s; offload_time: 0.5668 ms, put_time: 0.1122 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,933] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-0ab59ca3e51d457aacf8725031932734 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,934] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.9631 ms, throughput: 2.7171 GB/s; offload_time: 0.7556 ms, put_time: 0.2075 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,934] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-421c198ea03a4e3389bdfb7222c7bb98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,935] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.8473 ms, throughput: 3.3720 GB/s; offload_time: 0.7604 ms, put_time: 0.0869 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:00,941] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,951] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,960] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,969] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,978] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,987] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,994] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4233de9bc8c5438c8d358f7ee9671ebe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,995] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4068 ms, throughput: 8.4019 GB/s; offload_time: 0.3444 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:00,995] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-83abc45ae8b349e59782b3e4503402db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:00,996] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7477 ms, throughput: 4.5714 GB/s; offload_time: 0.6912 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,000] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,007] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c632f9c3405144a69a39c34e4839f9c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,007] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.3958 ms, throughput: 8.6349 GB/s; offload_time: 0.3349 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,011] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,017] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-026b3d35b4fc46ea8dc667c27b7b0dc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,018] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3871 ms, throughput: 8.8289 GB/s; offload_time: 0.3251 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,021] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,031] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,040] LMCache INFO:[0m Reqid: chatcmpl-ee709e88deb843fda15d9599b8567847, Total tokens 1734, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,041] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,073] LMCache INFO:[0m Storing KV cache for 198 out of 1734 tokens (skip_leading_tokens=1536) for request chatcmpl-ee709e88deb843fda15d9599b8567847 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,073] LMCache INFO:[0m Stored 198 out of total 1734 tokens. size: 0.0053 gb, cost 0.6130 ms, throughput: 8.6250 GB/s; offload_time: 0.5210 ms, put_time: 0.0920 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,074] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0b34eddc735c4338ac161f1e5f217b23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,075] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0777 ms, throughput: 3.1715 GB/s; offload_time: 1.0081 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,080] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,089] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,097] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,104] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e31f7b903b8347d7a470dacb3b6c0eaa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,104] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3974 ms, throughput: 8.6015 GB/s; offload_time: 0.3355 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,107] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,114] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e77b230bd38e4202bcc962f3900f4672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,114] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4164 ms, throughput: 8.2074 GB/s; offload_time: 0.3534 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,118] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,124] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,125] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3852 ms, throughput: 8.8743 GB/s; offload_time: 0.3169 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,128] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,137] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,143] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b5334654c47e4fadaac02aeceebc28de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,143] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3776 ms, throughput: 9.0510 GB/s; offload_time: 0.3177 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,147] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,153] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c2e9b8d4191f4254b9247df557c6a6a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,154] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3947 ms, throughput: 8.6602 GB/s; offload_time: 0.3311 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,158] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,164] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,165] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4543 ms, throughput: 7.5228 GB/s; offload_time: 0.3924 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,168] LMCache INFO:[0m Reqid: chatcmpl-e469177a37fb447182394db81f68d17a, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,170] LMCache INFO:[0m Reqid: chatcmpl-97e286b9df0b494794502abad4cf67de, Total tokens 188, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,170] LMCache INFO:[0m Reqid: chatcmpl-2c2dbc46268645b38be6b6917ada14d8, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,171] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,201] LMCache INFO:[0m Storing KV cache for 188 out of 188 tokens (skip_leading_tokens=0) for request chatcmpl-97e286b9df0b494794502abad4cf67de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,201] LMCache INFO:[0m Stored 188 out of total 188 tokens. size: 0.0050 gb, cost 0.5149 ms, throughput: 9.7501 GB/s; offload_time: 0.4241 ms, put_time: 0.0908 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,202] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-2c2dbc46268645b38be6b6917ada14d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,202] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.7305 ms, throughput: 3.5823 GB/s; offload_time: 0.6600 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,203] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-421c198ea03a4e3389bdfb7222c7bb98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,204] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4949 ms, throughput: 6.9069 GB/s; offload_time: 0.4392 ms, put_time: 0.0557 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,208] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,217] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,226] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,233] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1934df6070c94aa1a200276c12a36da8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,233] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4249 ms, throughput: 8.0439 GB/s; offload_time: 0.3660 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,237] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,244] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-b18fa09bfa314997b410c483913f261e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,244] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4574 ms, throughput: 7.4728 GB/s; offload_time: 0.3961 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,248] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,257] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,266] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,275] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,284] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,293] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,301] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,310] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,316] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-579ac96a414c462da4daca8dee72773e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,317] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3943 ms, throughput: 8.6695 GB/s; offload_time: 0.3353 ms, put_time: 0.0589 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,320] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,327] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c8b1bd8f9c0c4fb4a5a1367d92054633 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,328] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4667 ms, throughput: 7.3231 GB/s; offload_time: 0.4035 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,328] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-625492c99616493cb41e804bc5a74ce4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,329] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6139 ms, throughput: 5.5681 GB/s; offload_time: 0.5545 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,333] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,339] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-88a2992bf3e044c684249bd631d7cd9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,340] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4784 ms, throughput: 7.1451 GB/s; offload_time: 0.4134 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,343] LMCache INFO:[0m Reqid: chatcmpl-5d858f26f8fb4239a752d5b8ac647934, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,345] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,378] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-5e76d035f1804af985f87422d602855e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,378] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.4856 ms, throughput: 7.0384 GB/s; offload_time: 0.4220 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,382] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,388] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-87b30922fb74455ba7ee77637b6dd1e9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,389] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4425 ms, throughput: 7.7235 GB/s; offload_time: 0.3792 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,392] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,401] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,409] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,418] LMCache INFO:[0m Reqid: chatcmpl-f15adb2d2dcb40debf664880e9edba23, Total tokens 1138, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,419] LMCache INFO:[0m Reqid: chatcmpl-9d8b5b6aa7a34e67ab6e84afc3c4ebf2, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,419] LMCache INFO:[0m Reqid: chatcmpl-f7143e8ac890480280b4ca61f804ad0c, Total tokens 141, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,420] LMCache INFO:[0m Reqid: chatcmpl-c44ca4219f074c73a39be203051e56f2, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,420] LMCache INFO:[0m Reqid: chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb, Total tokens 925, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,450] LMCache INFO:[0m Storing KV cache for 626 out of 1138 tokens (skip_leading_tokens=512) for request chatcmpl-f15adb2d2dcb40debf664880e9edba23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,452] LMCache INFO:[0m Stored 626 out of total 1138 tokens. size: 0.0167 gb, cost 1.0650 ms, throughput: 15.6959 GB/s; offload_time: 0.9161 ms, put_time: 0.1489 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,454] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-9d8b5b6aa7a34e67ab6e84afc3c4ebf2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,455] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 1.0344 ms, throughput: 2.8397 GB/s; offload_time: 0.9665 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,455] LMCache INFO:[0m Storing KV cache for 141 out of 141 tokens (skip_leading_tokens=0) for request chatcmpl-f7143e8ac890480280b4ca61f804ad0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,456] LMCache INFO:[0m Stored 141 out of total 141 tokens. size: 0.0038 gb, cost 0.9852 ms, throughput: 3.8218 GB/s; offload_time: 0.5989 ms, put_time: 0.3862 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,457] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,457] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.5550 ms, throughput: 5.3410 GB/s; offload_time: 0.5052 ms, put_time: 0.0497 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,463] LMCache INFO:[0m Reqid: chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb, Total tokens 925, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,472] LMCache INFO:[0m Reqid: chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb, Total tokens 925, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,480] LMCache INFO:[0m Reqid: chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb, Total tokens 925, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,481] LMCache INFO:[0m Reqid: chatcmpl-28921425465248c5bc3ebef4b0cf8255, Total tokens 658, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,482] LMCache INFO:[0m Reqid: chatcmpl-1746b84cc7d44fb2ad890ef098e5b315, Total tokens 526, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,508] LMCache INFO:[0m Storing KV cache for 541 out of 925 tokens (skip_leading_tokens=384) for request chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,509] LMCache INFO:[0m Stored 541 out of total 925 tokens. size: 0.0144 gb, cost 1.0677 ms, throughput: 13.5298 GB/s; offload_time: 0.9076 ms, put_time: 0.1601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,510] LMCache INFO:[0m Storing KV cache for 274 out of 658 tokens (skip_leading_tokens=384) for request chatcmpl-28921425465248c5bc3ebef4b0cf8255 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,513] LMCache INFO:[0m Stored 274 out of total 658 tokens. size: 0.0073 gb, cost 3.2589 ms, throughput: 2.2451 GB/s; offload_time: 3.1487 ms, put_time: 0.1102 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,520] LMCache INFO:[0m Reqid: chatcmpl-1746b84cc7d44fb2ad890ef098e5b315, Total tokens 526, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,526] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-761679abdcf24947b2c82ab5ef4ef37f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,528] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.0680 ms, throughput: 3.2002 GB/s; offload_time: 1.0034 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,528] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,529] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2597 ms, throughput: 2.7133 GB/s; offload_time: 1.1895 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,533] LMCache INFO:[0m Reqid: chatcmpl-1746b84cc7d44fb2ad890ef098e5b315, Total tokens 526, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,542] LMCache INFO:[0m Reqid: chatcmpl-1746b84cc7d44fb2ad890ef098e5b315, Total tokens 526, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,542] LMCache INFO:[0m Reqid: chatcmpl-6eb97a299ac84b298ebdd58983fbc1f2, Total tokens 185, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,543] LMCache INFO:[0m Reqid: chatcmpl-e07785c78a8148afb31249948eb30b50, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,543] LMCache INFO:[0m Reqid: chatcmpl-324fea1c8fa649e18a9132eeccda1da4, Total tokens 551, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,544] LMCache INFO:[0m Reqid: chatcmpl-d6d1005f8040400fbb840b7118f53438, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,545] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,569] LMCache INFO:[0m Storing KV cache for 270 out of 526 tokens (skip_leading_tokens=256) for request chatcmpl-1746b84cc7d44fb2ad890ef098e5b315 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,569] LMCache INFO:[0m Stored 270 out of total 526 tokens. size: 0.0072 gb, cost 0.7242 ms, throughput: 9.9562 GB/s; offload_time: 0.6014 ms, put_time: 0.1228 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,570] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-e07785c78a8148afb31249948eb30b50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,571] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.8982 ms, throughput: 2.9730 GB/s; offload_time: 0.6783 ms, put_time: 0.2199 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,571] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-d6d1005f8040400fbb840b7118f53438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,572] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 0.4272 ms, throughput: 7.0632 GB/s; offload_time: 0.3705 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,577] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,586] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:36918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,596] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,602] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f48dfb37b7274044bffe7b533a36921b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,603] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1126 ms, throughput: 3.0721 GB/s; offload_time: 1.0480 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,607] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,614] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-25b9d7977eec4d67a9a5f1a554453b93 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,616] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.0555 ms, throughput: 3.2383 GB/s; offload_time: 0.9904 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,616] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5d858f26f8fb4239a752d5b8ac647934 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,618] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.3992 ms, throughput: 2.4429 GB/s; offload_time: 1.3344 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,622] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,628] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f7ddda6ef95e4f1c8531254b4357bb69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,629] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9767 ms, throughput: 3.4993 GB/s; offload_time: 0.9132 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,630] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-581208a665894023b6fc52762f40e2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,631] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3191 ms, throughput: 2.5911 GB/s; offload_time: 1.2564 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,636] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,645] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,654] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,661] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f15adb2d2dcb40debf664880e9edba23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,662] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0118 ms, throughput: 3.3781 GB/s; offload_time: 0.9481 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,666] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,673] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,674] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.0497 ms, throughput: 3.2562 GB/s; offload_time: 0.9855 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,678] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,687] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,694] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,695] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9494 ms, throughput: 3.6000 GB/s; offload_time: 0.8830 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,699] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,708] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,717] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,726] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,732] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d6d1005f8040400fbb840b7118f53438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,733] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9743 ms, throughput: 3.5083 GB/s; offload_time: 0.9061 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,738] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,747] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,754] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-f561f579230b4daaaad850e5e7abb3b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,755] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.0310 ms, throughput: 3.3153 GB/s; offload_time: 0.9652 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,755] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-38b7303763b143959d35ba1aab9fb63a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,756] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2812 ms, throughput: 2.6677 GB/s; offload_time: 1.2180 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,757] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-3f0722d12d1e48458104edb98002bd1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,758] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2372 ms, throughput: 2.7626 GB/s; offload_time: 1.1773 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,763] LMCache INFO:[0m Reqid: chatcmpl-760ef6d65b1144a1a38b274592590193, Total tokens 2324, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,765] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-11 15:21:01 [loggers.py:118] Engine 000: Avg prompt throughput: 15782.6 tokens/s, Avg generation throughput: 4588.2 tokens/s, Running: 65 reqs, Waiting: 32 reqs, GPU KV cache usage: 95.7%, Prefix cache hit rate: 32.3%
[32;20m[2025-07-11 15:21:01,805] LMCache INFO:[0m Storing KV cache for 148 out of 2324 tokens (skip_leading_tokens=2176) for request chatcmpl-760ef6d65b1144a1a38b274592590193 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,806] LMCache INFO:[0m Stored 148 out of total 2324 tokens. size: 0.0040 gb, cost 0.6263 ms, throughput: 6.3100 GB/s; offload_time: 0.5390 ms, put_time: 0.0873 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,806] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1530f0fabc084e18baac9f7ffaccc50e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,808] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2918 ms, throughput: 2.6460 GB/s; offload_time: 1.2332 ms, put_time: 0.0585 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,811] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:01,819] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-f9a9d934bc4947389154fc6545f5e0d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,819] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.4824 ms, throughput: 7.0857 GB/s; offload_time: 0.4195 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,823] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,833] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,842] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,849] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-a4329ef4197c4e2ab18630786fc7a18a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,849] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4581 ms, throughput: 7.4607 GB/s; offload_time: 0.3934 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,850] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-275ce2c21fa24d9a899b9a82136a4e9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,850] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5595 ms, throughput: 6.1090 GB/s; offload_time: 0.5021 ms, put_time: 0.0574 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,851] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-ee709e88deb843fda15d9599b8567847 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,851] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6351 ms, throughput: 5.3815 GB/s; offload_time: 0.5803 ms, put_time: 0.0548 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,856] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,862] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,863] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.4861 ms, throughput: 7.0320 GB/s; offload_time: 0.4251 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,867] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,873] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c9d8468fdbd34c51aff88edefa28c886 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,874] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4277 ms, throughput: 7.9910 GB/s; offload_time: 0.3669 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,878] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,887] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,896] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,905] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,911] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e07785c78a8148afb31249948eb30b50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,911] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3691 ms, throughput: 9.2611 GB/s; offload_time: 0.3099 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,915] LMCache INFO:[0m Reqid: chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26, Total tokens 1931, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,917] LMCache INFO:[0m Reqid: chatcmpl-c3ec9c08f01c4b2287c4248aa7cc2298, Total tokens 726, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,918] LMCache INFO:[0m Reqid: chatcmpl-de086c29dd7044249dbb21504fb797de, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,918] LMCache INFO:[0m Reqid: chatcmpl-9ad356d5afff4e719f830ced469f229a, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,919] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,946] LMCache INFO:[0m Storing KV cache for 139 out of 1931 tokens (skip_leading_tokens=1792) for request chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,946] LMCache INFO:[0m Stored 139 out of total 1931 tokens. size: 0.0037 gb, cost 0.6196 ms, throughput: 5.9910 GB/s; offload_time: 0.5278 ms, put_time: 0.0918 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,947] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-de086c29dd7044249dbb21504fb797de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,948] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 1.1336 ms, throughput: 2.3086 GB/s; offload_time: 1.0785 ms, put_time: 0.0550 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,948] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-9ad356d5afff4e719f830ced469f229a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,949] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.7824 ms, throughput: 3.3448 GB/s; offload_time: 0.6893 ms, put_time: 0.0931 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,949] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0697b242db254501a3bf111e43922ae8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,950] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5494 ms, throughput: 6.2215 GB/s; offload_time: 0.5024 ms, put_time: 0.0470 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,955] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,964] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,970] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,971] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4589 ms, throughput: 7.4483 GB/s; offload_time: 0.3974 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,974] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,981] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-e469177a37fb447182394db81f68d17a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,982] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4550 ms, throughput: 7.5118 GB/s; offload_time: 0.3945 ms, put_time: 0.0605 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,985] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,992] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,993] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4856 ms, throughput: 7.0384 GB/s; offload_time: 0.4242 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,993] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2904e2ab38e747bf8285c9c312ed4d98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:01,994] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5920 ms, throughput: 5.7737 GB/s; offload_time: 0.5404 ms, put_time: 0.0516 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:01,997] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,006] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,015] LMCache INFO:[0m Reqid: chatcmpl-3ad13e90968c4a2db162ec33b52a875c, Total tokens 1004, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,016] LMCache INFO:[0m Reqid: chatcmpl-393667bddc2540d0bd3b967094160351, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,016] LMCache INFO:[0m Reqid: chatcmpl-cd29d10e2dba445e8334f3bd223434ef, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,017] LMCache INFO:[0m Reqid: chatcmpl-d856eb8c084b41289265282edb978ea4, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,018] LMCache INFO:[0m Reqid: chatcmpl-4068ed711a21481a944bcbf28e36812e, Total tokens 952, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,045] LMCache INFO:[0m Storing KV cache for 620 out of 1004 tokens (skip_leading_tokens=384) for request chatcmpl-3ad13e90968c4a2db162ec33b52a875c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,048] LMCache INFO:[0m Stored 620 out of total 1004 tokens. size: 0.0166 gb, cost 2.3248 ms, throughput: 7.1212 GB/s; offload_time: 1.9844 ms, put_time: 0.3405 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,048] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,050] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 1.7845 ms, throughput: 1.6460 GB/s; offload_time: 1.5591 ms, put_time: 0.2254 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,050] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-cd29d10e2dba445e8334f3bd223434ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52200 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,054] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 3.0131 ms, throughput: 1.1698 GB/s; offload_time: 1.7620 ms, put_time: 1.2511 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,055] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-d856eb8c084b41289265282edb978ea4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52214 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,056] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.9529 ms, throughput: 2.7183 GB/s; offload_time: 0.8803 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,060] LMCache INFO:[0m Reqid: chatcmpl-4068ed711a21481a944bcbf28e36812e, Total tokens 952, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,069] LMCache INFO:[0m Reqid: chatcmpl-4068ed711a21481a944bcbf28e36812e, Total tokens 952, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,078] LMCache INFO:[0m Reqid: chatcmpl-4068ed711a21481a944bcbf28e36812e, Total tokens 952, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,079] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,104] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,110] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-ccdd3a778ba846bab1ca6987a12f4e89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,111] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4505 ms, throughput: 7.5867 GB/s; offload_time: 0.3844 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,115] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,116] LMCache INFO:[0m Reqid: chatcmpl-c60081dd700740ebb19da6154112706c, Total tokens 926, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,134] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-597def71c0994eebafdcf99bc2516f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,135] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4868 ms, throughput: 7.0215 GB/s; offload_time: 0.4232 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,147] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 735, LMCache hit tokens: 640, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,156] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 735, LMCache hit tokens: 640, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,165] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 735, LMCache hit tokens: 640, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,173] LMCache INFO:[0m Reqid: chatcmpl-075be102a3134b1a88b338d29a48916b, Total tokens 735, LMCache hit tokens: 640, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,174] LMCache INFO:[0m Reqid: chatcmpl-c60081dd700740ebb19da6154112706c, Total tokens 926, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,175] LMCache INFO:[0m Reqid: chatcmpl-f7b8d1290df94fe58da693c87564b960, Total tokens 760, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,197] LMCache INFO:[0m Reqid: chatcmpl-f7b8d1290df94fe58da693c87564b960, Total tokens 760, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,198] LMCache INFO:[0m Reqid: chatcmpl-7f428578bee44657aa2d88319001dc05, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,199] LMCache INFO:[0m Reqid: chatcmpl-bd4dd16d93f14ae4a798e20839a44eae, Total tokens 1011, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,217] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-7f428578bee44657aa2d88319001dc05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,217] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.3325 ms, throughput: 9.7984 GB/s; offload_time: 0.2727 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,221] LMCache INFO:[0m Reqid: chatcmpl-bd4dd16d93f14ae4a798e20839a44eae, Total tokens 1011, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,223] LMCache INFO:[0m Reqid: chatcmpl-223f22db11d14abf8696dd15c2265e9d, Total tokens 1726, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,245] LMCache INFO:[0m Reqid: chatcmpl-223f22db11d14abf8696dd15c2265e9d, Total tokens 1726, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,254] LMCache INFO:[0m Reqid: chatcmpl-223f22db11d14abf8696dd15c2265e9d, Total tokens 1726, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,263] LMCache INFO:[0m Reqid: chatcmpl-223f22db11d14abf8696dd15c2265e9d, Total tokens 1726, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,264] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1092, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,296] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1092, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,305] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1092, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,311] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7f428578bee44657aa2d88319001dc05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,311] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3684 ms, throughput: 9.2767 GB/s; offload_time: 0.3089 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,315] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1092, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,322] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1763283e3bb54538afc6003083aea068 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,322] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4067 ms, throughput: 8.4032 GB/s; offload_time: 0.3389 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,322] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,323] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5864 ms, throughput: 5.8291 GB/s; offload_time: 0.5019 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,327] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1092, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,328] LMCache INFO:[0m Reqid: chatcmpl-8d16741c8402453fbe71bfd6b591e79a, Total tokens 996, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,355] LMCache INFO:[0m Storing KV cache for 1092 out of 1092 tokens (skip_leading_tokens=0) for request chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,357] LMCache INFO:[0m Stored 1092 out of total 1092 tokens. size: 0.0292 gb, cost 2.0264 ms, throughput: 14.3900 GB/s; offload_time: 1.4510 ms, put_time: 0.5754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,357] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f7b8d1290df94fe58da693c87564b960 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,361] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 4.1459 ms, throughput: 0.8244 GB/s; offload_time: 3.8414 ms, put_time: 0.3045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,369] LMCache INFO:[0m Reqid: chatcmpl-8d16741c8402453fbe71bfd6b591e79a, Total tokens 996, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,375] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-3ad13e90968c4a2db162ec33b52a875c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,377] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0782 ms, throughput: 3.1701 GB/s; offload_time: 1.0064 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:37122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,387] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c700b225736a44458efa75aeb5e63fd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,388] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9773 ms, throughput: 3.4974 GB/s; offload_time: 0.9180 ms, put_time: 0.0592 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,392] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 132 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,401] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 148 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,408] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-288cb4434b4e4d1fb85e477a08e73f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,409] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.0449 ms, throughput: 3.2711 GB/s; offload_time: 0.9836 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,410] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-de086c29dd7044249dbb21504fb797de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,411] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2028 ms, throughput: 2.8416 GB/s; offload_time: 1.1448 ms, put_time: 0.0580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,411] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9ad356d5afff4e719f830ced469f229a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,412] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2286 ms, throughput: 2.7821 GB/s; offload_time: 1.1620 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,417] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 228 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,424] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,425] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3462 ms, throughput: 2.5390 GB/s; offload_time: 1.2634 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,429] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 292 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,436] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-bd4dd16d93f14ae4a798e20839a44eae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,437] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0147 ms, throughput: 3.3684 GB/s; offload_time: 0.9518 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,440] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 356 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,447] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-3be445a3f58749528495ec030ed797ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,449] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.0760 ms, throughput: 3.1767 GB/s; offload_time: 1.0117 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,453] LMCache INFO:[0m Reqid: chatcmpl-527fd97e56fd4ec49fb6061b597ffa9f, Total tokens 1094, LMCache hit tokens: 1092, need to load: 420 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,453] LMCache INFO:[0m Reqid: chatcmpl-8d16741c8402453fbe71bfd6b591e79a, Total tokens 996, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,454] LMCache INFO:[0m Reqid: chatcmpl-44ede6547a5c4ff9a2945f2087c2ff31, Total tokens 542, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,455] LMCache INFO:[0m Reqid: chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12, Total tokens 1599, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,486] LMCache INFO:[0m Storing KV cache for 228 out of 996 tokens (skip_leading_tokens=768) for request chatcmpl-8d16741c8402453fbe71bfd6b591e79a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,486] LMCache INFO:[0m Stored 228 out of total 996 tokens. size: 0.0061 gb, cost 0.5594 ms, throughput: 10.8842 GB/s; offload_time: 0.4800 ms, put_time: 0.0794 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,487] LMCache INFO:[0m Storing KV cache for 158 out of 542 tokens (skip_leading_tokens=384) for request chatcmpl-44ede6547a5c4ff9a2945f2087c2ff31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,488] LMCache INFO:[0m Stored 158 out of total 542 tokens. size: 0.0042 gb, cost 0.9685 ms, throughput: 4.3561 GB/s; offload_time: 0.8976 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,493] LMCache INFO:[0m Reqid: chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12, Total tokens 1599, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,503] LMCache INFO:[0m Reqid: chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12, Total tokens 1599, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,504] LMCache INFO:[0m Reqid: chatcmpl-4c3a2d8bc48247dfbdaef1892e014d52, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,505] LMCache INFO:[0m Reqid: chatcmpl-78ff63b0d3664fc7a8751f3c0c851600, Total tokens 325, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,505] LMCache INFO:[0m Reqid: chatcmpl-51b78a882cd84966a4fbe391f9c163bd, Total tokens 185, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,538] LMCache INFO:[0m Storing KV cache for 447 out of 1599 tokens (skip_leading_tokens=1152) for request chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,540] LMCache INFO:[0m Stored 447 out of total 1599 tokens. size: 0.0119 gb, cost 1.0893 ms, throughput: 10.9574 GB/s; offload_time: 0.7863 ms, put_time: 0.3030 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,545] LMCache INFO:[0m Reqid: chatcmpl-51b78a882cd84966a4fbe391f9c163bd, Total tokens 185, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,551] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0e4dd1ede1b94e88bc0e331d61c182f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,552] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5649 ms, throughput: 6.0507 GB/s; offload_time: 0.4817 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,562] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d856eb8c084b41289265282edb978ea4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,563] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3840 ms, throughput: 8.8999 GB/s; offload_time: 0.3160 ms, put_time: 0.0681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,566] LMCache INFO:[0m Reqid: chatcmpl-78ff63b0d3664fc7a8751f3c0c851600, Total tokens 327, LMCache hit tokens: 256, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,573] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-44a32f8e47c44173ab89c9fc909e4d99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,573] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4791 ms, throughput: 7.1334 GB/s; offload_time: 0.4135 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,574] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f5d302be5704490bb22fbd3ee15f2b91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,574] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5716 ms, throughput: 5.9792 GB/s; offload_time: 0.5179 ms, put_time: 0.0538 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,578] LMCache INFO:[0m Reqid: chatcmpl-78ff63b0d3664fc7a8751f3c0c851600, Total tokens 327, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,586] LMCache INFO:[0m Reqid: chatcmpl-78ff63b0d3664fc7a8751f3c0c851600, Total tokens 327, LMCache hit tokens: 256, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,600] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c3ec9c08f01c4b2287c4248aa7cc2298 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,601] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4292 ms, throughput: 7.9645 GB/s; offload_time: 0.3632 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,604] LMCache INFO:[0m Reqid: chatcmpl-4c3a2d8bc48247dfbdaef1892e014d52, Total tokens 172, LMCache hit tokens: 128, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,621] LMCache INFO:[0m Reqid: chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12, Total tokens 1607, LMCache hit tokens: 1599, need to load: 127 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,630] LMCache INFO:[0m Reqid: chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12, Total tokens 1607, LMCache hit tokens: 1599, need to load: 143 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,631] LMCache INFO:[0m Reqid: chatcmpl-4c3a2d8bc48247dfbdaef1892e014d52, Total tokens 172, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,632] LMCache INFO:[0m Reqid: chatcmpl-78ff63b0d3664fc7a8751f3c0c851600, Total tokens 327, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,632] LMCache INFO:[0m Reqid: chatcmpl-51b78a882cd84966a4fbe391f9c163bd, Total tokens 185, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,633] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,647] LMCache INFO:[0m Storing KV cache for 185 out of 185 tokens (skip_leading_tokens=0) for request chatcmpl-51b78a882cd84966a4fbe391f9c163bd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,649] LMCache INFO:[0m Stored 185 out of total 185 tokens. size: 0.0049 gb, cost 1.1530 ms, throughput: 4.2847 GB/s; offload_time: 1.0603 ms, put_time: 0.0927 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,654] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,661] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1fe64bf0a9804c7d9c4872b2a2130ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,662] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0076 ms, throughput: 3.3922 GB/s; offload_time: 0.9405 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,665] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,672] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ede0feb939204ad9ac28337175f96c75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,673] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0223 ms, throughput: 3.3436 GB/s; offload_time: 0.9548 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,677] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,686] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,693] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-3d73690ff5154c75a9a8aec99da8713f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,694] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0393 ms, throughput: 3.2886 GB/s; offload_time: 0.9624 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,694] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-075be102a3134b1a88b338d29a48916b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,696] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3910 ms, throughput: 2.4571 GB/s; offload_time: 1.3241 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,699] LMCache INFO:[0m Reqid: chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad, Total tokens 1250, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,701] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,727] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,736] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,745] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,754] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,763] LMCache INFO:[0m Reqid: chatcmpl-601c6b4e949a46b8af0dbdb51858f27b, Total tokens 1943, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,764] LMCache INFO:[0m Reqid: chatcmpl-14e50578d3564434a43cbae4692cf727, Total tokens 126, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,764] LMCache INFO:[0m Reqid: chatcmpl-09e473a3336449d1b415645a34a2865f, Total tokens 685, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,765] LMCache INFO:[0m Reqid: chatcmpl-746a09e3c7b44a6b9fd2826603343482, Total tokens 125, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,765] LMCache INFO:[0m Reqid: chatcmpl-d70db0ae058142058cea55d9b5922acd, Total tokens 584, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,805] LMCache INFO:[0m Storing KV cache for 151 out of 1943 tokens (skip_leading_tokens=1792) for request chatcmpl-601c6b4e949a46b8af0dbdb51858f27b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,805] LMCache INFO:[0m Stored 151 out of total 1943 tokens. size: 0.0040 gb, cost 0.6405 ms, throughput: 6.2952 GB/s; offload_time: 0.5496 ms, put_time: 0.0909 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,806] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-14e50578d3564434a43cbae4692cf727 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,807] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 0.9525 ms, throughput: 3.5325 GB/s; offload_time: 0.7929 ms, put_time: 0.1596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,807] LMCache INFO:[0m Storing KV cache for 429 out of 685 tokens (skip_leading_tokens=256) for request chatcmpl-09e473a3336449d1b415645a34a2865f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,809] LMCache INFO:[0m Stored 429 out of total 685 tokens. size: 0.0115 gb, cost 1.6595 ms, throughput: 6.9032 GB/s; offload_time: 1.5142 ms, put_time: 0.1453 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,810] LMCache INFO:[0m Storing KV cache for 125 out of 125 tokens (skip_leading_tokens=0) for request chatcmpl-746a09e3c7b44a6b9fd2826603343482 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,811] LMCache INFO:[0m Stored 125 out of total 125 tokens. size: 0.0033 gb, cost 1.5002 ms, throughput: 2.2249 GB/s; offload_time: 1.4113 ms, put_time: 0.0889 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,826] LMCache INFO:[0m Reqid: chatcmpl-746a09e3c7b44a6b9fd2826603343482, Total tokens 126, LMCache hit tokens: 125, need to load: 77 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,826] LMCache INFO:[0m Reqid: chatcmpl-d70db0ae058142058cea55d9b5922acd, Total tokens 584, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,827] LMCache INFO:[0m Reqid: chatcmpl-c47f3415c2184a259e1190d0255dd20a, Total tokens 114, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,828] LMCache INFO:[0m Reqid: chatcmpl-abb1c3e8e5cb4aae968e5cffc2f59a77, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,828] LMCache INFO:[0m Reqid: chatcmpl-4d4204731f9040098f5e3e205486dcec, Total tokens 432, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,829] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,858] LMCache INFO:[0m Storing KV cache for 584 out of 584 tokens (skip_leading_tokens=0) for request chatcmpl-d70db0ae058142058cea55d9b5922acd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,859] LMCache INFO:[0m Stored 584 out of total 584 tokens. size: 0.0156 gb, cost 1.0485 ms, throughput: 14.8735 GB/s; offload_time: 0.8907 ms, put_time: 0.1578 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,860] LMCache INFO:[0m Storing KV cache for 114 out of 114 tokens (skip_leading_tokens=0) for request chatcmpl-c47f3415c2184a259e1190d0255dd20a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,862] LMCache INFO:[0m Stored 114 out of total 114 tokens. size: 0.0030 gb, cost 1.7048 ms, throughput: 1.7856 GB/s; offload_time: 1.4093 ms, put_time: 0.2954 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,862] LMCache INFO:[0m Storing KV cache for 304 out of 432 tokens (skip_leading_tokens=128) for request chatcmpl-4d4204731f9040098f5e3e205486dcec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,869] LMCache INFO:[0m Stored 304 out of total 432 tokens. size: 0.0081 gb, cost 6.5342 ms, throughput: 1.2423 GB/s; offload_time: 6.3925 ms, put_time: 0.1417 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,869] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-83abc45ae8b349e59782b3e4503402db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,871] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.8913 ms, throughput: 1.8072 GB/s; offload_time: 1.8314 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,872] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-14e50578d3564434a43cbae4692cf727 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,874] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4323 ms, throughput: 2.3864 GB/s; offload_time: 1.2538 ms, put_time: 0.1785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,879] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,885] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c632f9c3405144a69a39c34e4839f9c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:02,887] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2410 ms, throughput: 2.7541 GB/s; offload_time: 1.1740 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,890] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,897] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-026b3d35b4fc46ea8dc667c27b7b0dc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,898] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9748 ms, throughput: 3.5062 GB/s; offload_time: 0.9095 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,898] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-746a09e3c7b44a6b9fd2826603343482 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,900] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1694 ms, throughput: 2.9227 GB/s; offload_time: 1.1061 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,904] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,913] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,920] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-8d16741c8402453fbe71bfd6b591e79a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,921] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0517 ms, throughput: 3.2500 GB/s; offload_time: 0.9822 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,925] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,932] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0b34eddc735c4338ac161f1e5f217b23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,933] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0669 ms, throughput: 3.2036 GB/s; offload_time: 0.9995 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,937] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,946] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,955] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,964] LMCache INFO:[0m Reqid: chatcmpl-125f30c081a14b2099437d51ef71238a, Total tokens 1513, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,965] LMCache INFO:[0m Reqid: chatcmpl-3182db47afa54bcc902d3e28a6a40f9b, Total tokens 138, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,966] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,997] LMCache INFO:[0m Storing KV cache for 138 out of 138 tokens (skip_leading_tokens=0) for request chatcmpl-3182db47afa54bcc902d3e28a6a40f9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,997] LMCache INFO:[0m Stored 138 out of total 138 tokens. size: 0.0037 gb, cost 0.5272 ms, throughput: 6.9898 GB/s; offload_time: 0.4355 ms, put_time: 0.0917 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,998] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e77b230bd38e4202bcc962f3900f4672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:02,999] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0369 ms, throughput: 3.2963 GB/s; offload_time: 0.9712 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:02,999] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,001] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0650 ms, throughput: 3.2095 GB/s; offload_time: 1.0041 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,005] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,012] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,012] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4111 ms, throughput: 8.3150 GB/s; offload_time: 0.3473 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,016] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,025] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,031] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b5334654c47e4fadaac02aeceebc28de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,032] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4149 ms, throughput: 8.2387 GB/s; offload_time: 0.3500 ms, put_time: 0.0649 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,035] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,045] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,051] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,052] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4765 ms, throughput: 7.1725 GB/s; offload_time: 0.4119 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,052] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c47f3415c2184a259e1190d0255dd20a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,053] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7298 ms, throughput: 4.6832 GB/s; offload_time: 0.5617 ms, put_time: 0.1681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,057] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,064] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-421c198ea03a4e3389bdfb7222c7bb98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,065] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4160 ms, throughput: 8.2169 GB/s; offload_time: 0.3487 ms, put_time: 0.0673 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,068] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,078] LMCache INFO:[0m Reqid: chatcmpl-32e436b0a9254c4398203cc7e870baa3, Total tokens 1381, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,078] LMCache INFO:[0m Reqid: chatcmpl-fbbcc8cdcda84a858978650d8bd668ba, Total tokens 144, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,079] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,108] LMCache INFO:[0m Storing KV cache for 144 out of 144 tokens (skip_leading_tokens=0) for request chatcmpl-fbbcc8cdcda84a858978650d8bd668ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,109] LMCache INFO:[0m Stored 144 out of total 144 tokens. size: 0.0038 gb, cost 0.5323 ms, throughput: 7.2237 GB/s; offload_time: 0.4392 ms, put_time: 0.0931 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,113] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,120] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1934df6070c94aa1a200276c12a36da8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,121] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4585 ms, throughput: 7.4541 GB/s; offload_time: 0.3837 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,124] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,131] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-b18fa09bfa314997b410c483913f261e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,132] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4645 ms, throughput: 7.3587 GB/s; offload_time: 0.3985 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,135] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,142] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-28921425465248c5bc3ebef4b0cf8255 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,142] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4281 ms, throughput: 7.9832 GB/s; offload_time: 0.3632 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,146] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,147] LMCache INFO:[0m Reqid: chatcmpl-e4c99553b05146f9a538d0ca84d21a6c, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,147] LMCache INFO:[0m Reqid: chatcmpl-b582ae786d4b45b9be91c997da0ce14b, Total tokens 145, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,148] LMCache INFO:[0m Reqid: chatcmpl-c65a64a517ff4530a3fedf57477f2e1e, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,166] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-e4c99553b05146f9a538d0ca84d21a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,167] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.3620 ms, throughput: 7.7446 GB/s; offload_time: 0.2961 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,167] LMCache INFO:[0m Storing KV cache for 145 out of 145 tokens (skip_leading_tokens=0) for request chatcmpl-b582ae786d4b45b9be91c997da0ce14b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,168] LMCache INFO:[0m Stored 145 out of total 145 tokens. size: 0.0039 gb, cost 0.9757 ms, throughput: 3.9684 GB/s; offload_time: 0.8894 ms, put_time: 0.0863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,179] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f7143e8ac890480280b4ca61f804ad0c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,179] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4017 ms, throughput: 8.5094 GB/s; offload_time: 0.3355 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,182] LMCache INFO:[0m Reqid: chatcmpl-b582ae786d4b45b9be91c997da0ce14b, Total tokens 146, LMCache hit tokens: 145, need to load: 65 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,189] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,190] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4787 ms, throughput: 7.1407 GB/s; offload_time: 0.4123 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,199] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4068ed711a21481a944bcbf28e36812e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,200] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4577 ms, throughput: 7.4675 GB/s; offload_time: 0.3929 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,211] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 576, LMCache hit tokens: 512, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,220] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 576, LMCache hit tokens: 512, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,227] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-579ac96a414c462da4daca8dee72773e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,228] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0369 ms, throughput: 3.2965 GB/s; offload_time: 0.9707 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,228] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1746b84cc7d44fb2ad890ef098e5b315 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,230] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4404 ms, throughput: 2.3729 GB/s; offload_time: 1.3328 ms, put_time: 0.1076 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,233] LMCache INFO:[0m Reqid: chatcmpl-e3b86b2941bd48ca90dcf95bb45db659, Total tokens 576, LMCache hit tokens: 512, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,234] LMCache INFO:[0m Reqid: chatcmpl-e4c99553b05146f9a538d0ca84d21a6c, Total tokens 108, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,235] LMCache INFO:[0m Reqid: chatcmpl-b582ae786d4b45b9be91c997da0ce14b, Total tokens 146, LMCache hit tokens: 145, need to load: 97 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,235] LMCache INFO:[0m Reqid: chatcmpl-c65a64a517ff4530a3fedf57477f2e1e, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,235] LMCache INFO:[0m Reqid: chatcmpl-d99b06e63492486ea0cb38e809d4e208, Total tokens 139, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,236] LMCache INFO:[0m Reqid: chatcmpl-a57fa3ea15de4124a175ac1b5617793a, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,237] LMCache INFO:[0m Reqid: chatcmpl-c897241b787443b2a14e0dd3a9c920e6, Total tokens 1074, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,237] LMCache INFO:[0m Reqid: chatcmpl-2eef0f72ac3a4e7b996003652e983fb4, Total tokens 237, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,238] LMCache INFO:[0m Reqid: chatcmpl-759bbd94f4d743168eba033705585f8e, Total tokens 1518, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,267] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-c65a64a517ff4530a3fedf57477f2e1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,267] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.3608 ms, throughput: 7.6960 GB/s; offload_time: 0.2962 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,267] LMCache INFO:[0m Storing KV cache for 139 out of 139 tokens (skip_leading_tokens=0) for request chatcmpl-d99b06e63492486ea0cb38e809d4e208 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,268] LMCache INFO:[0m Stored 139 out of total 139 tokens. size: 0.0037 gb, cost 0.8126 ms, throughput: 4.5675 GB/s; offload_time: 0.7247 ms, put_time: 0.0879 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,270] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-a57fa3ea15de4124a175ac1b5617793a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,271] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.8424 ms, throughput: 3.1383 GB/s; offload_time: 0.7458 ms, put_time: 0.0965 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,272] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-625492c99616493cb41e804bc5a74ce4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,273] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.3226 ms, throughput: 2.5842 GB/s; offload_time: 1.2585 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,279] LMCache INFO:[0m Reqid: chatcmpl-759bbd94f4d743168eba033705585f8e, Total tokens 1518, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52382 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,289] LMCache INFO:[0m Reqid: chatcmpl-759bbd94f4d743168eba033705585f8e, Total tokens 1518, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,296] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-223f22db11d14abf8696dd15c2265e9d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,297] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6190 ms, throughput: 5.5216 GB/s; offload_time: 0.5396 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,302] LMCache INFO:[0m Reqid: chatcmpl-759bbd94f4d743168eba033705585f8e, Total tokens 1518, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,303] LMCache INFO:[0m Reqid: chatcmpl-8371e8f41566432bb57069a1ab90dbae, Total tokens 607, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,304] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,346] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-125f30c081a14b2099437d51ef71238a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,347] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6244 ms, throughput: 5.4742 GB/s; offload_time: 0.5465 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,351] LMCache INFO:[0m Reqid: chatcmpl-8371e8f41566432bb57069a1ab90dbae, Total tokens 608, LMCache hit tokens: 512, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,361] LMCache INFO:[0m Reqid: chatcmpl-8371e8f41566432bb57069a1ab90dbae, Total tokens 608, LMCache hit tokens: 512, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,370] LMCache INFO:[0m Reqid: chatcmpl-8371e8f41566432bb57069a1ab90dbae, Total tokens 608, LMCache hit tokens: 512, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,380] LMCache INFO:[0m Reqid: chatcmpl-8371e8f41566432bb57069a1ab90dbae, Total tokens 608, LMCache hit tokens: 512, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,381] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,396] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,405] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,415] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,422] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,423] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4864 ms, throughput: 7.0271 GB/s; offload_time: 0.4097 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,427] LMCache INFO:[0m Reqid: chatcmpl-59db00d2408e4128927b4814a00d6ea2, Total tokens 1996, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,429] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,469] LMCache INFO:[0m Storing KV cache for 1996 out of 1996 tokens (skip_leading_tokens=0) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,478] LMCache INFO:[0m Stored 1996 out of total 1996 tokens. size: 0.0533 gb, cost 9.6402 ms, throughput: 5.5288 GB/s; offload_time: 7.1708 ms, put_time: 2.4695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,490] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,500] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,510] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,519] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,526] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-32e436b0a9254c4398203cc7e870baa3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,527] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3900 ms, throughput: 2.4590 GB/s; offload_time: 1.3140 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,532] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,540] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-5d858f26f8fb4239a752d5b8ac647934 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,541] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.3527 ms, throughput: 2.5267 GB/s; offload_time: 1.2770 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,541] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,543] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.3602 ms, throughput: 2.5128 GB/s; offload_time: 1.2889 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,543] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-78ff63b0d3664fc7a8751f3c0c851600 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,545] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5183 ms, throughput: 2.2511 GB/s; offload_time: 1.4419 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,550] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,557] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-581208a665894023b6fc52762f40e2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,558] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1986 ms, throughput: 2.8516 GB/s; offload_time: 1.1212 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,563] LMCache INFO:[0m Reqid: chatcmpl-ce11b90819d1470ca140c2e507fd4d78, Total tokens 1082, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,564] LMCache INFO:[0m Reqid: chatcmpl-0fce6169d9ff40cfb301ab89171bd156, Total tokens 840, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,565] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,601] LMCache INFO:[0m Storing KV cache for 200 out of 840 tokens (skip_leading_tokens=640) for request chatcmpl-0fce6169d9ff40cfb301ab89171bd156 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,601] LMCache INFO:[0m Stored 200 out of total 840 tokens. size: 0.0053 gb, cost 0.7430 ms, throughput: 7.1883 GB/s; offload_time: 0.6367 ms, put_time: 0.1063 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,602] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2eef0f72ac3a4e7b996003652e983fb4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,603] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9348 ms, throughput: 3.6564 GB/s; offload_time: 0.8592 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,608] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,615] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e4c99553b05146f9a538d0ca84d21a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,616] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4486 ms, throughput: 7.6192 GB/s; offload_time: 0.3737 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,620] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,628] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f15adb2d2dcb40debf664880e9edba23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,629] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6281 ms, throughput: 5.4414 GB/s; offload_time: 0.5450 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,629] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-759bbd94f4d743168eba033705585f8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,630] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9494 ms, throughput: 3.6003 GB/s; offload_time: 0.8823 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,634] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,642] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-10ec1f6df96340a591a8b9ade9326a2e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,642] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5707 ms, throughput: 5.9886 GB/s; offload_time: 0.4958 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,647] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,657] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,664] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,665] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4978 ms, throughput: 6.8660 GB/s; offload_time: 0.4173 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,665] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c65a64a517ff4530a3fedf57477f2e1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,666] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3729 ms, throughput: 2.4895 GB/s; offload_time: 1.3039 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,670] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,681] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,690] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,699] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,706] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d6d1005f8040400fbb840b7118f53438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,707] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2464 ms, throughput: 2.7424 GB/s; offload_time: 1.1689 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,708] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-d70db0ae058142058cea55d9b5922acd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,709] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4203 ms, throughput: 2.4066 GB/s; offload_time: 1.3500 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,714] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,721] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c60081dd700740ebb19da6154112706c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,722] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2824 ms, throughput: 2.6653 GB/s; offload_time: 1.2035 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,726] LMCache INFO:[0m Reqid: chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a, Total tokens 1838, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,727] LMCache INFO:[0m Reqid: chatcmpl-46146810cc36479dbe18a7d7700c76b5, Total tokens 159, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,728] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,768] LMCache INFO:[0m Storing KV cache for 1838 out of 1838 tokens (skip_leading_tokens=0) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,780] LMCache INFO:[0m Stored 1838 out of total 1838 tokens. size: 0.0491 gb, cost 11.3124 ms, throughput: 4.3386 GB/s; offload_time: 10.4782 ms, put_time: 0.8342 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,791] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,798] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-22de3a5b5e474fa1927ec84b37cf1e26 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,800] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3814 ms, throughput: 2.4743 GB/s; offload_time: 1.3053 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,804] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,814] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,823] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,832] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,839] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-a4329ef4197c4e2ab18630786fc7a18a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,841] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2911 ms, throughput: 2.6473 GB/s; offload_time: 1.2155 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,841] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-275ce2c21fa24d9a899b9a82136a4e9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,843] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4388 ms, throughput: 2.3756 GB/s; offload_time: 1.3660 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,847] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,854] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-d8436790e9f74c3ab30c43772c370c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,856] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3470 ms, throughput: 2.5375 GB/s; offload_time: 1.2691 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,860] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,870] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,879] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,889] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,896] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8371e8f41566432bb57069a1ab90dbae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,897] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2640 ms, throughput: 2.7040 GB/s; offload_time: 1.1898 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,901] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52558 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:03,909] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e07785c78a8148afb31249948eb30b50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,910] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2378 ms, throughput: 2.7613 GB/s; offload_time: 1.1618 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,914] LMCache INFO:[0m Reqid: chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef, Total tokens 1068, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,916] LMCache INFO:[0m Reqid: chatcmpl-7957ab811fdf4a9c8fcbab146c91f97f, Total tokens 217, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,916] LMCache INFO:[0m Reqid: chatcmpl-74f34abe1891428599cd08096aebb037, Total tokens 168, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,917] LMCache INFO:[0m Reqid: chatcmpl-cb3e7f2343f04dacb7063fe8ef872017, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,917] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,947] LMCache INFO:[0m Storing KV cache for 168 out of 168 tokens (skip_leading_tokens=0) for request chatcmpl-74f34abe1891428599cd08096aebb037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,948] LMCache INFO:[0m Stored 168 out of total 168 tokens. size: 0.0045 gb, cost 0.6799 ms, throughput: 6.5980 GB/s; offload_time: 0.5708 ms, put_time: 0.1091 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,948] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-cb3e7f2343f04dacb7063fe8ef872017 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,949] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.6381 ms, throughput: 4.1429 GB/s; offload_time: 0.5579 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,950] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0697b242db254501a3bf111e43922ae8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,951] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.8399 ms, throughput: 4.0693 GB/s; offload_time: 0.7720 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,956] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,966] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,972] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,973] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6004 ms, throughput: 5.6929 GB/s; offload_time: 0.5231 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,977] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,985] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-e469177a37fb447182394db81f68d17a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,985] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6377 ms, throughput: 5.3597 GB/s; offload_time: 0.5522 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,989] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,997] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,998] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6623 ms, throughput: 5.1605 GB/s; offload_time: 0.5820 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:03,998] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-44ede6547a5c4ff9a2945f2087c2ff31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:03,999] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8438 ms, throughput: 4.0506 GB/s; offload_time: 0.7745 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,003] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,014] LMCache INFO:[0m Reqid: chatcmpl-a735a75ddd6547c680f468159ea8c754, Total tokens 934, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,014] LMCache INFO:[0m Reqid: chatcmpl-41733bb0411b4847affc8adefc6bd61b, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,015] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,037] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-41733bb0411b4847affc8adefc6bd61b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,038] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.4636 ms, throughput: 5.7599 GB/s; offload_time: 0.3903 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,042] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,052] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52574 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,062] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,071] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,081] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,088] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-09e473a3336449d1b415645a34a2865f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,088] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5709 ms, throughput: 5.9870 GB/s; offload_time: 0.4944 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,093] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,103] LMCache INFO:[0m Reqid: chatcmpl-f0f908196129408d986369c40bf81a3c, Total tokens 1177, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,104] LMCache INFO:[0m Reqid: chatcmpl-6507d6757f084a8887aee44d17ef5140, Total tokens 783, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,105] LMCache INFO:[0m Reqid: chatcmpl-fe5c414bf6ff4175bf4d9a5eb0fa800a, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,106] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,139] LMCache INFO:[0m Storing KV cache for 143 out of 783 tokens (skip_leading_tokens=640) for request chatcmpl-6507d6757f084a8887aee44d17ef5140 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,140] LMCache INFO:[0m Stored 143 out of total 783 tokens. size: 0.0038 gb, cost 0.7507 ms, throughput: 5.0868 GB/s; offload_time: 0.6439 ms, put_time: 0.1068 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,141] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-fe5c414bf6ff4175bf4d9a5eb0fa800a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,142] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.8508 ms, throughput: 3.0758 GB/s; offload_time: 0.7758 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,150] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,160] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,170] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,179] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,190] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,199] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,209] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,218] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,228] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,235] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e3b86b2941bd48ca90dcf95bb45db659 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,236] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7822 ms, throughput: 4.3699 GB/s; offload_time: 0.6933 ms, put_time: 0.0888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,237] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,238] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3314 ms, throughput: 2.5673 GB/s; offload_time: 1.2504 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,244] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,254] LMCache INFO:[0m Reqid: chatcmpl-d26cb94168944a01929ddc01ec7227ef, Total tokens 1518, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,255] LMCache INFO:[0m Reqid: chatcmpl-460c831c44d74ca2af33a299afdbefb3, Total tokens 1158, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,256] LMCache INFO:[0m Reqid: chatcmpl-62bf38511e9c49e58a03f2f18ee58e7f, Total tokens 158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,257] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,290] LMCache INFO:[0m Storing KV cache for 494 out of 1518 tokens (skip_leading_tokens=1024) for request chatcmpl-d26cb94168944a01929ddc01ec7227ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,292] LMCache INFO:[0m Stored 494 out of total 1518 tokens. size: 0.0132 gb, cost 1.0044 ms, throughput: 13.1328 GB/s; offload_time: 0.8650 ms, put_time: 0.1394 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,292] LMCache INFO:[0m Storing KV cache for 134 out of 1158 tokens (skip_leading_tokens=1024) for request chatcmpl-460c831c44d74ca2af33a299afdbefb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,294] LMCache INFO:[0m Stored 134 out of total 1158 tokens. size: 0.0036 gb, cost 2.1001 ms, throughput: 1.7039 GB/s; offload_time: 2.0160 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,295] LMCache INFO:[0m Storing KV cache for 158 out of 158 tokens (skip_leading_tokens=0) for request chatcmpl-62bf38511e9c49e58a03f2f18ee58e7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,296] LMCache INFO:[0m Stored 158 out of total 158 tokens. size: 0.0042 gb, cost 0.6685 ms, throughput: 6.3109 GB/s; offload_time: 0.5915 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,297] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-abb1c3e8e5cb4aae968e5cffc2f59a77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,298] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4155 ms, throughput: 2.4146 GB/s; offload_time: 1.3480 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,304] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,310] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,312] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0445 ms, throughput: 3.2724 GB/s; offload_time: 0.9794 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,316] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,323] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f7b8d1290df94fe58da693c87564b960 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,324] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1140 ms, throughput: 3.0681 GB/s; offload_time: 1.0482 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,328] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,335] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-3ad13e90968c4a2db162ec33b52a875c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,336] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0663 ms, throughput: 3.2054 GB/s; offload_time: 0.9965 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,340] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,350] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,357] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-cb3e7f2343f04dacb7063fe8ef872017 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,358] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9805 ms, throughput: 3.4860 GB/s; offload_time: 0.9159 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,362] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,369] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-de086c29dd7044249dbb21504fb797de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,370] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9891 ms, throughput: 3.4557 GB/s; offload_time: 0.9238 ms, put_time: 0.0653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,370] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9ad356d5afff4e719f830ced469f229a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,372] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3085 ms, throughput: 2.6121 GB/s; offload_time: 1.2452 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,377] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,384] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,385] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0434 ms, throughput: 3.2758 GB/s; offload_time: 0.9771 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,389] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,398] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,405] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0fce6169d9ff40cfb301ab89171bd156 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,407] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0308 ms, throughput: 3.3160 GB/s; offload_time: 0.9625 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,411] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,418] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-41733bb0411b4847affc8adefc6bd61b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,419] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9984 ms, throughput: 3.4234 GB/s; offload_time: 0.9308 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,423] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,432] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,439] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c897241b787443b2a14e0dd3a9c920e6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,441] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3549 ms, throughput: 2.5226 GB/s; offload_time: 1.2856 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,445] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,463] LMCache INFO:[0m Reqid: chatcmpl-62bf38511e9c49e58a03f2f18ee58e7f, Total tokens 172, LMCache hit tokens: 158, need to load: 110 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,470] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-44a32f8e47c44173ab89c9fc909e4d99 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,471] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.0925 ms, throughput: 3.1285 GB/s; offload_time: 1.0269 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,471] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f5d302be5704490bb22fbd3ee15f2b91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,473] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1762 ms, throughput: 2.9060 GB/s; offload_time: 1.1160 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,473] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7957ab811fdf4a9c8fcbab146c91f97f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,475] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4818 ms, throughput: 2.3066 GB/s; offload_time: 1.3079 ms, put_time: 0.1739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,479] LMCache INFO:[0m Reqid: chatcmpl-62bf38511e9c49e58a03f2f18ee58e7f, Total tokens 172, LMCache hit tokens: 158, need to load: 110 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,480] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1666, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,481] LMCache INFO:[0m Reqid: chatcmpl-2408cc793feb4e16b398f4eabc8d78eb, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,512] LMCache INFO:[0m Storing KV cache for 130 out of 1666 tokens (skip_leading_tokens=1536) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,512] LMCache INFO:[0m Stored 130 out of total 1666 tokens. size: 0.0035 gb, cost 0.5996 ms, throughput: 5.7891 GB/s; offload_time: 0.5095 ms, put_time: 0.0901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,527] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1667, LMCache hit tokens: 1666, need to load: 146 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,534] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c3ec9c08f01c4b2287c4248aa7cc2298 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,534] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4089 ms, throughput: 8.3599 GB/s; offload_time: 0.3486 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,534] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d26cb94168944a01929ddc01ec7227ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,535] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9062 ms, throughput: 3.7716 GB/s; offload_time: 0.8497 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,540] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1667, LMCache hit tokens: 1666, need to load: 274 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,549] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1667, LMCache hit tokens: 1666, need to load: 354 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,559] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1667, LMCache hit tokens: 1666, need to load: 418 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,568] LMCache INFO:[0m Reqid: chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb, Total tokens 1667, LMCache hit tokens: 1666, need to load: 418 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,569] LMCache INFO:[0m Reqid: chatcmpl-2408cc793feb4e16b398f4eabc8d78eb, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,570] LMCache INFO:[0m Reqid: chatcmpl-70cecd401f3e4cffa2d61eefc5769465, Total tokens 1980, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,581] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-2408cc793feb4e16b398f4eabc8d78eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,582] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.3566 ms, throughput: 6.8897 GB/s; offload_time: 0.2921 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,586] LMCache INFO:[0m Reqid: chatcmpl-70cecd401f3e4cffa2d61eefc5769465, Total tokens 1980, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,588] LMCache INFO:[0m Reqid: chatcmpl-f568c762ce6344e4ad65f7c0005d460a, Total tokens 622, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,588] LMCache INFO:[0m Reqid: chatcmpl-14115e1b21024990981db7829c0ec396, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,620] LMCache INFO:[0m Storing KV cache for 238 out of 622 tokens (skip_leading_tokens=384) for request chatcmpl-f568c762ce6344e4ad65f7c0005d460a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,621] LMCache INFO:[0m Stored 238 out of total 622 tokens. size: 0.0064 gb, cost 0.5685 ms, throughput: 11.1793 GB/s; offload_time: 0.4773 ms, put_time: 0.0912 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,621] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1fe64bf0a9804c7d9c4872b2a2130ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,622] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.8804 ms, throughput: 3.8823 GB/s; offload_time: 0.8217 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,623] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ce11b90819d1470ca140c2e507fd4d78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,623] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6872 ms, throughput: 4.9737 GB/s; offload_time: 0.6288 ms, put_time: 0.0584 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,635] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ede0feb939204ad9ac28337175f96c75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,636] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4171 ms, throughput: 8.1954 GB/s; offload_time: 0.3541 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,640] LMCache INFO:[0m Reqid: chatcmpl-f568c762ce6344e4ad65f7c0005d460a, Total tokens 623, LMCache hit tokens: 622, need to load: 126 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,649] LMCache INFO:[0m Reqid: chatcmpl-f568c762ce6344e4ad65f7c0005d460a, Total tokens 623, LMCache hit tokens: 622, need to load: 174 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,656] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-3d73690ff5154c75a9a8aec99da8713f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,657] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4236 ms, throughput: 8.0689 GB/s; offload_time: 0.3580 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,657] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-075be102a3134b1a88b338d29a48916b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,658] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.8135 ms, throughput: 4.2016 GB/s; offload_time: 0.7258 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,662] LMCache INFO:[0m Reqid: chatcmpl-f568c762ce6344e4ad65f7c0005d460a, Total tokens 623, LMCache hit tokens: 622, need to load: 302 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,663] LMCache INFO:[0m Reqid: chatcmpl-14115e1b21024990981db7829c0ec396, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,663] LMCache INFO:[0m Reqid: chatcmpl-4b34a105c5ce4ceda37b9934c4d5a2a2, Total tokens 271, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,664] LMCache INFO:[0m Reqid: chatcmpl-720cbb9a65ce4e53947cc7105f944d09, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,665] LMCache INFO:[0m Reqid: chatcmpl-e9ed9aae811147668f28bf5c2d392af8, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52634 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,679] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-14115e1b21024990981db7829c0ec396 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,679] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3536 ms, throughput: 7.5526 GB/s; offload_time: 0.2888 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,680] LMCache INFO:[0m Storing KV cache for 143 out of 271 tokens (skip_leading_tokens=128) for request chatcmpl-4b34a105c5ce4ceda37b9934c4d5a2a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,680] LMCache INFO:[0m Stored 143 out of total 271 tokens. size: 0.0038 gb, cost 0.7316 ms, throughput: 5.2195 GB/s; offload_time: 0.6489 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,681] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-720cbb9a65ce4e53947cc7105f944d09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,682] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.7084 ms, throughput: 3.6941 GB/s; offload_time: 0.6520 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,690] LMCache INFO:[0m Reqid: chatcmpl-e9ed9aae811147668f28bf5c2d392af8, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,699] LMCache INFO:[0m Reqid: chatcmpl-e9ed9aae811147668f28bf5c2d392af8, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,709] LMCache INFO:[0m Reqid: chatcmpl-e9ed9aae811147668f28bf5c2d392af8, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,718] LMCache INFO:[0m Reqid: chatcmpl-e9ed9aae811147668f28bf5c2d392af8, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,720] LMCache INFO:[0m Reqid: chatcmpl-2bf45d73cb19497bb58c91c13794e4aa, Total tokens 1904, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,750] LMCache INFO:[0m Reqid: chatcmpl-2bf45d73cb19497bb58c91c13794e4aa, Total tokens 1904, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,759] LMCache INFO:[0m Reqid: chatcmpl-2bf45d73cb19497bb58c91c13794e4aa, Total tokens 1904, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,765] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3182db47afa54bcc902d3e28a6a40f9b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,766] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3855 ms, throughput: 8.8662 GB/s; offload_time: 0.3144 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,770] LMCache INFO:[0m Reqid: chatcmpl-2bf45d73cb19497bb58c91c13794e4aa, Total tokens 1904, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,778] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-83abc45ae8b349e59782b3e4503402db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,778] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4770 ms, throughput: 7.1656 GB/s; offload_time: 0.4074 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,779] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-14e50578d3564434a43cbae4692cf727 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,779] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6327 ms, throughput: 5.4023 GB/s; offload_time: 0.5768 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,784] LMCache INFO:[0m Reqid: chatcmpl-2bf45d73cb19497bb58c91c13794e4aa, Total tokens 1904, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,785] LMCache INFO:[0m Reqid: chatcmpl-cfc3afedb3cf49f098267360d926ba3e, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,786] LMCache INFO:[0m Reqid: chatcmpl-510cc852edc1415dacbea79c024c5f30, Total tokens 1027, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52648 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,818] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-cfc3afedb3cf49f098267360d926ba3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,819] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.3505 ms, throughput: 7.3894 GB/s; offload_time: 0.2872 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,819] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c632f9c3405144a69a39c34e4839f9c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,820] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6101 ms, throughput: 5.6022 GB/s; offload_time: 0.5508 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,825] LMCache INFO:[0m Reqid: chatcmpl-510cc852edc1415dacbea79c024c5f30, Total tokens 1027, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,826] LMCache INFO:[0m Reqid: chatcmpl-678cb04b65dd434184374fc890775a6f, Total tokens 403, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,848] LMCache INFO:[0m Storing KV cache for 387 out of 1027 tokens (skip_leading_tokens=640) for request chatcmpl-510cc852edc1415dacbea79c024c5f30 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,849] LMCache INFO:[0m Stored 387 out of total 1027 tokens. size: 0.0103 gb, cost 0.9032 ms, throughput: 11.4413 GB/s; offload_time: 0.7461 ms, put_time: 0.1571 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,849] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-026b3d35b4fc46ea8dc667c27b7b0dc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,851] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 2.2708 ms, throughput: 1.5052 GB/s; offload_time: 2.2024 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,851] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-746a09e3c7b44a6b9fd2826603343482 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,853] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6583 ms, throughput: 2.0611 GB/s; offload_time: 1.5790 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,858] LMCache INFO:[0m Reqid: chatcmpl-678cb04b65dd434184374fc890775a6f, Total tokens 403, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,859] LMCache INFO:[0m Reqid: chatcmpl-1891ff4756334e3199ea5f7d0ea1466e, Total tokens 1134, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,860] LMCache INFO:[0m Reqid: chatcmpl-ff29854e2a574f0296cf9b402f56ad75, Total tokens 255, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,860] LMCache INFO:[0m Reqid: chatcmpl-a97a9fb444ca4a34bd4fd0e4d7cb22f6, Total tokens 129, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,861] LMCache INFO:[0m Reqid: chatcmpl-021db7dfed2b4801b44a4b2607a5bbe3, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,861] LMCache INFO:[0m Reqid: chatcmpl-af173868aeb14211ba22a6a0001ed085, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,861] LMCache INFO:[0m Reqid: chatcmpl-3aa0bd087d704430a92e8fc5c1378a8f, Total tokens 258, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,893] LMCache INFO:[0m Storing KV cache for 147 out of 403 tokens (skip_leading_tokens=256) for request chatcmpl-678cb04b65dd434184374fc890775a6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,893] LMCache INFO:[0m Stored 147 out of total 403 tokens. size: 0.0039 gb, cost 0.5535 ms, throughput: 7.0919 GB/s; offload_time: 0.4602 ms, put_time: 0.0932 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,894] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-a97a9fb444ca4a34bd4fd0e4d7cb22f6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,895] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 1.0868 ms, throughput: 3.1697 GB/s; offload_time: 1.0017 ms, put_time: 0.0850 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,895] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-021db7dfed2b4801b44a4b2607a5bbe3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,898] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 1.6149 ms, throughput: 1.6866 GB/s; offload_time: 1.5466 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,898] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-af173868aeb14211ba22a6a0001ed085 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,899] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.5041 ms, throughput: 5.1387 GB/s; offload_time: 0.4419 ms, put_time: 0.0621 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,904] LMCache INFO:[0m Reqid: chatcmpl-3aa0bd087d704430a92e8fc5c1378a8f, Total tokens 258, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,904] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 391, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,917] LMCache INFO:[0m Storing KV cache for 130 out of 258 tokens (skip_leading_tokens=128) for request chatcmpl-3aa0bd087d704430a92e8fc5c1378a8f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,918] LMCache INFO:[0m Stored 130 out of total 258 tokens. size: 0.0035 gb, cost 0.5351 ms, throughput: 6.4869 GB/s; offload_time: 0.4424 ms, put_time: 0.0927 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,918] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-8d16741c8402453fbe71bfd6b591e79a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,920] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4427 ms, throughput: 2.3691 GB/s; offload_time: 1.3797 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,920] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ff29854e2a574f0296cf9b402f56ad75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,921] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3267 ms, throughput: 10.4630 GB/s; offload_time: 0.2806 ms, put_time: 0.0461 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,925] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 391, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,932] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0b34eddc735c4338ac161f1e5f217b23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,933] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4322 ms, throughput: 7.9085 GB/s; offload_time: 0.3690 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,936] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 391, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:04,955] LMCache INFO:[0m Reqid: chatcmpl-3aa0bd087d704430a92e8fc5c1378a8f, Total tokens 261, LMCache hit tokens: 258, need to load: 50 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,964] LMCache INFO:[0m Reqid: chatcmpl-3aa0bd087d704430a92e8fc5c1378a8f, Total tokens 261, LMCache hit tokens: 258, need to load: 162 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,965] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 391, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,965] LMCache INFO:[0m Reqid: chatcmpl-a432641499764942810594ef70b8633d, Total tokens 116, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,967] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,982] LMCache INFO:[0m Storing KV cache for 135 out of 391 tokens (skip_leading_tokens=256) for request chatcmpl-3aa33406f8ba47a286778d0a36d14bac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,982] LMCache INFO:[0m Stored 135 out of total 391 tokens. size: 0.0036 gb, cost 0.5528 ms, throughput: 6.5210 GB/s; offload_time: 0.4615 ms, put_time: 0.0913 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,983] LMCache INFO:[0m Storing KV cache for 116 out of 116 tokens (skip_leading_tokens=0) for request chatcmpl-a432641499764942810594ef70b8633d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,984] LMCache INFO:[0m Stored 116 out of total 116 tokens. size: 0.0031 gb, cost 0.8719 ms, throughput: 3.5526 GB/s; offload_time: 0.8181 ms, put_time: 0.0539 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,984] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-e77b230bd38e4202bcc962f3900f4672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,985] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9443 ms, throughput: 3.6195 GB/s; offload_time: 0.8900 ms, put_time: 0.0543 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,985] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:04,987] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2525 ms, throughput: 2.7289 GB/s; offload_time: 1.1946 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:04,998] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,000] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1090 ms, throughput: 3.0820 GB/s; offload_time: 1.0422 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,000] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f568c762ce6344e4ad65f7c0005d460a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,001] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1478 ms, throughput: 2.9779 GB/s; offload_time: 1.0872 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,014] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 135 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,021] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,022] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.0675 ms, throughput: 3.2019 GB/s; offload_time: 1.0043 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,026] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 199 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,035] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 263 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,042] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-c45e8edf6e8d455b9e6ad75fceb7f242 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,043] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.0618 ms, throughput: 3.2191 GB/s; offload_time: 0.9937 ms, put_time: 0.0681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,047] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 343 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,054] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-421c198ea03a4e3389bdfb7222c7bb98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,055] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0307 ms, throughput: 3.3163 GB/s; offload_time: 0.9603 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,059] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 343 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,069] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 343 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,076] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d99b06e63492486ea0cb38e809d4e208 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,077] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9660 ms, throughput: 3.5383 GB/s; offload_time: 0.8977 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,078] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-2bf45d73cb19497bb58c91c13794e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,079] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.5014 ms, throughput: 2.2765 GB/s; offload_time: 1.4308 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,083] LMCache INFO:[0m Reqid: chatcmpl-3aa33406f8ba47a286778d0a36d14bac, Total tokens 393, LMCache hit tokens: 391, need to load: 343 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,084] LMCache INFO:[0m Reqid: chatcmpl-a432641499764942810594ef70b8633d, Total tokens 117, LMCache hit tokens: 116, need to load: 68 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,085] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,096] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1934df6070c94aa1a200276c12a36da8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,097] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0737 ms, throughput: 3.1835 GB/s; offload_time: 1.0017 ms, put_time: 0.0719 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,101] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,112] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,119] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-28921425465248c5bc3ebef4b0cf8255 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,120] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.0526 ms, throughput: 3.2470 GB/s; offload_time: 0.9859 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,124] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,131] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-14115e1b21024990981db7829c0ec396 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,132] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9802 ms, throughput: 3.4871 GB/s; offload_time: 0.9147 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,133] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1891ff4756334e3199ea5f7d0ea1466e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,134] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3972 ms, throughput: 2.4462 GB/s; offload_time: 1.3365 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,139] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,148] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,155] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,156] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.0619 ms, throughput: 3.2186 GB/s; offload_time: 0.9953 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,160] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,168] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-4068ed711a21481a944bcbf28e36812e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,169] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0738 ms, throughput: 3.1829 GB/s; offload_time: 1.0092 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,174] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,183] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,190] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,191] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0123 ms, throughput: 3.3765 GB/s; offload_time: 0.9482 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,195] LMCache INFO:[0m Reqid: chatcmpl-6fac4c7103d04c21b39bceaabc025747, Total tokens 1875, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,196] LMCache INFO:[0m Reqid: chatcmpl-17c0939e328b4be1bed5bf7aee20f2ad, Total tokens 156, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,197] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,234] LMCache INFO:[0m Storing KV cache for 156 out of 156 tokens (skip_leading_tokens=0) for request chatcmpl-17c0939e328b4be1bed5bf7aee20f2ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,235] LMCache INFO:[0m Stored 156 out of total 156 tokens. size: 0.0042 gb, cost 0.4995 ms, throughput: 8.3393 GB/s; offload_time: 0.4095 ms, put_time: 0.0900 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,235] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1746b84cc7d44fb2ad890ef098e5b315 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,236] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0734 ms, throughput: 3.1843 GB/s; offload_time: 1.0135 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,237] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-46146810cc36479dbe18a7d7700c76b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,238] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8466 ms, throughput: 4.0375 GB/s; offload_time: 0.6790 ms, put_time: 0.1676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,243] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,253] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,260] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-021db7dfed2b4801b44a4b2607a5bbe3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,260] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4284 ms, throughput: 7.9782 GB/s; offload_time: 0.3558 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,265] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,273] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-223f22db11d14abf8696dd15c2265e9d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,273] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5674 ms, throughput: 6.0234 GB/s; offload_time: 0.4896 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,274] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-74f34abe1891428599cd08096aebb037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,274] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6794 ms, throughput: 5.0309 GB/s; offload_time: 0.6116 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,279] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,289] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,297] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-125f30c081a14b2099437d51ef71238a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,297] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5490 ms, throughput: 6.2259 GB/s; offload_time: 0.4749 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,298] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-cfc3afedb3cf49f098267360d926ba3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,298] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7310 ms, throughput: 4.6754 GB/s; offload_time: 0.6350 ms, put_time: 0.0961 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,303] LMCache INFO:[0m Reqid: chatcmpl-9424701fe32a4aaeabe54795307e7692, Total tokens 1320, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,304] LMCache INFO:[0m Reqid: chatcmpl-ee6c22f516c047a88c60cd756a3d0d50, Total tokens 220, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,305] LMCache INFO:[0m Reqid: chatcmpl-c1092ed1d7a84c17b6bc3e1db843c2e7, Total tokens 773, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,336] LMCache INFO:[0m Reqid: chatcmpl-c1092ed1d7a84c17b6bc3e1db843c2e7, Total tokens 773, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,343] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-af173868aeb14211ba22a6a0001ed085 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,343] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4684 ms, throughput: 7.2969 GB/s; offload_time: 0.3849 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,357] LMCache INFO:[0m Reqid: chatcmpl-ee6c22f516c047a88c60cd756a3d0d50, Total tokens 222, LMCache hit tokens: 128, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,366] LMCache INFO:[0m Reqid: chatcmpl-ee6c22f516c047a88c60cd756a3d0d50, Total tokens 222, LMCache hit tokens: 128, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,367] LMCache INFO:[0m Reqid: chatcmpl-c1092ed1d7a84c17b6bc3e1db843c2e7, Total tokens 773, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,368] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,391] LMCache INFO:[0m Storing KV cache for 773 out of 773 tokens (skip_leading_tokens=0) for request chatcmpl-c1092ed1d7a84c17b6bc3e1db843c2e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,393] LMCache INFO:[0m Stored 773 out of total 773 tokens. size: 0.0206 gb, cost 2.4217 ms, throughput: 8.5237 GB/s; offload_time: 1.3655 ms, put_time: 1.0562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,402] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,412] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,419] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b3ff257469684f5fbe863ddd2ee1b3a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,420] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4903 ms, throughput: 6.9709 GB/s; offload_time: 0.4076 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,424] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,431] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-e9ed9aae811147668f28bf5c2d392af8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,432] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5457 ms, throughput: 6.2631 GB/s; offload_time: 0.4689 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,436] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,446] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52820 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,456] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52836 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,466] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,473] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-32e436b0a9254c4398203cc7e870baa3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,474] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.3054 ms, throughput: 2.6183 GB/s; offload_time: 1.2299 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,478] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,486] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-ff07b1ddbaee4cac8feba08d4d030d12 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,488] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2727 ms, throughput: 2.6855 GB/s; offload_time: 1.1939 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,488] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-78ff63b0d3664fc7a8751f3c0c851600 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,490] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3800 ms, throughput: 2.4769 GB/s; offload_time: 1.2965 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,494] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,502] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-581208a665894023b6fc52762f40e2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,503] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2227 ms, throughput: 2.7955 GB/s; offload_time: 1.1467 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,507] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,517] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,525] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e4c99553b05146f9a538d0ca84d21a6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,526] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1827 ms, throughput: 2.8900 GB/s; offload_time: 1.1064 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,530] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,538] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-759bbd94f4d743168eba033705585f8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,539] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.2566 ms, throughput: 2.7200 GB/s; offload_time: 1.1802 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,543] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,553] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,563] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,570] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,571] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2057 ms, throughput: 2.8348 GB/s; offload_time: 1.1268 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,575] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,586] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1627, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,587] LMCache INFO:[0m Reqid: chatcmpl-0141fc469f1f42ad843db5b0886cbfac, Total tokens 236, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,616] LMCache INFO:[0m Storing KV cache for 347 out of 1627 tokens (skip_leading_tokens=1280) for request chatcmpl-40fde7c3f2b946c397a1608f69a2558c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,617] LMCache INFO:[0m Stored 347 out of total 1627 tokens. size: 0.0093 gb, cost 0.9281 ms, throughput: 9.9834 GB/s; offload_time: 0.7931 ms, put_time: 0.1350 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,632] LMCache INFO:[0m Reqid: chatcmpl-40fde7c3f2b946c397a1608f69a2558c, Total tokens 1628, LMCache hit tokens: 1627, need to load: 59 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,632] LMCache INFO:[0m Reqid: chatcmpl-0141fc469f1f42ad843db5b0886cbfac, Total tokens 236, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,640] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-d70db0ae058142058cea55d9b5922acd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,640] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4986 ms, throughput: 6.8547 GB/s; offload_time: 0.4159 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,644] LMCache INFO:[0m Reqid: chatcmpl-0141fc469f1f42ad843db5b0886cbfac, Total tokens 236, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,652] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c60081dd700740ebb19da6154112706c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52894 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,652] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5301 ms, throughput: 6.4479 GB/s; offload_time: 0.4545 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,653] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-70cecd401f3e4cffa2d61eefc5769465 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,654] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.7862 ms, throughput: 4.3476 GB/s; offload_time: 0.7196 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,658] LMCache INFO:[0m Reqid: chatcmpl-0141fc469f1f42ad843db5b0886cbfac, Total tokens 236, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,659] LMCache INFO:[0m Reqid: chatcmpl-d527ac080d604b85bbdfedc1ef6a277e, Total tokens 290, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,660] LMCache INFO:[0m Reqid: chatcmpl-24590c9cf6b642f1b0c4a6c4f25341dd, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,660] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 274, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,661] LMCache INFO:[0m Reqid: chatcmpl-4e7a8ba0064647ee8ef1481367b32184, Total tokens 150, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,661] LMCache INFO:[0m Reqid: chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb, Total tokens 190, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,684] LMCache INFO:[0m Storing KV cache for 236 out of 236 tokens (skip_leading_tokens=0) for request chatcmpl-0141fc469f1f42ad843db5b0886cbfac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,685] LMCache INFO:[0m Stored 236 out of total 236 tokens. size: 0.0063 gb, cost 0.6701 ms, throughput: 9.4047 GB/s; offload_time: 0.5550 ms, put_time: 0.1151 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,685] LMCache INFO:[0m Storing KV cache for 162 out of 290 tokens (skip_leading_tokens=128) for request chatcmpl-d527ac080d604b85bbdfedc1ef6a277e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,687] LMCache INFO:[0m Stored 162 out of total 290 tokens. size: 0.0043 gb, cost 1.3644 ms, throughput: 3.1704 GB/s; offload_time: 1.2674 ms, put_time: 0.0971 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,687] LMCache INFO:[0m Storing KV cache for 146 out of 274 tokens (skip_leading_tokens=128) for request chatcmpl-5c329c78e8e143e8924dddd745a6f955 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,690] LMCache INFO:[0m Stored 146 out of total 274 tokens. size: 0.0039 gb, cost 2.0311 ms, throughput: 1.9195 GB/s; offload_time: 1.7989 ms, put_time: 0.2322 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,691] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f0f908196129408d986369c40bf81a3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,693] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.5143 ms, throughput: 1.3594 GB/s; offload_time: 2.4375 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,698] LMCache INFO:[0m Reqid: chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb, Total tokens 190, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,717] LMCache INFO:[0m Reqid: chatcmpl-4e7a8ba0064647ee8ef1481367b32184, Total tokens 152, LMCache hit tokens: 128, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,735] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 278, LMCache hit tokens: 274, need to load: 114 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,745] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 278, LMCache hit tokens: 274, need to load: 178 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,754] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 278, LMCache hit tokens: 274, need to load: 226 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,754] LMCache INFO:[0m Reqid: chatcmpl-4e7a8ba0064647ee8ef1481367b32184, Total tokens 152, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,755] LMCache INFO:[0m Reqid: chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb, Total tokens 190, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,755] LMCache INFO:[0m Reqid: chatcmpl-3fc7dbb6eea647b79d9f163760926816, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,756] LMCache INFO:[0m Reqid: chatcmpl-87a4618c643f4c7b8cbac13e70c9c9df, Total tokens 152, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,757] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,772] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-3fc7dbb6eea647b79d9f163760926816 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,773] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.4163 ms, throughput: 6.9278 GB/s; offload_time: 0.3383 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,773] LMCache INFO:[0m Storing KV cache for 152 out of 152 tokens (skip_leading_tokens=0) for request chatcmpl-87a4618c643f4c7b8cbac13e70c9c9df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,775] LMCache INFO:[0m Stored 152 out of total 152 tokens. size: 0.0041 gb, cost 2.2206 ms, throughput: 1.8278 GB/s; offload_time: 2.1137 ms, put_time: 0.1070 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,781] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,788] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-62bf38511e9c49e58a03f2f18ee58e7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,790] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1907 ms, throughput: 2.8706 GB/s; offload_time: 1.1139 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,794] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,804] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,811] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6507d6757f084a8887aee44d17ef5140 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,812] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2775 ms, throughput: 2.6755 GB/s; offload_time: 1.1964 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,817] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,824] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e07785c78a8148afb31249948eb30b50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,825] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1770 ms, throughput: 2.9039 GB/s; offload_time: 1.0804 ms, put_time: 0.0966 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,839] LMCache INFO:[0m Reqid: chatcmpl-87a4618c643f4c7b8cbac13e70c9c9df, Total tokens 157, LMCache hit tokens: 152, need to load: 72 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,855] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,857] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2555 ms, throughput: 2.7224 GB/s; offload_time: 1.1841 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,857] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-6fac4c7103d04c21b39bceaabc025747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,859] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4910 ms, throughput: 2.2924 GB/s; offload_time: 1.4244 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,880] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-8bcb9a0f6e474a5c8bb6e8d99e713830 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,881] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2870 ms, throughput: 2.6558 GB/s; offload_time: 1.2090 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,881] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-44ede6547a5c4ff9a2945f2087c2ff31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,883] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5084 ms, throughput: 2.2660 GB/s; offload_time: 1.4396 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,887] LMCache INFO:[0m Reqid: chatcmpl-4e7a8ba0064647ee8ef1481367b32184, Total tokens 161, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,906] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 289, LMCache hit tokens: 274, need to load: 98 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,915] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 289, LMCache hit tokens: 274, need to load: 162 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,922] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0141fc469f1f42ad843db5b0886cbfac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,923] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1550 ms, throughput: 2.9593 GB/s; offload_time: 1.0824 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:05,927] LMCache INFO:[0m Reqid: chatcmpl-5c329c78e8e143e8924dddd745a6f955, Total tokens 289, LMCache hit tokens: 274, need to load: 226 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,928] LMCache INFO:[0m Reqid: chatcmpl-4e7a8ba0064647ee8ef1481367b32184, Total tokens 161, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,928] LMCache INFO:[0m Reqid: chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb, Total tokens 198, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,928] LMCache INFO:[0m Reqid: chatcmpl-3fc7dbb6eea647b79d9f163760926816, Total tokens 115, LMCache hit tokens: 108, need to load: 60 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:05,944] LMCache INFO:[0m Reqid: chatcmpl-3fc7dbb6eea647b79d9f163760926816, Total tokens 115, LMCache hit tokens: 108, need to load: 60 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,944] LMCache INFO:[0m Reqid: chatcmpl-87a4618c643f4c7b8cbac13e70c9c9df, Total tokens 157, LMCache hit tokens: 152, need to load: 104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,945] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,958] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,968] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,977] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,987] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:05,997] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,006] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,016] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,026] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,033] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-460c831c44d74ca2af33a299afdbefb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,035] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2766 ms, throughput: 2.6775 GB/s; offload_time: 1.2027 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,039] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,049] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,059] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,069] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,077] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e3b86b2941bd48ca90dcf95bb45db659 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,078] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1991 ms, throughput: 2.8504 GB/s; offload_time: 1.1227 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,078] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,080] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.7345 ms, throughput: 1.9706 GB/s; offload_time: 1.6657 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,081] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-40fde7c3f2b946c397a1608f69a2558c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,083] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.8289 ms, throughput: 1.8689 GB/s; offload_time: 1.5862 ms, put_time: 0.2427 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,087] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,095] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3fc7dbb6eea647b79d9f163760926816 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,096] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1944 ms, throughput: 2.8618 GB/s; offload_time: 1.1174 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,100] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,107] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-abb1c3e8e5cb4aae968e5cffc2f59a77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,109] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2079 ms, throughput: 2.8296 GB/s; offload_time: 1.1326 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,113] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,120] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,122] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1943 ms, throughput: 2.8619 GB/s; offload_time: 1.1186 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,126] LMCache INFO:[0m Reqid: chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206, Total tokens 1591, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,128] LMCache INFO:[0m Reqid: chatcmpl-36b65bb6671548769d1fb3681b2f4116, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,128] LMCache INFO:[0m Reqid: chatcmpl-0ae1fad60b3d43358d0b1940ea0eb8da, Total tokens 310, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,129] LMCache INFO:[0m Reqid: chatcmpl-b1464e1a3303450483011d6291b44247, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,130] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52964 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,158] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-36b65bb6671548769d1fb3681b2f4116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,159] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.4342 ms, throughput: 6.2114 GB/s; offload_time: 0.3588 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,160] LMCache INFO:[0m Storing KV cache for 310 out of 310 tokens (skip_leading_tokens=0) for request chatcmpl-0ae1fad60b3d43358d0b1940ea0eb8da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,161] LMCache INFO:[0m Stored 310 out of total 310 tokens. size: 0.0083 gb, cost 1.1222 ms, throughput: 7.3765 GB/s; offload_time: 0.9857 ms, put_time: 0.1365 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,161] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-b1464e1a3303450483011d6291b44247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,163] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 1.4554 ms, throughput: 1.9998 GB/s; offload_time: 1.3012 ms, put_time: 0.1542 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,163] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f7b8d1290df94fe58da693c87564b960 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,164] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6159 ms, throughput: 5.5492 GB/s; offload_time: 0.5451 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,171] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,182] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,191] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,201] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,208] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-de086c29dd7044249dbb21504fb797de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,209] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4622 ms, throughput: 7.3950 GB/s; offload_time: 0.3893 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,209] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9ad356d5afff4e719f830ced469f229a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,210] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7302 ms, throughput: 4.6809 GB/s; offload_time: 0.6620 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,215] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,222] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-db3f95fac1ce4a1983c118109a213937 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,224] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2883 ms, throughput: 2.6530 GB/s; offload_time: 1.2052 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,229] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,238] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,245] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0fce6169d9ff40cfb301ab89171bd156 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,247] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2439 ms, throughput: 2.7477 GB/s; offload_time: 1.1671 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,251] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,261] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,271] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,278] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c897241b787443b2a14e0dd3a9c920e6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,279] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2128 ms, throughput: 2.8183 GB/s; offload_time: 1.1387 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,279] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4b34a105c5ce4ceda37b9934c4d5a2a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,281] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3798 ms, throughput: 2.4772 GB/s; offload_time: 1.2859 ms, put_time: 0.0938 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,286] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,296] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,305] LMCache INFO:[0m Reqid: chatcmpl-65f561c51f9f4b358e2af67c8223c7a7, Total tokens 1649, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,307] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,342] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f5d302be5704490bb22fbd3ee15f2b91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,342] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5011 ms, throughput: 6.8215 GB/s; offload_time: 0.4291 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,347] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,357] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,366] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,373] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c3ec9c08f01c4b2287c4248aa7cc2298 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,374] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4894 ms, throughput: 6.9847 GB/s; offload_time: 0.4144 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,374] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-678cb04b65dd434184374fc890775a6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,375] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7113 ms, throughput: 4.8052 GB/s; offload_time: 0.6413 ms, put_time: 0.0700 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,379] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,387] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,388] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5540 ms, throughput: 6.1695 GB/s; offload_time: 0.4776 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,392] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,402] LMCache INFO:[0m Reqid: chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c, Total tokens 1616, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,403] LMCache INFO:[0m Reqid: chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1, Total tokens 387, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,438] LMCache INFO:[0m Reqid: chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1, Total tokens 387, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,438] LMCache INFO:[0m Reqid: chatcmpl-9aff1ed8569d4d1685f950554af6347b, Total tokens 295, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,439] LMCache INFO:[0m Reqid: chatcmpl-9e22a00ea5184746ae716d5ac80e4d83, Total tokens 168, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,439] LMCache INFO:[0m Reqid: chatcmpl-d3529258d8a94cfc85e936a836f1b1bc, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,439] LMCache INFO:[0m Reqid: chatcmpl-544a67fb391a47de95e182d3656c3d6f, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,440] LMCache INFO:[0m Reqid: chatcmpl-fea0348cf43a46fd94f1000451ad5630, Total tokens 133, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,440] LMCache INFO:[0m Reqid: chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02, Total tokens 431, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,441] LMCache INFO:[0m Reqid: chatcmpl-1b238ead0085445092d9c7f23e739f44, Total tokens 670, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,441] LMCache INFO:[0m Reqid: chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15, Total tokens 128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,442] LMCache INFO:[0m Reqid: chatcmpl-4f941fc3bf614c8b8441e5533926f8bf, Total tokens 313, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,471] LMCache INFO:[0m Storing KV cache for 131 out of 387 tokens (skip_leading_tokens=256) for request chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,472] LMCache INFO:[0m Stored 131 out of total 387 tokens. size: 0.0035 gb, cost 0.6302 ms, throughput: 5.5504 GB/s; offload_time: 0.5239 ms, put_time: 0.1063 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,472] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-d3529258d8a94cfc85e936a836f1b1bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,473] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 1.1462 ms, throughput: 2.4461 GB/s; offload_time: 1.0536 ms, put_time: 0.0926 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,474] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-544a67fb391a47de95e182d3656c3d6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,476] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.8367 ms, throughput: 3.0956 GB/s; offload_time: 0.7571 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,477] LMCache INFO:[0m Storing KV cache for 133 out of 133 tokens (skip_leading_tokens=0) for request chatcmpl-fea0348cf43a46fd94f1000451ad5630 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,478] LMCache INFO:[0m Stored 133 out of total 133 tokens. size: 0.0036 gb, cost 1.4316 ms, throughput: 2.4807 GB/s; offload_time: 1.2581 ms, put_time: 0.1735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,479] LMCache INFO:[0m Storing KV cache for 175 out of 431 tokens (skip_leading_tokens=256) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,480] LMCache INFO:[0m Stored 175 out of total 431 tokens. size: 0.0047 gb, cost 1.4455 ms, throughput: 3.2328 GB/s; offload_time: 1.2367 ms, put_time: 0.2088 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,481] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,482] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0054 ms, throughput: 3.3998 GB/s; offload_time: 0.9201 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,487] LMCache INFO:[0m Reqid: chatcmpl-4f941fc3bf614c8b8441e5533926f8bf, Total tokens 313, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,488] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 919, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,503] LMCache INFO:[0m Storing KV cache for 185 out of 313 tokens (skip_leading_tokens=128) for request chatcmpl-4f941fc3bf614c8b8441e5533926f8bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,504] LMCache INFO:[0m Stored 185 out of total 313 tokens. size: 0.0049 gb, cost 0.6335 ms, throughput: 7.7974 GB/s; offload_time: 0.5287 ms, put_time: 0.1049 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,504] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-ce11b90819d1470ca140c2e507fd4d78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,506] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3194 ms, throughput: 2.5905 GB/s; offload_time: 1.2407 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,511] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 919, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,521] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 919, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,531] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 919, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,532] LMCache INFO:[0m Reqid: chatcmpl-41f3373eca704fe5a2ae7689a8c0387c, Total tokens 819, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,552] LMCache INFO:[0m Storing KV cache for 151 out of 919 tokens (skip_leading_tokens=768) for request chatcmpl-1c1282ce28f145038a4f462c3c4f3898 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,553] LMCache INFO:[0m Stored 151 out of total 919 tokens. size: 0.0040 gb, cost 0.6623 ms, throughput: 6.0879 GB/s; offload_time: 0.5591 ms, put_time: 0.1032 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,554] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-075be102a3134b1a88b338d29a48916b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,555] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4453 ms, throughput: 2.3648 GB/s; offload_time: 1.3807 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,567] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-9424701fe32a4aaeabe54795307e7692 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,568] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5281 ms, throughput: 6.4721 GB/s; offload_time: 0.4548 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,572] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 135 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,582] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 231 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,589] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-36b65bb6671548769d1fb3681b2f4116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,589] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4313 ms, throughput: 7.9256 GB/s; offload_time: 0.3577 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,593] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 279 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,601] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,602] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5623 ms, throughput: 6.0783 GB/s; offload_time: 0.4813 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,606] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 407 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,616] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 487 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,626] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 567 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,633] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-510cc852edc1415dacbea79c024c5f30 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,634] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.2101 ms, throughput: 2.8246 GB/s; offload_time: 1.1381 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,635] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-17c0939e328b4be1bed5bf7aee20f2ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,636] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4116 ms, throughput: 2.4214 GB/s; offload_time: 1.3229 ms, put_time: 0.0886 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,641] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 647 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,648] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-14e50578d3564434a43cbae4692cf727 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,650] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1910 ms, throughput: 2.8699 GB/s; offload_time: 1.1155 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,654] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 759 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,663] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 839 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,670] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-746a09e3c7b44a6b9fd2826603343482 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,672] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1419 ms, throughput: 2.9933 GB/s; offload_time: 1.0670 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,676] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 855 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,686] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,693] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8d16741c8402453fbe71bfd6b591e79a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,694] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2345 ms, throughput: 2.7686 GB/s; offload_time: 1.1541 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,699] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,706] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0b34eddc735c4338ac161f1e5f217b23 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,708] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1846 ms, throughput: 2.8853 GB/s; offload_time: 1.1114 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,712] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,721] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,731] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,740] LMCache INFO:[0m Reqid: chatcmpl-1c1282ce28f145038a4f462c3c4f3898, Total tokens 920, LMCache hit tokens: 919, need to load: 871 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,740] LMCache INFO:[0m Reqid: chatcmpl-41f3373eca704fe5a2ae7689a8c0387c, Total tokens 819, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,748] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-892e6ad5e7c34a609ccb90d25c94adcb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,749] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0548 ms, throughput: 3.2403 GB/s; offload_time: 0.9903 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,749] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3aa33406f8ba47a286778d0a36d14bac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,751] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3484 ms, throughput: 2.5348 GB/s; offload_time: 1.2852 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,751] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,752] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1874 ms, throughput: 2.8784 GB/s; offload_time: 1.0745 ms, put_time: 0.1129 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,756] LMCache INFO:[0m Reqid: chatcmpl-41f3373eca704fe5a2ae7689a8c0387c, Total tokens 819, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,757] LMCache INFO:[0m Reqid: chatcmpl-70cd959aca2240d884936018bd299468, Total tokens 364, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,758] LMCache INFO:[0m Reqid: chatcmpl-1cd8c28ded1a4ba09401ce0e143af581, Total tokens 142, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,759] LMCache INFO:[0m Reqid: chatcmpl-b7dae668b3824ce88ef4232f477d919d, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,759] LMCache INFO:[0m Reqid: chatcmpl-039cd03d86d640f5ac3212eb3f186b66, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,779] LMCache INFO:[0m Storing KV cache for 179 out of 819 tokens (skip_leading_tokens=640) for request chatcmpl-41f3373eca704fe5a2ae7689a8c0387c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,780] LMCache INFO:[0m Stored 179 out of total 819 tokens. size: 0.0048 gb, cost 0.7120 ms, throughput: 6.7132 GB/s; offload_time: 0.6075 ms, put_time: 0.1045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,780] LMCache INFO:[0m Storing KV cache for 142 out of 142 tokens (skip_leading_tokens=0) for request chatcmpl-1cd8c28ded1a4ba09401ce0e143af581 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,782] LMCache INFO:[0m Stored 142 out of total 142 tokens. size: 0.0038 gb, cost 1.8776 ms, throughput: 2.0195 GB/s; offload_time: 1.6994 ms, put_time: 0.1782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,783] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-b7dae668b3824ce88ef4232f477d919d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,784] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.8554 ms, throughput: 3.0593 GB/s; offload_time: 0.7887 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,784] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-7860033fdd2c40cbb603e1dd3598ce78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,787] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7773 ms, throughput: 1.9231 GB/s; offload_time: 1.5216 ms, put_time: 0.2557 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,799] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d3529258d8a94cfc85e936a836f1b1bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,800] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9806 ms, throughput: 3.4856 GB/s; offload_time: 0.9150 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,810] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,811] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.0991 ms, throughput: 3.1097 GB/s; offload_time: 1.0361 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,814] LMCache INFO:[0m Reqid: chatcmpl-1cd8c28ded1a4ba09401ce0e143af581, Total tokens 144, LMCache hit tokens: 142, need to load: 94 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,815] LMCache INFO:[0m Reqid: chatcmpl-b7dae668b3824ce88ef4232f477d919d, Total tokens 99, LMCache hit tokens: 98, need to load: 50 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,815] LMCache INFO:[0m Reqid: chatcmpl-039cd03d86d640f5ac3212eb3f186b66, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,817] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,830] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-039cd03d86d640f5ac3212eb3f186b66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,831] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.3418 ms, throughput: 8.0464 GB/s; offload_time: 0.2824 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,841] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,850] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,857] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-421c198ea03a4e3389bdfb7222c7bb98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,858] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0166 ms, throughput: 3.3621 GB/s; offload_time: 0.9537 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,862] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,878] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d99b06e63492486ea0cb38e809d4e208 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,879] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9860 ms, throughput: 3.4665 GB/s; offload_time: 0.9203 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,880] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-2bf45d73cb19497bb58c91c13794e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,881] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5866 ms, throughput: 2.1543 GB/s; offload_time: 1.5253 ms, put_time: 0.0613 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,894] LMCache INFO:[0m Reqid: chatcmpl-1cd8c28ded1a4ba09401ce0e143af581, Total tokens 149, LMCache hit tokens: 142, need to load: 46 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,901] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-544a67fb391a47de95e182d3656c3d6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,902] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9532 ms, throughput: 3.5858 GB/s; offload_time: 0.8845 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,905] LMCache INFO:[0m Reqid: chatcmpl-1cd8c28ded1a4ba09401ce0e143af581, Total tokens 149, LMCache hit tokens: 142, need to load: 94 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,912] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-28921425465248c5bc3ebef4b0cf8255 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,913] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0493 ms, throughput: 3.2573 GB/s; offload_time: 0.9766 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,924] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1891ff4756334e3199ea5f7d0ea1466e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,925] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0562 ms, throughput: 3.2360 GB/s; offload_time: 0.9915 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,928] LMCache INFO:[0m Reqid: chatcmpl-70cd959aca2240d884936018bd299468, Total tokens 375, LMCache hit tokens: 256, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,929] LMCache INFO:[0m Reqid: chatcmpl-1cd8c28ded1a4ba09401ce0e143af581, Total tokens 149, LMCache hit tokens: 142, need to load: 94 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,929] LMCache INFO:[0m Reqid: chatcmpl-b7dae668b3824ce88ef4232f477d919d, Total tokens 103, LMCache hit tokens: 98, need to load: 50 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,929] LMCache INFO:[0m Reqid: chatcmpl-039cd03d86d640f5ac3212eb3f186b66, Total tokens 107, LMCache hit tokens: 103, need to load: 55 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,930] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,945] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,951] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-12c6b6b9ac5f4f3ab29372ab5190c4ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,953] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.0381 ms, throughput: 3.2925 GB/s; offload_time: 0.9758 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,956] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,963] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-4068ed711a21481a944bcbf28e36812e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,965] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0459 ms, throughput: 3.2681 GB/s; offload_time: 0.9826 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,965] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d527ac080d604b85bbdfedc1ef6a277e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,966] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1998 ms, throughput: 2.8488 GB/s; offload_time: 1.1327 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:06,970] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,980] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,987] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,988] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0360 ms, throughput: 3.2993 GB/s; offload_time: 0.9725 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:36968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:06,992] LMCache INFO:[0m Reqid: chatcmpl-ce7e332191734512b674a77575df7865, Total tokens 2009, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,993] LMCache INFO:[0m Reqid: chatcmpl-cac0948b9a5648f58ccbd30c020c36c6, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:06,994] LMCache INFO:[0m Reqid: chatcmpl-3b0af34610ca4283803d05803e4b2944, Total tokens 1286, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,032] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-cac0948b9a5648f58ccbd30c020c36c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,032] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.3348 ms, throughput: 8.3734 GB/s; offload_time: 0.2728 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,032] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-46146810cc36479dbe18a7d7700c76b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,034] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7230 ms, throughput: 4.7274 GB/s; offload_time: 0.6657 ms, put_time: 0.0573 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,038] LMCache INFO:[0m Reqid: chatcmpl-3b0af34610ca4283803d05803e4b2944, Total tokens 1286, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,047] LMCache INFO:[0m Reqid: chatcmpl-3b0af34610ca4283803d05803e4b2944, Total tokens 1286, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,054] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-021db7dfed2b4801b44a4b2607a5bbe3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,055] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3661 ms, throughput: 9.3356 GB/s; offload_time: 0.3042 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,058] LMCache INFO:[0m Reqid: chatcmpl-3b0af34610ca4283803d05803e4b2944, Total tokens 1286, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,068] LMCache INFO:[0m Reqid: chatcmpl-3b0af34610ca4283803d05803e4b2944, Total tokens 1286, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,068] LMCache INFO:[0m Reqid: chatcmpl-2461622fca8847af80252285804d4cfb, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,069] LMCache INFO:[0m Reqid: chatcmpl-a6953e4974b44db9864f7c3c7d0da8a5, Total tokens 629, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,069] LMCache INFO:[0m Reqid: chatcmpl-90fb645ac39d4f8dbdc217e93d5ce4bf, Total tokens 165, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,070] LMCache INFO:[0m Reqid: chatcmpl-6ad8dc3faca74e32b182dea3af584a69, Total tokens 375, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,101] LMCache INFO:[0m Storing KV cache for 134 out of 1286 tokens (skip_leading_tokens=1152) for request chatcmpl-3b0af34610ca4283803d05803e4b2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,102] LMCache INFO:[0m Stored 134 out of total 1286 tokens. size: 0.0036 gb, cost 0.5785 ms, throughput: 6.1851 GB/s; offload_time: 0.4907 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,102] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,103] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.5171 ms, throughput: 5.2152 GB/s; offload_time: 0.4392 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,103] LMCache INFO:[0m Storing KV cache for 501 out of 629 tokens (skip_leading_tokens=128) for request chatcmpl-a6953e4974b44db9864f7c3c7d0da8a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,105] LMCache INFO:[0m Stored 501 out of total 629 tokens. size: 0.0134 gb, cost 1.6336 ms, throughput: 8.1892 GB/s; offload_time: 1.4087 ms, put_time: 0.2249 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,105] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-70cd959aca2240d884936018bd299468 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,108] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.3453 ms, throughput: 1.4574 GB/s; offload_time: 2.2605 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,121] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-125f30c081a14b2099437d51ef71238a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,121] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4808 ms, throughput: 7.1094 GB/s; offload_time: 0.4114 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,122] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c1092ed1d7a84c17b6bc3e1db843c2e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,122] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6142 ms, throughput: 5.5651 GB/s; offload_time: 0.5614 ms, put_time: 0.0528 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,135] LMCache INFO:[0m Reqid: chatcmpl-a6953e4974b44db9864f7c3c7d0da8a5, Total tokens 631, LMCache hit tokens: 629, need to load: 101 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,135] LMCache INFO:[0m Reqid: chatcmpl-90fb645ac39d4f8dbdc217e93d5ce4bf, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,136] LMCache INFO:[0m Reqid: chatcmpl-6ad8dc3faca74e32b182dea3af584a69, Total tokens 375, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,136] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,152] LMCache INFO:[0m Storing KV cache for 375 out of 375 tokens (skip_leading_tokens=0) for request chatcmpl-6ad8dc3faca74e32b182dea3af584a69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,153] LMCache INFO:[0m Stored 375 out of total 375 tokens. size: 0.0100 gb, cost 0.7184 ms, throughput: 13.9390 GB/s; offload_time: 0.6128 ms, put_time: 0.1056 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,157] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,165] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,166] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4718 ms, throughput: 7.2452 GB/s; offload_time: 0.4085 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,170] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,180] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,189] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,198] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,208] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,214] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-e9ed9aae811147668f28bf5c2d392af8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,215] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4600 ms, throughput: 7.4307 GB/s; offload_time: 0.3978 ms, put_time: 0.0622 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,219] LMCache INFO:[0m Reqid: chatcmpl-9fdd1675e9be4ee1bccc038fe694abd7, Total tokens 1015, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,220] LMCache INFO:[0m Reqid: chatcmpl-7770976043cc4497a239256f6f3c075a, Total tokens 837, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,244] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-3cb5ec4dc4b048e6a2253205f0e75206 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,245] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4757 ms, throughput: 7.1852 GB/s; offload_time: 0.4055 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,249] LMCache INFO:[0m Reqid: chatcmpl-7770976043cc4497a239256f6f3c075a, Total tokens 837, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,251] LMCache INFO:[0m Reqid: chatcmpl-42d145d71c004b0bb0701bd0573da095, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,273] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0ae1fad60b3d43358d0b1940ea0eb8da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,274] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4923 ms, throughput: 6.9434 GB/s; offload_time: 0.4122 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,278] LMCache INFO:[0m Reqid: chatcmpl-42d145d71c004b0bb0701bd0573da095, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,279] LMCache INFO:[0m Reqid: chatcmpl-3dfdc664e67e4039bb3de1922770bf65, Total tokens 163, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,280] LMCache INFO:[0m Reqid: chatcmpl-280ed666fbe04c5590a5d35bf604e911, Total tokens 335, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,280] LMCache INFO:[0m Reqid: chatcmpl-c9495be01d614ce1854de65d7cbf6b55, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,281] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1056, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,310] LMCache INFO:[0m Storing KV cache for 163 out of 163 tokens (skip_leading_tokens=0) for request chatcmpl-3dfdc664e67e4039bb3de1922770bf65 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,311] LMCache INFO:[0m Stored 163 out of total 163 tokens. size: 0.0044 gb, cost 0.6674 ms, throughput: 6.5214 GB/s; offload_time: 0.5639 ms, put_time: 0.1036 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,311] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-c9495be01d614ce1854de65d7cbf6b55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,312] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 1.0267 ms, throughput: 2.7570 GB/s; offload_time: 0.9460 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,312] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-039cd03d86d640f5ac3212eb3f186b66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,313] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6835 ms, throughput: 5.0010 GB/s; offload_time: 0.6127 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,313] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a6953e4974b44db9864f7c3c7d0da8a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,314] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6895 ms, throughput: 4.9575 GB/s; offload_time: 0.6201 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,315] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6ad8dc3faca74e32b182dea3af584a69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,316] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1635 ms, throughput: 2.9376 GB/s; offload_time: 1.0922 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,321] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1056, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,322] LMCache INFO:[0m Reqid: chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea, Total tokens 131, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,323] LMCache INFO:[0m Reqid: chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e, Total tokens 205, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,323] LMCache INFO:[0m Reqid: chatcmpl-643f837cc9e74a48a27414b31168cd37, Total tokens 216, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,349] LMCache INFO:[0m Storing KV cache for 131 out of 131 tokens (skip_leading_tokens=0) for request chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,350] LMCache INFO:[0m Stored 131 out of total 131 tokens. size: 0.0035 gb, cost 0.6681 ms, throughput: 5.2359 GB/s; offload_time: 0.5596 ms, put_time: 0.1085 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,351] LMCache INFO:[0m Storing KV cache for 205 out of 205 tokens (skip_leading_tokens=0) for request chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,352] LMCache INFO:[0m Stored 205 out of total 205 tokens. size: 0.0055 gb, cost 1.1596 ms, throughput: 4.7206 GB/s; offload_time: 1.0099 ms, put_time: 0.1497 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,353] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-32e436b0a9254c4398203cc7e870baa3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,354] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1164 ms, throughput: 3.0615 GB/s; offload_time: 1.0462 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:36802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,367] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-78ff63b0d3664fc7a8751f3c0c851600 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,367] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4932 ms, throughput: 6.9308 GB/s; offload_time: 0.4113 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,372] LMCache INFO:[0m Reqid: chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e, Total tokens 206, LMCache hit tokens: 205, need to load: 93 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:37026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,379] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-581208a665894023b6fc52762f40e2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,380] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5083 ms, throughput: 6.7249 GB/s; offload_time: 0.4327 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,380] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4e7a8ba0064647ee8ef1481367b32184 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,381] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5972 ms, throughput: 5.7238 GB/s; offload_time: 0.5334 ms, put_time: 0.0638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53032 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,386] LMCache INFO:[0m Reqid: chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e, Total tokens 206, LMCache hit tokens: 205, need to load: 141 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,392] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-b7dae668b3824ce88ef4232f477d919d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,394] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1844 ms, throughput: 2.8857 GB/s; offload_time: 1.1083 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,415] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-759bbd94f4d743168eba033705585f8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,416] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2721 ms, throughput: 2.6868 GB/s; offload_time: 1.1986 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,421] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1061, LMCache hit tokens: 1024, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,428] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-cac0948b9a5648f58ccbd30c020c36c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,429] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1786 ms, throughput: 2.9000 GB/s; offload_time: 1.1015 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,433] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1061, LMCache hit tokens: 1024, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,440] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-87a4618c643f4c7b8cbac13e70c9c9df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,442] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1814 ms, throughput: 2.8931 GB/s; offload_time: 1.1076 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,446] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1061, LMCache hit tokens: 1024, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,453] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,454] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2045 ms, throughput: 2.8377 GB/s; offload_time: 1.1278 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,459] LMCache INFO:[0m Reqid: chatcmpl-8afe9b0553394f978ce146e5ea228e09, Total tokens 1061, LMCache hit tokens: 1024, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,460] LMCache INFO:[0m Reqid: chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea, Total tokens 135, LMCache hit tokens: 131, need to load: 83 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,460] LMCache INFO:[0m Reqid: chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e, Total tokens 206, LMCache hit tokens: 205, need to load: 157 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,460] LMCache INFO:[0m Reqid: chatcmpl-643f837cc9e74a48a27414b31168cd37, Total tokens 216, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,461] LMCache INFO:[0m Reqid: chatcmpl-39b88047342b40f2898fe6c499109a50, Total tokens 897, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,476] LMCache INFO:[0m Storing KV cache for 216 out of 216 tokens (skip_leading_tokens=0) for request chatcmpl-643f837cc9e74a48a27414b31168cd37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,477] LMCache INFO:[0m Stored 216 out of total 216 tokens. size: 0.0058 gb, cost 1.3984 ms, throughput: 4.1245 GB/s; offload_time: 1.2889 ms, put_time: 0.1095 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,492] LMCache INFO:[0m Reqid: chatcmpl-643f837cc9e74a48a27414b31168cd37, Total tokens 217, LMCache hit tokens: 216, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,501] LMCache INFO:[0m Reqid: chatcmpl-643f837cc9e74a48a27414b31168cd37, Total tokens 217, LMCache hit tokens: 216, need to load: 104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,517] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c60081dd700740ebb19da6154112706c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,518] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2858 ms, throughput: 2.6583 GB/s; offload_time: 1.1999 ms, put_time: 0.0859 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,522] LMCache INFO:[0m Reqid: chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e, Total tokens 210, LMCache hit tokens: 205, need to load: 109 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,523] LMCache INFO:[0m Reqid: chatcmpl-643f837cc9e74a48a27414b31168cd37, Total tokens 217, LMCache hit tokens: 216, need to load: 168 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,524] LMCache INFO:[0m Reqid: chatcmpl-39b88047342b40f2898fe6c499109a50, Total tokens 897, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,535] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f0f908196129408d986369c40bf81a3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,537] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2691 ms, throughput: 2.6931 GB/s; offload_time: 1.1834 ms, put_time: 0.0858 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,537] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,539] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4206 ms, throughput: 2.4061 GB/s; offload_time: 1.3404 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,543] LMCache INFO:[0m Reqid: chatcmpl-39b88047342b40f2898fe6c499109a50, Total tokens 897, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,553] LMCache INFO:[0m Reqid: chatcmpl-39b88047342b40f2898fe6c499109a50, Total tokens 897, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,554] LMCache INFO:[0m Reqid: chatcmpl-fcf8fddd58894dc887583af77012b203, Total tokens 1066, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,578] LMCache INFO:[0m Storing KV cache for 129 out of 897 tokens (skip_leading_tokens=768) for request chatcmpl-39b88047342b40f2898fe6c499109a50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,578] LMCache INFO:[0m Stored 129 out of total 897 tokens. size: 0.0034 gb, cost 0.6634 ms, throughput: 5.1927 GB/s; offload_time: 0.5481 ms, put_time: 0.1153 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,579] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4f941fc3bf614c8b8441e5533926f8bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,580] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9639 ms, throughput: 3.5461 GB/s; offload_time: 0.7992 ms, put_time: 0.1646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,586] LMCache INFO:[0m Reqid: chatcmpl-fcf8fddd58894dc887583af77012b203, Total tokens 1066, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,587] LMCache INFO:[0m Reqid: chatcmpl-467a40cfd8f44a4184ac48e8475df438, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,587] LMCache INFO:[0m Reqid: chatcmpl-dbbc92f313c644be9bedb18d43aea0ab, Total tokens 369, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,588] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,613] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-467a40cfd8f44a4184ac48e8475df438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,613] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.3965 ms, throughput: 7.2060 GB/s; offload_time: 0.3222 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,618] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,629] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,638] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,648] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,654] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c9495be01d614ce1854de65d7cbf6b55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,655] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4240 ms, throughput: 8.0610 GB/s; offload_time: 0.3498 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,660] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,667] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-ce7e332191734512b674a77575df7865 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,667] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.5668 ms, throughput: 6.0305 GB/s; offload_time: 0.4856 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,672] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,682] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,689] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6507d6757f084a8887aee44d17ef5140 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,690] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4981 ms, throughput: 6.8621 GB/s; offload_time: 0.4260 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,694] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,701] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e07785c78a8148afb31249948eb30b50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,702] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4686 ms, throughput: 7.2947 GB/s; offload_time: 0.3913 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,702] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,704] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.6174 ms, throughput: 2.1133 GB/s; offload_time: 1.5435 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,709] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,718] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,728] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,735] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,737] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3506 ms, throughput: 2.5308 GB/s; offload_time: 1.2741 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,737] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-6fac4c7103d04c21b39bceaabc025747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,739] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5695 ms, throughput: 2.1777 GB/s; offload_time: 1.4992 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,743] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,753] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,763] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,772] LMCache INFO:[0m Reqid: chatcmpl-31022f2973b9414a84fa6602360c71b7, Total tokens 929, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,773] LMCache INFO:[0m Reqid: chatcmpl-f353c33f6a81404fa223317b12da8b7d, Total tokens 392, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,774] LMCache INFO:[0m Reqid: chatcmpl-4524c6a1f5984bfaaaf2ee985e45cb6d, Total tokens 747, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,800] LMCache INFO:[0m Storing KV cache for 136 out of 392 tokens (skip_leading_tokens=256) for request chatcmpl-f353c33f6a81404fa223317b12da8b7d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,800] LMCache INFO:[0m Stored 136 out of total 392 tokens. size: 0.0036 gb, cost 0.6653 ms, throughput: 5.4585 GB/s; offload_time: 0.5582 ms, put_time: 0.1071 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,801] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dbbc92f313c644be9bedb18d43aea0ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,802] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3373 ms, throughput: 2.5558 GB/s; offload_time: 1.2112 ms, put_time: 0.1261 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,807] LMCache INFO:[0m Reqid: chatcmpl-4524c6a1f5984bfaaaf2ee985e45cb6d, Total tokens 747, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,808] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,823] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9aff1ed8569d4d1685f950554af6347b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,823] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4884 ms, throughput: 6.9989 GB/s; offload_time: 0.4090 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,824] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-42d145d71c004b0bb0701bd0573da095 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,825] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0037 ms, throughput: 3.4054 GB/s; offload_time: 0.9363 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,829] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,836] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0141fc469f1f42ad843db5b0886cbfac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,837] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4621 ms, throughput: 7.3971 GB/s; offload_time: 0.3857 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,841] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53096 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53128 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,851] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,860] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,870] LMCache INFO:[0m Reqid: chatcmpl-b879d88427854f84852f00ea746123a3, Total tokens 1085, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,871] LMCache INFO:[0m Reqid: chatcmpl-f29ab62c378f4d9498c26f0ff51db3e4, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,899] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-467a40cfd8f44a4184ac48e8475df438 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,900] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4337 ms, throughput: 7.8814 GB/s; offload_time: 0.3640 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,905] LMCache INFO:[0m Reqid: chatcmpl-f29ab62c378f4d9498c26f0ff51db3e4, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,914] LMCache INFO:[0m Reqid: chatcmpl-f29ab62c378f4d9498c26f0ff51db3e4, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,915] LMCache INFO:[0m Reqid: chatcmpl-fc78f36e72db449fac2ff3aa7ff899a8, Total tokens 869, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,916] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,941] LMCache INFO:[0m Storing KV cache for 357 out of 869 tokens (skip_leading_tokens=512) for request chatcmpl-fc78f36e72db449fac2ff3aa7ff899a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,943] LMCache INFO:[0m Stored 357 out of total 869 tokens. size: 0.0095 gb, cost 1.0728 ms, throughput: 8.8858 GB/s; offload_time: 0.7744 ms, put_time: 0.2985 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,950] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,959] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:51892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:07,966] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1b238ead0085445092d9c7f23e739f44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,967] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5002 ms, throughput: 6.8326 GB/s; offload_time: 0.4239 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,971] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,981] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,988] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-460c831c44d74ca2af33a299afdbefb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:07,988] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5338 ms, throughput: 6.4032 GB/s; offload_time: 0.4596 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:07,993] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,002] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,012] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,022] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,030] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e3b86b2941bd48ca90dcf95bb45db659 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,031] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5201 ms, throughput: 6.5712 GB/s; offload_time: 0.4379 ms, put_time: 0.0822 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,031] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,032] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.1608 ms, throughput: 2.9445 GB/s; offload_time: 1.0953 ms, put_time: 0.0655 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,033] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-40fde7c3f2b946c397a1608f69a2558c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,034] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6561 ms, throughput: 2.0639 GB/s; offload_time: 1.5872 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,035] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-280ed666fbe04c5590a5d35bf604e911 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,037] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7846 ms, throughput: 1.9152 GB/s; offload_time: 1.7039 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,042] LMCache INFO:[0m Reqid: chatcmpl-802f7faa9b994e6eac330783d39a4c9f, Total tokens 1069, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,043] LMCache INFO:[0m Reqid: chatcmpl-8dc4dd47f11341f5b2f28484cd54ccb3, Total tokens 579, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,044] LMCache INFO:[0m Reqid: chatcmpl-ea00a259f10a49f9b181d39f880b6ab5, Total tokens 158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:51952 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,077] LMCache INFO:[0m Storing KV cache for 173 out of 1069 tokens (skip_leading_tokens=896) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,078] LMCache INFO:[0m Stored 173 out of total 1069 tokens. size: 0.0046 gb, cost 0.7009 ms, throughput: 6.5907 GB/s; offload_time: 0.5926 ms, put_time: 0.1083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:51984 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,083] LMCache INFO:[0m Reqid: chatcmpl-ea00a259f10a49f9b181d39f880b6ab5, Total tokens 158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,084] LMCache INFO:[0m Reqid: chatcmpl-bf10c1b9bdb74a4690e920a917f7e614, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,084] LMCache INFO:[0m Reqid: chatcmpl-7906934839aa48e4afb10b2943e2dc46, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,099] LMCache INFO:[0m Storing KV cache for 158 out of 158 tokens (skip_leading_tokens=0) for request chatcmpl-ea00a259f10a49f9b181d39f880b6ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,100] LMCache INFO:[0m Stored 158 out of total 158 tokens. size: 0.0042 gb, cost 0.6440 ms, throughput: 6.5512 GB/s; offload_time: 0.5347 ms, put_time: 0.1093 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,100] LMCache INFO:[0m Storing KV cache for 135 out of 135 tokens (skip_leading_tokens=0) for request chatcmpl-bf10c1b9bdb74a4690e920a917f7e614 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,102] LMCache INFO:[0m Stored 135 out of total 135 tokens. size: 0.0036 gb, cost 1.3281 ms, throughput: 2.7143 GB/s; offload_time: 1.2236 ms, put_time: 0.1045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,115] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,115] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4667 ms, throughput: 7.3239 GB/s; offload_time: 0.3903 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,128] LMCache INFO:[0m Reqid: chatcmpl-ea00a259f10a49f9b181d39f880b6ab5, Total tokens 160, LMCache hit tokens: 158, need to load: 94 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,144] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4524c6a1f5984bfaaaf2ee985e45cb6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,145] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4946 ms, throughput: 6.9109 GB/s; offload_time: 0.4105 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,149] LMCache INFO:[0m Reqid: chatcmpl-8dc4dd47f11341f5b2f28484cd54ccb3, Total tokens 584, LMCache hit tokens: 512, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,149] LMCache INFO:[0m Reqid: chatcmpl-ea00a259f10a49f9b181d39f880b6ab5, Total tokens 160, LMCache hit tokens: 158, need to load: 110 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,150] LMCache INFO:[0m Reqid: chatcmpl-bf10c1b9bdb74a4690e920a917f7e614, Total tokens 136, LMCache hit tokens: 135, need to load: 87 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,150] LMCache INFO:[0m Reqid: chatcmpl-7906934839aa48e4afb10b2943e2dc46, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,151] LMCache INFO:[0m Reqid: chatcmpl-75b601edb80f47f69afc3f5e01cd3996, Total tokens 1103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,163] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-7906934839aa48e4afb10b2943e2dc46 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,164] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.4276 ms, throughput: 6.7452 GB/s; offload_time: 0.3521 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,168] LMCache INFO:[0m Reqid: chatcmpl-75b601edb80f47f69afc3f5e01cd3996, Total tokens 1103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,175] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9ad356d5afff4e719f830ced469f229a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,176] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4746 ms, throughput: 7.2016 GB/s; offload_time: 0.3986 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,180] LMCache INFO:[0m Reqid: chatcmpl-75b601edb80f47f69afc3f5e01cd3996, Total tokens 1103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,187] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7770976043cc4497a239256f6f3c075a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,188] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5144 ms, throughput: 6.6445 GB/s; offload_time: 0.4390 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,191] LMCache INFO:[0m Reqid: chatcmpl-75b601edb80f47f69afc3f5e01cd3996, Total tokens 1103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,201] LMCache INFO:[0m Reqid: chatcmpl-75b601edb80f47f69afc3f5e01cd3996, Total tokens 1103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,202] LMCache INFO:[0m Reqid: chatcmpl-225d204d715c4f79bdff3752c9680d28, Total tokens 416, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,203] LMCache INFO:[0m Reqid: chatcmpl-a8a2e0e52bc34ce8afc74c852a7df048, Total tokens 153, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,204] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,237] LMCache INFO:[0m Storing KV cache for 1103 out of 1103 tokens (skip_leading_tokens=0) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,243] LMCache INFO:[0m Stored 1103 out of total 1103 tokens. size: 0.0295 gb, cost 6.3528 ms, throughput: 4.6362 GB/s; offload_time: 5.1928 ms, put_time: 1.1601 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,244] LMCache INFO:[0m Storing KV cache for 153 out of 153 tokens (skip_leading_tokens=0) for request chatcmpl-a8a2e0e52bc34ce8afc74c852a7df048 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,248] LMCache INFO:[0m Stored 153 out of total 153 tokens. size: 0.0041 gb, cost 3.9156 ms, throughput: 1.0434 GB/s; offload_time: 3.7337 ms, put_time: 0.1819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,249] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0fce6169d9ff40cfb301ab89171bd156 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:51986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:51996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,253] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 4.0731 ms, throughput: 0.8392 GB/s; offload_time: 3.8650 ms, put_time: 0.2081 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,258] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,265] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0bea0d5b23ff4160bd85999dcff5d17e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,266] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1844 ms, throughput: 2.8858 GB/s; offload_time: 1.1068 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,270] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,280] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,287] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c897241b787443b2a14e0dd3a9c920e6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,288] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2654 ms, throughput: 2.7011 GB/s; offload_time: 1.1832 ms, put_time: 0.0822 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,289] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4b34a105c5ce4ceda37b9934c4d5a2a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,290] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4944 ms, throughput: 2.2872 GB/s; offload_time: 1.4211 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,295] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,305] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,323] LMCache INFO:[0m Reqid: chatcmpl-225d204d715c4f79bdff3752c9680d28, Total tokens 422, LMCache hit tokens: 384, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,323] LMCache INFO:[0m Reqid: chatcmpl-a8a2e0e52bc34ce8afc74c852a7df048, Total tokens 159, LMCache hit tokens: 153, need to load: 105 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,338] LMCache INFO:[0m Reqid: chatcmpl-a8a2e0e52bc34ce8afc74c852a7df048, Total tokens 159, LMCache hit tokens: 153, need to load: 105 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,338] LMCache INFO:[0m Reqid: chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8, Total tokens 872, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,340] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,364] LMCache INFO:[0m Storing KV cache for 360 out of 872 tokens (skip_leading_tokens=512) for request chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,365] LMCache INFO:[0m Stored 360 out of total 872 tokens. size: 0.0096 gb, cost 0.9259 ms, throughput: 10.3820 GB/s; offload_time: 0.7792 ms, put_time: 0.1467 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,366] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fea0348cf43a46fd94f1000451ad5630 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,368] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3196 ms, throughput: 2.5901 GB/s; offload_time: 1.2505 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,368] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-fc78f36e72db449fac2ff3aa7ff899a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,369] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6594 ms, throughput: 5.1835 GB/s; offload_time: 0.5979 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,374] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,381] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-678cb04b65dd434184374fc890775a6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,383] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2319 ms, throughput: 2.7745 GB/s; offload_time: 1.1494 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,387] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,395] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,396] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.3085 ms, throughput: 2.6122 GB/s; offload_time: 1.2311 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,397] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,398] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4178 ms, throughput: 2.4107 GB/s; offload_time: 1.3475 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,399] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1c1282ce28f145038a4f462c3c4f3898 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,400] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3613 ms, throughput: 2.5108 GB/s; offload_time: 1.2946 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,405] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,415] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,424] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,431] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,432] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2426 ms, throughput: 2.7507 GB/s; offload_time: 1.1663 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,437] LMCache INFO:[0m Reqid: chatcmpl-179caddbb59d40a7a16141616d35d61d, Total tokens 1966, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,438] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 421, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,439] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 398, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,473] LMCache INFO:[0m Storing KV cache for 174 out of 1966 tokens (skip_leading_tokens=1792) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,474] LMCache INFO:[0m Stored 174 out of total 1966 tokens. size: 0.0046 gb, cost 0.8102 ms, throughput: 5.7349 GB/s; offload_time: 0.6937 ms, put_time: 0.1165 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,475] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ce11b90819d1470ca140c2e507fd4d78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,477] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5034 ms, throughput: 2.2734 GB/s; offload_time: 1.4334 ms, put_time: 0.0700 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,490] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 422, LMCache hit tokens: 384, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,497] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7906934839aa48e4afb10b2943e2dc46 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,497] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4579 ms, throughput: 7.4648 GB/s; offload_time: 0.3827 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,501] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 422, LMCache hit tokens: 384, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,502] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 398, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,516] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 398, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,523] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-9424701fe32a4aaeabe54795307e7692 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,524] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5641 ms, throughput: 6.0592 GB/s; offload_time: 0.4880 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,527] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 398, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,544] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-36b65bb6671548769d1fb3681b2f4116 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,544] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5136 ms, throughput: 6.6545 GB/s; offload_time: 0.4306 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,548] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 425, LMCache hit tokens: 384, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,556] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,557] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6721 ms, throughput: 5.0857 GB/s; offload_time: 0.5845 ms, put_time: 0.0876 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,557] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-90fb645ac39d4f8dbdc217e93d5ce4bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,558] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6966 ms, throughput: 4.9069 GB/s; offload_time: 0.6227 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,562] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 425, LMCache hit tokens: 384, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,571] LMCache INFO:[0m Reqid: chatcmpl-c033f85132574f24bc7cf5eae1ac71ba, Total tokens 425, LMCache hit tokens: 384, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,572] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 398, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,572] LMCache INFO:[0m Reqid: chatcmpl-c1c6894be7eb4cae840d2a26f9adf917, Total tokens 201, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,573] LMCache INFO:[0m Reqid: chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1, Total tokens 443, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,592] LMCache INFO:[0m Storing KV cache for 142 out of 398 tokens (skip_leading_tokens=256) for request chatcmpl-962e3fec02664859bcb64afca577bba6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,592] LMCache INFO:[0m Stored 142 out of total 398 tokens. size: 0.0038 gb, cost 0.7018 ms, throughput: 5.4029 GB/s; offload_time: 0.5861 ms, put_time: 0.1157 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,593] LMCache INFO:[0m Storing KV cache for 201 out of 201 tokens (skip_leading_tokens=0) for request chatcmpl-c1c6894be7eb4cae840d2a26f9adf917 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,594] LMCache INFO:[0m Stored 201 out of total 201 tokens. size: 0.0054 gb, cost 1.4058 ms, throughput: 3.8181 GB/s; offload_time: 1.3053 ms, put_time: 0.1005 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,600] LMCache INFO:[0m Reqid: chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1, Total tokens 443, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,607] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-17c0939e328b4be1bed5bf7aee20f2ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,608] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2804 ms, throughput: 2.6695 GB/s; offload_time: 1.2061 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,612] LMCache INFO:[0m Reqid: chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1, Total tokens 443, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,621] LMCache INFO:[0m Reqid: chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1, Total tokens 443, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,628] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1cd8c28ded1a4ba09401ce0e143af581 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,629] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2078 ms, throughput: 2.8300 GB/s; offload_time: 1.1325 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,642] LMCache INFO:[0m Reqid: chatcmpl-c1c6894be7eb4cae840d2a26f9adf917, Total tokens 205, LMCache hit tokens: 201, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,651] LMCache INFO:[0m Reqid: chatcmpl-c1c6894be7eb4cae840d2a26f9adf917, Total tokens 205, LMCache hit tokens: 201, need to load: 121 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,668] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 405, LMCache hit tokens: 398, need to load: 158 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,677] LMCache INFO:[0m Reqid: chatcmpl-962e3fec02664859bcb64afca577bba6, Total tokens 405, LMCache hit tokens: 398, need to load: 174 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,678] LMCache INFO:[0m Reqid: chatcmpl-c1c6894be7eb4cae840d2a26f9adf917, Total tokens 205, LMCache hit tokens: 201, need to load: 153 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,689] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-3a4c4c31541944eaacad4cf4bd1ca2a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,690] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2643 ms, throughput: 2.7034 GB/s; offload_time: 1.1883 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,694] LMCache INFO:[0m Reqid: chatcmpl-c1c6894be7eb4cae840d2a26f9adf917, Total tokens 205, LMCache hit tokens: 201, need to load: 153 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,694] LMCache INFO:[0m Reqid: chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1, Total tokens 443, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,695] LMCache INFO:[0m Reqid: chatcmpl-9fea699b5c154289a68469925ac5f538, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,696] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,714] LMCache INFO:[0m Storing KV cache for 135 out of 135 tokens (skip_leading_tokens=0) for request chatcmpl-9fea699b5c154289a68469925ac5f538 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,714] LMCache INFO:[0m Stored 135 out of total 135 tokens. size: 0.0036 gb, cost 0.6474 ms, throughput: 5.5684 GB/s; offload_time: 0.5380 ms, put_time: 0.1094 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,715] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3dfdc664e67e4039bb3de1922770bf65 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,716] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8829 ms, throughput: 3.8713 GB/s; offload_time: 0.7884 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,721] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,728] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,730] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2497 ms, throughput: 2.7350 GB/s; offload_time: 1.1728 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,734] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,743] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,753] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,760] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,762] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.4657 ms, throughput: 2.3320 GB/s; offload_time: 1.3813 ms, put_time: 0.0844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,766] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,776] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,785] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,795] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,804] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,814] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,824] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,830] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-fcf8fddd58894dc887583af77012b203 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,832] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3316 ms, throughput: 2.5668 GB/s; offload_time: 1.2558 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,836] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,843] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-28921425465248c5bc3ebef4b0cf8255 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,845] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3925 ms, throughput: 2.4545 GB/s; offload_time: 1.3153 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,849] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,856] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1891ff4756334e3199ea5f7d0ea1466e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,858] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3452 ms, throughput: 2.5409 GB/s; offload_time: 1.2720 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,858] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b879d88427854f84852f00ea746123a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,860] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4376 ms, throughput: 2.3775 GB/s; offload_time: 1.3679 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,864] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,874] LMCache INFO:[0m Reqid: chatcmpl-dd1da90ef0fe43aa90b797f740ee964e, Total tokens 1826, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,875] LMCache INFO:[0m Reqid: chatcmpl-55b912a773834deb921e3471a4175e40, Total tokens 1009, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,876] LMCache INFO:[0m Reqid: chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3, Total tokens 145, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:08,919] LMCache INFO:[0m Storing KV cache for 369 out of 1009 tokens (skip_leading_tokens=640) for request chatcmpl-55b912a773834deb921e3471a4175e40 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,920] LMCache INFO:[0m Stored 369 out of total 1009 tokens. size: 0.0099 gb, cost 1.0715 ms, throughput: 9.1963 GB/s; offload_time: 0.7917 ms, put_time: 0.2797 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,933] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,934] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6110 ms, throughput: 5.5937 GB/s; offload_time: 0.5202 ms, put_time: 0.0908 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,937] LMCache INFO:[0m Reqid: chatcmpl-55b912a773834deb921e3471a4175e40, Total tokens 1010, LMCache hit tokens: 1009, need to load: 161 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,947] LMCache INFO:[0m Reqid: chatcmpl-55b912a773834deb921e3471a4175e40, Total tokens 1010, LMCache hit tokens: 1009, need to load: 193 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,954] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1349bc78f7d34ebd9d4f991f2b80adef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,955] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6108 ms, throughput: 5.5962 GB/s; offload_time: 0.5321 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,959] LMCache INFO:[0m Reqid: chatcmpl-55b912a773834deb921e3471a4175e40, Total tokens 1010, LMCache hit tokens: 1009, need to load: 289 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,960] LMCache INFO:[0m Reqid: chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3, Total tokens 145, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,961] LMCache INFO:[0m Reqid: chatcmpl-2dd684b3d2da47f8a9d7e4c187465be1, Total tokens 164, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,961] LMCache INFO:[0m Reqid: chatcmpl-5c9c7be46e8148a59380f9696153372c, Total tokens 323, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,962] LMCache INFO:[0m Reqid: chatcmpl-41ad16f9c17d4044aa44ec2183b41a66, Total tokens 124, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,962] LMCache INFO:[0m Reqid: chatcmpl-3d8f42c7d9994333b5ee1357fc436ef6, Total tokens 1357, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,981] LMCache INFO:[0m Storing KV cache for 145 out of 145 tokens (skip_leading_tokens=0) for request chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,982] LMCache INFO:[0m Stored 145 out of total 145 tokens. size: 0.0039 gb, cost 0.6881 ms, throughput: 5.6272 GB/s; offload_time: 0.5705 ms, put_time: 0.1176 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,982] LMCache INFO:[0m Storing KV cache for 195 out of 323 tokens (skip_leading_tokens=128) for request chatcmpl-5c9c7be46e8148a59380f9696153372c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,986] LMCache INFO:[0m Stored 195 out of total 323 tokens. size: 0.0052 gb, cost 3.0728 ms, throughput: 1.6946 GB/s; offload_time: 2.9679 ms, put_time: 0.1049 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,986] LMCache INFO:[0m Storing KV cache for 124 out of 124 tokens (skip_leading_tokens=0) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,987] LMCache INFO:[0m Stored 124 out of total 124 tokens. size: 0.0033 gb, cost 1.1967 ms, throughput: 2.7669 GB/s; offload_time: 1.0082 ms, put_time: 0.1885 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,988] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-46146810cc36479dbe18a7d7700c76b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,989] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9286 ms, throughput: 3.6809 GB/s; offload_time: 0.8557 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,989] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8dc4dd47f11341f5b2f28484cd54ccb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:08,990] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0462 ms, throughput: 3.2670 GB/s; offload_time: 0.9512 ms, put_time: 0.0950 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:08,996] LMCache INFO:[0m Reqid: chatcmpl-3d8f42c7d9994333b5ee1357fc436ef6, Total tokens 1357, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,005] LMCache INFO:[0m Reqid: chatcmpl-3d8f42c7d9994333b5ee1357fc436ef6, Total tokens 1357, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,015] LMCache INFO:[0m Reqid: chatcmpl-3d8f42c7d9994333b5ee1357fc436ef6, Total tokens 1357, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,015] LMCache INFO:[0m Reqid: chatcmpl-71e6d147fc2a4c2ca09ed5d0cc2fe9b8, Total tokens 277, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,016] LMCache INFO:[0m Reqid: chatcmpl-ce4ece654ee94accaf7397ee804c3168, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,046] LMCache INFO:[0m Storing KV cache for 149 out of 277 tokens (skip_leading_tokens=128) for request chatcmpl-71e6d147fc2a4c2ca09ed5d0cc2fe9b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,047] LMCache INFO:[0m Stored 149 out of total 277 tokens. size: 0.0040 gb, cost 0.6633 ms, throughput: 5.9985 GB/s; offload_time: 0.5464 ms, put_time: 0.1169 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,052] LMCache INFO:[0m Reqid: chatcmpl-ce4ece654ee94accaf7397ee804c3168, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,059] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-70cd959aca2240d884936018bd299468 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,060] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4946 ms, throughput: 6.9104 GB/s; offload_time: 0.4126 ms, put_time: 0.0820 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,060] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,061] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7273 ms, throughput: 4.6992 GB/s; offload_time: 0.6587 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,065] LMCache INFO:[0m Reqid: chatcmpl-ce4ece654ee94accaf7397ee804c3168, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,073] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-125f30c081a14b2099437d51ef71238a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,073] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5699 ms, throughput: 5.9972 GB/s; offload_time: 0.4957 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,078] LMCache INFO:[0m Reqid: chatcmpl-ce4ece654ee94accaf7397ee804c3168, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,079] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,095] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,104] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,111] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,112] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5591 ms, throughput: 6.1130 GB/s; offload_time: 0.4820 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,116] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,126] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,136] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,145] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,155] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,164] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:09,171] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-55b912a773834deb921e3471a4175e40 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,172] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4997 ms, throughput: 6.8398 GB/s; offload_time: 0.4266 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,177] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,187] LMCache INFO:[0m Reqid: chatcmpl-189cb593006941d7b5b3d62e437496a1, Total tokens 961, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,188] LMCache INFO:[0m Reqid: chatcmpl-7efadbeb285f440f9d8c17a3f9cac985, Total tokens 266, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,188] LMCache INFO:[0m Reqid: chatcmpl-b62f0c31e96143ff9ca002411b74c4b3, Total tokens 91, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,189] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1886, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,215] LMCache INFO:[0m Storing KV cache for 138 out of 266 tokens (skip_leading_tokens=128) for request chatcmpl-7efadbeb285f440f9d8c17a3f9cac985 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,215] LMCache INFO:[0m Stored 138 out of total 266 tokens. size: 0.0037 gb, cost 0.6099 ms, throughput: 6.0418 GB/s; offload_time: 0.4986 ms, put_time: 0.1113 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,216] LMCache INFO:[0m Storing KV cache for 91 out of 91 tokens (skip_leading_tokens=0) for request chatcmpl-b62f0c31e96143ff9ca002411b74c4b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,217] LMCache INFO:[0m Stored 91 out of total 91 tokens. size: 0.0024 gb, cost 0.8793 ms, throughput: 2.7636 GB/s; offload_time: 0.7927 ms, put_time: 0.0866 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,217] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6ad8dc3faca74e32b182dea3af584a69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,219] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4565 ms, throughput: 2.3467 GB/s; offload_time: 1.3842 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,219] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-31022f2973b9414a84fa6602360c71b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,220] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6895 ms, throughput: 4.9573 GB/s; offload_time: 0.6328 ms, put_time: 0.0567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,227] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1886, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,228] LMCache INFO:[0m Reqid: chatcmpl-0414963f403f44a9bddaf4faab164414, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,264] LMCache INFO:[0m Storing KV cache for 606 out of 1886 tokens (skip_leading_tokens=1280) for request chatcmpl-c11d75b682fd49cf9baa5952bece9746 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,266] LMCache INFO:[0m Stored 606 out of total 1886 tokens. size: 0.0162 gb, cost 1.4514 ms, throughput: 11.1493 GB/s; offload_time: 1.1017 ms, put_time: 0.3497 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,279] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-78ff63b0d3664fc7a8751f3c0c851600 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,280] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5013 ms, throughput: 6.8179 GB/s; offload_time: 0.4155 ms, put_time: 0.0859 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,284] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1887, LMCache hit tokens: 1886, need to load: 78 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,291] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,292] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4636 ms, throughput: 7.3727 GB/s; offload_time: 0.3846 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,297] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1887, LMCache hit tokens: 1886, need to load: 110 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,303] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b7dae668b3824ce88ef4232f477d919d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,304] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4591 ms, throughput: 7.4447 GB/s; offload_time: 0.3731 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,309] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1887, LMCache hit tokens: 1886, need to load: 190 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,310] LMCache INFO:[0m Reqid: chatcmpl-0414963f403f44a9bddaf4faab164414, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,318] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,318] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5253 ms, throughput: 6.5066 GB/s; offload_time: 0.4472 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,322] LMCache INFO:[0m Reqid: chatcmpl-0414963f403f44a9bddaf4faab164414, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,339] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-cac0948b9a5648f58ccbd30c020c36c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,340] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2671 ms, throughput: 2.6975 GB/s; offload_time: 1.1906 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,345] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1889, LMCache hit tokens: 1886, need to load: 126 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,352] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f29ab62c378f4d9498c26f0ff51db3e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,353] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2222 ms, throughput: 2.7966 GB/s; offload_time: 1.1444 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,358] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1889, LMCache hit tokens: 1886, need to load: 190 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,366] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c44ca4219f074c73a39be203051e56f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,367] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2424 ms, throughput: 2.7511 GB/s; offload_time: 1.1649 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,372] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1889, LMCache hit tokens: 1886, need to load: 254 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,382] LMCache INFO:[0m Reqid: chatcmpl-c11d75b682fd49cf9baa5952bece9746, Total tokens 1889, LMCache hit tokens: 1886, need to load: 366 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,383] LMCache INFO:[0m Reqid: chatcmpl-0414963f403f44a9bddaf4faab164414, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,383] LMCache INFO:[0m Reqid: chatcmpl-33017275292042f999afb8c902740146, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,384] LMCache INFO:[0m Reqid: chatcmpl-583acce7f2064e748294e3c9c975f07d, Total tokens 140, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,385] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1202, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,404] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-33017275292042f999afb8c902740146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,405] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.3945 ms, throughput: 6.7005 GB/s; offload_time: 0.3202 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,405] LMCache INFO:[0m Storing KV cache for 140 out of 140 tokens (skip_leading_tokens=0) for request chatcmpl-583acce7f2064e748294e3c9c975f07d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,407] LMCache INFO:[0m Stored 140 out of total 140 tokens. size: 0.0037 gb, cost 0.9585 ms, throughput: 3.9003 GB/s; offload_time: 0.8564 ms, put_time: 0.1021 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,413] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1202, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:09,423] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1202, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,433] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1202, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,450] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-f0f908196129408d986369c40bf81a3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,450] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5578 ms, throughput: 6.1271 GB/s; offload_time: 0.4806 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,451] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,452] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4706 ms, throughput: 2.3242 GB/s; offload_time: 1.3379 ms, put_time: 0.1327 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,464] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c1c6894be7eb4cae840d2a26f9adf917 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,465] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.1755 ms, throughput: 2.9077 GB/s; offload_time: 1.0992 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,476] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4f941fc3bf614c8b8441e5533926f8bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,477] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2073 ms, throughput: 2.8312 GB/s; offload_time: 1.1246 ms, put_time: 0.0826 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,481] LMCache INFO:[0m Reqid: chatcmpl-0414963f403f44a9bddaf4faab164414, Total tokens 509, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,482] LMCache INFO:[0m Reqid: chatcmpl-33017275292042f999afb8c902740146, Total tokens 104, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,483] LMCache INFO:[0m Reqid: chatcmpl-583acce7f2064e748294e3c9c975f07d, Total tokens 144, LMCache hit tokens: 140, need to load: 92 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,484] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1202, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,485] LMCache INFO:[0m Reqid: chatcmpl-e29458928f0246eaad14fcb563818711, Total tokens 321, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,515] LMCache INFO:[0m Storing KV cache for 178 out of 1202 tokens (skip_leading_tokens=1024) for request chatcmpl-65374604f09142d092178075e8d4a2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,516] LMCache INFO:[0m Stored 178 out of total 1202 tokens. size: 0.0048 gb, cost 0.6845 ms, throughput: 6.9437 GB/s; offload_time: 0.5669 ms, put_time: 0.1176 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,521] LMCache INFO:[0m Reqid: chatcmpl-e29458928f0246eaad14fcb563818711, Total tokens 321, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,541] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1204, LMCache hit tokens: 1202, need to load: 98 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,548] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0414963f403f44a9bddaf4faab164414 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,548] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4680 ms, throughput: 7.3031 GB/s; offload_time: 0.3874 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,553] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1204, LMCache hit tokens: 1202, need to load: 178 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,563] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1204, LMCache hit tokens: 1202, need to load: 290 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,570] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-ce7e332191734512b674a77575df7865 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,571] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5816 ms, throughput: 5.8767 GB/s; offload_time: 0.5052 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,575] LMCache INFO:[0m Reqid: chatcmpl-65374604f09142d092178075e8d4a2ca, Total tokens 1204, LMCache hit tokens: 1202, need to load: 338 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,576] LMCache INFO:[0m Reqid: chatcmpl-e29458928f0246eaad14fcb563818711, Total tokens 321, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,577] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 516, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,578] LMCache INFO:[0m Reqid: chatcmpl-3c2bb209e5a64c9f92b07d7554083996, Total tokens 347, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,578] LMCache INFO:[0m Reqid: chatcmpl-1a5f828cdcc04470b6646a166c1ac11b, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,579] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,600] LMCache INFO:[0m Storing KV cache for 132 out of 516 tokens (skip_leading_tokens=384) for request chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,601] LMCache INFO:[0m Stored 132 out of total 516 tokens. size: 0.0035 gb, cost 0.6386 ms, throughput: 5.5192 GB/s; offload_time: 0.5339 ms, put_time: 0.1048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,601] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-1a5f828cdcc04470b6646a166c1ac11b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,603] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 1.1495 ms, throughput: 2.2998 GB/s; offload_time: 1.0372 ms, put_time: 0.1123 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,603] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ea00a259f10a49f9b181d39f880b6ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,605] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.1466 ms, throughput: 1.5923 GB/s; offload_time: 2.0747 ms, put_time: 0.0719 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,611] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,621] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,628] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,628] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4848 ms, throughput: 7.0508 GB/s; offload_time: 0.4038 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,633] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,644] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,651] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,652] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.5916 ms, throughput: 5.7778 GB/s; offload_time: 0.5162 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,656] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,664] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-6bdbea87a85c4ee4a278b1db6b75c745 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,666] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.3725 ms, throughput: 2.4903 GB/s; offload_time: 1.2959 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,666] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-6fac4c7103d04c21b39bceaabc025747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,668] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.3696 ms, throughput: 2.4957 GB/s; offload_time: 1.3030 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,668] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-225d204d715c4f79bdff3752c9680d28 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,670] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.6035 ms, throughput: 2.1315 GB/s; offload_time: 1.5285 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,675] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,685] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52128 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:09,695] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,705] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,712] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-dbbc92f313c644be9bedb18d43aea0ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,713] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1904 ms, throughput: 2.8714 GB/s; offload_time: 1.1148 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,725] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-42d145d71c004b0bb0701bd0573da095 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,726] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3216 ms, throughput: 2.5862 GB/s; offload_time: 1.2429 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,727] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,728] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1494 ms, throughput: 2.9738 GB/s; offload_time: 1.0782 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,733] LMCache INFO:[0m Reqid: chatcmpl-3c2bb209e5a64c9f92b07d7554083996, Total tokens 357, LMCache hit tokens: 256, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,740] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0141fc469f1f42ad843db5b0886cbfac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,741] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2243 ms, throughput: 2.7917 GB/s; offload_time: 1.1460 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,745] LMCache INFO:[0m Reqid: chatcmpl-3c2bb209e5a64c9f92b07d7554083996, Total tokens 357, LMCache hit tokens: 256, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,755] LMCache INFO:[0m Reqid: chatcmpl-3c2bb209e5a64c9f92b07d7554083996, Total tokens 357, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,771] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-3d8f42c7d9994333b5ee1357fc436ef6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,773] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2481 ms, throughput: 2.7385 GB/s; offload_time: 1.1727 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,777] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,787] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 148 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,797] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 196 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,806] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 260 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,814] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-c11d75b682fd49cf9baa5952bece9746 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,815] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.3078 ms, throughput: 2.6136 GB/s; offload_time: 1.2267 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,815] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-33017275292042f999afb8c902740146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,817] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4762 ms, throughput: 2.3153 GB/s; offload_time: 1.4019 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,821] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 404 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,829] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1b238ead0085445092d9c7f23e739f44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,830] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2499 ms, throughput: 2.7346 GB/s; offload_time: 1.1702 ms, put_time: 0.0797 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,835] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 420 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,852] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-460c831c44d74ca2af33a299afdbefb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,853] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2864 ms, throughput: 2.6570 GB/s; offload_time: 1.2083 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,853] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5c9c7be46e8148a59380f9696153372c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52144 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:09,855] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5287 ms, throughput: 2.2359 GB/s; offload_time: 1.4555 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,859] LMCache INFO:[0m Reqid: chatcmpl-e29458928f0246eaad14fcb563818711, Total tokens 342, LMCache hit tokens: 256, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,860] LMCache INFO:[0m Reqid: chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459, Total tokens 530, LMCache hit tokens: 516, need to load: 468 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,861] LMCache INFO:[0m Reqid: chatcmpl-3c2bb209e5a64c9f92b07d7554083996, Total tokens 357, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,861] LMCache INFO:[0m Reqid: chatcmpl-1a5f828cdcc04470b6646a166c1ac11b, Total tokens 109, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,862] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,879] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,889] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,899] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,907] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-e3b86b2941bd48ca90dcf95bb45db659 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,908] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2857 ms, throughput: 2.6584 GB/s; offload_time: 1.2096 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,909] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,910] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.5630 ms, throughput: 2.1868 GB/s; offload_time: 1.4913 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,911] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-40fde7c3f2b946c397a1608f69a2558c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,913] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.7502 ms, throughput: 1.9530 GB/s; offload_time: 1.6716 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,917] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,927] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,937] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,944] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-393667bddc2540d0bd3b967094160351 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,945] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2219 ms, throughput: 2.7972 GB/s; offload_time: 1.1361 ms, put_time: 0.0858 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:09,949] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,959] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,970] LMCache INFO:[0m Reqid: chatcmpl-94bd9489c4ae4c048b40e6625432b2ef, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,970] LMCache INFO:[0m Reqid: chatcmpl-9a036238cbf144ecb6f220d48591a93f, Total tokens 117, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:09,971] LMCache INFO:[0m Reqid: chatcmpl-e2c883068be84046b30e4dab7f9ff2db, Total tokens 1388, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,005] LMCache INFO:[0m Storing KV cache for 117 out of 117 tokens (skip_leading_tokens=0) for request chatcmpl-9a036238cbf144ecb6f220d48591a93f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,005] LMCache INFO:[0m Stored 117 out of total 117 tokens. size: 0.0031 gb, cost 0.3972 ms, throughput: 7.8653 GB/s; offload_time: 0.3232 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,010] LMCache INFO:[0m Reqid: chatcmpl-e2c883068be84046b30e4dab7f9ff2db, Total tokens 1388, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,011] LMCache INFO:[0m Reqid: chatcmpl-e885984a094e473fa10a505a56817107, Total tokens 116, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,012] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,038] LMCache INFO:[0m Storing KV cache for 116 out of 116 tokens (skip_leading_tokens=0) for request chatcmpl-e885984a094e473fa10a505a56817107 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,038] LMCache INFO:[0m Stored 116 out of total 116 tokens. size: 0.0031 gb, cost 0.4000 ms, throughput: 7.7442 GB/s; offload_time: 0.3238 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,043] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,053] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,060] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-7770976043cc4497a239256f6f3c075a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,061] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5112 ms, throughput: 6.6867 GB/s; offload_time: 0.4359 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,065] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,075] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,082] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-0fce6169d9ff40cfb301ab89171bd156 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,083] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5190 ms, throughput: 6.5854 GB/s; offload_time: 0.4421 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,087] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,097] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,107] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,114] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c897241b787443b2a14e0dd3a9c920e6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,115] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5365 ms, throughput: 6.3706 GB/s; offload_time: 0.4616 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,115] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4b34a105c5ce4ceda37b9934c4d5a2a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,116] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6514 ms, throughput: 5.2472 GB/s; offload_time: 0.5843 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,116] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-189cb593006941d7b5b3d62e437496a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,117] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6765 ms, throughput: 5.0526 GB/s; offload_time: 0.6135 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,122] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,132] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,141] LMCache INFO:[0m Reqid: chatcmpl-74c235d876b9466fbc94447a583b034b, Total tokens 1659, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,142] LMCache INFO:[0m Reqid: chatcmpl-5819e63b84bb4152b1c51aebe4e7e4d9, Total tokens 181, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,143] LMCache INFO:[0m Reqid: chatcmpl-22243a2354c44f8c90d222a55c4355bd, Total tokens 255, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,143] LMCache INFO:[0m Reqid: chatcmpl-87f0ada150fb475da335289dd25cb5bb, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,144] LMCache INFO:[0m Reqid: chatcmpl-e89569baec794faabf98bbce35e8beff, Total tokens 435, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,144] LMCache INFO:[0m Reqid: chatcmpl-1f524e69b9384043a0b57056408d4ab5, Total tokens 346, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,187] LMCache INFO:[0m Storing KV cache for 255 out of 255 tokens (skip_leading_tokens=0) for request chatcmpl-22243a2354c44f8c90d222a55c4355bd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,188] LMCache INFO:[0m Stored 255 out of total 255 tokens. size: 0.0068 gb, cost 0.6580 ms, throughput: 10.3489 GB/s; offload_time: 0.5457 ms, put_time: 0.1122 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,188] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-87f0ada150fb475da335289dd25cb5bb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,189] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.9433 ms, throughput: 2.6325 GB/s; offload_time: 0.8744 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,190] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9a036238cbf144ecb6f220d48591a93f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,191] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6831 ms, throughput: 5.0039 GB/s; offload_time: 0.6105 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,195] LMCache INFO:[0m Reqid: chatcmpl-1f524e69b9384043a0b57056408d4ab5, Total tokens 346, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,202] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-22243a2354c44f8c90d222a55c4355bd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,203] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4478 ms, throughput: 7.6333 GB/s; offload_time: 0.3702 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,207] LMCache INFO:[0m Reqid: chatcmpl-1f524e69b9384043a0b57056408d4ab5, Total tokens 346, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,214] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e885984a094e473fa10a505a56817107 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,214] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4475 ms, throughput: 7.6372 GB/s; offload_time: 0.3717 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,225] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-678cb04b65dd434184374fc890775a6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,226] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4848 ms, throughput: 7.0496 GB/s; offload_time: 0.4099 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,230] LMCache INFO:[0m Reqid: chatcmpl-e89569baec794faabf98bbce35e8beff, Total tokens 438, LMCache hit tokens: 384, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,231] LMCache INFO:[0m Reqid: chatcmpl-1f524e69b9384043a0b57056408d4ab5, Total tokens 346, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,232] LMCache INFO:[0m Reqid: chatcmpl-e54f92177eb6419eb2bbc3dd2b4a0531, Total tokens 215, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,233] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,253] LMCache INFO:[0m Storing KV cache for 346 out of 346 tokens (skip_leading_tokens=0) for request chatcmpl-1f524e69b9384043a0b57056408d4ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,254] LMCache INFO:[0m Stored 346 out of total 346 tokens. size: 0.0092 gb, cost 0.8352 ms, throughput: 11.0622 GB/s; offload_time: 0.7043 ms, put_time: 0.1309 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,254] LMCache INFO:[0m Storing KV cache for 215 out of 215 tokens (skip_leading_tokens=0) for request chatcmpl-e54f92177eb6419eb2bbc3dd2b4a0531 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,258] LMCache INFO:[0m Stored 215 out of total 215 tokens. size: 0.0057 gb, cost 2.5664 ms, throughput: 2.2371 GB/s; offload_time: 2.3947 ms, put_time: 0.1716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,258] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,260] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5084 ms, throughput: 2.2659 GB/s; offload_time: 1.4432 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,260] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,262] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0826 ms, throughput: 3.1572 GB/s; offload_time: 0.8166 ms, put_time: 0.2660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,267] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,274] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-962e3fec02664859bcb64afca577bba6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,275] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4630 ms, throughput: 7.3829 GB/s; offload_time: 0.3880 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,275] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-74c235d876b9466fbc94447a583b034b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,276] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.8105 ms, throughput: 4.2173 GB/s; offload_time: 0.7435 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,281] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,288] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-94bd9489c4ae4c048b40e6625432b2ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,290] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3083 ms, throughput: 2.6125 GB/s; offload_time: 1.2210 ms, put_time: 0.0873 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,294] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,301] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,302] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2028 ms, throughput: 2.8417 GB/s; offload_time: 1.1258 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,303] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3c2bb209e5a64c9f92b07d7554083996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,304] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3693 ms, throughput: 2.4961 GB/s; offload_time: 1.2980 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,308] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,316] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-ce11b90819d1470ca140c2e507fd4d78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,318] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2820 ms, throughput: 2.6660 GB/s; offload_time: 1.2044 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,318] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-dd1da90ef0fe43aa90b797f740ee964e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,320] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4702 ms, throughput: 2.3248 GB/s; offload_time: 1.3988 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,320] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ce4ece654ee94accaf7397ee804c3168 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,322] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6578 ms, throughput: 2.0617 GB/s; offload_time: 1.5785 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,326] LMCache INFO:[0m Reqid: chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af, Total tokens 1159, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,327] LMCache INFO:[0m Reqid: chatcmpl-42a454aa15754982a95ce1b34094b409, Total tokens 290, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,327] LMCache INFO:[0m Reqid: chatcmpl-b56d41ac03f24f8faf7741e1305e95c6, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,328] LMCache INFO:[0m Reqid: chatcmpl-52e8dc383fd742849f6e8f74de050c7a, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,358] LMCache INFO:[0m Storing KV cache for 135 out of 1159 tokens (skip_leading_tokens=1024) for request chatcmpl-1a8c2653ffbc4520a79b083ffa1a08af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,359] LMCache INFO:[0m Stored 135 out of total 1159 tokens. size: 0.0036 gb, cost 0.6837 ms, throughput: 5.2727 GB/s; offload_time: 0.5707 ms, put_time: 0.1130 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,359] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-b56d41ac03f24f8faf7741e1305e95c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,360] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.7522 ms, throughput: 3.3725 GB/s; offload_time: 0.6797 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,361] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-52e8dc383fd742849f6e8f74de050c7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,362] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.8814 ms, throughput: 2.9994 GB/s; offload_time: 0.7996 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,374] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7906934839aa48e4afb10b2943e2dc46 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,374] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4486 ms, throughput: 7.6185 GB/s; offload_time: 0.3722 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,374] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2dd684b3d2da47f8a9d7e4c187465be1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,375] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8355 ms, throughput: 4.0911 GB/s; offload_time: 0.7661 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,376] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-e2c883068be84046b30e4dab7f9ff2db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,377] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7556 ms, throughput: 4.5234 GB/s; offload_time: 0.6917 ms, put_time: 0.0640 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,400] LMCache INFO:[0m Reqid: chatcmpl-42a454aa15754982a95ce1b34094b409, Total tokens 293, LMCache hit tokens: 256, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,409] LMCache INFO:[0m Reqid: chatcmpl-42a454aa15754982a95ce1b34094b409, Total tokens 293, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,410] LMCache INFO:[0m Reqid: chatcmpl-b56d41ac03f24f8faf7741e1305e95c6, Total tokens 97, LMCache hit tokens: 95, need to load: 47 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,410] LMCache INFO:[0m Reqid: chatcmpl-52e8dc383fd742849f6e8f74de050c7a, Total tokens 101, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52198 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,425] LMCache INFO:[0m Reqid: chatcmpl-34280e0ae00b48dc813e03e73d13e3eb, Total tokens 1798, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,426] LMCache INFO:[0m Reqid: chatcmpl-71c2048b1d2548fb86b1c79be6a7820d, Total tokens 1003, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,464] LMCache INFO:[0m Storing KV cache for 134 out of 1798 tokens (skip_leading_tokens=1664) for request chatcmpl-34280e0ae00b48dc813e03e73d13e3eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,465] LMCache INFO:[0m Stored 134 out of total 1798 tokens. size: 0.0036 gb, cost 0.7269 ms, throughput: 4.9225 GB/s; offload_time: 0.6098 ms, put_time: 0.1171 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,466] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,468] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.2042 ms, throughput: 2.8385 GB/s; offload_time: 1.1328 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,468] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-90fb645ac39d4f8dbdc217e93d5ce4bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,469] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5959 ms, throughput: 5.7361 GB/s; offload_time: 0.5326 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,484] LMCache INFO:[0m Reqid: chatcmpl-34280e0ae00b48dc813e03e73d13e3eb, Total tokens 1799, LMCache hit tokens: 1798, need to load: 134 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,494] LMCache INFO:[0m Reqid: chatcmpl-34280e0ae00b48dc813e03e73d13e3eb, Total tokens 1799, LMCache hit tokens: 1798, need to load: 182 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,495] LMCache INFO:[0m Reqid: chatcmpl-71c2048b1d2548fb86b1c79be6a7820d, Total tokens 1003, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,495] LMCache INFO:[0m Reqid: chatcmpl-2685a839adb9408ba00645435aa97209, Total tokens 229, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,496] LMCache INFO:[0m Reqid: chatcmpl-239d14a65e6b4acd8c7ca95753431454, Total tokens 244, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,496] LMCache INFO:[0m Reqid: chatcmpl-27714f9ddf984aea881485b69c860b45, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,520] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-27714f9ddf984aea881485b69c860b45 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,520] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3860 ms, throughput: 6.9171 GB/s; offload_time: 0.3167 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,521] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-17c0939e328b4be1bed5bf7aee20f2ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,522] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7136 ms, throughput: 4.7895 GB/s; offload_time: 0.6502 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,542] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1cd8c28ded1a4ba09401ce0e143af581 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,543] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4585 ms, throughput: 7.4548 GB/s; offload_time: 0.3828 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,543] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9fea699b5c154289a68469925ac5f538 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,544] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7506 ms, throughput: 4.5535 GB/s; offload_time: 0.6740 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,550] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,560] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,567] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e29458928f0246eaad14fcb563818711 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,567] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4561 ms, throughput: 7.4945 GB/s; offload_time: 0.3808 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,573] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,583] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,593] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,603] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,613] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,620] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3dfdc664e67e4039bb3de1922770bf65 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,620] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4570 ms, throughput: 7.4799 GB/s; offload_time: 0.3850 ms, put_time: 0.0719 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,625] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,632] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d44fffc016244ba2a6e5c44f2ae1dddb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,633] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4602 ms, throughput: 7.4271 GB/s; offload_time: 0.3872 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,638] LMCache INFO:[0m Reqid: chatcmpl-2fffeebd38f04530bdbdf3961921cf6a, Total tokens 1794, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,639] LMCache INFO:[0m Reqid: chatcmpl-eee904f833d445e78b0ee628979de976, Total tokens 1141, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,675] LMCache INFO:[0m Storing KV cache for 130 out of 1794 tokens (skip_leading_tokens=1664) for request chatcmpl-2fffeebd38f04530bdbdf3961921cf6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,676] LMCache INFO:[0m Stored 130 out of total 1794 tokens. size: 0.0035 gb, cost 0.7178 ms, throughput: 4.8360 GB/s; offload_time: 0.6059 ms, put_time: 0.1120 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,677] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,678] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7595 ms, throughput: 4.5000 GB/s; offload_time: 0.6882 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,684] LMCache INFO:[0m Reqid: chatcmpl-eee904f833d445e78b0ee628979de976, Total tokens 1141, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,694] LMCache INFO:[0m Reqid: chatcmpl-eee904f833d445e78b0ee628979de976, Total tokens 1141, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,694] LMCache INFO:[0m Reqid: chatcmpl-dc6411db9bf947c6bff0514a9e34fb88, Total tokens 219, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,695] LMCache INFO:[0m Reqid: chatcmpl-acd05d9da2234fdbabe95c66df9966b6, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,695] LMCache INFO:[0m Reqid: chatcmpl-bf0264ad57cb4361a036ffc103348866, Total tokens 528, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,696] LMCache INFO:[0m Reqid: chatcmpl-11cfd7b1a7484c44933f7f1e3f81b759, Total tokens 154, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,731] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-acd05d9da2234fdbabe95c66df9966b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,731] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.4015 ms, throughput: 7.2492 GB/s; offload_time: 0.3243 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,732] LMCache INFO:[0m Storing KV cache for 144 out of 528 tokens (skip_leading_tokens=384) for request chatcmpl-bf0264ad57cb4361a036ffc103348866 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,733] LMCache INFO:[0m Stored 144 out of total 528 tokens. size: 0.0038 gb, cost 1.3898 ms, throughput: 2.7668 GB/s; offload_time: 1.1924 ms, put_time: 0.1974 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,733] LMCache INFO:[0m Storing KV cache for 154 out of 154 tokens (skip_leading_tokens=0) for request chatcmpl-11cfd7b1a7484c44933f7f1e3f81b759 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,735] LMCache INFO:[0m Stored 154 out of total 154 tokens. size: 0.0041 gb, cost 1.2271 ms, throughput: 3.3513 GB/s; offload_time: 1.0104 ms, put_time: 0.2167 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,735] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,738] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.5254 ms, throughput: 2.2407 GB/s; offload_time: 1.4555 ms, put_time: 0.0700 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,767] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-65374604f09142d092178075e8d4a2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,768] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5168 ms, throughput: 6.6134 GB/s; offload_time: 0.4416 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,779] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-87f0ada150fb475da335289dd25cb5bb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,780] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4330 ms, throughput: 7.8929 GB/s; offload_time: 0.3599 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,808] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-fcf8fddd58894dc887583af77012b203 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,809] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5124 ms, throughput: 6.6703 GB/s; offload_time: 0.4396 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,813] LMCache INFO:[0m Reqid: chatcmpl-e5b3d51364f64c1c9d161ef50d0ee416, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,834] LMCache INFO:[0m Reqid: chatcmpl-e7692c5ebe1640968b85c1c6c711147f, Total tokens 971, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,841] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b879d88427854f84852f00ea746123a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,842] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5245 ms, throughput: 6.5164 GB/s; offload_time: 0.4501 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,846] LMCache INFO:[0m Reqid: chatcmpl-e7692c5ebe1640968b85c1c6c711147f, Total tokens 971, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,853] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-52e8dc383fd742849f6e8f74de050c7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,854] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4357 ms, throughput: 7.8443 GB/s; offload_time: 0.3597 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,858] LMCache INFO:[0m Reqid: chatcmpl-e7692c5ebe1640968b85c1c6c711147f, Total tokens 971, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,860] LMCache INFO:[0m Reqid: chatcmpl-31681ea7fc9642bc834c3b8a577cab6b, Total tokens 490, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,880] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1f524e69b9384043a0b57056408d4ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,880] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4389 ms, throughput: 7.7883 GB/s; offload_time: 0.3615 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,881] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-eee904f833d445e78b0ee628979de976 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,882] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.8734 ms, throughput: 3.9134 GB/s; offload_time: 0.8064 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,886] LMCache INFO:[0m Reqid: chatcmpl-31681ea7fc9642bc834c3b8a577cab6b, Total tokens 490, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,894] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,894] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5326 ms, throughput: 6.4173 GB/s; offload_time: 0.4493 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,908] LMCache INFO:[0m Reqid: chatcmpl-e7692c5ebe1640968b85c1c6c711147f, Total tokens 973, LMCache hit tokens: 896, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,909] LMCache INFO:[0m Reqid: chatcmpl-31681ea7fc9642bc834c3b8a577cab6b, Total tokens 490, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,910] LMCache INFO:[0m Reqid: chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae, Total tokens 537, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:10,928] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e54f92177eb6419eb2bbc3dd2b4a0531 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,929] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4353 ms, throughput: 7.8523 GB/s; offload_time: 0.3613 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,929] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2685a839adb9408ba00645435aa97209 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,930] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7537 ms, throughput: 4.5346 GB/s; offload_time: 0.6474 ms, put_time: 0.1063 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,934] LMCache INFO:[0m Reqid: chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae, Total tokens 537, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,942] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8dc4dd47f11341f5b2f28484cd54ccb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,943] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4957 ms, throughput: 6.8959 GB/s; offload_time: 0.4206 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,943] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-27714f9ddf984aea881485b69c860b45 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,945] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4608 ms, throughput: 2.3397 GB/s; offload_time: 1.3856 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,949] LMCache INFO:[0m Reqid: chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae, Total tokens 537, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,956] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e5b3d51364f64c1c9d161ef50d0ee416 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,958] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1965 ms, throughput: 2.8566 GB/s; offload_time: 1.1182 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,962] LMCache INFO:[0m Reqid: chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae, Total tokens 537, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,963] LMCache INFO:[0m Reqid: chatcmpl-39fd6936c885448c8c481bcc4571ecf4, Total tokens 1063, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,964] LMCache INFO:[0m Reqid: chatcmpl-15e6cc1ebcac446eb5344f988dc45eee, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,965] LMCache INFO:[0m Reqid: chatcmpl-6ceb3d5a3b7c4fe9b33e6a669a00c74a, Total tokens 784, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,996] LMCache INFO:[0m Storing KV cache for 153 out of 537 tokens (skip_leading_tokens=384) for request chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,996] LMCache INFO:[0m Stored 153 out of total 537 tokens. size: 0.0041 gb, cost 0.6332 ms, throughput: 6.4525 GB/s; offload_time: 0.5259 ms, put_time: 0.1073 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:10,997] LMCache INFO:[0m Storing KV cache for 167 out of 1063 tokens (skip_leading_tokens=896) for request chatcmpl-39fd6936c885448c8c481bcc4571ecf4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:10,999] LMCache INFO:[0m Stored 167 out of total 1063 tokens. size: 0.0045 gb, cost 1.2283 ms, throughput: 3.6306 GB/s; offload_time: 1.1273 ms, put_time: 0.1010 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,000] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-15e6cc1ebcac446eb5344f988dc45eee [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,001] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.9944 ms, throughput: 3.2224 GB/s; offload_time: 0.8115 ms, put_time: 0.1829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,006] LMCache INFO:[0m Reqid: chatcmpl-6ceb3d5a3b7c4fe9b33e6a669a00c74a, Total tokens 784, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,007] LMCache INFO:[0m Reqid: chatcmpl-c971901052fc4529bd95046058affd1e, Total tokens 584, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,029] LMCache INFO:[0m Reqid: chatcmpl-c971901052fc4529bd95046058affd1e, Total tokens 584, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,029] LMCache INFO:[0m Reqid: chatcmpl-70e80257fcfe423f9b65c2f7e316becc, Total tokens 358, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,030] LMCache INFO:[0m Reqid: chatcmpl-e7f6a71cd55846ab8c5dfcf3c64b467e, Total tokens 183, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,030] LMCache INFO:[0m Reqid: chatcmpl-1262420eb32c45eba79b91b158e6b621, Total tokens 125, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,051] LMCache INFO:[0m Storing KV cache for 183 out of 183 tokens (skip_leading_tokens=0) for request chatcmpl-e7f6a71cd55846ab8c5dfcf3c64b467e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,051] LMCache INFO:[0m Stored 183 out of total 183 tokens. size: 0.0049 gb, cost 0.5089 ms, throughput: 9.6016 GB/s; offload_time: 0.4211 ms, put_time: 0.0879 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,052] LMCache INFO:[0m Storing KV cache for 125 out of 125 tokens (skip_leading_tokens=0) for request chatcmpl-1262420eb32c45eba79b91b158e6b621 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,053] LMCache INFO:[0m Stored 125 out of total 125 tokens. size: 0.0033 gb, cost 1.0919 ms, throughput: 3.0569 GB/s; offload_time: 0.6660 ms, put_time: 0.4259 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,054] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-70cd959aca2240d884936018bd299468 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,054] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6983 ms, throughput: 4.8947 GB/s; offload_time: 0.6453 ms, put_time: 0.0530 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,055] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,056] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9065 ms, throughput: 3.7707 GB/s; offload_time: 0.8368 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,056] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-acd05d9da2234fdbabe95c66df9966b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,057] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7027 ms, throughput: 4.8644 GB/s; offload_time: 0.6500 ms, put_time: 0.0527 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,076] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7efadbeb285f440f9d8c17a3f9cac985 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,077] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0636 ms, throughput: 3.2137 GB/s; offload_time: 0.9976 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,087] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1262420eb32c45eba79b91b158e6b621 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,089] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0291 ms, throughput: 3.3214 GB/s; offload_time: 0.9604 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,098] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,100] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.1269 ms, throughput: 3.0331 GB/s; offload_time: 1.0600 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,113] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,119] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-15e6cc1ebcac446eb5344f988dc45eee [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,120] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0266 ms, throughput: 3.3293 GB/s; offload_time: 0.9614 ms, put_time: 0.0653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,124] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,134] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,143] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,152] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,161] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,170] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,178] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-6ad8dc3faca74e32b182dea3af584a69 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,179] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0619 ms, throughput: 3.2187 GB/s; offload_time: 0.9966 ms, put_time: 0.0653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,179] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-31022f2973b9414a84fa6602360c71b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,181] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6576 ms, throughput: 2.0620 GB/s; offload_time: 1.5858 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,185] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,195] LMCache INFO:[0m Reqid: chatcmpl-124f2a83f9034bdd8e57e9927eedef75, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,196] LMCache INFO:[0m Reqid: chatcmpl-b98b4f0476e94cb8aa919dbc59efc8b4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,221] LMCache INFO:[0m Storing KV cache for 244 out of 1140 tokens (skip_leading_tokens=896) for request chatcmpl-124f2a83f9034bdd8e57e9927eedef75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,221] LMCache INFO:[0m Stored 244 out of total 1140 tokens. size: 0.0065 gb, cost 0.5876 ms, throughput: 11.0886 GB/s; offload_time: 0.4977 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,222] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-583acce7f2064e748294e3c9c975f07d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,223] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6539 ms, throughput: 5.2269 GB/s; offload_time: 0.5947 ms, put_time: 0.0592 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,228] LMCache INFO:[0m Reqid: chatcmpl-b98b4f0476e94cb8aa919dbc59efc8b4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,235] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,235] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4007 ms, throughput: 8.5300 GB/s; offload_time: 0.3351 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,239] LMCache INFO:[0m Reqid: chatcmpl-b98b4f0476e94cb8aa919dbc59efc8b4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,246] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b7dae668b3824ce88ef4232f477d919d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,247] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3984 ms, throughput: 8.5788 GB/s; offload_time: 0.3353 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,250] LMCache INFO:[0m Reqid: chatcmpl-b98b4f0476e94cb8aa919dbc59efc8b4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,251] LMCache INFO:[0m Reqid: chatcmpl-93e863191fb74c8196ccd81c6f640feb, Total tokens 128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,252] LMCache INFO:[0m Reqid: chatcmpl-e4246d643e1a47bcbd0bb86cb41f0757, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,252] LMCache INFO:[0m Reqid: chatcmpl-814b734b3d4f48ffb7709437a699100c, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,269] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-93e863191fb74c8196ccd81c6f640feb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,270] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0395 ms, throughput: 3.2881 GB/s; offload_time: 0.9709 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,270] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-e4246d643e1a47bcbd0bb86cb41f0757 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,271] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.5163 ms, throughput: 6.2060 GB/s; offload_time: 0.4521 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,271] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-814b734b3d4f48ffb7709437a699100c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,272] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.4936 ms, throughput: 5.6266 GB/s; offload_time: 0.4303 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,272] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,274] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5339 ms, throughput: 2.2283 GB/s; offload_time: 1.4733 ms, put_time: 0.0606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,274] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-31681ea7fc9642bc834c3b8a577cab6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,284] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 10.1767 ms, throughput: 0.3359 GB/s; offload_time: 9.8532 ms, put_time: 0.3235 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,296] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-dc6411db9bf947c6bff0514a9e34fb88 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,297] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2349 ms, throughput: 2.7678 GB/s; offload_time: 1.1704 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,308] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-cac0948b9a5648f58ccbd30c020c36c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,309] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0341 ms, throughput: 3.3054 GB/s; offload_time: 0.9613 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,313] LMCache INFO:[0m Reqid: chatcmpl-814b734b3d4f48ffb7709437a699100c, Total tokens 106, LMCache hit tokens: 104, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,327] LMCache INFO:[0m Reqid: chatcmpl-323295e122d24498aa1ad01e1ddd0379, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,337] LMCache INFO:[0m Reqid: chatcmpl-323295e122d24498aa1ad01e1ddd0379, Total tokens 1493, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,338] LMCache INFO:[0m Reqid: chatcmpl-e0e03195691f4da09b72abe27fce70fd, Total tokens 661, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,372] LMCache INFO:[0m Reqid: chatcmpl-e0e03195691f4da09b72abe27fce70fd, Total tokens 661, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,381] LMCache INFO:[0m Reqid: chatcmpl-e0e03195691f4da09b72abe27fce70fd, Total tokens 661, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,390] LMCache INFO:[0m Reqid: chatcmpl-e0e03195691f4da09b72abe27fce70fd, Total tokens 661, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,396] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5819e63b84bb4152b1c51aebe4e7e4d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,397] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.3731 ms, throughput: 9.1606 GB/s; offload_time: 0.3124 ms, put_time: 0.0607 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,397] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e4246d643e1a47bcbd0bb86cb41f0757 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,397] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6196 ms, throughput: 5.5165 GB/s; offload_time: 0.5543 ms, put_time: 0.0653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,402] LMCache INFO:[0m Reqid: chatcmpl-e0e03195691f4da09b72abe27fce70fd, Total tokens 661, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,403] LMCache INFO:[0m Reqid: chatcmpl-dfcea3292be54a41be2293fd2bc6349a, Total tokens 1056, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,404] LMCache INFO:[0m Reqid: chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb, Total tokens 653, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,405] LMCache INFO:[0m Reqid: chatcmpl-62efcb51b0e343f08b5cea72c203586d, Total tokens 1573, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,439] LMCache INFO:[0m Storing KV cache for 416 out of 1056 tokens (skip_leading_tokens=640) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,440] LMCache INFO:[0m Stored 416 out of total 1056 tokens. size: 0.0111 gb, cost 0.8904 ms, throughput: 12.4753 GB/s; offload_time: 0.7586 ms, put_time: 0.1318 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,440] LMCache INFO:[0m Storing KV cache for 141 out of 653 tokens (skip_leading_tokens=512) for request chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,444] LMCache INFO:[0m Stored 141 out of total 653 tokens. size: 0.0038 gb, cost 3.8520 ms, throughput: 0.9774 GB/s; offload_time: 3.6569 ms, put_time: 0.1951 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,445] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-70e80257fcfe423f9b65c2f7e316becc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,447] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.2004 ms, throughput: 1.5534 GB/s; offload_time: 2.0022 ms, put_time: 0.1982 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,448] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-124f2a83f9034bdd8e57e9927eedef75 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,449] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.8156 ms, throughput: 4.1906 GB/s; offload_time: 0.7371 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,455] LMCache INFO:[0m Reqid: chatcmpl-62efcb51b0e343f08b5cea72c203586d, Total tokens 1573, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,462] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-f0f908196129408d986369c40bf81a3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,462] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5517 ms, throughput: 6.1959 GB/s; offload_time: 0.4742 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,463] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,464] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6873 ms, throughput: 4.9729 GB/s; offload_time: 0.6210 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,468] LMCache INFO:[0m Reqid: chatcmpl-62efcb51b0e343f08b5cea72c203586d, Total tokens 1573, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,470] LMCache INFO:[0m Reqid: chatcmpl-6c2bc27cd7aa4145a8bcef10329bc37e, Total tokens 155, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,470] LMCache INFO:[0m Reqid: chatcmpl-67aaa8bf8796464598fe05cd89ed6ec7, Total tokens 387, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,508] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e89569baec794faabf98bbce35e8beff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,509] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4379 ms, throughput: 7.8060 GB/s; offload_time: 0.3626 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,513] LMCache INFO:[0m Reqid: chatcmpl-67aaa8bf8796464598fe05cd89ed6ec7, Total tokens 387, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,514] LMCache INFO:[0m Reqid: chatcmpl-cf54126eade34f00a82cf98dbe3271c3, Total tokens 129, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,515] LMCache INFO:[0m Reqid: chatcmpl-560e6056852543139c15c7b3b939f966, Total tokens 1291, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,531] LMCache INFO:[0m Storing KV cache for 387 out of 387 tokens (skip_leading_tokens=0) for request chatcmpl-67aaa8bf8796464598fe05cd89ed6ec7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,533] LMCache INFO:[0m Stored 387 out of total 387 tokens. size: 0.0103 gb, cost 1.1919 ms, throughput: 8.6703 GB/s; offload_time: 0.8385 ms, put_time: 0.3534 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,534] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-cf54126eade34f00a82cf98dbe3271c3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52518 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,536] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 1.8719 ms, throughput: 1.8402 GB/s; offload_time: 1.6776 ms, put_time: 0.1943 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,537] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4f941fc3bf614c8b8441e5533926f8bf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,538] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2199 ms, throughput: 2.8018 GB/s; offload_time: 1.1397 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,543] LMCache INFO:[0m Reqid: chatcmpl-560e6056852543139c15c7b3b939f966, Total tokens 1291, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52534 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,554] LMCache INFO:[0m Reqid: chatcmpl-560e6056852543139c15c7b3b939f966, Total tokens 1291, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,555] LMCache INFO:[0m Reqid: chatcmpl-fc14e6d32af44b46b03e25937c73c757, Total tokens 1264, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,585] LMCache INFO:[0m Storing KV cache for 1291 out of 1291 tokens (skip_leading_tokens=0) for request chatcmpl-560e6056852543139c15c7b3b939f966 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,591] LMCache INFO:[0m Stored 1291 out of total 1291 tokens. size: 0.0345 gb, cost 6.1214 ms, throughput: 5.6316 GB/s; offload_time: 5.1919 ms, put_time: 0.9295 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,602] LMCache INFO:[0m Reqid: chatcmpl-fc14e6d32af44b46b03e25937c73c757, Total tokens 1264, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,603] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1066, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,604] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 392, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,604] LMCache INFO:[0m Reqid: chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,652] LMCache INFO:[0m Storing KV cache for 624 out of 1264 tokens (skip_leading_tokens=640) for request chatcmpl-fc14e6d32af44b46b03e25937c73c757 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,653] LMCache INFO:[0m Stored 624 out of total 1264 tokens. size: 0.0167 gb, cost 1.5251 ms, throughput: 10.9257 GB/s; offload_time: 1.0846 ms, put_time: 0.4405 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,654] LMCache INFO:[0m Storing KV cache for 136 out of 392 tokens (skip_leading_tokens=256) for request chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,656] LMCache INFO:[0m Stored 136 out of total 392 tokens. size: 0.0036 gb, cost 1.5066 ms, throughput: 2.4104 GB/s; offload_time: 1.4100 ms, put_time: 0.0966 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,656] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,658] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 1.9585 ms, throughput: 1.2544 GB/s; offload_time: 1.2296 ms, put_time: 0.7289 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,671] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0414963f403f44a9bddaf4faab164414 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,672] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4924 ms, throughput: 6.9411 GB/s; offload_time: 0.4151 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,676] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 393, LMCache hit tokens: 392, need to load: 120 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,685] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 393, LMCache hit tokens: 392, need to load: 216 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,692] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-ce7e332191734512b674a77575df7865 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,693] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.6094 ms, throughput: 5.6091 GB/s; offload_time: 0.5357 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,698] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 393, LMCache hit tokens: 392, need to load: 296 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,705] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ea00a259f10a49f9b181d39f880b6ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,706] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2611 ms, throughput: 2.7103 GB/s; offload_time: 1.1869 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,720] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1071, LMCache hit tokens: 1024, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,721] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 393, LMCache hit tokens: 392, need to load: 344 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,722] LMCache INFO:[0m Reqid: chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58, Total tokens 93, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,736] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,738] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2739 ms, throughput: 2.6831 GB/s; offload_time: 1.1990 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,752] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 394, LMCache hit tokens: 392, need to load: 152 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,759] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,760] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.3413 ms, throughput: 2.5483 GB/s; offload_time: 1.2671 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,761] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,763] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5494 ms, throughput: 2.2060 GB/s; offload_time: 1.4738 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,767] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 394, LMCache hit tokens: 392, need to load: 248 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,774] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-225d204d715c4f79bdff3752c9680d28 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,776] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2281 ms, throughput: 2.7832 GB/s; offload_time: 1.1521 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO 07-11 15:21:11 [loggers.py:118] Engine 000: Avg prompt throughput: 14615.0 tokens/s, Avg generation throughput: 5043.1 tokens/s, Running: 84 reqs, Waiting: 14 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 23.2%
[32;20m[2025-07-11 15:21:11,790] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1075, LMCache hit tokens: 1024, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,800] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1075, LMCache hit tokens: 1024, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52672 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52682 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,810] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1075, LMCache hit tokens: 1024, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,817] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-dbbc92f313c644be9bedb18d43aea0ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,818] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2376 ms, throughput: 2.7619 GB/s; offload_time: 1.1599 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,822] LMCache INFO:[0m Reqid: chatcmpl-924649e3606447bd895d632d6d1afa7a, Total tokens 1075, LMCache hit tokens: 1024, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,824] LMCache INFO:[0m Reqid: chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590, Total tokens 394, LMCache hit tokens: 392, need to load: 344 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,824] LMCache INFO:[0m Reqid: chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58, Total tokens 93, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,825] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,840] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,842] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2538 ms, throughput: 2.7262 GB/s; offload_time: 1.1765 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,842] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-e7692c5ebe1640968b85c1c6c711147f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,844] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.6435 ms, throughput: 2.0797 GB/s; offload_time: 1.5635 ms, put_time: 0.0800 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,849] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,860] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,867] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-fc14e6d32af44b46b03e25937c73c757 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,869] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2857 ms, throughput: 2.6585 GB/s; offload_time: 1.2106 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,874] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,884] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,894] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:11,904] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,915] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,925] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,932] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-c11d75b682fd49cf9baa5952bece9746 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,934] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.3589 ms, throughput: 2.5153 GB/s; offload_time: 1.2835 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,939] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,947] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-42a454aa15754982a95ce1b34094b409 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,948] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2657 ms, throughput: 2.7004 GB/s; offload_time: 1.1845 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,953] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,961] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c971901052fc4529bd95046058affd1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,962] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2813 ms, throughput: 2.6676 GB/s; offload_time: 1.2030 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,967] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,974] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5c9c7be46e8148a59380f9696153372c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,975] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2554 ms, throughput: 2.7227 GB/s; offload_time: 1.1765 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:11,980] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:11,990] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,001] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,011] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,018] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,019] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 1.4405 ms, throughput: 2.3728 GB/s; offload_time: 1.3648 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,025] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,035] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,045] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,056] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,064] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-323295e122d24498aa1ad01e1ddd0379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,065] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.3556 ms, throughput: 2.5213 GB/s; offload_time: 1.2774 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,070] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,081] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,091] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52698 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52746 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,102] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,112] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,122] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,132] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,142] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,149] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e7f6a71cd55846ab8c5dfcf3c64b467e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,150] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2672 ms, throughput: 2.6972 GB/s; offload_time: 1.1914 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,155] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,165] LMCache INFO:[0m Reqid: chatcmpl-33fd647f3fb347fe9e6d2968622848f5, Total tokens 2252, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,166] LMCache INFO:[0m Reqid: chatcmpl-6d4a00222b1b4d659b749432debe8137, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,167] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,213] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-6d4a00222b1b4d659b749432debe8137 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,213] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.3969 ms, throughput: 6.1898 GB/s; offload_time: 0.3232 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,213] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-c897241b787443b2a14e0dd3a9c920e6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,214] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.7986 ms, throughput: 4.2799 GB/s; offload_time: 0.7304 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,220] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,230] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,240] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,247] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9a036238cbf144ecb6f220d48591a93f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,247] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4418 ms, throughput: 7.7359 GB/s; offload_time: 0.3694 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,252] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,262] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,269] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e885984a094e473fa10a505a56817107 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,269] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4430 ms, throughput: 7.7155 GB/s; offload_time: 0.3706 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,274] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,282] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,282] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4327 ms, throughput: 7.8992 GB/s; offload_time: 0.3580 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,287] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,294] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,295] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5754 ms, throughput: 5.9403 GB/s; offload_time: 0.5045 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,295] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-cbad0a5973ef4712bb32a27ac5dab6d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,296] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7462 ms, throughput: 4.5808 GB/s; offload_time: 0.6816 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,301] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,308] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-74c235d876b9466fbc94447a583b034b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,309] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5518 ms, throughput: 6.1947 GB/s; offload_time: 0.4808 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,313] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,321] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-94bd9489c4ae4c048b40e6625432b2ef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,322] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5446 ms, throughput: 6.2761 GB/s; offload_time: 0.4689 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,326] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,334] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,334] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4773 ms, throughput: 7.1615 GB/s; offload_time: 0.4011 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,335] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3c2bb209e5a64c9f92b07d7554083996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,335] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5154 ms, throughput: 6.6311 GB/s; offload_time: 0.4507 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,340] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,347] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-dd1da90ef0fe43aa90b797f740ee964e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,348] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.5779 ms, throughput: 5.9145 GB/s; offload_time: 0.5004 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,348] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ce4ece654ee94accaf7397ee804c3168 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,349] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6457 ms, throughput: 5.2938 GB/s; offload_time: 0.5840 ms, put_time: 0.0616 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,355] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,366] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,372] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7906934839aa48e4afb10b2943e2dc46 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,373] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4667 ms, throughput: 7.3233 GB/s; offload_time: 0.3910 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,378] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,385] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-34280e0ae00b48dc813e03e73d13e3eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,386] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5880 ms, throughput: 5.8127 GB/s; offload_time: 0.5156 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,391] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,401] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,410] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,421] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,428] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,429] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.5920 ms, throughput: 5.7740 GB/s; offload_time: 0.5186 ms, put_time: 0.0734 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,429] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-bf0264ad57cb4361a036ffc103348866 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,431] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4860 ms, throughput: 2.3001 GB/s; offload_time: 1.4180 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,436] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,446] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,455] LMCache INFO:[0m Reqid: chatcmpl-214ce059bcde44c8b53a2caa1ec24619, Total tokens 1484, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,456] LMCache INFO:[0m Reqid: chatcmpl-1d719705177b40a386de9dc4d04584a2, Total tokens 134, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,457] LMCache INFO:[0m Reqid: chatcmpl-6a7faa244a7c4583a3e381b9aad7e2a9, Total tokens 289, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,457] LMCache INFO:[0m Reqid: chatcmpl-d0b06f13b86c4d048c5632754211659c, Total tokens 267, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,458] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52800 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,496] LMCache INFO:[0m Storing KV cache for 134 out of 134 tokens (skip_leading_tokens=0) for request chatcmpl-1d719705177b40a386de9dc4d04584a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,497] LMCache INFO:[0m Stored 134 out of total 134 tokens. size: 0.0036 gb, cost 0.6025 ms, throughput: 5.9388 GB/s; offload_time: 0.4990 ms, put_time: 0.1035 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,497] LMCache INFO:[0m Storing KV cache for 139 out of 267 tokens (skip_leading_tokens=128) for request chatcmpl-d0b06f13b86c4d048c5632754211659c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,499] LMCache INFO:[0m Stored 139 out of total 267 tokens. size: 0.0037 gb, cost 1.6076 ms, throughput: 2.3089 GB/s; offload_time: 1.5117 ms, put_time: 0.0958 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,506] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,516] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,523] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1cd8c28ded1a4ba09401ce0e143af581 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,523] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4645 ms, throughput: 7.3576 GB/s; offload_time: 0.3938 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,524] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9fea699b5c154289a68469925ac5f538 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,525] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7045 ms, throughput: 4.8518 GB/s; offload_time: 0.6434 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,530] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,540] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,550] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,557] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-be274f5bc3d948b0b2ddd8fc46691aae [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,558] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4850 ms, throughput: 7.0469 GB/s; offload_time: 0.4011 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,563] LMCache INFO:[0m Reqid: chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3, Total tokens 1582, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,564] LMCache INFO:[0m Reqid: chatcmpl-49c59bdaba9d498aa4df7fa3de5ef672, Total tokens 379, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,564] LMCache INFO:[0m Reqid: chatcmpl-d9bef1da41b8469584b438df15793925, Total tokens 134, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,565] LMCache INFO:[0m Reqid: chatcmpl-acc04e6079a84a7981fc48f16ac0c155, Total tokens 707, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,566] LMCache INFO:[0m Reqid: chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5, Total tokens 211, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,566] LMCache INFO:[0m Reqid: chatcmpl-935799d0bff54ac7883a8044fd51b398, Total tokens 623, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,567] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,620] LMCache INFO:[0m Storing KV cache for 174 out of 1582 tokens (skip_leading_tokens=1408) for request chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,621] LMCache INFO:[0m Stored 174 out of total 1582 tokens. size: 0.0046 gb, cost 0.7264 ms, throughput: 6.3960 GB/s; offload_time: 0.6140 ms, put_time: 0.1124 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,621] LMCache INFO:[0m Storing KV cache for 134 out of 134 tokens (skip_leading_tokens=0) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,623] LMCache INFO:[0m Stored 134 out of total 134 tokens. size: 0.0036 gb, cost 1.4766 ms, throughput: 2.4232 GB/s; offload_time: 1.3356 ms, put_time: 0.1410 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,624] LMCache INFO:[0m Storing KV cache for 211 out of 211 tokens (skip_leading_tokens=0) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,628] LMCache INFO:[0m Stored 211 out of total 211 tokens. size: 0.0056 gb, cost 2.9715 ms, throughput: 1.8961 GB/s; offload_time: 2.8763 ms, put_time: 0.0951 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,628] LMCache INFO:[0m Storing KV cache for 367 out of 623 tokens (skip_leading_tokens=256) for request chatcmpl-935799d0bff54ac7883a8044fd51b398 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,630] LMCache INFO:[0m Stored 367 out of total 623 tokens. size: 0.0098 gb, cost 2.2948 ms, throughput: 4.2705 GB/s; offload_time: 1.8956 ms, put_time: 0.3991 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,637] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,646] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,663] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3dfdc664e67e4039bb3de1922770bf65 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,663] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4686 ms, throughput: 7.2941 GB/s; offload_time: 0.3920 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,667] LMCache INFO:[0m Reqid: chatcmpl-935799d0bff54ac7883a8044fd51b398, Total tokens 626, LMCache hit tokens: 623, need to load: 207 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,677] LMCache INFO:[0m Reqid: chatcmpl-935799d0bff54ac7883a8044fd51b398, Total tokens 626, LMCache hit tokens: 623, need to load: 255 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,684] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,685] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4581 ms, throughput: 7.4612 GB/s; offload_time: 0.3857 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,685] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-49c59bdaba9d498aa4df7fa3de5ef672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,686] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0043 ms, throughput: 3.4034 GB/s; offload_time: 0.7133 ms, put_time: 0.2910 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,691] LMCache INFO:[0m Reqid: chatcmpl-935799d0bff54ac7883a8044fd51b398, Total tokens 626, LMCache hit tokens: 623, need to load: 367 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,692] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,706] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,713] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,714] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.6043 ms, throughput: 5.6561 GB/s; offload_time: 0.5287 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,718] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,728] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,737] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,744] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-65374604f09142d092178075e8d4a2ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,745] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5371 ms, throughput: 6.3641 GB/s; offload_time: 0.4601 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,749] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,759] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,769] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,778] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,788] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,789] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,814] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,823] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,830] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-52e8dc383fd742849f6e8f74de050c7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,831] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4263 ms, throughput: 8.0186 GB/s; offload_time: 0.3537 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,831] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-62efcb51b0e343f08b5cea72c203586d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,832] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.9770 ms, throughput: 3.4985 GB/s; offload_time: 0.9029 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,837] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,845] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1f524e69b9384043a0b57056408d4ab5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,845] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4501 ms, throughput: 7.5943 GB/s; offload_time: 0.3762 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,845] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-eee904f833d445e78b0ee628979de976 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,846] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.8765 ms, throughput: 3.8996 GB/s; offload_time: 0.8082 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,851] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,858] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,859] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5422 ms, throughput: 6.3043 GB/s; offload_time: 0.4593 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,863] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,870] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,872] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3406 ms, throughput: 2.5495 GB/s; offload_time: 1.2576 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,872] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-935799d0bff54ac7883a8044fd51b398 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,874] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4316 ms, throughput: 2.3875 GB/s; offload_time: 1.3619 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,879] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,886] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e54f92177eb6419eb2bbc3dd2b4a0531 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,887] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2300 ms, throughput: 2.7789 GB/s; offload_time: 1.1496 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,888] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2685a839adb9408ba00645435aa97209 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,889] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4565 ms, throughput: 2.3467 GB/s; offload_time: 1.3843 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,890] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-924649e3606447bd895d632d6d1afa7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,891] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4786 ms, throughput: 2.3117 GB/s; offload_time: 1.4121 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,896] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,903] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8dc4dd47f11341f5b2f28484cd54ccb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,905] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3060 ms, throughput: 2.6172 GB/s; offload_time: 1.2273 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,905] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-27714f9ddf984aea881485b69c860b45 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,907] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4010 ms, throughput: 2.4396 GB/s; offload_time: 1.2696 ms, put_time: 0.1314 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,907] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-dac32ae70d7f40659591c1e0f774be67 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,909] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4856 ms, throughput: 2.3008 GB/s; offload_time: 1.4205 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,913] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,932] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 770, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,939] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-33fd647f3fb347fe9e6d2968622848f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,941] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.3713 ms, throughput: 2.4926 GB/s; offload_time: 1.2942 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,945] LMCache INFO:[0m Reqid: chatcmpl-dac32ae70d7f40659591c1e0f774be67, Total tokens 770, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,946] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,959] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,960] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2505 ms, throughput: 2.7333 GB/s; offload_time: 1.1733 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:12,960] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-acd05d9da2234fdbabe95c66df9966b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,962] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4524 ms, throughput: 2.3534 GB/s; offload_time: 1.3810 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52838 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:12,967] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,977] LMCache INFO:[0m Reqid: chatcmpl-c4c9f9c387354b77b7c394a53c74acc9, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,977] LMCache INFO:[0m Reqid: chatcmpl-84b718ca6abf4c24863092731007d910, Total tokens 332, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,978] LMCache INFO:[0m Reqid: chatcmpl-ed56c62d5cad4ac180cd7c77baf8d5de, Total tokens 255, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,978] LMCache INFO:[0m Reqid: chatcmpl-053d9db7970949cbad71aebe7d42e706, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:12,979] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,005] LMCache INFO:[0m Storing KV cache for 255 out of 255 tokens (skip_leading_tokens=0) for request chatcmpl-ed56c62d5cad4ac180cd7c77baf8d5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,005] LMCache INFO:[0m Stored 255 out of total 255 tokens. size: 0.0068 gb, cost 0.6448 ms, throughput: 10.5609 GB/s; offload_time: 0.5319 ms, put_time: 0.1129 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,006] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-053d9db7970949cbad71aebe7d42e706 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,007] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 1.4895 ms, throughput: 1.6493 GB/s; offload_time: 1.4035 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,008] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7efadbeb285f440f9d8c17a3f9cac985 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,009] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7023 ms, throughput: 4.8666 GB/s; offload_time: 0.6376 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,015] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,022] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ed56c62d5cad4ac180cd7c77baf8d5de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,024] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2869 ms, throughput: 2.6559 GB/s; offload_time: 1.2086 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,028] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,035] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,037] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.6474 ms, throughput: 2.0747 GB/s; offload_time: 1.5683 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,042] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,049] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e0e03195691f4da09b72abe27fce70fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,050] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2794 ms, throughput: 2.6714 GB/s; offload_time: 1.2023 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,055] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,065] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,075] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,085] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52860 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52878 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,113] LMCache INFO:[0m Reqid: chatcmpl-ed56c62d5cad4ac180cd7c77baf8d5de, Total tokens 264, LMCache hit tokens: 255, need to load: 159 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,120] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-31022f2973b9414a84fa6602360c71b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,121] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3387 ms, throughput: 2.5532 GB/s; offload_time: 1.2630 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,132] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,134] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2973 ms, throughput: 2.6346 GB/s; offload_time: 1.2139 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,138] LMCache INFO:[0m Reqid: chatcmpl-84b718ca6abf4c24863092731007d910, Total tokens 343, LMCache hit tokens: 256, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,145] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-583acce7f2064e748294e3c9c975f07d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,146] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2582 ms, throughput: 2.7166 GB/s; offload_time: 1.1772 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,150] LMCache INFO:[0m Reqid: chatcmpl-84b718ca6abf4c24863092731007d910, Total tokens 343, LMCache hit tokens: 256, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,158] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c6a5f6c172c04dc38786628e7b2a88ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,159] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2665 ms, throughput: 2.6987 GB/s; offload_time: 1.1893 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,163] LMCache INFO:[0m Reqid: chatcmpl-84b718ca6abf4c24863092731007d910, Total tokens 343, LMCache hit tokens: 256, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,173] LMCache INFO:[0m Reqid: chatcmpl-84b718ca6abf4c24863092731007d910, Total tokens 343, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,173] LMCache INFO:[0m Reqid: chatcmpl-ed56c62d5cad4ac180cd7c77baf8d5de, Total tokens 264, LMCache hit tokens: 255, need to load: 207 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,174] LMCache INFO:[0m Reqid: chatcmpl-053d9db7970949cbad71aebe7d42e706, Total tokens 100, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,175] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52894 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,188] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,190] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.1277 ms, throughput: 1.6064 GB/s; offload_time: 2.0485 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,195] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,202] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dc6411db9bf947c6bff0514a9e34fb88 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,204] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2739 ms, throughput: 2.6830 GB/s; offload_time: 1.1957 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,208] LMCache INFO:[0m Reqid: chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19, Total tokens 1247, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,210] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,241] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-cac0948b9a5648f58ccbd30c020c36c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,242] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4587 ms, throughput: 7.4511 GB/s; offload_time: 0.3751 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,242] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,243] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7377 ms, throughput: 4.6332 GB/s; offload_time: 0.6660 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,248] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,256] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-560e6056852543139c15c7b3b939f966 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,257] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5396 ms, throughput: 6.3345 GB/s; offload_time: 0.4641 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,257] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-214ce059bcde44c8b53a2caa1ec24619 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,258] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7235 ms, throughput: 4.7241 GB/s; offload_time: 0.6584 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,262] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,272] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,282] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,292] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,301] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,311] LMCache INFO:[0m Reqid: chatcmpl-59952dc1db99483a9e18c0307e4318db, Total tokens 1130, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,313] LMCache INFO:[0m Reqid: chatcmpl-353b1ec2c9fa42648bd8fc2e0560c472, Total tokens 819, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,313] LMCache INFO:[0m Reqid: chatcmpl-60ccb02e25e949b18be10d4e9bd8bfb9, Total tokens 464, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,314] LMCache INFO:[0m Reqid: chatcmpl-6e368a8d9c714945aecad1e6dd54c813, Total tokens 118, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,315] LMCache INFO:[0m Reqid: chatcmpl-3440ae676fbf410ba110b2fc661de661, Total tokens 536, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,315] LMCache INFO:[0m Reqid: chatcmpl-df13ae3b68d34056a2917eea30a43ffe, Total tokens 665, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:52928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,355] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-6e368a8d9c714945aecad1e6dd54c813 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,355] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.3905 ms, throughput: 8.0693 GB/s; offload_time: 0.3189 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,360] LMCache INFO:[0m Reqid: chatcmpl-df13ae3b68d34056a2917eea30a43ffe, Total tokens 665, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,362] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1345, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,378] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,379] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4520 ms, throughput: 7.5622 GB/s; offload_time: 0.3778 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,384] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1345, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,385] LMCache INFO:[0m Reqid: chatcmpl-6b00e29d9390404e939f43aebc0435cc, Total tokens 410, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,406] LMCache INFO:[0m Storing KV cache for 193 out of 1345 tokens (skip_leading_tokens=1152) for request chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,407] LMCache INFO:[0m Stored 193 out of total 1345 tokens. size: 0.0052 gb, cost 0.7072 ms, throughput: 7.2873 GB/s; offload_time: 0.5943 ms, put_time: 0.1129 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,407] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-cf54126eade34f00a82cf98dbe3271c3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,409] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9500 ms, throughput: 3.5979 GB/s; offload_time: 0.8564 ms, put_time: 0.0936 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:52974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52984 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:52988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,425] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 145 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,435] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 225 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,445] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 257 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,455] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 337 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,465] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 385 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,475] LMCache INFO:[0m Reqid: chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d, Total tokens 1346, LMCache hit tokens: 1345, need to load: 481 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,476] LMCache INFO:[0m Reqid: chatcmpl-6b00e29d9390404e939f43aebc0435cc, Total tokens 410, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,476] LMCache INFO:[0m Reqid: chatcmpl-4287322e6a854890876e1aa01003a27c, Total tokens 214, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,477] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,496] LMCache INFO:[0m Storing KV cache for 154 out of 410 tokens (skip_leading_tokens=256) for request chatcmpl-6b00e29d9390404e939f43aebc0435cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,497] LMCache INFO:[0m Stored 154 out of total 410 tokens. size: 0.0041 gb, cost 1.0874 ms, throughput: 3.7816 GB/s; offload_time: 0.9823 ms, put_time: 0.1052 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,498] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-acc04e6079a84a7981fc48f16ac0c155 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,501] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 3.0328 ms, throughput: 1.1270 GB/s; offload_time: 2.9704 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,507] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,514] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,515] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4716 ms, throughput: 7.2475 GB/s; offload_time: 0.3967 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,515] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6e368a8d9c714945aecad1e6dd54c813 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,516] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6335 ms, throughput: 5.3953 GB/s; offload_time: 0.5667 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,521] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,530] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,537] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,538] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5208 ms, throughput: 6.5630 GB/s; offload_time: 0.4454 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,542] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,553] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,560] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,562] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.4222 ms, throughput: 2.4034 GB/s; offload_time: 1.3446 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,562] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,564] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5309 ms, throughput: 2.2327 GB/s; offload_time: 1.4579 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,569] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,576] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-225d204d715c4f79bdff3752c9680d28 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,578] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2664 ms, throughput: 2.6990 GB/s; offload_time: 1.1877 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,582] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,593] LMCache INFO:[0m Reqid: chatcmpl-f8fd96abc7b843158a4ae5b1a1119812, Total tokens 1105, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,593] LMCache INFO:[0m Reqid: chatcmpl-e265362e6236418ca4fa526e2b8cdd94, Total tokens 140, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,594] LMCache INFO:[0m Reqid: chatcmpl-e2b1ba3704984dbf8f89ca842ef8bb52, Total tokens 91, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,594] LMCache INFO:[0m Reqid: chatcmpl-2c33ce6cdaad4494a20c24455da08565, Total tokens 176, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,595] LMCache INFO:[0m Reqid: chatcmpl-d8cbd46ad1b34cb492928ee0bd8cafc3, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,595] LMCache INFO:[0m Reqid: chatcmpl-c5c3a9fd92ff43d688174d0986140d36, Total tokens 190, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,596] LMCache INFO:[0m Reqid: chatcmpl-5e916300cba94438a670e07bf421ae50, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,632] LMCache INFO:[0m Storing KV cache for 209 out of 1105 tokens (skip_leading_tokens=896) for request chatcmpl-f8fd96abc7b843158a4ae5b1a1119812 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,633] LMCache INFO:[0m Stored 209 out of total 1105 tokens. size: 0.0056 gb, cost 0.7046 ms, throughput: 7.9208 GB/s; offload_time: 0.5864 ms, put_time: 0.1181 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,634] LMCache INFO:[0m Storing KV cache for 140 out of 140 tokens (skip_leading_tokens=0) for request chatcmpl-e265362e6236418ca4fa526e2b8cdd94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,635] LMCache INFO:[0m Stored 140 out of total 140 tokens. size: 0.0037 gb, cost 1.3466 ms, throughput: 2.7762 GB/s; offload_time: 1.2486 ms, put_time: 0.0980 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,635] LMCache INFO:[0m Storing KV cache for 91 out of 91 tokens (skip_leading_tokens=0) for request chatcmpl-e2b1ba3704984dbf8f89ca842ef8bb52 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,637] LMCache INFO:[0m Stored 91 out of total 91 tokens. size: 0.0024 gb, cost 1.1496 ms, throughput: 2.1137 GB/s; offload_time: 1.0829 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,637] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-d8cbd46ad1b34cb492928ee0bd8cafc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,638] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 1.1404 ms, throughput: 2.2947 GB/s; offload_time: 0.9892 ms, put_time: 0.1512 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,639] LMCache INFO:[0m Storing KV cache for 190 out of 190 tokens (skip_leading_tokens=0) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,640] LMCache INFO:[0m Stored 190 out of total 190 tokens. size: 0.0051 gb, cost 1.4657 ms, throughput: 3.4615 GB/s; offload_time: 1.3031 ms, put_time: 0.1626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,646] LMCache INFO:[0m Reqid: chatcmpl-5e916300cba94438a670e07bf421ae50, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,647] LMCache INFO:[0m Reqid: chatcmpl-2acd6788a1634147ac6cf6652447d888, Total tokens 679, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,665] LMCache INFO:[0m Storing KV cache for 150 out of 790 tokens (skip_leading_tokens=640) for request chatcmpl-5e916300cba94438a670e07bf421ae50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,666] LMCache INFO:[0m Stored 150 out of total 790 tokens. size: 0.0040 gb, cost 0.6720 ms, throughput: 5.9606 GB/s; offload_time: 0.5613 ms, put_time: 0.1107 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,671] LMCache INFO:[0m Reqid: chatcmpl-2acd6788a1634147ac6cf6652447d888, Total tokens 679, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,672] LMCache INFO:[0m Reqid: chatcmpl-1becbd4aca244616a5c4046e5cb2c849, Total tokens 222, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,673] LMCache INFO:[0m Reqid: chatcmpl-c6604ef17507432284278953f0ac64d0, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,673] LMCache INFO:[0m Reqid: chatcmpl-ac906dfeb9ea4effbd0057b1971ae9aa, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,674] LMCache INFO:[0m Reqid: chatcmpl-62c92cd18f19410498168327860d0d40, Total tokens 232, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,674] LMCache INFO:[0m Reqid: chatcmpl-3988b968ab5c47aa9f2a51e1982de934, Total tokens 190, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,675] LMCache INFO:[0m Reqid: chatcmpl-344d6abade6642a183411935427cfdab, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,676] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53084 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,703] LMCache INFO:[0m Storing KV cache for 167 out of 679 tokens (skip_leading_tokens=512) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,704] LMCache INFO:[0m Stored 167 out of total 679 tokens. size: 0.0045 gb, cost 0.6970 ms, throughput: 6.3978 GB/s; offload_time: 0.5897 ms, put_time: 0.1073 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,705] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-c6604ef17507432284278953f0ac64d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,706] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.7341 ms, throughput: 3.3465 GB/s; offload_time: 0.5918 ms, put_time: 0.1423 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,707] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-ac906dfeb9ea4effbd0057b1971ae9aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,708] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 1.0155 ms, throughput: 2.4454 GB/s; offload_time: 0.5196 ms, put_time: 0.4959 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,708] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-344d6abade6642a183411935427cfdab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,709] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.6008 ms, throughput: 4.7115 GB/s; offload_time: 0.5461 ms, put_time: 0.0547 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,710] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-053d9db7970949cbad71aebe7d42e706 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,711] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9212 ms, throughput: 3.7104 GB/s; offload_time: 0.8617 ms, put_time: 0.0595 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,718] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,725] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8fb19dbc2a8643c08c22de50cc2b19f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,726] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4942 ms, throughput: 6.9167 GB/s; offload_time: 0.4193 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,726] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-e7692c5ebe1640968b85c1c6c711147f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,728] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7230 ms, throughput: 1.9837 GB/s; offload_time: 1.6543 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,734] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:13,745] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,752] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-59952dc1db99483a9e18c0307e4318db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,753] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3225 ms, throughput: 2.5844 GB/s; offload_time: 1.2475 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,758] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,769] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,779] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,789] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,796] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8888f7c1f8ba4905b3eb57b36a5d2b19 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,798] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3318 ms, throughput: 2.5664 GB/s; offload_time: 1.2513 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,803] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,814] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,824] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,834] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,841] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c971901052fc4529bd95046058affd1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,843] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2684 ms, throughput: 2.6947 GB/s; offload_time: 1.1940 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,843] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,845] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.9399 ms, throughput: 1.7619 GB/s; offload_time: 1.8236 ms, put_time: 0.1163 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,851] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,858] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-5c9c7be46e8148a59380f9696153372c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,860] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2572 ms, throughput: 2.7188 GB/s; offload_time: 1.1784 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,864] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,872] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-84b718ca6abf4c24863092731007d910 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,873] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2512 ms, throughput: 2.7318 GB/s; offload_time: 1.1674 ms, put_time: 0.0838 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,878] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,888] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,898] LMCache INFO:[0m Reqid: chatcmpl-9919c9c415494cef9b524cefe216e828, Total tokens 1723, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,899] LMCache INFO:[0m Reqid: chatcmpl-f631cd5aa402440fabf32edf22b1548c, Total tokens 310, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,900] LMCache INFO:[0m Reqid: chatcmpl-a9d902d585e04f729f8738c430e74efc, Total tokens 650, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,901] LMCache INFO:[0m Reqid: chatcmpl-486575f0a8114f6997d1c7f1168e057d, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,901] LMCache INFO:[0m Reqid: chatcmpl-86ff2ba5874c41bf9df482730981e46c, Total tokens 617, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,948] LMCache INFO:[0m Storing KV cache for 182 out of 310 tokens (skip_leading_tokens=128) for request chatcmpl-f631cd5aa402440fabf32edf22b1548c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,949] LMCache INFO:[0m Stored 182 out of total 310 tokens. size: 0.0049 gb, cost 0.6313 ms, throughput: 7.6987 GB/s; offload_time: 0.5227 ms, put_time: 0.1086 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,949] LMCache INFO:[0m Storing KV cache for 138 out of 650 tokens (skip_leading_tokens=512) for request chatcmpl-a9d902d585e04f729f8738c430e74efc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,951] LMCache INFO:[0m Stored 138 out of total 650 tokens. size: 0.0037 gb, cost 1.4869 ms, throughput: 2.4784 GB/s; offload_time: 1.3853 ms, put_time: 0.1015 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,951] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-486575f0a8114f6997d1c7f1168e057d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,952] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.6866 ms, throughput: 3.8503 GB/s; offload_time: 0.5931 ms, put_time: 0.0935 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,953] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-59db00d2408e4128927b4814a00d6ea2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,955] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 1.0792 ms, throughput: 3.1672 GB/s; offload_time: 1.0132 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:13,960] LMCache INFO:[0m Reqid: chatcmpl-86ff2ba5874c41bf9df482730981e46c, Total tokens 617, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,970] LMCache INFO:[0m Reqid: chatcmpl-86ff2ba5874c41bf9df482730981e46c, Total tokens 617, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,971] LMCache INFO:[0m Reqid: chatcmpl-89951b9e652a4fa4ace2da38ab066c09, Total tokens 1278, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,971] LMCache INFO:[0m Reqid: chatcmpl-f03ee3b67f894aa3a43200f0eccffb3b, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:13,972] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,004] LMCache INFO:[0m Storing KV cache for 254 out of 1278 tokens (skip_leading_tokens=1024) for request chatcmpl-89951b9e652a4fa4ace2da38ab066c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,005] LMCache INFO:[0m Stored 254 out of total 1278 tokens. size: 0.0068 gb, cost 0.7038 ms, throughput: 9.6364 GB/s; offload_time: 0.5985 ms, put_time: 0.1053 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,006] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-f03ee3b67f894aa3a43200f0eccffb3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,007] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.9308 ms, throughput: 2.7255 GB/s; offload_time: 0.8639 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,013] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,023] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,031] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-323295e122d24498aa1ad01e1ddd0379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,032] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5550 ms, throughput: 6.1589 GB/s; offload_time: 0.4806 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,032] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-89951b9e652a4fa4ace2da38ab066c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,033] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.8396 ms, throughput: 4.0710 GB/s; offload_time: 0.7718 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,038] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,048] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,058] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,068] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,075] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-62c92cd18f19410498168327860d0d40 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,076] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4612 ms, throughput: 7.4105 GB/s; offload_time: 0.3862 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,080] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,090] LMCache INFO:[0m Reqid: chatcmpl-9a5fded8ff8a4b70a84d713062df35c0, Total tokens 1411, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,091] LMCache INFO:[0m Reqid: chatcmpl-d9c1fc2fd6c8428cbf129a48b622c10b, Total tokens 526, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,092] LMCache INFO:[0m Reqid: chatcmpl-b5b0ee60309b43458801c119a7cbaac5, Total tokens 168, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,127] LMCache INFO:[0m Storing KV cache for 131 out of 1411 tokens (skip_leading_tokens=1280) for request chatcmpl-9a5fded8ff8a4b70a84d713062df35c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,128] LMCache INFO:[0m Stored 131 out of total 1411 tokens. size: 0.0035 gb, cost 0.6931 ms, throughput: 5.0469 GB/s; offload_time: 0.5839 ms, put_time: 0.1092 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,128] LMCache INFO:[0m Storing KV cache for 142 out of 526 tokens (skip_leading_tokens=384) for request chatcmpl-d9c1fc2fd6c8428cbf129a48b622c10b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,130] LMCache INFO:[0m Stored 142 out of total 526 tokens. size: 0.0038 gb, cost 1.5070 ms, throughput: 2.5161 GB/s; offload_time: 1.2238 ms, put_time: 0.2832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,136] LMCache INFO:[0m Reqid: chatcmpl-b5b0ee60309b43458801c119a7cbaac5, Total tokens 168, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,137] LMCache INFO:[0m Reqid: chatcmpl-b08a299ce8c14b79b311ca86d9165459, Total tokens 445, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,150] LMCache INFO:[0m Storing KV cache for 168 out of 168 tokens (skip_leading_tokens=0) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,150] LMCache INFO:[0m Stored 168 out of total 168 tokens. size: 0.0045 gb, cost 0.6523 ms, throughput: 6.8778 GB/s; offload_time: 0.5317 ms, put_time: 0.1206 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,155] LMCache INFO:[0m Reqid: chatcmpl-b08a299ce8c14b79b311ca86d9165459, Total tokens 445, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,156] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1052, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,173] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e7f6a71cd55846ab8c5dfcf3c64b467e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,174] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4353 ms, throughput: 7.8518 GB/s; offload_time: 0.3598 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,179] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1052, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,187] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-60ccb02e25e949b18be10d4e9bd8bfb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,187] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4721 ms, throughput: 7.2400 GB/s; offload_time: 0.3929 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,191] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1052, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,201] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1052, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,211] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1052, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,212] LMCache INFO:[0m Reqid: chatcmpl-bada7a64fb1c434382eb02391493a9b7, Total tokens 365, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,239] LMCache INFO:[0m Storing KV cache for 1052 out of 1052 tokens (skip_leading_tokens=0) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,243] LMCache INFO:[0m Stored 1052 out of total 1052 tokens. size: 0.0281 gb, cost 4.0010 ms, throughput: 7.0211 GB/s; offload_time: 3.7199 ms, put_time: 0.2811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,243] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4287322e6a854890876e1aa01003a27c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,249] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 5.3227 ms, throughput: 0.6421 GB/s; offload_time: 5.0730 ms, put_time: 0.2497 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,266] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1053, LMCache hit tokens: 1052, need to load: 124 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,276] LMCache INFO:[0m Reqid: chatcmpl-f9ad70b924fb4694808333631e63b8c1, Total tokens 1053, LMCache hit tokens: 1052, need to load: 172 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,277] LMCache INFO:[0m Reqid: chatcmpl-bada7a64fb1c434382eb02391493a9b7, Total tokens 365, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,277] LMCache INFO:[0m Reqid: chatcmpl-b23be3e0e9e4488e93abb92b0fbf8b6c, Total tokens 566, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,278] LMCache INFO:[0m Reqid: chatcmpl-f2b78fb6e17c4635932591dd2a0fc46a, Total tokens 356, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,279] LMCache INFO:[0m Reqid: chatcmpl-d08d8b25245a4822a3f3ea2ed278b228, Total tokens 498, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,306] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-ac906dfeb9ea4effbd0057b1971ae9aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,306] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4401 ms, throughput: 7.7659 GB/s; offload_time: 0.3622 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,310] LMCache INFO:[0m Reqid: chatcmpl-d08d8b25245a4822a3f3ea2ed278b228, Total tokens 498, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,318] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,318] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4610 ms, throughput: 7.4135 GB/s; offload_time: 0.3863 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,323] LMCache INFO:[0m Reqid: chatcmpl-d08d8b25245a4822a3f3ea2ed278b228, Total tokens 498, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,330] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,332] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.4325 ms, throughput: 2.3860 GB/s; offload_time: 1.3544 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,344] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-74c235d876b9466fbc94447a583b034b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,345] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.3675 ms, throughput: 2.4994 GB/s; offload_time: 1.2900 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53250 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,350] LMCache INFO:[0m Reqid: chatcmpl-f2b78fb6e17c4635932591dd2a0fc46a, Total tokens 359, LMCache hit tokens: 256, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,351] LMCache INFO:[0m Reqid: chatcmpl-d08d8b25245a4822a3f3ea2ed278b228, Total tokens 498, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,366] LMCache INFO:[0m Reqid: chatcmpl-d08d8b25245a4822a3f3ea2ed278b228, Total tokens 498, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,367] LMCache INFO:[0m Reqid: chatcmpl-f371a6637aa84f1d9b10e11d75331f89, Total tokens 421, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,367] LMCache INFO:[0m Reqid: chatcmpl-e820907b249b4f088ddf71a8a25e1187, Total tokens 136, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,368] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,392] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-e820907b249b4f088ddf71a8a25e1187 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,393] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 0.6182 ms, throughput: 5.8740 GB/s; offload_time: 0.5060 ms, put_time: 0.1123 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,393] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-170c10ebcd4d4d88b96acbd9c172bc15 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,395] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2542 ms, throughput: 2.7252 GB/s; offload_time: 1.0962 ms, put_time: 0.1580 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,400] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,408] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-86ff2ba5874c41bf9df482730981e46c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,408] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4849 ms, throughput: 7.0491 GB/s; offload_time: 0.4090 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,412] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,423] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,432] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,440] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-34280e0ae00b48dc813e03e73d13e3eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,441] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.4381 ms, throughput: 2.3768 GB/s; offload_time: 1.3623 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,445] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 621, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,446] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 219, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,447] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53266 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,470] LMCache INFO:[0m Storing KV cache for 219 out of 219 tokens (skip_leading_tokens=0) for request chatcmpl-13f230aa4aee4661a040780ca69bbdc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,471] LMCache INFO:[0m Stored 219 out of total 219 tokens. size: 0.0058 gb, cost 0.6277 ms, throughput: 9.3160 GB/s; offload_time: 0.5118 ms, put_time: 0.1159 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,471] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1d719705177b40a386de9dc4d04584a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,473] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0878 ms, throughput: 3.1420 GB/s; offload_time: 0.9924 ms, put_time: 0.0954 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,473] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f8fd96abc7b843158a4ae5b1a1119812 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,474] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.9703 ms, throughput: 3.5227 GB/s; offload_time: 0.9074 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,475] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-486575f0a8114f6997d1c7f1168e057d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,476] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5707 ms, throughput: 2.1760 GB/s; offload_time: 1.3912 ms, put_time: 0.1795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,491] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 220, LMCache hit tokens: 219, need to load: 139 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,492] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,502] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,503] LMCache INFO:[0m Reqid: chatcmpl-03ba5e3808374bc0be4698715bb3e1a2, Total tokens 1442, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,524] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,525] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5747 ms, throughput: 5.9479 GB/s; offload_time: 0.4932 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,526] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-bf0264ad57cb4361a036ffc103348866 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,526] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7420 ms, throughput: 4.6065 GB/s; offload_time: 0.6709 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,531] LMCache INFO:[0m Reqid: chatcmpl-03ba5e3808374bc0be4698715bb3e1a2, Total tokens 1442, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,550] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,558] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,558] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4454 ms, throughput: 7.6740 GB/s; offload_time: 0.3714 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,558] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f03ee3b67f894aa3a43200f0eccffb3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,559] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6056 ms, throughput: 5.6442 GB/s; offload_time: 0.5031 ms, put_time: 0.1025 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,564] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,571] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-76ed86fc031d4cb6a4aecb89007cd87d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,573] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3328 ms, throughput: 2.5645 GB/s; offload_time: 1.2537 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,577] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,584] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9fea699b5c154289a68469925ac5f538 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,586] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2894 ms, throughput: 2.6508 GB/s; offload_time: 1.2101 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,591] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,598] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-bada7a64fb1c434382eb02391493a9b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,599] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3024 ms, throughput: 2.6243 GB/s; offload_time: 1.2272 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,600] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d08d8b25245a4822a3f3ea2ed278b228 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,602] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5872 ms, throughput: 2.1535 GB/s; offload_time: 1.5146 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,606] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 496 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,616] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 560 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,625] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 576 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,635] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,645] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,664] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 233, LMCache hit tokens: 219, need to load: 107 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,680] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,682] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2811 ms, throughput: 2.6679 GB/s; offload_time: 1.2022 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,682] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-49c59bdaba9d498aa4df7fa3de5ef672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,684] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4722 ms, throughput: 2.3217 GB/s; offload_time: 1.3892 ms, put_time: 0.0829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,688] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 638, LMCache hit tokens: 512, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,698] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 638, LMCache hit tokens: 512, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,699] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 233, LMCache hit tokens: 219, need to load: 171 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,699] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,713] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-8a70d2828d5c417ca4dcfe4068288d1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,714] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 1.4592 ms, throughput: 2.3423 GB/s; offload_time: 1.3833 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,715] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,716] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6978 ms, throughput: 2.0132 GB/s; offload_time: 1.6104 ms, put_time: 0.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,717] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-f2b78fb6e17c4635932591dd2a0fc46a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,719] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3846 ms, throughput: 2.4685 GB/s; offload_time: 1.3123 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,733] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 234, LMCache hit tokens: 219, need to load: 75 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,740] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3988b968ab5c47aa9f2a51e1982de934 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,741] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2373 ms, throughput: 2.7625 GB/s; offload_time: 1.1529 ms, put_time: 0.0844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,742] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,743] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7060 ms, throughput: 2.0035 GB/s; offload_time: 1.6379 ms, put_time: 0.0681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,748] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 234, LMCache hit tokens: 219, need to load: 123 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,749] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,771] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 235, LMCache hit tokens: 219, need to load: 107 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,790] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,800] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,809] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,819] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,826] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-52e8dc383fd742849f6e8f74de050c7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,829] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.2415 ms, throughput: 1.5249 GB/s; offload_time: 2.1633 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,829] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-62efcb51b0e343f08b5cea72c203586d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,831] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 2.0025 ms, throughput: 1.7068 GB/s; offload_time: 1.9150 ms, put_time: 0.0876 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,836] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,844] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-eee904f833d445e78b0ee628979de976 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,845] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3397 ms, throughput: 2.5513 GB/s; offload_time: 1.2630 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,849] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,857] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,858] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.3269 ms, throughput: 2.5758 GB/s; offload_time: 1.2439 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,862] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,870] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,872] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3512 ms, throughput: 2.5296 GB/s; offload_time: 1.2741 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,872] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-935799d0bff54ac7883a8044fd51b398 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,874] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4282 ms, throughput: 2.3933 GB/s; offload_time: 1.3552 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,880] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 448 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,887] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-924649e3606447bd895d632d6d1afa7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,889] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.4915 ms, throughput: 2.2917 GB/s; offload_time: 1.4133 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,889] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2c33ce6cdaad4494a20c24455da08565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,891] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3878 ms, throughput: 2.4629 GB/s; offload_time: 1.3146 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,896] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,905] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:14,922] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-dac32ae70d7f40659591c1e0f774be67 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,923] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2723 ms, throughput: 2.6864 GB/s; offload_time: 1.1998 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,927] LMCache INFO:[0m Reqid: chatcmpl-e820907b249b4f088ddf71a8a25e1187, Total tokens 177, LMCache hit tokens: 136, need to load: 24 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,935] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-33fd647f3fb347fe9e6d2968622848f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,936] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.3939 ms, throughput: 2.4520 GB/s; offload_time: 1.3134 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,940] LMCache INFO:[0m Reqid: chatcmpl-e820907b249b4f088ddf71a8a25e1187, Total tokens 177, LMCache hit tokens: 136, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,941] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 644, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,942] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 235, LMCache hit tokens: 219, need to load: 171 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,955] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,956] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2901 ms, throughput: 2.6493 GB/s; offload_time: 1.2133 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,957] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-acd05d9da2234fdbabe95c66df9966b6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,959] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6288 ms, throughput: 2.0984 GB/s; offload_time: 1.5538 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,973] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 645, LMCache hit tokens: 512, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,980] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-7efadbeb285f440f9d8c17a3f9cac985 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,982] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2512 ms, throughput: 2.7318 GB/s; offload_time: 1.1737 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,982] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-df13ae3b68d34056a2917eea30a43ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,984] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.6479 ms, throughput: 2.0741 GB/s; offload_time: 1.5731 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,984] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-9919c9c415494cef9b524cefe216e828 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,986] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6059 ms, throughput: 2.1284 GB/s; offload_time: 1.5355 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:14,990] LMCache INFO:[0m Reqid: chatcmpl-bcfc6319defe426c85cbbe9eed39e3ab, Total tokens 645, LMCache hit tokens: 512, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,991] LMCache INFO:[0m Reqid: chatcmpl-13f230aa4aee4661a040780ca69bbdc0, Total tokens 235, LMCache hit tokens: 219, need to load: 171 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,992] LMCache INFO:[0m Reqid: chatcmpl-52fb98632a9f4c26972785314e9de8f0, Total tokens 686, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:14,993] LMCache INFO:[0m Reqid: chatcmpl-03ba5e3808374bc0be4698715bb3e1a2, Total tokens 1442, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,010] LMCache INFO:[0m Reqid: chatcmpl-03ba5e3808374bc0be4698715bb3e1a2, Total tokens 1442, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,011] LMCache INFO:[0m Reqid: chatcmpl-2a31bb46181b423caeffe68382fcdff8, Total tokens 570, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,012] LMCache INFO:[0m Reqid: chatcmpl-fa867745fa4a4b9081d724cd709a63e0, Total tokens 788, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,050] LMCache INFO:[0m Storing KV cache for 1442 out of 1442 tokens (skip_leading_tokens=0) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,058] LMCache INFO:[0m Stored 1442 out of total 1442 tokens. size: 0.0385 gb, cost 7.6983 ms, throughput: 5.0018 GB/s; offload_time: 7.1415 ms, put_time: 0.5567 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,058] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,069] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 11.4318 ms, throughput: 0.2990 GB/s; offload_time: 11.3540 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,078] LMCache INFO:[0m Reqid: chatcmpl-fa867745fa4a4b9081d724cd709a63e0, Total tokens 788, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,085] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e0e03195691f4da09b72abe27fce70fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,086] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2950 ms, throughput: 2.6393 GB/s; offload_time: 1.2189 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,091] LMCache INFO:[0m Reqid: chatcmpl-fa867745fa4a4b9081d724cd709a63e0, Total tokens 788, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,098] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,099] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.2603 ms, throughput: 2.7120 GB/s; offload_time: 1.1832 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,110] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-f631cd5aa402440fabf32edf22b1548c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,111] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2556 ms, throughput: 2.7223 GB/s; offload_time: 1.1792 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,116] LMCache INFO:[0m Reqid: chatcmpl-2a31bb46181b423caeffe68382fcdff8, Total tokens 573, LMCache hit tokens: 512, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,116] LMCache INFO:[0m Reqid: chatcmpl-fa867745fa4a4b9081d724cd709a63e0, Total tokens 788, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,117] LMCache INFO:[0m Reqid: chatcmpl-6957940dd1b144d2b66c0111f9596bc5, Total tokens 207, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,118] LMCache INFO:[0m Reqid: chatcmpl-e7de067351814e828efb54d340dd332a, Total tokens 1402, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53376 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,145] LMCache INFO:[0m Storing KV cache for 148 out of 788 tokens (skip_leading_tokens=640) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,145] LMCache INFO:[0m Stored 148 out of total 788 tokens. size: 0.0040 gb, cost 0.6635 ms, throughput: 5.9563 GB/s; offload_time: 0.5484 ms, put_time: 0.1151 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,146] LMCache INFO:[0m Storing KV cache for 207 out of 207 tokens (skip_leading_tokens=0) for request chatcmpl-6957940dd1b144d2b66c0111f9596bc5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,147] LMCache INFO:[0m Stored 207 out of total 207 tokens. size: 0.0055 gb, cost 1.2218 ms, throughput: 4.5242 GB/s; offload_time: 1.1278 ms, put_time: 0.0940 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,153] LMCache INFO:[0m Reqid: chatcmpl-e7de067351814e828efb54d340dd332a, Total tokens 1402, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,160] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6b00e29d9390404e939f43aebc0435cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,161] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4582 ms, throughput: 7.4599 GB/s; offload_time: 0.3830 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,165] LMCache INFO:[0m Reqid: chatcmpl-e7de067351814e828efb54d340dd332a, Total tokens 1402, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,175] LMCache INFO:[0m Reqid: chatcmpl-e7de067351814e828efb54d340dd332a, Total tokens 1402, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,176] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,210] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,218] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-31022f2973b9414a84fa6602360c71b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,218] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5121 ms, throughput: 6.6743 GB/s; offload_time: 0.4384 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,218] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b08a299ce8c14b79b311ca86d9165459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,219] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.8534 ms, throughput: 4.0052 GB/s; offload_time: 0.7847 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,224] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,232] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,232] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4885 ms, throughput: 6.9967 GB/s; offload_time: 0.4118 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,236] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,243] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-583acce7f2064e748294e3c9c975f07d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,244] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4666 ms, throughput: 7.3259 GB/s; offload_time: 0.3933 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,248] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,258] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,268] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,275] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,276] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5432 ms, throughput: 6.2925 GB/s; offload_time: 0.4664 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,276] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-e7de067351814e828efb54d340dd332a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,277] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.8675 ms, throughput: 3.9399 GB/s; offload_time: 0.8021 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,282] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,289] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-dc6411db9bf947c6bff0514a9e34fb88 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,290] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4770 ms, throughput: 7.1649 GB/s; offload_time: 0.4017 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,294] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,301] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,302] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4632 ms, throughput: 7.3784 GB/s; offload_time: 0.3884 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,306] LMCache INFO:[0m Reqid: chatcmpl-100fe76785d947ed8190d9173925e11a, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,307] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,331] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-560e6056852543139c15c7b3b939f966 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,331] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5122 ms, throughput: 6.6728 GB/s; offload_time: 0.4356 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,335] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,346] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,353] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5e916300cba94438a670e07bf421ae50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,354] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4755 ms, throughput: 7.1888 GB/s; offload_time: 0.4031 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,358] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,367] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,374] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-13f230aa4aee4661a040780ca69bbdc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,375] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4561 ms, throughput: 7.4937 GB/s; offload_time: 0.3724 ms, put_time: 0.0837 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,379] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,389] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,397] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b23be3e0e9e4488e93abb92b0fbf8b6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,398] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4871 ms, throughput: 7.0175 GB/s; offload_time: 0.4122 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,402] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,410] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,410] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4852 ms, throughput: 7.0441 GB/s; offload_time: 0.4045 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,414] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,421] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-cf54126eade34f00a82cf98dbe3271c3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,422] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4536 ms, throughput: 7.5359 GB/s; offload_time: 0.3794 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,426] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,435] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,445] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,452] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e265362e6236418ca4fa526e2b8cdd94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,453] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2871 ms, throughput: 2.6556 GB/s; offload_time: 1.2121 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,457] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,464] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,466] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2197 ms, throughput: 2.8024 GB/s; offload_time: 1.1443 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,470] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,479] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,489] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53476 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,496] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-acc04e6079a84a7981fc48f16ac0c155 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,498] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.2836 ms, throughput: 2.6628 GB/s; offload_time: 1.2085 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,501] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,509] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-cc4b89abe6fb4bd8b2786e87e0547590 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,510] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2478 ms, throughput: 2.7392 GB/s; offload_time: 1.1664 ms, put_time: 0.0814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,514] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,524] LMCache INFO:[0m Reqid: chatcmpl-d7c27d3404d244dd920073cf660bebf7, Total tokens 1458, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,525] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1573, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,526] LMCache INFO:[0m Reqid: chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,579] LMCache INFO:[0m Storing KV cache for 1458 out of 1458 tokens (skip_leading_tokens=0) for request chatcmpl-d7c27d3404d244dd920073cf660bebf7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,582] LMCache INFO:[0m Stored 1458 out of total 1458 tokens. size: 0.0389 gb, cost 2.4519 ms, throughput: 15.8786 GB/s; offload_time: 2.1048 ms, put_time: 0.3471 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,584] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,588] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 3.8190 ms, throughput: 0.8950 GB/s; offload_time: 3.4323 ms, put_time: 0.3868 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,594] LMCache INFO:[0m Reqid: chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,605] LMCache INFO:[0m Reqid: chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,612] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,614] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.4005 ms, throughput: 2.4406 GB/s; offload_time: 1.3235 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,614] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,616] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5074 ms, throughput: 2.2675 GB/s; offload_time: 1.4411 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,630] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,640] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,650] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,659] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,666] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-053d9db7970949cbad71aebe7d42e706 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,668] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2435 ms, throughput: 2.7488 GB/s; offload_time: 1.1679 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,672] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,680] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-e7692c5ebe1640968b85c1c6c711147f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,681] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2900 ms, throughput: 2.6495 GB/s; offload_time: 1.2140 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,685] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,696] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 512 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,703] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-59952dc1db99483a9e18c0307e4318db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,704] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.3303 ms, throughput: 2.5693 GB/s; offload_time: 1.2470 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,705] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,706] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5078 ms, throughput: 2.2668 GB/s; offload_time: 1.4335 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,712] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,721] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 672 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,731] LMCache INFO:[0m Reqid: chatcmpl-29b3bd4a742c4742a1204da81b22b4e5, Total tokens 1576, LMCache hit tokens: 1536, need to load: 784 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,732] LMCache INFO:[0m Reqid: chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,733] LMCache INFO:[0m Reqid: chatcmpl-5a99df1a5357469b82db40be11e4d4a6, Total tokens 1637, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,747] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,747] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.4108 ms, throughput: 7.9305 GB/s; offload_time: 0.3355 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,747] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a9d902d585e04f729f8738c430e74efc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,749] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.7766 ms, throughput: 1.9238 GB/s; offload_time: 1.6560 ms, put_time: 0.1206 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,750] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,751] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4124 ms, throughput: 2.4200 GB/s; offload_time: 1.3455 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,756] LMCache INFO:[0m Reqid: chatcmpl-5a99df1a5357469b82db40be11e4d4a6, Total tokens 1637, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,766] LMCache INFO:[0m Reqid: chatcmpl-5a99df1a5357469b82db40be11e4d4a6, Total tokens 1637, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,768] LMCache INFO:[0m Reqid: chatcmpl-ca871f3942b54d97bf3aa89ef68bae83, Total tokens 563, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,768] LMCache INFO:[0m Reqid: chatcmpl-c5a4babe97a841c9bd6dc27205f2d674, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,769] LMCache INFO:[0m Reqid: chatcmpl-f9de432d8ffe4a558456696bbe434ee3, Total tokens 554, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53530 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,811] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-c5a4babe97a841c9bd6dc27205f2d674 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,812] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 0.6033 ms, throughput: 5.8428 GB/s; offload_time: 0.4944 ms, put_time: 0.1089 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,817] LMCache INFO:[0m Reqid: chatcmpl-f9de432d8ffe4a558456696bbe434ee3, Total tokens 554, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,818] LMCache INFO:[0m Reqid: chatcmpl-e8499ac4ffb44f12adac47f9fc884179, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,819] LMCache INFO:[0m Reqid: chatcmpl-ac6b72a2fd9f43fb960c592341e76d44, Total tokens 620, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,820] LMCache INFO:[0m Reqid: chatcmpl-3ad7318ff1a8461c95ee9df6842be628, Total tokens 407, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,820] LMCache INFO:[0m Reqid: chatcmpl-1513ed157e7c42b38c24ceaf72da4d9a, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,821] LMCache INFO:[0m Reqid: chatcmpl-7168e3099c384df282cce69a9b22e3df, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,821] LMCache INFO:[0m Reqid: chatcmpl-205abb7f668c49c8b5ad49ad89716b7f, Total tokens 161, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,851] LMCache INFO:[0m Storing KV cache for 298 out of 554 tokens (skip_leading_tokens=256) for request chatcmpl-f9de432d8ffe4a558456696bbe434ee3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,852] LMCache INFO:[0m Stored 298 out of total 554 tokens. size: 0.0080 gb, cost 1.0487 ms, throughput: 7.5877 GB/s; offload_time: 0.7358 ms, put_time: 0.3130 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,853] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-e8499ac4ffb44f12adac47f9fc884179 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,854] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 1.0550 ms, throughput: 2.6576 GB/s; offload_time: 0.9874 ms, put_time: 0.0677 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,854] LMCache INFO:[0m Storing KV cache for 151 out of 407 tokens (skip_leading_tokens=256) for request chatcmpl-3ad7318ff1a8461c95ee9df6842be628 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,858] LMCache INFO:[0m Stored 151 out of total 407 tokens. size: 0.0040 gb, cost 3.1596 ms, throughput: 1.2761 GB/s; offload_time: 3.0185 ms, put_time: 0.1411 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,858] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-1513ed157e7c42b38c24ceaf72da4d9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,859] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.6519 ms, throughput: 4.5470 GB/s; offload_time: 0.5006 ms, put_time: 0.1513 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,860] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-7168e3099c384df282cce69a9b22e3df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,861] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.4567 ms, throughput: 7.1337 GB/s; offload_time: 0.3988 ms, put_time: 0.0579 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53580 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,866] LMCache INFO:[0m Reqid: chatcmpl-205abb7f668c49c8b5ad49ad89716b7f, Total tokens 161, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,876] LMCache INFO:[0m Reqid: chatcmpl-205abb7f668c49c8b5ad49ad89716b7f, Total tokens 161, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,883] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c971901052fc4529bd95046058affd1e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,884] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4919 ms, throughput: 6.9490 GB/s; offload_time: 0.4185 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,884] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,886] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.8835 ms, throughput: 3.8687 GB/s; offload_time: 0.8176 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,886] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-100fe76785d947ed8190d9173925e11a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,887] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6749 ms, throughput: 5.0644 GB/s; offload_time: 0.6120 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,899] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6957940dd1b144d2b66c0111f9596bc5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,900] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4486 ms, throughput: 7.6199 GB/s; offload_time: 0.3737 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,900] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,901] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5242 ms, throughput: 6.5202 GB/s; offload_time: 0.4548 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,905] LMCache INFO:[0m Reqid: chatcmpl-7168e3099c384df282cce69a9b22e3df, Total tokens 125, LMCache hit tokens: 122, need to load: 74 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,905] LMCache INFO:[0m Reqid: chatcmpl-205abb7f668c49c8b5ad49ad89716b7f, Total tokens 161, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,907] LMCache INFO:[0m Reqid: chatcmpl-27052e53e4044883962519b44619574a, Total tokens 2168, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,908] LMCache INFO:[0m Reqid: chatcmpl-9cbae3108d22479dbefc7aea80f24f59, Total tokens 138, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,908] LMCache INFO:[0m Reqid: chatcmpl-30ee7f7de03f42cd884efc559dad7008, Total tokens 407, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,954] LMCache INFO:[0m Storing KV cache for 161 out of 161 tokens (skip_leading_tokens=0) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,954] LMCache INFO:[0m Stored 161 out of total 161 tokens. size: 0.0043 gb, cost 0.6108 ms, throughput: 7.0381 GB/s; offload_time: 0.4980 ms, put_time: 0.1129 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,955] LMCache INFO:[0m Storing KV cache for 138 out of 138 tokens (skip_leading_tokens=0) for request chatcmpl-9cbae3108d22479dbefc7aea80f24f59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,957] LMCache INFO:[0m Stored 138 out of total 138 tokens. size: 0.0037 gb, cost 1.5494 ms, throughput: 2.3783 GB/s; offload_time: 1.4462 ms, put_time: 0.1032 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,957] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-84b718ca6abf4c24863092731007d910 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,959] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.9624 ms, throughput: 1.7417 GB/s; offload_time: 1.8478 ms, put_time: 0.1146 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,964] LMCache INFO:[0m Reqid: chatcmpl-30ee7f7de03f42cd884efc559dad7008, Total tokens 407, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,965] LMCache INFO:[0m Reqid: chatcmpl-f83f6295bde849f084a790d14dda88a3, Total tokens 159, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53660 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:15,980] LMCache INFO:[0m Storing KV cache for 151 out of 407 tokens (skip_leading_tokens=256) for request chatcmpl-30ee7f7de03f42cd884efc559dad7008 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,981] LMCache INFO:[0m Stored 151 out of total 407 tokens. size: 0.0040 gb, cost 0.6318 ms, throughput: 6.3823 GB/s; offload_time: 0.5270 ms, put_time: 0.1048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:15,996] LMCache INFO:[0m Reqid: chatcmpl-30ee7f7de03f42cd884efc559dad7008, Total tokens 408, LMCache hit tokens: 407, need to load: 119 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,997] LMCache INFO:[0m Reqid: chatcmpl-f83f6295bde849f084a790d14dda88a3, Total tokens 159, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,997] LMCache INFO:[0m Reqid: chatcmpl-15d41bb3049f4d3d99ddaeec91ecfb3e, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,998] LMCache INFO:[0m Reqid: chatcmpl-e2b482c755e24aea8ad145f1f8a917f1, Total tokens 895, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:15,999] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,021] LMCache INFO:[0m Storing KV cache for 159 out of 159 tokens (skip_leading_tokens=0) for request chatcmpl-f83f6295bde849f084a790d14dda88a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,022] LMCache INFO:[0m Stored 159 out of total 159 tokens. size: 0.0042 gb, cost 0.6133 ms, throughput: 6.9227 GB/s; offload_time: 0.5058 ms, put_time: 0.1075 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,023] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-15d41bb3049f4d3d99ddaeec91ecfb3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,025] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 2.1853 ms, throughput: 1.3441 GB/s; offload_time: 2.0972 ms, put_time: 0.0881 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,026] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7168e3099c384df282cce69a9b22e3df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,027] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0064 ms, throughput: 3.3961 GB/s; offload_time: 0.5947 ms, put_time: 0.4117 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,042] LMCache INFO:[0m Reqid: chatcmpl-e2b482c755e24aea8ad145f1f8a917f1, Total tokens 896, LMCache hit tokens: 768, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,052] LMCache INFO:[0m Reqid: chatcmpl-e2b482c755e24aea8ad145f1f8a917f1, Total tokens 896, LMCache hit tokens: 768, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,053] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,066] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e2b482c755e24aea8ad145f1f8a917f1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,067] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5025 ms, throughput: 6.8017 GB/s; offload_time: 0.4270 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,071] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,079] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-323295e122d24498aa1ad01e1ddd0379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,080] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5564 ms, throughput: 6.1427 GB/s; offload_time: 0.4784 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,080] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-89951b9e652a4fa4ace2da38ab066c09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,081] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.0373 ms, throughput: 3.2951 GB/s; offload_time: 0.9693 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,086] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,094] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-27052e53e4044883962519b44619574a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,095] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.5828 ms, throughput: 5.8642 GB/s; offload_time: 0.5075 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,099] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,110] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,117] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-9a5fded8ff8a4b70a84d713062df35c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,117] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5512 ms, throughput: 6.2012 GB/s; offload_time: 0.4746 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,122] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,132] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,142] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,149] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1513ed157e7c42b38c24ceaf72da4d9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,149] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4463 ms, throughput: 7.6587 GB/s; offload_time: 0.3684 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,154] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,164] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,174] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,181] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-60ccb02e25e949b18be10d4e9bd8bfb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,182] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4794 ms, throughput: 7.1290 GB/s; offload_time: 0.4054 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,182] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,183] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8820 ms, throughput: 3.8751 GB/s; offload_time: 0.8109 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,195] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2a31bb46181b423caeffe68382fcdff8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,195] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4848 ms, throughput: 7.0509 GB/s; offload_time: 0.4068 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,200] LMCache INFO:[0m Reqid: chatcmpl-e2b482c755e24aea8ad145f1f8a917f1, Total tokens 907, LMCache hit tokens: 768, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,201] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,216] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,217] LMCache INFO:[0m Reqid: chatcmpl-5ac9846d010840028038b94ea3f3b6c1, Total tokens 643, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,242] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e8499ac4ffb44f12adac47f9fc884179 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,243] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4142 ms, throughput: 8.2522 GB/s; offload_time: 0.3414 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,247] LMCache INFO:[0m Reqid: chatcmpl-5ac9846d010840028038b94ea3f3b6c1, Total tokens 643, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,257] LMCache INFO:[0m Reqid: chatcmpl-5ac9846d010840028038b94ea3f3b6c1, Total tokens 643, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,264] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e820907b249b4f088ddf71a8a25e1187 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,265] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4467 ms, throughput: 7.6518 GB/s; offload_time: 0.3719 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,265] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-15d41bb3049f4d3d99ddaeec91ecfb3e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,266] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8450 ms, throughput: 4.0449 GB/s; offload_time: 0.5903 ms, put_time: 0.2547 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,270] LMCache INFO:[0m Reqid: chatcmpl-5ac9846d010840028038b94ea3f3b6c1, Total tokens 643, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,278] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5a99df1a5357469b82db40be11e4d4a6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,278] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5591 ms, throughput: 6.1128 GB/s; offload_time: 0.4749 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,290] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2a59ca2c172a4cdd87566cb76aa99e58 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,290] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4539 ms, throughput: 7.5301 GB/s; offload_time: 0.3804 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,294] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 826, LMCache hit tokens: 768, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,302] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-749fa5f75daf4ed1913b7f28f604f3fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,304] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.4154 ms, throughput: 2.4149 GB/s; offload_time: 1.3379 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,308] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 826, LMCache hit tokens: 768, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,316] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-74c235d876b9466fbc94447a583b034b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,317] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.4105 ms, throughput: 2.4232 GB/s; offload_time: 1.3318 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,321] LMCache INFO:[0m Reqid: chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31, Total tokens 826, LMCache hit tokens: 768, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,323] LMCache INFO:[0m Reqid: chatcmpl-5ac9846d010840028038b94ea3f3b6c1, Total tokens 643, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,324] LMCache INFO:[0m Reqid: chatcmpl-57c382b9911c4490afad27f65130b4c5, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,346] LMCache INFO:[0m Storing KV cache for 131 out of 643 tokens (skip_leading_tokens=512) for request chatcmpl-5ac9846d010840028038b94ea3f3b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,347] LMCache INFO:[0m Stored 131 out of total 643 tokens. size: 0.0035 gb, cost 0.6315 ms, throughput: 5.5393 GB/s; offload_time: 0.5247 ms, put_time: 0.1068 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,352] LMCache INFO:[0m Reqid: chatcmpl-57c382b9911c4490afad27f65130b4c5, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,360] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-52fb98632a9f4c26972785314e9de8f0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,360] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4905 ms, throughput: 6.9690 GB/s; offload_time: 0.4105 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,364] LMCache INFO:[0m Reqid: chatcmpl-57c382b9911c4490afad27f65130b4c5, Total tokens 761, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,365] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,387] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,396] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,406] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:16,415] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,423] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1d719705177b40a386de9dc4d04584a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,423] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4517 ms, throughput: 7.5674 GB/s; offload_time: 0.3772 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,424] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f8fd96abc7b843158a4ae5b1a1119812 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,425] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.8402 ms, throughput: 4.0680 GB/s; offload_time: 0.7743 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,429] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,439] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,448] LMCache INFO:[0m Reqid: chatcmpl-39508db55cb94fa3908c8f13237e31ec, Total tokens 483, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,449] LMCache INFO:[0m Reqid: chatcmpl-535eb28e15364edd9fcf2a0af2c5fb0a, Total tokens 396, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,449] LMCache INFO:[0m Reqid: chatcmpl-ef6b49326c744cf69b4af15756833af3, Total tokens 130, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,449] LMCache INFO:[0m Reqid: chatcmpl-9d868c41e2c9421f9bf052edd6f41b3c, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,450] LMCache INFO:[0m Reqid: chatcmpl-8fbab344d87545b08341f3b25db77d61, Total tokens 827, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,451] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 557, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,451] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,487] LMCache INFO:[0m Storing KV cache for 140 out of 396 tokens (skip_leading_tokens=256) for request chatcmpl-535eb28e15364edd9fcf2a0af2c5fb0a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,488] LMCache INFO:[0m Stored 140 out of total 396 tokens. size: 0.0037 gb, cost 0.6366 ms, throughput: 5.8722 GB/s; offload_time: 0.5287 ms, put_time: 0.1079 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,489] LMCache INFO:[0m Storing KV cache for 130 out of 130 tokens (skip_leading_tokens=0) for request chatcmpl-ef6b49326c744cf69b4af15756833af3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,490] LMCache INFO:[0m Stored 130 out of total 130 tokens. size: 0.0035 gb, cost 1.1773 ms, throughput: 2.9486 GB/s; offload_time: 1.0782 ms, put_time: 0.0991 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,490] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-9d868c41e2c9421f9bf052edd6f41b3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,492] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 1.2033 ms, throughput: 2.4633 GB/s; offload_time: 0.8819 ms, put_time: 0.3214 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,492] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-65f561c51f9f4b358e2af67c8223c7a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,494] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.5472 ms, throughput: 2.2091 GB/s; offload_time: 1.4925 ms, put_time: 0.0547 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,494] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-57c382b9911c4490afad27f65130b4c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,495] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7278 ms, throughput: 4.6963 GB/s; offload_time: 0.6081 ms, put_time: 0.1197 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,500] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,510] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,526] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,527] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4562 ms, throughput: 7.4923 GB/s; offload_time: 0.3851 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:16,531] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 560, LMCache hit tokens: 512, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,541] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 560, LMCache hit tokens: 512, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,548] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,550] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.3912 ms, throughput: 2.4568 GB/s; offload_time: 1.3194 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,554] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 560, LMCache hit tokens: 512, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,561] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-bada7a64fb1c434382eb02391493a9b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,562] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2881 ms, throughput: 2.6534 GB/s; offload_time: 1.2161 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,567] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 560, LMCache hit tokens: 512, need to load: 432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,588] LMCache INFO:[0m Reqid: chatcmpl-8fbab344d87545b08341f3b25db77d61, Total tokens 835, LMCache hit tokens: 768, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,588] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 560, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,589] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,604] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,613] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,632] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,642] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,649] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ebf8ee14bedb4e50ae31a1f6e1e7eeb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,651] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4824 ms, throughput: 2.3057 GB/s; offload_time: 1.3826 ms, put_time: 0.0998 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,651] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-49c59bdaba9d498aa4df7fa3de5ef672 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,653] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4344 ms, throughput: 2.3829 GB/s; offload_time: 1.3584 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,657] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,667] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,675] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,676] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3217 ms, throughput: 2.5861 GB/s; offload_time: 1.2460 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,681] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,688] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9d868c41e2c9421f9bf052edd6f41b3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,689] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2476 ms, throughput: 2.7397 GB/s; offload_time: 1.1753 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:16,693] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,703] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,713] LMCache INFO:[0m Reqid: chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302, Total tokens 563, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,714] LMCache INFO:[0m Reqid: chatcmpl-43d6dfaa657743eea7828b8700bee247, Total tokens 363, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,714] LMCache INFO:[0m Reqid: chatcmpl-06ad6a96a29b4f06b1a454f8a07d5161, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,715] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,715] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 317, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,716] LMCache INFO:[0m Reqid: chatcmpl-099a7d000f7747bcab291dd28492954b, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,747] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-06ad6a96a29b4f06b1a454f8a07d5161 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,747] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3964 ms, throughput: 6.7359 GB/s; offload_time: 0.3199 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,748] LMCache INFO:[0m Storing KV cache for 150 out of 790 tokens (skip_leading_tokens=640) for request chatcmpl-a386ebf6a4a749cc8954ff228502c8e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,749] LMCache INFO:[0m Stored 150 out of total 790 tokens. size: 0.0040 gb, cost 0.9524 ms, throughput: 4.2055 GB/s; offload_time: 0.8534 ms, put_time: 0.0990 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,765] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 318, LMCache hit tokens: 256, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,774] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 318, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,782] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,782] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4105 ms, throughput: 8.3259 GB/s; offload_time: 0.3540 ms, put_time: 0.0565 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,782] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d7c27d3404d244dd920073cf660bebf7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,783] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6726 ms, throughput: 5.0819 GB/s; offload_time: 0.6132 ms, put_time: 0.0594 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,796] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,805] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 118 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,814] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 150 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,824] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 230 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,831] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,832] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4697 ms, throughput: 7.2774 GB/s; offload_time: 0.4044 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,835] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 310 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,842] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,844] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.1480 ms, throughput: 2.9774 GB/s; offload_time: 1.0839 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,844] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-39508db55cb94fa3908c8f13237e31ec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,845] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3728 ms, throughput: 2.4898 GB/s; offload_time: 1.3032 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,850] LMCache INFO:[0m Reqid: chatcmpl-a386ebf6a4a749cc8954ff228502c8e1, Total tokens 794, LMCache hit tokens: 790, need to load: 454 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,850] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 318, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,851] LMCache INFO:[0m Reqid: chatcmpl-099a7d000f7747bcab291dd28492954b, Total tokens 147, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,851] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 194, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:16,864] LMCache INFO:[0m Storing KV cache for 147 out of 147 tokens (skip_leading_tokens=0) for request chatcmpl-099a7d000f7747bcab291dd28492954b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,865] LMCache INFO:[0m Stored 147 out of total 147 tokens. size: 0.0039 gb, cost 1.2579 ms, throughput: 3.1205 GB/s; offload_time: 1.1665 ms, put_time: 0.0914 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,870] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 194, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,870] LMCache INFO:[0m Reqid: chatcmpl-ab9e78d01c3c41af8f4daa9c48dc4a5a, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,871] LMCache INFO:[0m Reqid: chatcmpl-2a348f47e7b64ec8b961d47329d52e92, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,871] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,886] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-ab9e78d01c3c41af8f4daa9c48dc4a5a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,887] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.3398 ms, throughput: 7.8591 GB/s; offload_time: 0.2764 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,887] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-2a348f47e7b64ec8b961d47329d52e92 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,888] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.5975 ms, throughput: 4.6927 GB/s; offload_time: 0.5440 ms, put_time: 0.0535 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,892] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,901] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,908] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-dac32ae70d7f40659591c1e0f774be67 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,910] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1061 ms, throughput: 3.0902 GB/s; offload_time: 1.0432 ms, put_time: 0.0629 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,913] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,922] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,929] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,930] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0856 ms, throughput: 3.1485 GB/s; offload_time: 1.0237 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,934] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,944] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,951] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-df13ae3b68d34056a2917eea30a43ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,952] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1239 ms, throughput: 3.0413 GB/s; offload_time: 1.0608 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,952] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-9919c9c415494cef9b524cefe216e828 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,954] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.3400 ms, throughput: 2.5507 GB/s; offload_time: 1.2841 ms, put_time: 0.0559 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,974] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,975] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.1881 ms, throughput: 2.8769 GB/s; offload_time: 1.1189 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,987] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 203, LMCache hit tokens: 128, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,994] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,996] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1085 ms, throughput: 3.0833 GB/s; offload_time: 1.0447 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:16,996] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-43d6dfaa657743eea7828b8700bee247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:16,997] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3201 ms, throughput: 2.5892 GB/s; offload_time: 1.2526 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,001] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 203, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,008] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f631cd5aa402440fabf32edf22b1548c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,009] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1221 ms, throughput: 3.0459 GB/s; offload_time: 1.0541 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,022] LMCache INFO:[0m Reqid: chatcmpl-099a7d000f7747bcab291dd28492954b, Total tokens 160, LMCache hit tokens: 147, need to load: 83 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,028] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-6b00e29d9390404e939f43aebc0435cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,030] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1272 ms, throughput: 3.0322 GB/s; offload_time: 1.0546 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,033] LMCache INFO:[0m Reqid: chatcmpl-099a7d000f7747bcab291dd28492954b, Total tokens 160, LMCache hit tokens: 147, need to load: 99 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,034] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 203, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,054] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-29b3bd4a742c4742a1204da81b22b4e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,055] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1577 ms, throughput: 2.9524 GB/s; offload_time: 1.0834 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,066] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-31022f2973b9414a84fa6602360c71b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,067] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.1418 ms, throughput: 2.9934 GB/s; offload_time: 1.0711 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,068] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f9de432d8ffe4a558456696bbe434ee3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,069] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3869 ms, throughput: 2.4644 GB/s; offload_time: 1.3217 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,073] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 335, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,080] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,081] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1359 ms, throughput: 3.0091 GB/s; offload_time: 1.0718 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,082] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-06ad6a96a29b4f06b1a454f8a07d5161 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,083] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2530 ms, throughput: 2.7279 GB/s; offload_time: 1.1831 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,087] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 335, LMCache hit tokens: 256, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,096] LMCache INFO:[0m Reqid: chatcmpl-da173193285a44fdb019e92187206a07, Total tokens 335, LMCache hit tokens: 256, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,096] LMCache INFO:[0m Reqid: chatcmpl-099a7d000f7747bcab291dd28492954b, Total tokens 161, LMCache hit tokens: 147, need to load: 99 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,097] LMCache INFO:[0m Reqid: chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3, Total tokens 203, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,097] LMCache INFO:[0m Reqid: chatcmpl-ab9e78d01c3c41af8f4daa9c48dc4a5a, Total tokens 108, LMCache hit tokens: 100, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,097] LMCache INFO:[0m Reqid: chatcmpl-2a348f47e7b64ec8b961d47329d52e92, Total tokens 112, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,098] LMCache INFO:[0m Reqid: chatcmpl-45241968d4894047a1eff90d4c292933, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,098] LMCache INFO:[0m Reqid: chatcmpl-8109a51c703049988748d454e0d76fee, Total tokens 309, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,099] LMCache INFO:[0m Reqid: chatcmpl-31146a67f77f4f609d343c1494a5aebc, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,099] LMCache INFO:[0m Reqid: chatcmpl-9b4cce31d40b4c3a92bc0eefe5f2c3ba, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,100] LMCache INFO:[0m Reqid: chatcmpl-fc8780a1388b40d698e0159574c4eefc, Total tokens 836, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,123] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-9b4cce31d40b4c3a92bc0eefe5f2c3ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,124] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.3460 ms, throughput: 7.1773 GB/s; offload_time: 0.2798 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,128] LMCache INFO:[0m Reqid: chatcmpl-fc8780a1388b40d698e0159574c4eefc, Total tokens 836, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,129] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53764 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,156] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,163] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,163] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4570 ms, throughput: 7.4794 GB/s; offload_time: 0.3935 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,167] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,174] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-dc6411db9bf947c6bff0514a9e34fb88 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,175] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4112 ms, throughput: 8.3132 GB/s; offload_time: 0.3452 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,178] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,186] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,186] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.3994 ms, throughput: 8.5587 GB/s; offload_time: 0.3352 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,190] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,197] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-560e6056852543139c15c7b3b939f966 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,198] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4694 ms, throughput: 7.2811 GB/s; offload_time: 0.4000 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,211] LMCache INFO:[0m Reqid: chatcmpl-fc8780a1388b40d698e0159574c4eefc, Total tokens 841, LMCache hit tokens: 768, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,218] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5e916300cba94438a670e07bf421ae50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,218] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.4422 ms, throughput: 7.7300 GB/s; offload_time: 0.3706 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,222] LMCache INFO:[0m Reqid: chatcmpl-fc8780a1388b40d698e0159574c4eefc, Total tokens 841, LMCache hit tokens: 768, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,223] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,238] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,244] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-13f230aa4aee4661a040780ca69bbdc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,245] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3957 ms, throughput: 8.6378 GB/s; offload_time: 0.3342 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,249] LMCache INFO:[0m Reqid: chatcmpl-2f374e3a8dab438b8eba8ef48526041e, Total tokens 649, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,250] LMCache INFO:[0m Reqid: chatcmpl-e069534feb2f4307bc718c667ea4810f, Total tokens 366, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,250] LMCache INFO:[0m Reqid: chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a, Total tokens 298, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,251] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,280] LMCache INFO:[0m Storing KV cache for 137 out of 649 tokens (skip_leading_tokens=512) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,281] LMCache INFO:[0m Stored 137 out of total 649 tokens. size: 0.0037 gb, cost 0.5557 ms, throughput: 6.5830 GB/s; offload_time: 0.4571 ms, put_time: 0.0986 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,281] LMCache INFO:[0m Storing KV cache for 366 out of 366 tokens (skip_leading_tokens=0) for request chatcmpl-e069534feb2f4307bc718c667ea4810f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,285] LMCache INFO:[0m Stored 366 out of total 366 tokens. size: 0.0098 gb, cost 1.5972 ms, throughput: 6.1189 GB/s; offload_time: 1.1957 ms, put_time: 0.4015 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,285] LMCache INFO:[0m Storing KV cache for 170 out of 298 tokens (skip_leading_tokens=128) for request chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,287] LMCache INFO:[0m Stored 170 out of total 298 tokens. size: 0.0045 gb, cost 1.8511 ms, throughput: 2.4523 GB/s; offload_time: 1.7423 ms, put_time: 0.1088 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,288] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,290] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.9114 ms, throughput: 1.7882 GB/s; offload_time: 1.8393 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,296] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,303] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b23be3e0e9e4488e93abb92b0fbf8b6c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,305] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1224 ms, throughput: 3.0451 GB/s; offload_time: 1.0500 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,305] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,306] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3687 ms, throughput: 2.4973 GB/s; offload_time: 1.3067 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,311] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,318] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2461622fca8847af80252285804d4cfb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,319] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1442 ms, throughput: 2.9872 GB/s; offload_time: 1.0778 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:53780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,324] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,333] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,343] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,352] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,359] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-3ad7318ff1a8461c95ee9df6842be628 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,361] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1525 ms, throughput: 2.9657 GB/s; offload_time: 1.0789 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,361] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2a348f47e7b64ec8b961d47329d52e92 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,362] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4020 ms, throughput: 2.4378 GB/s; offload_time: 1.3290 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,367] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,374] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,375] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1178 ms, throughput: 3.0578 GB/s; offload_time: 1.0434 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,388] LMCache INFO:[0m Reqid: chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a, Total tokens 306, LMCache hit tokens: 298, need to load: 202 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,390] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,403] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,410] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-acc04e6079a84a7981fc48f16ac0c155 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,411] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1441 ms, throughput: 2.9875 GB/s; offload_time: 1.0770 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,412] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8fbab344d87545b08341f3b25db77d61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,413] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5315 ms, throughput: 2.2318 GB/s; offload_time: 1.4575 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,413] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-ab9e78d01c3c41af8f4daa9c48dc4a5a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,415] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.2522 ms, throughput: 2.7297 GB/s; offload_time: 1.1840 ms, put_time: 0.0681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,420] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,430] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,436] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-30ee7f7de03f42cd884efc559dad7008 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,438] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1127 ms, throughput: 3.0717 GB/s; offload_time: 1.0402 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,442] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,450] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,451] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1347 ms, throughput: 3.0123 GB/s; offload_time: 1.0583 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,455] LMCache INFO:[0m Reqid: chatcmpl-3714720b250043d4ae581a48abf9b343, Total tokens 1617, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,457] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,483] LMCache INFO:[0m Storing KV cache for 337 out of 1617 tokens (skip_leading_tokens=1280) for request chatcmpl-3714720b250043d4ae581a48abf9b343 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,484] LMCache INFO:[0m Stored 337 out of total 1617 tokens. size: 0.0090 gb, cost 0.9468 ms, throughput: 9.5045 GB/s; offload_time: 0.6887 ms, put_time: 0.2581 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,489] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,497] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-179caddbb59d40a7a16141616d35d61d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,498] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 0.5247 ms, throughput: 6.5141 GB/s; offload_time: 0.4586 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,498] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-ab02cd7fa01d4c6e83750d1f1e488459 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,499] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7096 ms, throughput: 4.8166 GB/s; offload_time: 0.6424 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,504] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,514] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,524] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,530] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e069534feb2f4307bc718c667ea4810f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,531] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.3950 ms, throughput: 8.6530 GB/s; offload_time: 0.3299 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,535] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,545] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,552] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-053d9db7970949cbad71aebe7d42e706 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,554] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1317 ms, throughput: 3.0202 GB/s; offload_time: 1.0584 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,559] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,568] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,578] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,585] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-59952dc1db99483a9e18c0307e4318db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53800 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,587] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.1627 ms, throughput: 2.9398 GB/s; offload_time: 1.0979 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,587] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,589] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.9020 ms, throughput: 1.7970 GB/s; offload_time: 1.8374 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,589] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9cbae3108d22479dbefc7aea80f24f59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,591] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2898 ms, throughput: 2.6500 GB/s; offload_time: 1.2295 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,596] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,602] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c5a4babe97a841c9bd6dc27205f2d674 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,604] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0883 ms, throughput: 3.1407 GB/s; offload_time: 1.0223 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,608] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,618] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,625] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a9d902d585e04f729f8738c430e74efc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,626] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1604 ms, throughput: 2.9454 GB/s; offload_time: 1.0865 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,627] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,628] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.4465 ms, throughput: 2.3629 GB/s; offload_time: 1.3802 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,633] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,643] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,652] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,662] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,672] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,679] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-5b996ebeaf2d4815b8c1ec52deb3cdd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,680] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.1977 ms, throughput: 2.8538 GB/s; offload_time: 1.1318 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,680] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-100fe76785d947ed8190d9173925e11a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53820 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,682] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7833 ms, throughput: 1.9166 GB/s; offload_time: 1.7188 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,687] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,695] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6957940dd1b144d2b66c0111f9596bc5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,696] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1022 ms, throughput: 3.1011 GB/s; offload_time: 1.0357 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,696] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,698] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2606 ms, throughput: 2.7115 GB/s; offload_time: 1.1825 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,702] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,709] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-84b718ca6abf4c24863092731007d910 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,711] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1249 ms, throughput: 3.0385 GB/s; offload_time: 1.0599 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,714] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,724] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,734] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,744] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,751] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a0aa83c10fdd4ad28daf09be0ae64302 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,752] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1347 ms, throughput: 3.0122 GB/s; offload_time: 1.0701 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,756] LMCache INFO:[0m Reqid: chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608, Total tokens 1451, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,757] LMCache INFO:[0m Reqid: chatcmpl-b798e3027d724ea78fee8a13cfbedc35, Total tokens 153, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,759] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,791] LMCache INFO:[0m Storing KV cache for 153 out of 153 tokens (skip_leading_tokens=0) for request chatcmpl-b798e3027d724ea78fee8a13cfbedc35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,791] LMCache INFO:[0m Stored 153 out of total 153 tokens. size: 0.0041 gb, cost 0.5163 ms, throughput: 7.9138 GB/s; offload_time: 0.4244 ms, put_time: 0.0918 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,799] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53834 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:17,807] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-da173193285a44fdb019e92187206a07 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,807] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4738 ms, throughput: 7.2137 GB/s; offload_time: 0.3958 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,812] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,820] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-323295e122d24498aa1ad01e1ddd0379 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,820] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5841 ms, throughput: 5.8521 GB/s; offload_time: 0.4929 ms, put_time: 0.0911 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,821] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-45241968d4894047a1eff90d4c292933 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,822] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7842 ms, throughput: 4.3584 GB/s; offload_time: 0.7070 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,827] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,835] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-27052e53e4044883962519b44619574a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,835] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.5143 ms, throughput: 6.6464 GB/s; offload_time: 0.4476 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,840] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,850] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,857] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-9a5fded8ff8a4b70a84d713062df35c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,858] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5250 ms, throughput: 6.5106 GB/s; offload_time: 0.4559 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,858] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,859] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6863 ms, throughput: 4.9805 GB/s; offload_time: 0.6228 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,863] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,873] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,882] LMCache INFO:[0m Reqid: chatcmpl-950c8c6b793f414caaffdc3043117589, Total tokens 1844, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,883] LMCache INFO:[0m Reqid: chatcmpl-3af70f27206540b7b8235f72ec2aaea8, Total tokens 212, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,884] LMCache INFO:[0m Reqid: chatcmpl-6efc4fad32c0458a9317186d4a999162, Total tokens 730, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,921] LMCache INFO:[0m Storing KV cache for 212 out of 212 tokens (skip_leading_tokens=0) for request chatcmpl-3af70f27206540b7b8235f72ec2aaea8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,922] LMCache INFO:[0m Stored 212 out of total 212 tokens. size: 0.0057 gb, cost 0.5206 ms, throughput: 10.8742 GB/s; offload_time: 0.4282 ms, put_time: 0.0924 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,926] LMCache INFO:[0m Reqid: chatcmpl-6efc4fad32c0458a9317186d4a999162, Total tokens 730, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,936] LMCache INFO:[0m Reqid: chatcmpl-6efc4fad32c0458a9317186d4a999162, Total tokens 730, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,937] LMCache INFO:[0m Reqid: chatcmpl-abde1d64334941649c2aef92cffebb09, Total tokens 429, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,958] LMCache INFO:[0m Reqid: chatcmpl-abde1d64334941649c2aef92cffebb09, Total tokens 429, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,964] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,965] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4206 ms, throughput: 8.1259 GB/s; offload_time: 0.3512 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,968] LMCache INFO:[0m Reqid: chatcmpl-abde1d64334941649c2aef92cffebb09, Total tokens 429, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,976] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2a31bb46181b423caeffe68382fcdff8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,976] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4120 ms, throughput: 8.2970 GB/s; offload_time: 0.3490 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:17,980] LMCache INFO:[0m Reqid: chatcmpl-abde1d64334941649c2aef92cffebb09, Total tokens 429, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,980] LMCache INFO:[0m Reqid: chatcmpl-e4e95de630d041a6b64ed277f1c753a5, Total tokens 126, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,981] LMCache INFO:[0m Reqid: chatcmpl-d0a1ac8ca00e4085872f7bd7cc777229, Total tokens 822, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,982] LMCache INFO:[0m Reqid: chatcmpl-288a7123ef7d4236b98d67dc375c400f, Total tokens 348, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,983] LMCache INFO:[0m Reqid: chatcmpl-8e3cb1a361e84dc7a6b8d3b662a49ccb, Total tokens 424, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,983] LMCache INFO:[0m Reqid: chatcmpl-2fe0fef3ef764b588c6c4fe490a75cff, Total tokens 472, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,984] LMCache INFO:[0m Reqid: chatcmpl-4b913291ffd5433682d14e0f2c733b79, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,984] LMCache INFO:[0m Reqid: chatcmpl-f33e38cfc4df45f386871d60461a046b, Total tokens 435, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,984] LMCache INFO:[0m Reqid: chatcmpl-e69ffc5cf14d49ce8eebb257198f9c41, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:17,985] LMCache INFO:[0m Reqid: chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,023] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-e4e95de630d041a6b64ed277f1c753a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,023] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 0.3533 ms, throughput: 9.5223 GB/s; offload_time: 0.2936 ms, put_time: 0.0597 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,024] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-4b913291ffd5433682d14e0f2c733b79 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,024] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.4828 ms, throughput: 5.9731 GB/s; offload_time: 0.4233 ms, put_time: 0.0595 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,025] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-e69ffc5cf14d49ce8eebb257198f9c41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,026] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.7055 ms, throughput: 3.7850 GB/s; offload_time: 0.6408 ms, put_time: 0.0647 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,033] LMCache INFO:[0m Reqid: chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,043] LMCache INFO:[0m Reqid: chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,050] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-fc8780a1388b40d698e0159574c4eefc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,051] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4266 ms, throughput: 8.0117 GB/s; offload_time: 0.3635 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,051] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e4e95de630d041a6b64ed277f1c753a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,052] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6324 ms, throughput: 5.4051 GB/s; offload_time: 0.5714 ms, put_time: 0.0610 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,056] LMCache INFO:[0m Reqid: chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f, Total tokens 673, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,057] LMCache INFO:[0m Reqid: chatcmpl-83664632731343008d10b16867e22a36, Total tokens 582, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53894 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,074] LMCache INFO:[0m Reqid: chatcmpl-83664632731343008d10b16867e22a36, Total tokens 582, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,080] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-5a99df1a5357469b82db40be11e4d4a6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,081] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4757 ms, throughput: 7.1852 GB/s; offload_time: 0.4103 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,085] LMCache INFO:[0m Reqid: chatcmpl-83664632731343008d10b16867e22a36, Total tokens 582, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,093] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-5ac9846d010840028038b94ea3f3b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,093] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4280 ms, throughput: 7.9866 GB/s; offload_time: 0.3644 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,094] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-535eb28e15364edd9fcf2a0af2c5fb0a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,095] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7812 ms, throughput: 4.3751 GB/s; offload_time: 0.7048 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,100] LMCache INFO:[0m Reqid: chatcmpl-83664632731343008d10b16867e22a36, Total tokens 582, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,101] LMCache INFO:[0m Reqid: chatcmpl-8c1b3822f886404cba9747e1e74d878a, Total tokens 185, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,102] LMCache INFO:[0m Reqid: chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7, Total tokens 1667, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:53896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:53908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,119] LMCache INFO:[0m Storing KV cache for 185 out of 185 tokens (skip_leading_tokens=0) for request chatcmpl-8c1b3822f886404cba9747e1e74d878a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,120] LMCache INFO:[0m Stored 185 out of total 185 tokens. size: 0.0049 gb, cost 0.5456 ms, throughput: 9.0540 GB/s; offload_time: 0.4559 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,125] LMCache INFO:[0m Reqid: chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7, Total tokens 1667, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,135] LMCache INFO:[0m Reqid: chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7, Total tokens 1667, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,136] LMCache INFO:[0m Reqid: chatcmpl-c57a2584c41e475992902878fae82747, Total tokens 299, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,137] LMCache INFO:[0m Reqid: chatcmpl-7a45dca1441e46bead24448e35c45cf3, Total tokens 121, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,137] LMCache INFO:[0m Reqid: chatcmpl-24cb35ba0c8c495ca32b68811196e8e5, Total tokens 348, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,138] LMCache INFO:[0m Reqid: chatcmpl-6eba9eacc44249c58c0af2fc000107aa, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,138] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,181] LMCache INFO:[0m Storing KV cache for 259 out of 1667 tokens (skip_leading_tokens=1408) for request chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,181] LMCache INFO:[0m Stored 259 out of total 1667 tokens. size: 0.0069 gb, cost 0.7855 ms, throughput: 8.8044 GB/s; offload_time: 0.6643 ms, put_time: 0.1212 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,182] LMCache INFO:[0m Storing KV cache for 121 out of 121 tokens (skip_leading_tokens=0) for request chatcmpl-7a45dca1441e46bead24448e35c45cf3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,183] LMCache INFO:[0m Stored 121 out of total 121 tokens. size: 0.0032 gb, cost 1.4035 ms, throughput: 2.3021 GB/s; offload_time: 1.3357 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,184] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-6eba9eacc44249c58c0af2fc000107aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,185] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 1.0259 ms, throughput: 2.6811 GB/s; offload_time: 0.9642 ms, put_time: 0.0617 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,197] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-52fb98632a9f4c26972785314e9de8f0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,197] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4178 ms, throughput: 8.1817 GB/s; offload_time: 0.3550 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,201] LMCache INFO:[0m Reqid: chatcmpl-6eba9eacc44249c58c0af2fc000107aa, Total tokens 104, LMCache hit tokens: 103, need to load: 55 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,208] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-3714720b250043d4ae581a48abf9b343 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,209] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.4829 ms, throughput: 7.0773 GB/s; offload_time: 0.4161 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:57356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57400 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,222] LMCache INFO:[0m Reqid: chatcmpl-24cb35ba0c8c495ca32b68811196e8e5, Total tokens 351, LMCache hit tokens: 256, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,231] LMCache INFO:[0m Reqid: chatcmpl-24cb35ba0c8c495ca32b68811196e8e5, Total tokens 351, LMCache hit tokens: 256, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,241] LMCache INFO:[0m Reqid: chatcmpl-24cb35ba0c8c495ca32b68811196e8e5, Total tokens 351, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,248] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1d719705177b40a386de9dc4d04584a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,248] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4166 ms, throughput: 8.2036 GB/s; offload_time: 0.3442 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,249] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f8fd96abc7b843158a4ae5b1a1119812 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,250] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.2286 ms, throughput: 2.7820 GB/s; offload_time: 1.1667 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,264] LMCache INFO:[0m Reqid: chatcmpl-7a45dca1441e46bead24448e35c45cf3, Total tokens 128, LMCache hit tokens: 121, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,279] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-57c382b9911c4490afad27f65130b4c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,280] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4257 ms, throughput: 8.0296 GB/s; offload_time: 0.3615 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,284] LMCache INFO:[0m Reqid: chatcmpl-c57a2584c41e475992902878fae82747, Total tokens 308, LMCache hit tokens: 256, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,284] LMCache INFO:[0m Reqid: chatcmpl-7a45dca1441e46bead24448e35c45cf3, Total tokens 128, LMCache hit tokens: 121, need to load: 73 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,285] LMCache INFO:[0m Reqid: chatcmpl-24cb35ba0c8c495ca32b68811196e8e5, Total tokens 351, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,285] LMCache INFO:[0m Reqid: chatcmpl-6eba9eacc44249c58c0af2fc000107aa, Total tokens 104, LMCache hit tokens: 103, need to load: 55 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,286] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,286] LMCache INFO:[0m Reqid: chatcmpl-69ce52d934bd4cfda41701c502b4f225, Total tokens 590, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,287] LMCache INFO:[0m Reqid: chatcmpl-6c75f04af93344568cd349b977bf182f, Total tokens 143, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,287] LMCache INFO:[0m Reqid: chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,287] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,311] LMCache INFO:[0m Storing KV cache for 143 out of 143 tokens (skip_leading_tokens=0) for request chatcmpl-6c75f04af93344568cd349b977bf182f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,312] LMCache INFO:[0m Stored 143 out of total 143 tokens. size: 0.0038 gb, cost 0.5328 ms, throughput: 7.1664 GB/s; offload_time: 0.4402 ms, put_time: 0.0926 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,312] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,313] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 0.4839 ms, throughput: 6.0151 GB/s; offload_time: 0.3127 ms, put_time: 0.1711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,314] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7a45dca1441e46bead24448e35c45cf3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,315] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8531 ms, throughput: 4.0068 GB/s; offload_time: 0.7941 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,326] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,327] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4039 ms, throughput: 8.4623 GB/s; offload_time: 0.3408 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,331] LMCache INFO:[0m Reqid: chatcmpl-6c75f04af93344568cd349b977bf182f, Total tokens 144, LMCache hit tokens: 143, need to load: 79 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,338] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,339] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1764 ms, throughput: 2.9056 GB/s; offload_time: 1.1102 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,350] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a386ebf6a4a749cc8954ff228502c8e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,351] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.1349 ms, throughput: 3.0118 GB/s; offload_time: 1.0605 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,355] LMCache INFO:[0m Reqid: chatcmpl-69ce52d934bd4cfda41701c502b4f225, Total tokens 593, LMCache hit tokens: 512, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,363] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,364] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.1493 ms, throughput: 2.9739 GB/s; offload_time: 1.0829 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,368] LMCache INFO:[0m Reqid: chatcmpl-69ce52d934bd4cfda41701c502b4f225, Total tokens 593, LMCache hit tokens: 512, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,378] LMCache INFO:[0m Reqid: chatcmpl-69ce52d934bd4cfda41701c502b4f225, Total tokens 593, LMCache hit tokens: 512, need to load: 352 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,396] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 518, LMCache hit tokens: 384, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,405] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 518, LMCache hit tokens: 384, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,415] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 518, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,421] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e69ffc5cf14d49ce8eebb257198f9c41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,422] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0531 ms, throughput: 3.2457 GB/s; offload_time: 0.9885 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,426] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 518, LMCache hit tokens: 384, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,427] LMCache INFO:[0m Reqid: chatcmpl-69ce52d934bd4cfda41701c502b4f225, Total tokens 593, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,428] LMCache INFO:[0m Reqid: chatcmpl-6c75f04af93344568cd349b977bf182f, Total tokens 144, LMCache hit tokens: 143, need to load: 95 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,429] LMCache INFO:[0m Reqid: chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb, Total tokens 110, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,429] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,443] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-31146a67f77f4f609d343c1494a5aebc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,445] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0824 ms, throughput: 3.1578 GB/s; offload_time: 1.0140 ms, put_time: 0.0684 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,466] LMCache INFO:[0m Reqid: chatcmpl-6c75f04af93344568cd349b977bf182f, Total tokens 146, LMCache hit tokens: 143, need to load: 95 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,467] LMCache INFO:[0m Reqid: chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb, Total tokens 111, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,467] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,480] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,487] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,488] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0879 ms, throughput: 3.1417 GB/s; offload_time: 1.0152 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,492] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,500] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9d868c41e2c9421f9bf052edd6f41b3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,501] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0819 ms, throughput: 3.1592 GB/s; offload_time: 1.0182 ms, put_time: 0.0637 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,501] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-099a7d000f7747bcab291dd28492954b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,503] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6885 ms, throughput: 2.0243 GB/s; offload_time: 1.6169 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,508] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,515] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6efc4fad32c0458a9317186d4a999162 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,516] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1018 ms, throughput: 3.1021 GB/s; offload_time: 1.0349 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,520] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,527] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,528] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0688 ms, throughput: 3.1980 GB/s; offload_time: 0.9975 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,529] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-288a7123ef7d4236b98d67dc375c400f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,530] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5792 ms, throughput: 2.1643 GB/s; offload_time: 1.5117 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:57466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,562] LMCache INFO:[0m Reqid: chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b, Total tokens 528, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,562] LMCache INFO:[0m Reqid: chatcmpl-6c75f04af93344568cd349b977bf182f, Total tokens 152, LMCache hit tokens: 143, need to load: 95 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,562] LMCache INFO:[0m Reqid: chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb, Total tokens 116, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,563] LMCache INFO:[0m Reqid: chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca, Total tokens 660, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,564] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,564] LMCache INFO:[0m Reqid: chatcmpl-be681d2cac1e402f985b21803df6c36b, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,565] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,597] LMCache INFO:[0m Storing KV cache for 148 out of 660 tokens (skip_leading_tokens=512) for request chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,597] LMCache INFO:[0m Stored 148 out of total 660 tokens. size: 0.0040 gb, cost 0.5746 ms, throughput: 6.8779 GB/s; offload_time: 0.4746 ms, put_time: 0.1000 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,598] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,599] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.8280 ms, throughput: 3.2573 GB/s; offload_time: 0.7638 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,600] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,601] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7742 ms, throughput: 4.4150 GB/s; offload_time: 0.7151 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,601] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-d7c27d3404d244dd920073cf660bebf7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,603] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.8999 ms, throughput: 1.7990 GB/s; offload_time: 1.8417 ms, put_time: 0.0582 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,603] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2fe0fef3ef764b588c6c4fe490a75cff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,605] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0647 ms, throughput: 3.2102 GB/s; offload_time: 0.9989 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,609] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,619] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,626] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6eba9eacc44249c58c0af2fc000107aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,627] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0834 ms, throughput: 3.1549 GB/s; offload_time: 1.0174 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,640] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: -80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,650] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,657] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,658] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.1851 ms, throughput: 2.8841 GB/s; offload_time: 1.1125 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,662] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,669] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,671] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.1866 ms, throughput: 2.8804 GB/s; offload_time: 1.1138 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,671] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-39508db55cb94fa3908c8f13237e31ec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,672] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.2523 ms, throughput: 2.7294 GB/s; offload_time: 1.1834 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,677] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,686] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,696] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,705] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,715] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,722] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-24cb35ba0c8c495ca32b68811196e8e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,723] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0961 ms, throughput: 3.1183 GB/s; offload_time: 1.0248 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,727] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,735] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,736] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.1191 ms, throughput: 3.0543 GB/s; offload_time: 1.0546 ms, put_time: 0.0645 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,736] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,737] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1117 ms, throughput: 3.0746 GB/s; offload_time: 1.0513 ms, put_time: 0.0603 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,742] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 741, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,743] LMCache INFO:[0m Reqid: chatcmpl-be681d2cac1e402f985b21803df6c36b, Total tokens 104, LMCache hit tokens: 101, need to load: 53 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,743] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,758] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,765] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-df13ae3b68d34056a2917eea30a43ffe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,767] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1812 ms, throughput: 2.8937 GB/s; offload_time: 1.1087 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,767] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-9919c9c415494cef9b524cefe216e828 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,769] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5868 ms, throughput: 2.1540 GB/s; offload_time: 1.5183 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,773] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,783] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,790] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,792] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.2129 ms, throughput: 2.8181 GB/s; offload_time: 1.1386 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,796] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,806] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,813] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,814] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1521 ms, throughput: 2.9666 GB/s; offload_time: 1.0852 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,814] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-43d6dfaa657743eea7828b8700bee247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,816] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4049 ms, throughput: 2.4329 GB/s; offload_time: 1.3403 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,827] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f631cd5aa402440fabf32edf22b1548c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,828] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.1059 ms, throughput: 3.0906 GB/s; offload_time: 1.0324 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,832] LMCache INFO:[0m Reqid: chatcmpl-be681d2cac1e402f985b21803df6c36b, Total tokens 110, LMCache hit tokens: 101, need to load: 21 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,851] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 749, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,860] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 749, LMCache hit tokens: 640, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,867] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-29b3bd4a742c4742a1204da81b22b4e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57524 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,869] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6927 ms, throughput: 2.0192 GB/s; offload_time: 1.6178 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,873] LMCache INFO:[0m Reqid: chatcmpl-67f476d9e80a4b48b2facac880f805cc, Total tokens 749, LMCache hit tokens: 640, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,874] LMCache INFO:[0m Reqid: chatcmpl-be681d2cac1e402f985b21803df6c36b, Total tokens 110, LMCache hit tokens: 101, need to load: 53 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,874] LMCache INFO:[0m Reqid: chatcmpl-71e21681fced451fbcb0f3defb4d5762, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,875] LMCache INFO:[0m Reqid: chatcmpl-9ec4c329fb664d04843503deb0bcbf1f, Total tokens 402, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,876] LMCache INFO:[0m Reqid: chatcmpl-e0af191e26284584bc421525c69cd0ba, Total tokens 138, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,876] LMCache INFO:[0m Reqid: chatcmpl-d4799eae3fc54875959fe0986b3c26f0, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,877] LMCache INFO:[0m Reqid: chatcmpl-d80c18b6b1ad4eebb81d42ad83ff458b, Total tokens 760, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,877] LMCache INFO:[0m Reqid: chatcmpl-8f645357485d45a3b96ee945b8e15ce5, Total tokens 143, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,878] LMCache INFO:[0m Reqid: chatcmpl-e6786b8f906e48fcabcf9bf603171466, Total tokens 217, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,878] LMCache INFO:[0m Reqid: chatcmpl-c29ceeada3bf4334b27498260d33ebed, Total tokens 137, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,878] LMCache INFO:[0m Reqid: chatcmpl-012dbf94bdf34de4887c82d8c882b818, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57558 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,879] LMCache INFO:[0m Reqid: chatcmpl-b47193fd0c9448428de182520c28236e, Total tokens 969, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:18,921] LMCache INFO:[0m Storing KV cache for 138 out of 138 tokens (skip_leading_tokens=0) for request chatcmpl-e0af191e26284584bc421525c69cd0ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,922] LMCache INFO:[0m Stored 138 out of total 138 tokens. size: 0.0037 gb, cost 0.5332 ms, throughput: 6.9114 GB/s; offload_time: 0.4416 ms, put_time: 0.0915 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,923] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-d4799eae3fc54875959fe0986b3c26f0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,924] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.9771 ms, throughput: 2.5416 GB/s; offload_time: 0.9102 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,924] LMCache INFO:[0m Storing KV cache for 143 out of 143 tokens (skip_leading_tokens=0) for request chatcmpl-8f645357485d45a3b96ee945b8e15ce5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,926] LMCache INFO:[0m Stored 143 out of total 143 tokens. size: 0.0038 gb, cost 1.2688 ms, throughput: 3.0095 GB/s; offload_time: 1.1753 ms, put_time: 0.0935 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,926] LMCache INFO:[0m Storing KV cache for 137 out of 137 tokens (skip_leading_tokens=0) for request chatcmpl-c29ceeada3bf4334b27498260d33ebed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,929] LMCache INFO:[0m Stored 137 out of total 137 tokens. size: 0.0037 gb, cost 2.2360 ms, throughput: 1.6361 GB/s; offload_time: 1.9149 ms, put_time: 0.3211 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,929] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-012dbf94bdf34de4887c82d8c882b818 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,930] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4963 ms, throughput: 4.9502 GB/s; offload_time: 0.4376 ms, put_time: 0.0586 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,930] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f9de432d8ffe4a558456696bbe434ee3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,932] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4415 ms, throughput: 2.3712 GB/s; offload_time: 1.3813 ms, put_time: 0.0602 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,932] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-83664632731343008d10b16867e22a36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,933] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7096 ms, throughput: 4.8164 GB/s; offload_time: 0.6549 ms, put_time: 0.0547 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,939] LMCache INFO:[0m Reqid: chatcmpl-b47193fd0c9448428de182520c28236e, Total tokens 969, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,940] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 651, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,965] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-4fe19b75b6884a1d9d5c1207a21013cb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,965] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.4116 ms, throughput: 8.3048 GB/s; offload_time: 0.3444 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:18,969] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 651, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,988] LMCache INFO:[0m Reqid: chatcmpl-b47193fd0c9448428de182520c28236e, Total tokens 971, LMCache hit tokens: 896, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,995] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:18,996] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4098 ms, throughput: 8.3409 GB/s; offload_time: 0.3448 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,000] LMCache INFO:[0m Reqid: chatcmpl-b47193fd0c9448428de182520c28236e, Total tokens 971, LMCache hit tokens: 896, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,007] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-802f7faa9b994e6eac330783d39a4c9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,008] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.4776 ms, throughput: 7.1560 GB/s; offload_time: 0.4124 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,012] LMCache INFO:[0m Reqid: chatcmpl-b47193fd0c9448428de182520c28236e, Total tokens 971, LMCache hit tokens: 896, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,013] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 651, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,014] LMCache INFO:[0m Reqid: chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc, Total tokens 358, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,033] LMCache INFO:[0m Storing KV cache for 139 out of 651 tokens (skip_leading_tokens=512) for request chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,034] LMCache INFO:[0m Stored 139 out of total 651 tokens. size: 0.0037 gb, cost 0.5506 ms, throughput: 6.7411 GB/s; offload_time: 0.4602 ms, put_time: 0.0904 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,038] LMCache INFO:[0m Reqid: chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc, Total tokens 358, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,045] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,046] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4233 ms, throughput: 8.0740 GB/s; offload_time: 0.3501 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,057] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,057] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.4626 ms, throughput: 7.3883 GB/s; offload_time: 0.3985 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,058] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-d80c18b6b1ad4eebb81d42ad83ff458b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,058] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5572 ms, throughput: 6.1336 GB/s; offload_time: 0.5033 ms, put_time: 0.0539 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,063] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 653, LMCache hit tokens: 651, need to load: 251 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,072] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 653, LMCache hit tokens: 651, need to load: 267 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,079] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5e916300cba94438a670e07bf421ae50 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,080] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.1616 ms, throughput: 2.9425 GB/s; offload_time: 1.0964 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,081] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-d0a1ac8ca00e4085872f7bd7cc777229 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,082] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5144 ms, throughput: 2.2570 GB/s; offload_time: 1.3979 ms, put_time: 0.1164 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,087] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 653, LMCache hit tokens: 651, need to load: 395 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,097] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 653, LMCache hit tokens: 651, need to load: 427 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,103] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-13f230aa4aee4661a040780ca69bbdc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,104] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4125 ms, throughput: 8.2868 GB/s; offload_time: 0.3398 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,108] LMCache INFO:[0m Reqid: chatcmpl-de3168bfa87042eeb30bf8cfe46a7e37, Total tokens 653, LMCache hit tokens: 651, need to load: 475 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,109] LMCache INFO:[0m Reqid: chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc, Total tokens 358, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,109] LMCache INFO:[0m Reqid: chatcmpl-d199ecd8b4844f819dccca5e0ee3a3f4, Total tokens 204, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,110] LMCache INFO:[0m Reqid: chatcmpl-b7e7f00a870241be955655c627abe2a3, Total tokens 168, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,111] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,130] LMCache INFO:[0m Storing KV cache for 168 out of 168 tokens (skip_leading_tokens=0) for request chatcmpl-b7e7f00a870241be955655c627abe2a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,130] LMCache INFO:[0m Stored 168 out of total 168 tokens. size: 0.0045 gb, cost 0.5153 ms, throughput: 8.7064 GB/s; offload_time: 0.4251 ms, put_time: 0.0902 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,131] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,132] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6833 ms, throughput: 2.0305 GB/s; offload_time: 1.5919 ms, put_time: 0.0915 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,133] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f33e38cfc4df45f386871d60461a046b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,135] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1854 ms, throughput: 2.8834 GB/s; offload_time: 1.1284 ms, put_time: 0.0570 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,135] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8c1b3822f886404cba9747e1e74d878a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,137] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7469 ms, throughput: 1.9566 GB/s; offload_time: 1.5943 ms, put_time: 0.1526 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,142] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,149] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-9803e49fa2a549e2bf73ae3c59fe7d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,150] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1653 ms, throughput: 2.9330 GB/s; offload_time: 1.0899 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,154] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,164] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,174] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,183] LMCache INFO:[0m Reqid: chatcmpl-7a554a54eff944068cdead394823d2b7, Total tokens 662, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,184] LMCache INFO:[0m Reqid: chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f, Total tokens 121, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,185] LMCache INFO:[0m Reqid: chatcmpl-8c705a6358c44ca198220ea622a31a55, Total tokens 1622, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,205] LMCache INFO:[0m Storing KV cache for 121 out of 121 tokens (skip_leading_tokens=0) for request chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,205] LMCache INFO:[0m Stored 121 out of total 121 tokens. size: 0.0032 gb, cost 0.3505 ms, throughput: 9.2181 GB/s; offload_time: 0.2897 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,206] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,207] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6609 ms, throughput: 5.1715 GB/s; offload_time: 0.6019 ms, put_time: 0.0590 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,212] LMCache INFO:[0m Reqid: chatcmpl-8c705a6358c44ca198220ea622a31a55, Total tokens 1622, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,219] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-abde1d64334941649c2aef92cffebb09 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,220] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4083 ms, throughput: 8.3710 GB/s; offload_time: 0.3449 ms, put_time: 0.0634 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,220] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-67f476d9e80a4b48b2facac880f805cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,221] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6145 ms, throughput: 5.5623 GB/s; offload_time: 0.5589 ms, put_time: 0.0556 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,232] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,232] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4054 ms, throughput: 8.4314 GB/s; offload_time: 0.3345 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,236] LMCache INFO:[0m Reqid: chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f, Total tokens 123, LMCache hit tokens: 121, need to load: 73 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,237] LMCache INFO:[0m Reqid: chatcmpl-8c705a6358c44ca198220ea622a31a55, Total tokens 1622, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,239] LMCache INFO:[0m Reqid: chatcmpl-f9b6a358e46b47deb1ae24cf4104481a, Total tokens 751, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,273] LMCache INFO:[0m Storing KV cache for 214 out of 1622 tokens (skip_leading_tokens=1408) for request chatcmpl-8c705a6358c44ca198220ea622a31a55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,274] LMCache INFO:[0m Stored 214 out of total 1622 tokens. size: 0.0057 gb, cost 0.5946 ms, throughput: 9.6108 GB/s; offload_time: 0.5042 ms, put_time: 0.0904 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,279] LMCache INFO:[0m Reqid: chatcmpl-f9b6a358e46b47deb1ae24cf4104481a, Total tokens 751, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,290] LMCache INFO:[0m Reqid: chatcmpl-f9b6a358e46b47deb1ae24cf4104481a, Total tokens 751, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,291] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 796, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,291] LMCache INFO:[0m Reqid: chatcmpl-b5efb67e7d9a4749a145569b389ffdbe, Total tokens 250, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,315] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-acc04e6079a84a7981fc48f16ac0c155 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,317] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.9724 ms, throughput: 1.7329 GB/s; offload_time: 1.9082 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,317] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-8fbab344d87545b08341f3b25db77d61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,318] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9665 ms, throughput: 3.5363 GB/s; offload_time: 0.9030 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,318] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ab9e78d01c3c41af8f4daa9c48dc4a5a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,319] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5472 ms, throughput: 6.2462 GB/s; offload_time: 0.4908 ms, put_time: 0.0564 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,330] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8e3cb1a361e84dc7a6b8d3b662a49ccb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,331] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4070 ms, throughput: 8.3987 GB/s; offload_time: 0.3349 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,336] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,343] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-30ee7f7de03f42cd884efc559dad7008 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,343] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4126 ms, throughput: 8.2842 GB/s; offload_time: 0.3474 ms, put_time: 0.0652 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,348] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,355] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-6cf69c09bad44d7dac4fe734ddfaba02 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,356] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.4483 ms, throughput: 7.6242 GB/s; offload_time: 0.3850 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,356] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b798e3027d724ea78fee8a13cfbedc35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,356] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6170 ms, throughput: 5.5398 GB/s; offload_time: 0.5247 ms, put_time: 0.0922 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,357] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,357] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3899 ms, throughput: 8.7657 GB/s; offload_time: 0.3281 ms, put_time: 0.0618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,362] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,372] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 416 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,381] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,390] LMCache INFO:[0m Reqid: chatcmpl-bb892d27b8f140d6af826f54f6ae529b, Total tokens 797, LMCache hit tokens: 768, need to load: 576 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,391] LMCache INFO:[0m Reqid: chatcmpl-b5efb67e7d9a4749a145569b389ffdbe, Total tokens 250, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,392] LMCache INFO:[0m Reqid: chatcmpl-18927124df7b4c8f8844c3885ec5f152, Total tokens 609, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,406] LMCache INFO:[0m Storing KV cache for 250 out of 250 tokens (skip_leading_tokens=0) for request chatcmpl-b5efb67e7d9a4749a145569b389ffdbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,407] LMCache INFO:[0m Stored 250 out of total 250 tokens. size: 0.0067 gb, cost 0.5801 ms, throughput: 11.5084 GB/s; offload_time: 0.4811 ms, put_time: 0.0989 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,407] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c57a2584c41e475992902878fae82747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,410] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6433 ms, throughput: 2.0800 GB/s; offload_time: 1.5727 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,416] LMCache INFO:[0m Reqid: chatcmpl-18927124df7b4c8f8844c3885ec5f152, Total tokens 609, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,417] LMCache INFO:[0m Reqid: chatcmpl-5ee0868f68df4e389d2ae6613b49131e, Total tokens 667, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,439] LMCache INFO:[0m Reqid: chatcmpl-5ee0868f68df4e389d2ae6613b49131e, Total tokens 667, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,449] LMCache INFO:[0m Reqid: chatcmpl-5ee0868f68df4e389d2ae6613b49131e, Total tokens 667, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,449] LMCache INFO:[0m Reqid: chatcmpl-576cd54fe7564ae99407912dd0922f55, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,450] LMCache INFO:[0m Reqid: chatcmpl-275273a6ddeb474584e6c537996aadb2, Total tokens 283, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,467] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-576cd54fe7564ae99407912dd0922f55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,467] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.3470 ms, throughput: 8.3103 GB/s; offload_time: 0.2843 ms, put_time: 0.0627 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,474] LMCache INFO:[0m Reqid: chatcmpl-275273a6ddeb474584e6c537996aadb2, Total tokens 283, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,482] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,483] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6764 ms, throughput: 5.0533 GB/s; offload_time: 0.5989 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,488] LMCache INFO:[0m Reqid: chatcmpl-275273a6ddeb474584e6c537996aadb2, Total tokens 283, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,504] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,504] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4337 ms, throughput: 7.8809 GB/s; offload_time: 0.3701 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,505] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9cbae3108d22479dbefc7aea80f24f59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,506] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.8693 ms, throughput: 3.9319 GB/s; offload_time: 0.7994 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,506] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b5efb67e7d9a4749a145569b389ffdbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,507] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6663 ms, throughput: 5.1301 GB/s; offload_time: 0.6005 ms, put_time: 0.0657 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,518] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c5a4babe97a841c9bd6dc27205f2d674 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,521] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.0801 ms, throughput: 1.6432 GB/s; offload_time: 2.0132 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,525] LMCache INFO:[0m Reqid: chatcmpl-5ee0868f68df4e389d2ae6613b49131e, Total tokens 671, LMCache hit tokens: 640, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,526] LMCache INFO:[0m Reqid: chatcmpl-576cd54fe7564ae99407912dd0922f55, Total tokens 111, LMCache hit tokens: 108, need to load: 60 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,526] LMCache INFO:[0m Reqid: chatcmpl-275273a6ddeb474584e6c537996aadb2, Total tokens 283, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,527] LMCache INFO:[0m Reqid: chatcmpl-8e60d4da9bb74f7da7ab77ecd16f307c, Total tokens 201, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,527] LMCache INFO:[0m Reqid: chatcmpl-bf942b9a41c04c428b34f6ede8105f41, Total tokens 232, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,545] LMCache INFO:[0m Storing KV cache for 155 out of 283 tokens (skip_leading_tokens=128) for request chatcmpl-275273a6ddeb474584e6c537996aadb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,546] LMCache INFO:[0m Stored 155 out of total 283 tokens. size: 0.0041 gb, cost 0.5287 ms, throughput: 7.8286 GB/s; offload_time: 0.4376 ms, put_time: 0.0911 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,551] LMCache INFO:[0m Reqid: chatcmpl-bf942b9a41c04c428b34f6ede8105f41, Total tokens 232, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,552] LMCache INFO:[0m Reqid: chatcmpl-5084650039974a68936dd3af8bb5fa1f, Total tokens 350, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,553] LMCache INFO:[0m Reqid: chatcmpl-acad9f47d63c46f789c60f168343db7b, Total tokens 832, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57648 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,573] LMCache INFO:[0m Storing KV cache for 232 out of 232 tokens (skip_leading_tokens=0) for request chatcmpl-bf942b9a41c04c428b34f6ede8105f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,575] LMCache INFO:[0m Stored 232 out of total 232 tokens. size: 0.0062 gb, cost 1.2978 ms, throughput: 4.7736 GB/s; offload_time: 1.2059 ms, put_time: 0.0919 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,575] LMCache INFO:[0m Storing KV cache for 350 out of 350 tokens (skip_leading_tokens=0) for request chatcmpl-5084650039974a68936dd3af8bb5fa1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,578] LMCache INFO:[0m Stored 350 out of total 350 tokens. size: 0.0093 gb, cost 2.5118 ms, throughput: 3.7209 GB/s; offload_time: 2.3914 ms, put_time: 0.1204 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,578] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-a9d902d585e04f729f8738c430e74efc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,582] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 3.7026 ms, throughput: 0.9231 GB/s; offload_time: 3.4018 ms, put_time: 0.3009 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,583] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,586] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.5644 ms, throughput: 1.3328 GB/s; offload_time: 2.4868 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,587] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,589] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7451 ms, throughput: 1.9587 GB/s; offload_time: 1.6609 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,594] LMCache INFO:[0m Reqid: chatcmpl-acad9f47d63c46f789c60f168343db7b, Total tokens 832, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,595] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,619] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f9b6a358e46b47deb1ae24cf4104481a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,619] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4937 ms, throughput: 6.9227 GB/s; offload_time: 0.4208 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,624] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,635] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,645] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,656] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,662] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-100fe76785d947ed8190d9173925e11a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,663] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5501 ms, throughput: 6.2132 GB/s; offload_time: 0.4719 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,668] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,675] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c4cccc54ee89409e9ccf3166d6fb617f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,676] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4914 ms, throughput: 6.9560 GB/s; offload_time: 0.4145 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,690] LMCache INFO:[0m Reqid: chatcmpl-acad9f47d63c46f789c60f168343db7b, Total tokens 838, LMCache hit tokens: 768, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,691] LMCache INFO:[0m Reqid: chatcmpl-2475e7ff701a4d4ca27931b40a5130c4, Total tokens 1450, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,693] LMCache INFO:[0m Reqid: chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8, Total tokens 896, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,727] LMCache INFO:[0m Reqid: chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8, Total tokens 896, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,737] LMCache INFO:[0m Reqid: chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8, Total tokens 896, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,747] LMCache INFO:[0m Reqid: chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8, Total tokens 896, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,756] LMCache INFO:[0m Reqid: chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8, Total tokens 896, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,757] LMCache INFO:[0m Reqid: chatcmpl-d7d1749fef274e89ba0102ffd2b91ad9, Total tokens 594, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,758] LMCache INFO:[0m Reqid: chatcmpl-8ae8c2f4d1a84dd5900ec24016cdbad6, Total tokens 412, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,785] LMCache INFO:[0m Storing KV cache for 256 out of 896 tokens (skip_leading_tokens=640) for request chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,786] LMCache INFO:[0m Stored 256 out of total 896 tokens. size: 0.0068 gb, cost 0.7205 ms, throughput: 9.4883 GB/s; offload_time: 0.6137 ms, put_time: 0.1068 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,791] LMCache INFO:[0m Reqid: chatcmpl-8ae8c2f4d1a84dd5900ec24016cdbad6, Total tokens 412, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,792] LMCache INFO:[0m Reqid: chatcmpl-8d2aca6fc8c94df0b0ebc37669fbb4e3, Total tokens 241, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,793] LMCache INFO:[0m Reqid: chatcmpl-ea255f0e35284dd498f721e147abf6ba, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,794] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,812] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-ea255f0e35284dd498f721e147abf6ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,813] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 0.4267 ms, throughput: 7.0716 GB/s; offload_time: 0.3519 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,818] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,828] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,839] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,849] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,856] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c591ee2c87364be983b4f0a36fdc1bc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,857] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4740 ms, throughput: 7.2115 GB/s; offload_time: 0.3954 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,862] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,873] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,882] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,889] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-b47193fd0c9448428de182520c28236e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,890] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5474 ms, throughput: 6.2438 GB/s; offload_time: 0.4721 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,895] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:19,906] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,916] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,923] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,923] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5324 ms, throughput: 6.4203 GB/s; offload_time: 0.4516 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,924] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-18927124df7b4c8f8844c3885ec5f152 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,925] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7967 ms, throughput: 4.2904 GB/s; offload_time: 0.6874 ms, put_time: 0.1092 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,930] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,937] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2a31bb46181b423caeffe68382fcdff8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,938] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5309 ms, throughput: 6.4377 GB/s; offload_time: 0.4552 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,938] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-8c705a6358c44ca198220ea622a31a55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,939] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.9813 ms, throughput: 3.4833 GB/s; offload_time: 0.9049 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,940] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-bf942b9a41c04c428b34f6ede8105f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,941] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5821 ms, throughput: 5.8717 GB/s; offload_time: 0.5167 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,952] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,962] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,969] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d199ecd8b4844f819dccca5e0ee3a3f4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,970] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4823 ms, throughput: 7.0869 GB/s; offload_time: 0.4064 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,975] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,982] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-fc8780a1388b40d698e0159574c4eefc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,984] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4211 ms, throughput: 2.4051 GB/s; offload_time: 1.3341 ms, put_time: 0.0871 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,984] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e4e95de630d041a6b64ed277f1c753a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,986] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3454 ms, throughput: 2.5405 GB/s; offload_time: 1.2755 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:19,991] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:19,998] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8d2aca6fc8c94df0b0ebc37669fbb4e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,000] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.2890 ms, throughput: 2.6517 GB/s; offload_time: 1.2110 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,000] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-ea255f0e35284dd498f721e147abf6ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,002] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4350 ms, throughput: 2.3819 GB/s; offload_time: 1.3643 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:57778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:20,007] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,014] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-5a99df1a5357469b82db40be11e4d4a6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,016] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4487 ms, throughput: 2.3593 GB/s; offload_time: 1.3714 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:57794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:20,021] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,028] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5ac9846d010840028038b94ea3f3b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,030] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3708 ms, throughput: 2.4934 GB/s; offload_time: 1.2895 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,030] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,032] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5992 ms, throughput: 2.1373 GB/s; offload_time: 1.5270 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,038] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,047] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,057] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,067] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,074] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5084650039974a68936dd3af8bb5fa1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,075] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3082 ms, throughput: 2.6128 GB/s; offload_time: 1.2318 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,080] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,090] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,100] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,110] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,120] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,127] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1d719705177b40a386de9dc4d04584a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,128] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3591 ms, throughput: 2.5148 GB/s; offload_time: 1.2847 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,134] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,143] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,153] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,161] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-57c382b9911c4490afad27f65130b4c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,162] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3718 ms, throughput: 2.4916 GB/s; offload_time: 1.2967 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,168] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,178] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1976, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,179] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,225] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,232] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,233] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5170 ms, throughput: 6.6118 GB/s; offload_time: 0.4266 ms, put_time: 0.0904 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,233] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,235] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0311 ms, throughput: 3.3148 GB/s; offload_time: 0.9585 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,239] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,249] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,257] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,258] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6262 ms, throughput: 5.4579 GB/s; offload_time: 0.5499 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,262] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,272] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,279] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,280] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5193 ms, throughput: 6.5819 GB/s; offload_time: 0.4377 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,295] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,305] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,315] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,322] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e69ffc5cf14d49ce8eebb257198f9c41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,323] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4854 ms, throughput: 7.0417 GB/s; offload_time: 0.4013 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,327] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,335] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-31146a67f77f4f609d343c1494a5aebc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,336] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4779 ms, throughput: 7.1514 GB/s; offload_time: 0.3977 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,336] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8e60d4da9bb74f7da7ab77ecd16f307c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,337] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6307 ms, throughput: 5.4197 GB/s; offload_time: 0.5582 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,342] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,352] LMCache INFO:[0m Reqid: chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5, Total tokens 1982, LMCache hit tokens: 1920, need to load: 432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,353] LMCache INFO:[0m Reqid: chatcmpl-2159a66075e0490d8f68e6da54767a3a, Total tokens 790, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,354] LMCache INFO:[0m Reqid: chatcmpl-e2f896ad07e545f2981b0792f67b511d, Total tokens 681, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,375] LMCache INFO:[0m Storing KV cache for 150 out of 790 tokens (skip_leading_tokens=640) for request chatcmpl-2159a66075e0490d8f68e6da54767a3a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,376] LMCache INFO:[0m Stored 150 out of total 790 tokens. size: 0.0040 gb, cost 0.6793 ms, throughput: 5.8961 GB/s; offload_time: 0.5707 ms, put_time: 0.1086 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,382] LMCache INFO:[0m Reqid: chatcmpl-e2f896ad07e545f2981b0792f67b511d, Total tokens 681, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,383] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 378, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,384] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,404] LMCache INFO:[0m Storing KV cache for 250 out of 378 tokens (skip_leading_tokens=128) for request chatcmpl-9a3e29b74e154d83996f2f3fd05582d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,405] LMCache INFO:[0m Stored 250 out of total 378 tokens. size: 0.0067 gb, cost 0.7302 ms, throughput: 9.1418 GB/s; offload_time: 0.6206 ms, put_time: 0.1096 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,410] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,418] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,418] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5055 ms, throughput: 6.7612 GB/s; offload_time: 0.4287 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,419] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-d7d1749fef274e89ba0102ffd2b91ad9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,419] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5518 ms, throughput: 6.1941 GB/s; offload_time: 0.4888 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,424] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,431] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9d868c41e2c9421f9bf052edd6f41b3c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,432] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5384 ms, throughput: 6.3479 GB/s; offload_time: 0.4598 ms, put_time: 0.0786 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,436] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,452] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,453] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4873 ms, throughput: 7.0145 GB/s; offload_time: 0.4117 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,457] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 382, LMCache hit tokens: 378, need to load: 234 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,464] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b7e7f00a870241be955655c627abe2a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,466] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3058 ms, throughput: 2.6175 GB/s; offload_time: 1.2296 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,470] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 382, LMCache hit tokens: 378, need to load: 314 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,489] LMCache INFO:[0m Reqid: chatcmpl-e2f896ad07e545f2981b0792f67b511d, Total tokens 688, LMCache hit tokens: 640, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,496] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,498] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3954 ms, throughput: 2.4494 GB/s; offload_time: 1.3189 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,498] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-d7c27d3404d244dd920073cf660bebf7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,500] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.7269 ms, throughput: 1.9792 GB/s; offload_time: 1.6545 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,500] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2fe0fef3ef764b588c6c4fe490a75cff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,502] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6302 ms, throughput: 2.0967 GB/s; offload_time: 1.5047 ms, put_time: 0.1255 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,507] LMCache INFO:[0m Reqid: chatcmpl-e2f896ad07e545f2981b0792f67b511d, Total tokens 688, LMCache hit tokens: 640, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,514] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-acad9f47d63c46f789c60f168343db7b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,516] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3880 ms, throughput: 2.4624 GB/s; offload_time: 1.3094 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,520] LMCache INFO:[0m Reqid: chatcmpl-e2f896ad07e545f2981b0792f67b511d, Total tokens 688, LMCache hit tokens: 640, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,521] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 382, LMCache hit tokens: 378, need to load: 330 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,522] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,539] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,549] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 730, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,550] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,571] LMCache INFO:[0m Storing KV cache for 602 out of 730 tokens (skip_leading_tokens=128) for request chatcmpl-50338afb5a064f44b4fa92af949de58a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,575] LMCache INFO:[0m Stored 602 out of total 730 tokens. size: 0.0161 gb, cost 4.0295 ms, throughput: 3.9894 GB/s; offload_time: 3.8235 ms, put_time: 0.2059 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,576] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9a3e29b74e154d83996f2f3fd05582d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,580] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6287 ms, throughput: 2.0986 GB/s; offload_time: 1.5584 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,586] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,593] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-75b601edb80f47f69afc3f5e01cd3996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,595] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4246 ms, throughput: 2.3993 GB/s; offload_time: 1.3476 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,599] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,606] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-dfcea3292be54a41be2293fd2bc6349a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,608] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.3920 ms, throughput: 2.4554 GB/s; offload_time: 1.3154 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,612] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,622] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,631] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,641] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,650] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,660] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,667] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,668] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4436 ms, throughput: 2.3677 GB/s; offload_time: 1.3689 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,669] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,670] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4836 ms, throughput: 2.3039 GB/s; offload_time: 1.4131 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,685] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 186 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:20,692] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-9919c9c415494cef9b524cefe216e828 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:20,693] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.4980 ms, throughput: 2.2817 GB/s; offload_time: 1.4159 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,694] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e0af191e26284584bc421525c69cd0ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,695] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4776 ms, throughput: 2.3132 GB/s; offload_time: 1.4034 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,700] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 234 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,710] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 314 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,717] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-8ebcc583af544e4c8b9d734aaaabee5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,719] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 1.4772 ms, throughput: 2.3139 GB/s; offload_time: 1.3999 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,723] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 474 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,733] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 538 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,741] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,743] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4422 ms, throughput: 2.3700 GB/s; offload_time: 1.3640 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,743] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-43d6dfaa657743eea7828b8700bee247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,745] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4737 ms, throughput: 2.3193 GB/s; offload_time: 1.4004 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,749] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 618 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,759] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 650 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,766] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-7a554a54eff944068cdead394823d2b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,767] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3637 ms, throughput: 2.5065 GB/s; offload_time: 1.2873 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,772] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,782] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,791] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,799] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-29b3bd4a742c4742a1204da81b22b4e5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,800] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.4223 ms, throughput: 2.4031 GB/s; offload_time: 1.3472 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,804] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,812] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f9de432d8ffe4a558456696bbe434ee3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,813] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4102 ms, throughput: 2.4238 GB/s; offload_time: 1.3308 ms, put_time: 0.0794 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,814] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-83664632731343008d10b16867e22a36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,816] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5990 ms, throughput: 2.1376 GB/s; offload_time: 1.5288 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,821] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,828] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-bb892d27b8f140d6af826f54f6ae529b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,830] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3743 ms, throughput: 2.4870 GB/s; offload_time: 1.2967 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,843] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 406, LMCache hit tokens: 378, need to load: 122 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,853] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 406, LMCache hit tokens: 378, need to load: 186 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,860] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,861] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3307 ms, throughput: 2.5685 GB/s; offload_time: 1.2532 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,867] LMCache INFO:[0m Reqid: chatcmpl-9a3e29b74e154d83996f2f3fd05582d5, Total tokens 406, LMCache hit tokens: 378, need to load: 330 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,868] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,881] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-2475e7ff701a4d4ca27931b40a5130c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,883] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 2.0911 ms, throughput: 1.6346 GB/s; offload_time: 2.0122 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,887] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,898] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,905] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,906] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3717 ms, throughput: 2.4917 GB/s; offload_time: 1.2903 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,911] LMCache INFO:[0m Reqid: chatcmpl-50338afb5a064f44b4fa92af949de58a, Total tokens 739, LMCache hit tokens: 730, need to load: 682 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,912] LMCache INFO:[0m Reqid: chatcmpl-c745167344af47909fe691e143e72d55, Total tokens 872, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,913] LMCache INFO:[0m Reqid: chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7, Total tokens 1787, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,940] LMCache INFO:[0m Storing KV cache for 488 out of 872 tokens (skip_leading_tokens=384) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,941] LMCache INFO:[0m Stored 488 out of total 872 tokens. size: 0.0130 gb, cost 1.1005 ms, throughput: 11.8415 GB/s; offload_time: 0.9417 ms, put_time: 0.1588 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,942] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,944] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 2.4725 ms, throughput: 1.3824 GB/s; offload_time: 2.4032 ms, put_time: 0.0693 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,945] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-d80c18b6b1ad4eebb81d42ad83ff458b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,947] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 2.4080 ms, throughput: 1.4194 GB/s; offload_time: 2.1191 ms, put_time: 0.2889 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,953] LMCache INFO:[0m Reqid: chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7, Total tokens 1787, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,963] LMCache INFO:[0m Reqid: chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7, Total tokens 1787, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,970] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-d0a1ac8ca00e4085872f7bd7cc777229 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,971] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3835 ms, throughput: 2.4706 GB/s; offload_time: 1.3060 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,976] LMCache INFO:[0m Reqid: chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7, Total tokens 1787, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,983] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-275273a6ddeb474584e6c537996aadb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,984] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3164 ms, throughput: 2.5965 GB/s; offload_time: 1.2231 ms, put_time: 0.0933 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:20,989] LMCache INFO:[0m Reqid: chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7, Total tokens 1787, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,990] LMCache INFO:[0m Reqid: chatcmpl-595b20f1c0524f6a9d7a170456913c96, Total tokens 126, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,990] LMCache INFO:[0m Reqid: chatcmpl-196eecb221f24ddcb9cf87330884a7d0, Total tokens 142, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,992] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1776, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,993] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:20,994] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,062] LMCache INFO:[0m Storing KV cache for 1787 out of 1787 tokens (skip_leading_tokens=0) for request chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,065] LMCache INFO:[0m Stored 1787 out of total 1787 tokens. size: 0.0477 gb, cost 2.9139 ms, throughput: 16.3762 GB/s; offload_time: 2.5085 ms, put_time: 0.4053 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,067] LMCache INFO:[0m Storing KV cache for 126 out of 126 tokens (skip_leading_tokens=0) for request chatcmpl-595b20f1c0524f6a9d7a170456913c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,069] LMCache INFO:[0m Stored 126 out of total 126 tokens. size: 0.0034 gb, cost 1.5502 ms, throughput: 2.1704 GB/s; offload_time: 1.4564 ms, put_time: 0.0938 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,070] LMCache INFO:[0m Storing KV cache for 142 out of 142 tokens (skip_leading_tokens=0) for request chatcmpl-196eecb221f24ddcb9cf87330884a7d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,074] LMCache INFO:[0m Stored 142 out of total 142 tokens. size: 0.0038 gb, cost 4.3802 ms, throughput: 0.8657 GB/s; offload_time: 3.7241 ms, put_time: 0.6561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,075] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-78362672c0464fec85d5a2f94a283710 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,080] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 4.1606 ms, throughput: 0.8472 GB/s; offload_time: 3.8342 ms, put_time: 0.3264 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,084] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,092] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,093] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3803 ms, throughput: 2.4763 GB/s; offload_time: 1.2908 ms, put_time: 0.0895 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,094] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f33e38cfc4df45f386871d60461a046b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,095] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3488 ms, throughput: 2.5340 GB/s; offload_time: 1.2701 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,096] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8c1b3822f886404cba9747e1e74d878a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,097] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4745 ms, throughput: 2.3181 GB/s; offload_time: 1.4032 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,102] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,109] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-595b20f1c0524f6a9d7a170456913c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,111] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3006 ms, throughput: 2.6280 GB/s; offload_time: 1.2153 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,115] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,134] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 136, LMCache hit tokens: 132, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,141] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,143] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.4183 ms, throughput: 2.4098 GB/s; offload_time: 1.3435 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,154] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,155] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3338 ms, throughput: 2.5625 GB/s; offload_time: 1.2580 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,161] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1782, LMCache hit tokens: 1664, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,168] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-67f476d9e80a4b48b2facac880f805cc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,169] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3617 ms, throughput: 2.5101 GB/s; offload_time: 1.2829 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,174] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1782, LMCache hit tokens: 1664, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,181] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,183] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3646 ms, throughput: 2.5047 GB/s; offload_time: 1.2795 ms, put_time: 0.0851 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,188] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1782, LMCache hit tokens: 1664, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,198] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1782, LMCache hit tokens: 1664, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,208] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1782, LMCache hit tokens: 1664, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,209] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 136, LMCache hit tokens: 132, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,210] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,223] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-8fbab344d87545b08341f3b25db77d61 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,225] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3920 ms, throughput: 2.4554 GB/s; offload_time: 1.3096 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,229] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,237] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8ae8c2f4d1a84dd5900ec24016cdbad6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,238] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3640 ms, throughput: 2.5058 GB/s; offload_time: 1.2853 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,242] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,250] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-30ee7f7de03f42cd884efc559dad7008 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,252] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4106 ms, throughput: 2.4231 GB/s; offload_time: 1.3279 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,263] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,265] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3347 ms, throughput: 2.5609 GB/s; offload_time: 1.2568 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,268] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 139, LMCache hit tokens: 132, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,289] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1787, LMCache hit tokens: 1664, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,300] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1787, LMCache hit tokens: 1664, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,307] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c57a2584c41e475992902878fae82747 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,308] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3428 ms, throughput: 2.5453 GB/s; offload_time: 1.2621 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,313] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1787, LMCache hit tokens: 1664, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,314] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 139, LMCache hit tokens: 132, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,337] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,338] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3811 ms, throughput: 2.4749 GB/s; offload_time: 1.3042 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,344] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1788, LMCache hit tokens: 1664, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,351] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-9ecd58a1aa7f4c13b1a9bac413d440c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,353] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.4366 ms, throughput: 2.3793 GB/s; offload_time: 1.3512 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,359] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1788, LMCache hit tokens: 1664, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,368] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,369] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4310 ms, throughput: 2.3885 GB/s; offload_time: 1.3507 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,375] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1788, LMCache hit tokens: 1664, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,385] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1788, LMCache hit tokens: 1664, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,392] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,393] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4298 ms, throughput: 2.3906 GB/s; offload_time: 1.3516 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,394] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b5efb67e7d9a4749a145569b389ffdbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,396] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6238 ms, throughput: 2.1049 GB/s; offload_time: 1.5521 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,401] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1788, LMCache hit tokens: 1664, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,402] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 139, LMCache hit tokens: 132, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,415] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c5a4babe97a841c9bd6dc27205f2d674 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,417] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3515 ms, throughput: 2.5291 GB/s; offload_time: 1.2726 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,417] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-50338afb5a064f44b4fa92af949de58a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,419] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.8231 ms, throughput: 1.8748 GB/s; offload_time: 1.7468 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,433] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1789, LMCache hit tokens: 1664, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,441] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-a9d902d585e04f729f8738c430e74efc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,443] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4035 ms, throughput: 2.4353 GB/s; offload_time: 1.3234 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,443] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,445] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.6955 ms, throughput: 2.0160 GB/s; offload_time: 1.6225 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,445] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,447] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.0268 ms, throughput: 1.6864 GB/s; offload_time: 1.9459 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,452] LMCache INFO:[0m Reqid: chatcmpl-65d842ad537a42578c13543a778e5b6e, Total tokens 1789, LMCache hit tokens: 1664, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,453] LMCache INFO:[0m Reqid: chatcmpl-78362672c0464fec85d5a2f94a283710, Total tokens 139, LMCache hit tokens: 132, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,454] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,467] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-f9b6a358e46b47deb1ae24cf4104481a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,468] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3990 ms, throughput: 2.4432 GB/s; offload_time: 1.3210 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,473] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1112, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,474] LMCache INFO:[0m Reqid: chatcmpl-0b65b00e9af5435fb1581f7f4fd8d684, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,500] LMCache INFO:[0m Storing KV cache for 216 out of 1112 tokens (skip_leading_tokens=896) for request chatcmpl-fc62939130904aeeaf862bc2dad8342d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,501] LMCache INFO:[0m Stored 216 out of total 1112 tokens. size: 0.0058 gb, cost 0.7259 ms, throughput: 7.9456 GB/s; offload_time: 0.6125 ms, put_time: 0.1134 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,516] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1113, LMCache hit tokens: 1112, need to load: 88 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,523] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-65d842ad537a42578c13543a778e5b6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,524] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5899 ms, throughput: 5.7944 GB/s; offload_time: 0.5096 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,528] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1113, LMCache hit tokens: 1112, need to load: 136 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,536] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-100fe76785d947ed8190d9173925e11a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,536] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5679 ms, throughput: 6.0190 GB/s; offload_time: 0.4761 ms, put_time: 0.0917 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,541] LMCache INFO:[0m Reqid: chatcmpl-fc62939130904aeeaf862bc2dad8342d, Total tokens 1113, LMCache hit tokens: 1112, need to load: 168 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,542] LMCache INFO:[0m Reqid: chatcmpl-0b65b00e9af5435fb1581f7f4fd8d684, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,542] LMCache INFO:[0m Reqid: chatcmpl-75ab689c314b4c94ae42709b42bcd2f9, Total tokens 626, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,557] LMCache INFO:[0m Storing KV cache for 115 out of 115 tokens (skip_leading_tokens=0) for request chatcmpl-0b65b00e9af5435fb1581f7f4fd8d684 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,558] LMCache INFO:[0m Stored 115 out of total 115 tokens. size: 0.0031 gb, cost 0.4738 ms, throughput: 6.4812 GB/s; offload_time: 0.3957 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,563] LMCache INFO:[0m Reqid: chatcmpl-75ab689c314b4c94ae42709b42bcd2f9, Total tokens 626, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,563] LMCache INFO:[0m Reqid: chatcmpl-9f0a8fe50b084300aef0ebdccdc61623, Total tokens 190, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,584] LMCache INFO:[0m Reqid: chatcmpl-9f0a8fe50b084300aef0ebdccdc61623, Total tokens 190, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,585] LMCache INFO:[0m Reqid: chatcmpl-5f0661cec68142b697b693733c623aef, Total tokens 190, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,586] LMCache INFO:[0m Reqid: chatcmpl-7b880a91c9c34d71b9f3124f958a621b, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,587] LMCache INFO:[0m Reqid: chatcmpl-1f0a8f2579d64c5c894b48728246b245, Total tokens 1018, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,588] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,615] LMCache INFO:[0m Storing KV cache for 190 out of 190 tokens (skip_leading_tokens=0) for request chatcmpl-9f0a8fe50b084300aef0ebdccdc61623 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,616] LMCache INFO:[0m Stored 190 out of total 190 tokens. size: 0.0051 gb, cost 0.6807 ms, throughput: 7.4536 GB/s; offload_time: 0.5696 ms, put_time: 0.1111 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,616] LMCache INFO:[0m Storing KV cache for 115 out of 115 tokens (skip_leading_tokens=0) for request chatcmpl-7b880a91c9c34d71b9f3124f958a621b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,617] LMCache INFO:[0m Stored 115 out of total 115 tokens. size: 0.0031 gb, cost 1.2489 ms, throughput: 2.4589 GB/s; offload_time: 1.1656 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,624] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,633] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,643] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,653] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,660] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,661] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5293 ms, throughput: 6.4580 GB/s; offload_time: 0.4540 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,666] LMCache INFO:[0m Reqid: chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0, Total tokens 1986, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,667] LMCache INFO:[0m Reqid: chatcmpl-461f7fc3a29742ff9cfc055aca9a939f, Total tokens 417, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,708] LMCache INFO:[0m Storing KV cache for 194 out of 1986 tokens (skip_leading_tokens=1792) for request chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,709] LMCache INFO:[0m Stored 194 out of total 1986 tokens. size: 0.0052 gb, cost 0.7785 ms, throughput: 6.6539 GB/s; offload_time: 0.6700 ms, put_time: 0.1086 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,714] LMCache INFO:[0m Reqid: chatcmpl-461f7fc3a29742ff9cfc055aca9a939f, Total tokens 417, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,721] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1f0a8f2579d64c5c894b48728246b245 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,722] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5280 ms, throughput: 6.4737 GB/s; offload_time: 0.4489 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,726] LMCache INFO:[0m Reqid: chatcmpl-461f7fc3a29742ff9cfc055aca9a939f, Total tokens 417, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,727] LMCache INFO:[0m Reqid: chatcmpl-45550a4853a84599a9ed50b7ce1327ac, Total tokens 513, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,728] LMCache INFO:[0m Reqid: chatcmpl-2a1857ff39ec499ebdd4c8943e762d83, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,729] LMCache INFO:[0m Reqid: chatcmpl-bddfe569413947dfb065edce0f140bf4, Total tokens 1756, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,751] LMCache INFO:[0m Storing KV cache for 257 out of 513 tokens (skip_leading_tokens=256) for request chatcmpl-45550a4853a84599a9ed50b7ce1327ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,752] LMCache INFO:[0m Stored 257 out of total 513 tokens. size: 0.0069 gb, cost 1.0032 ms, throughput: 6.8409 GB/s; offload_time: 0.7201 ms, put_time: 0.2831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,752] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-2a1857ff39ec499ebdd4c8943e762d83 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,754] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.6309 ms, throughput: 4.0630 GB/s; offload_time: 0.5184 ms, put_time: 0.1125 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,761] LMCache INFO:[0m Reqid: chatcmpl-bddfe569413947dfb065edce0f140bf4, Total tokens 1756, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,771] LMCache INFO:[0m Reqid: chatcmpl-bddfe569413947dfb065edce0f140bf4, Total tokens 1756, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,772] LMCache INFO:[0m Reqid: chatcmpl-c3a1d0631ce2416fb9a0c60aa4886fea, Total tokens 226, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,773] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1168, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-11 15:21:21 [loggers.py:118] Engine 000: Avg prompt throughput: 10887.2 tokens/s, Avg generation throughput: 5312.9 tokens/s, Running: 80 reqs, Waiting: 16 reqs, GPU KV cache usage: 96.4%, Prefix cache hit rate: 19.9%
INFO:     127.0.0.1:57914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,807] LMCache INFO:[0m Storing KV cache for 226 out of 226 tokens (skip_leading_tokens=0) for request chatcmpl-c3a1d0631ce2416fb9a0c60aa4886fea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,808] LMCache INFO:[0m Stored 226 out of total 226 tokens. size: 0.0060 gb, cost 0.6894 ms, throughput: 8.7541 GB/s; offload_time: 0.5733 ms, put_time: 0.1161 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,814] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1168, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,824] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1168, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,825] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,847] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e2f896ad07e545f2981b0792f67b511d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,847] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5463 ms, throughput: 6.2565 GB/s; offload_time: 0.4648 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,848] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-0b65b00e9af5435fb1581f7f4fd8d684 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,849] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6677 ms, throughput: 5.1194 GB/s; offload_time: 0.5981 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,854] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,861] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b47193fd0c9448428de182520c28236e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,862] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6889 ms, throughput: 4.9615 GB/s; offload_time: 0.5969 ms, put_time: 0.0920 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,868] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,875] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-75ab689c314b4c94ae42709b42bcd2f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,876] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5308 ms, throughput: 6.4396 GB/s; offload_time: 0.4536 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,876] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7b880a91c9c34d71b9f3124f958a621b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,877] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6638 ms, throughput: 5.1491 GB/s; offload_time: 0.5935 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:57920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,892] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1171, LMCache hit tokens: 1152, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,899] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,900] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5441 ms, throughput: 6.2823 GB/s; offload_time: 0.4678 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,900] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-18927124df7b4c8f8844c3885ec5f152 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,901] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0030 ms, throughput: 3.4077 GB/s; offload_time: 0.9149 ms, put_time: 0.0881 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,906] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1171, LMCache hit tokens: 1152, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,914] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2a31bb46181b423caeffe68382fcdff8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,914] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5379 ms, throughput: 6.3542 GB/s; offload_time: 0.4637 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,915] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-8c705a6358c44ca198220ea622a31a55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,916] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.8586 ms, throughput: 3.9808 GB/s; offload_time: 0.7922 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,916] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-bf942b9a41c04c428b34f6ede8105f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,918] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.9260 ms, throughput: 1.7747 GB/s; offload_time: 1.8589 ms, put_time: 0.0670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,924] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1171, LMCache hit tokens: 1152, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,933] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1171, LMCache hit tokens: 1152, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,940] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d199ecd8b4844f819dccca5e0ee3a3f4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,941] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5036 ms, throughput: 6.7875 GB/s; offload_time: 0.4172 ms, put_time: 0.0863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,945] LMCache INFO:[0m Reqid: chatcmpl-e65eba34ae374886bd642aea7abccbfb, Total tokens 1171, LMCache hit tokens: 1152, need to load: 352 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,946] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57952 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:21,961] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,968] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8d2aca6fc8c94df0b0ebc37669fbb4e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,968] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5099 ms, throughput: 6.7028 GB/s; offload_time: 0.4266 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,969] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ea255f0e35284dd498f721e147abf6ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,970] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7738 ms, throughput: 1.9269 GB/s; offload_time: 1.6754 ms, put_time: 0.0985 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,976] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,983] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-5a99df1a5357469b82db40be11e4d4a6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,985] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.4694 ms, throughput: 2.3261 GB/s; offload_time: 1.3910 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,989] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,996] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5ac9846d010840028038b94ea3f3b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:21,998] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3850 ms, throughput: 2.4679 GB/s; offload_time: 1.3004 ms, put_time: 0.0846 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:21,998] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,000] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.7110 ms, throughput: 1.9976 GB/s; offload_time: 1.6371 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,005] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,015] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,025] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:57966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:57990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,036] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,043] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5084650039974a68936dd3af8bb5fa1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,045] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3381 ms, throughput: 2.5543 GB/s; offload_time: 1.2588 ms, put_time: 0.0793 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,045] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2159a66075e0490d8f68e6da54767a3a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,047] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.6069 ms, throughput: 2.1270 GB/s; offload_time: 1.5237 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,051] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,061] LMCache INFO:[0m Reqid: chatcmpl-338fa4ecae4e4126912df84a26dee2b5, Total tokens 1506, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,062] LMCache INFO:[0m Reqid: chatcmpl-b54bb766a7e04cb6872346b46a250c01, Total tokens 452, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,063] LMCache INFO:[0m Reqid: chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909, Total tokens 702, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,105] LMCache INFO:[0m Storing KV cache for 452 out of 452 tokens (skip_leading_tokens=0) for request chatcmpl-b54bb766a7e04cb6872346b46a250c01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,106] LMCache INFO:[0m Stored 452 out of total 452 tokens. size: 0.0121 gb, cost 1.0562 ms, throughput: 11.4271 GB/s; offload_time: 0.8871 ms, put_time: 0.1692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,112] LMCache INFO:[0m Reqid: chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909, Total tokens 702, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,122] LMCache INFO:[0m Reqid: chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909, Total tokens 702, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,123] LMCache INFO:[0m Reqid: chatcmpl-7f26801420f143c3b5bf0f5b473bf728, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,124] LMCache INFO:[0m Reqid: chatcmpl-06d6b980dc7340f2a29777cdb20e482d, Total tokens 853, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,125] LMCache INFO:[0m Reqid: chatcmpl-0e5d1010ccda4ae0ab734478cb55757c, Total tokens 777, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,126] LMCache INFO:[0m Reqid: chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57, Total tokens 427, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,126] LMCache INFO:[0m Reqid: chatcmpl-06cc306c443c4e20be5a58038f1b572c, Total tokens 730, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,127] LMCache INFO:[0m Reqid: chatcmpl-93d102cfe51744e69e86e1ec6b7becd8, Total tokens 221, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,127] LMCache INFO:[0m Reqid: chatcmpl-b988865ccb11495da32c68e6b8f082fb, Total tokens 149, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,128] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58032 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58048 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,177] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-7f26801420f143c3b5bf0f5b473bf728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,177] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.5078 ms, throughput: 5.4166 GB/s; offload_time: 0.4151 ms, put_time: 0.0926 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,178] LMCache INFO:[0m Storing KV cache for 265 out of 777 tokens (skip_leading_tokens=512) for request chatcmpl-0e5d1010ccda4ae0ab734478cb55757c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,179] LMCache INFO:[0m Stored 265 out of total 777 tokens. size: 0.0071 gb, cost 1.3498 ms, throughput: 5.2426 GB/s; offload_time: 1.2087 ms, put_time: 0.1411 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,180] LMCache INFO:[0m Storing KV cache for 299 out of 427 tokens (skip_leading_tokens=128) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,184] LMCache INFO:[0m Stored 299 out of total 427 tokens. size: 0.0080 gb, cost 3.7227 ms, throughput: 2.1447 GB/s; offload_time: 3.5589 ms, put_time: 0.1638 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,185] LMCache INFO:[0m Storing KV cache for 149 out of 149 tokens (skip_leading_tokens=0) for request chatcmpl-b988865ccb11495da32c68e6b8f082fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,187] LMCache INFO:[0m Stored 149 out of total 149 tokens. size: 0.0040 gb, cost 1.4805 ms, throughput: 2.6874 GB/s; offload_time: 1.3001 ms, put_time: 0.1804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,193] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,202] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,212] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,221] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,230] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,255] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,256] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5237 ms, throughput: 6.5262 GB/s; offload_time: 0.4463 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,256] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,257] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9110 ms, throughput: 3.7519 GB/s; offload_time: 0.8392 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,262] LMCache INFO:[0m Reqid: chatcmpl-93d102cfe51744e69e86e1ec6b7becd8, Total tokens 228, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,272] LMCache INFO:[0m Reqid: chatcmpl-93d102cfe51744e69e86e1ec6b7becd8, Total tokens 228, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,272] LMCache INFO:[0m Reqid: chatcmpl-b988865ccb11495da32c68e6b8f082fb, Total tokens 155, LMCache hit tokens: 149, need to load: 101 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,273] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,285] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,286] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6247 ms, throughput: 5.4715 GB/s; offload_time: 0.5422 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,286] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2a1857ff39ec499ebdd4c8943e762d83 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,288] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.7704 ms, throughput: 1.9307 GB/s; offload_time: 1.6916 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,289] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c3a1d0631ce2416fb9a0c60aa4886fea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,290] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5868 ms, throughput: 2.1540 GB/s; offload_time: 1.5057 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,295] LMCache INFO:[0m Reqid: chatcmpl-c0e7aef7f1004413af9e8a5433b29b47, Total tokens 539, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,296] LMCache INFO:[0m Reqid: chatcmpl-1e3d385b12df41cda95978f55af2b04c, Total tokens 217, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,296] LMCache INFO:[0m Reqid: chatcmpl-d79a62ac46374b368ffca5d366347beb, Total tokens 205, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,297] LMCache INFO:[0m Reqid: chatcmpl-23ea871b792b4fe180bbc799b84d51db, Total tokens 1222, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,322] LMCache INFO:[0m Storing KV cache for 217 out of 217 tokens (skip_leading_tokens=0) for request chatcmpl-1e3d385b12df41cda95978f55af2b04c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,323] LMCache INFO:[0m Stored 217 out of total 217 tokens. size: 0.0058 gb, cost 0.6583 ms, throughput: 8.8028 GB/s; offload_time: 0.5502 ms, put_time: 0.1081 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,329] LMCache INFO:[0m Reqid: chatcmpl-23ea871b792b4fe180bbc799b84d51db, Total tokens 1222, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,336] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,336] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5235 ms, throughput: 6.5289 GB/s; offload_time: 0.4459 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,341] LMCache INFO:[0m Reqid: chatcmpl-23ea871b792b4fe180bbc799b84d51db, Total tokens 1222, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,359] LMCache INFO:[0m Reqid: chatcmpl-d79a62ac46374b368ffca5d366347beb, Total tokens 208, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,368] LMCache INFO:[0m Reqid: chatcmpl-d79a62ac46374b368ffca5d366347beb, Total tokens 208, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,369] LMCache INFO:[0m Reqid: chatcmpl-23ea871b792b4fe180bbc799b84d51db, Total tokens 1222, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,382] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-bddfe569413947dfb065edce0f140bf4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,382] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6173 ms, throughput: 5.5371 GB/s; offload_time: 0.5349 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,387] LMCache INFO:[0m Reqid: chatcmpl-23ea871b792b4fe180bbc799b84d51db, Total tokens 1222, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,388] LMCache INFO:[0m Reqid: chatcmpl-4713112eda7f4ed18fe820e405be30f7, Total tokens 355, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,389] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58144 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58160 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,426] LMCache INFO:[0m Storing KV cache for 198 out of 1222 tokens (skip_leading_tokens=1024) for request chatcmpl-23ea871b792b4fe180bbc799b84d51db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,427] LMCache INFO:[0m Stored 198 out of total 1222 tokens. size: 0.0053 gb, cost 0.7597 ms, throughput: 6.9596 GB/s; offload_time: 0.6464 ms, put_time: 0.1133 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,427] LMCache INFO:[0m Storing KV cache for 355 out of 355 tokens (skip_leading_tokens=0) for request chatcmpl-4713112eda7f4ed18fe820e405be30f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,429] LMCache INFO:[0m Stored 355 out of total 355 tokens. size: 0.0095 gb, cost 1.4332 ms, throughput: 6.6142 GB/s; offload_time: 1.1810 ms, put_time: 0.2522 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,431] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-8e60d4da9bb74f7da7ab77ecd16f307c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,433] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1408 ms, throughput: 2.9960 GB/s; offload_time: 0.9258 ms, put_time: 0.2150 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,439] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,449] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,458] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,468] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,475] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,476] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8812 ms, throughput: 3.8789 GB/s; offload_time: 0.7645 ms, put_time: 0.1167 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,477] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-d7d1749fef274e89ba0102ffd2b91ad9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,478] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.8698 ms, throughput: 3.9296 GB/s; offload_time: 0.7728 ms, put_time: 0.0970 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,484] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,494] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,504] LMCache INFO:[0m Reqid: chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d, Total tokens 1199, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,505] LMCache INFO:[0m Reqid: chatcmpl-f07649ac8392457ab14e792d5d2a0823, Total tokens 148, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,505] LMCache INFO:[0m Reqid: chatcmpl-778c8381176b4a87b157641e0e9a8013, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,505] LMCache INFO:[0m Reqid: chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0, Total tokens 170, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,537] LMCache INFO:[0m Storing KV cache for 148 out of 148 tokens (skip_leading_tokens=0) for request chatcmpl-f07649ac8392457ab14e792d5d2a0823 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,538] LMCache INFO:[0m Stored 148 out of total 148 tokens. size: 0.0040 gb, cost 0.6135 ms, throughput: 6.4418 GB/s; offload_time: 0.5076 ms, put_time: 0.1059 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,538] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-778c8381176b4a87b157641e0e9a8013 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,540] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 1.4209 ms, throughput: 1.9545 GB/s; offload_time: 1.3577 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,540] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2bebb1a8e0aa48e8a23367d4682e433a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,541] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.0118 ms, throughput: 3.3782 GB/s; offload_time: 0.9432 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,547] LMCache INFO:[0m Reqid: chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0, Total tokens 170, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,548] LMCache INFO:[0m Reqid: chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415, Total tokens 424, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,548] LMCache INFO:[0m Reqid: chatcmpl-45f5d5aa427b43d1a8bc2158c797998e, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,549] LMCache INFO:[0m Reqid: chatcmpl-caa45cc719244bd696b51e36782fea94, Total tokens 717, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,567] LMCache INFO:[0m Storing KV cache for 170 out of 170 tokens (skip_leading_tokens=0) for request chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,568] LMCache INFO:[0m Stored 170 out of total 170 tokens. size: 0.0045 gb, cost 0.5832 ms, throughput: 7.7837 GB/s; offload_time: 0.4846 ms, put_time: 0.0986 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,568] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-45f5d5aa427b43d1a8bc2158c797998e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,571] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 1.6051 ms, throughput: 1.8133 GB/s; offload_time: 1.4382 ms, put_time: 0.1670 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,571] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b7e7f00a870241be955655c627abe2a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,572] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.8807 ms, throughput: 3.8812 GB/s; offload_time: 0.8165 ms, put_time: 0.0642 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,584] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7f26801420f143c3b5bf0f5b473bf728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,585] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4419 ms, throughput: 7.7352 GB/s; offload_time: 0.3617 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,599] LMCache INFO:[0m Reqid: chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415, Total tokens 426, LMCache hit tokens: 384, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,606] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,607] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5483 ms, throughput: 6.2339 GB/s; offload_time: 0.4729 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,607] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-d7c27d3404d244dd920073cf660bebf7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,608] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.8554 ms, throughput: 3.9958 GB/s; offload_time: 0.7928 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,608] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2fe0fef3ef764b588c6c4fe490a75cff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,609] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.4962 ms, throughput: 6.8887 GB/s; offload_time: 0.4401 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,614] LMCache INFO:[0m Reqid: chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415, Total tokens 426, LMCache hit tokens: 384, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,621] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-acad9f47d63c46f789c60f168343db7b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,622] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4281 ms, throughput: 2.3933 GB/s; offload_time: 1.3411 ms, put_time: 0.0871 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,623] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-338fa4ecae4e4126912df84a26dee2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,624] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5776 ms, throughput: 2.1665 GB/s; offload_time: 1.5068 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,629] LMCache INFO:[0m Reqid: chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415, Total tokens 426, LMCache hit tokens: 384, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,629] LMCache INFO:[0m Reqid: chatcmpl-45f5d5aa427b43d1a8bc2158c797998e, Total tokens 110, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,630] LMCache INFO:[0m Reqid: chatcmpl-caa45cc719244bd696b51e36782fea94, Total tokens 717, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,648] LMCache INFO:[0m Reqid: chatcmpl-caa45cc719244bd696b51e36782fea94, Total tokens 717, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,648] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,672] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,681] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,690] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,699] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,706] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9a3e29b74e154d83996f2f3fd05582d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,706] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4743 ms, throughput: 7.2066 GB/s; offload_time: 0.4037 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,711] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,711] LMCache INFO:[0m Reqid: chatcmpl-fcc9ccf0f93b47e1bebcda73082fe563, Total tokens 235, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,712] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,732] LMCache INFO:[0m Storing KV cache for 154 out of 538 tokens (skip_leading_tokens=384) for request chatcmpl-81971cb106a24f2488a8240b50dffaed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,733] LMCache INFO:[0m Stored 154 out of total 538 tokens. size: 0.0041 gb, cost 0.6603 ms, throughput: 6.2277 GB/s; offload_time: 0.5531 ms, put_time: 0.1072 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,738] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,745] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,746] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4388 ms, throughput: 7.7887 GB/s; offload_time: 0.3661 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,750] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,758] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-3c7fd481a2ae4c48b528f0f79d707fb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,759] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.7115 ms, throughput: 4.8036 GB/s; offload_time: 0.6211 ms, put_time: 0.0905 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,760] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-93d102cfe51744e69e86e1ec6b7becd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,761] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4835 ms, throughput: 2.3040 GB/s; offload_time: 1.4035 ms, put_time: 0.0800 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,766] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,773] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-06cc306c443c4e20be5a58038f1b572c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,774] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3456 ms, throughput: 2.5401 GB/s; offload_time: 1.2630 ms, put_time: 0.0826 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,779] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,785] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,787] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3796 ms, throughput: 2.4775 GB/s; offload_time: 1.3050 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,787] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,789] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4222 ms, throughput: 2.4034 GB/s; offload_time: 1.3492 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,795] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,811] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e0af191e26284584bc421525c69cd0ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,812] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3902 ms, throughput: 2.4587 GB/s; offload_time: 1.3084 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,817] LMCache INFO:[0m Reqid: chatcmpl-fcc9ccf0f93b47e1bebcda73082fe563, Total tokens 241, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,826] LMCache INFO:[0m Reqid: chatcmpl-fcc9ccf0f93b47e1bebcda73082fe563, Total tokens 241, LMCache hit tokens: 128, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,833] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-06d6b980dc7340f2a29777cdb20e482d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,834] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3493 ms, throughput: 2.5331 GB/s; offload_time: 1.2743 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,848] LMCache INFO:[0m Reqid: chatcmpl-81971cb106a24f2488a8240b50dffaed, Total tokens 547, LMCache hit tokens: 538, need to load: 154 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,848] LMCache INFO:[0m Reqid: chatcmpl-fcc9ccf0f93b47e1bebcda73082fe563, Total tokens 241, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,849] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 479, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,849] LMCache INFO:[0m Reqid: chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,849] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,871] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,872] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4412 ms, throughput: 5.5680 GB/s; offload_time: 0.3583 ms, put_time: 0.0829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,872] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-2acd6788a1634147ac6cf6652447d888 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,874] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.2932 ms, throughput: 2.6431 GB/s; offload_time: 1.2199 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,874] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4713112eda7f4ed18fe820e405be30f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,875] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9053 ms, throughput: 3.7756 GB/s; offload_time: 0.8109 ms, put_time: 0.0944 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,890] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 480, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,897] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7a554a54eff944068cdead394823d2b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:22,899] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5939 ms, throughput: 2.1444 GB/s; offload_time: 1.5101 ms, put_time: 0.0838 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,899] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-778c8381176b4a87b157641e0e9a8013 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,901] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.7629 ms, throughput: 1.9389 GB/s; offload_time: 1.6816 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,901] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-45f5d5aa427b43d1a8bc2158c797998e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,903] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4974 ms, throughput: 2.2826 GB/s; offload_time: 1.4190 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,908] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 480, LMCache hit tokens: 384, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,917] LMCache INFO:[0m Reqid: chatcmpl-98787553dd974ea097e5fcf882d8948c, Total tokens 480, LMCache hit tokens: 384, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,918] LMCache INFO:[0m Reqid: chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed, Total tokens 93, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,918] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,931] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-196eecb221f24ddcb9cf87330884a7d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,932] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3716 ms, throughput: 2.4919 GB/s; offload_time: 1.2864 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,933] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1e3d385b12df41cda95978f55af2b04c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,934] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5811 ms, throughput: 2.1618 GB/s; offload_time: 1.4887 ms, put_time: 0.0924 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,939] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,949] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,955] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-83664632731343008d10b16867e22a36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,957] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3874 ms, throughput: 2.4636 GB/s; offload_time: 1.3042 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,961] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 338, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,962] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 460, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,963] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 436, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,963] LMCache INFO:[0m Reqid: chatcmpl-43087c21797a4e0684ca359c10e9e2b5, Total tokens 376, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,964] LMCache INFO:[0m Reqid: chatcmpl-e1a382aea9d4410e8ccf0cf8f5456866, Total tokens 91, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,965] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,997] LMCache INFO:[0m Storing KV cache for 180 out of 436 tokens (skip_leading_tokens=256) for request chatcmpl-d77b08749d1a4b0495eadb8de83ec00f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:22,998] LMCache INFO:[0m Stored 180 out of total 436 tokens. size: 0.0048 gb, cost 0.6715 ms, throughput: 7.1574 GB/s; offload_time: 0.5536 ms, put_time: 0.1180 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:22,999] LMCache INFO:[0m Storing KV cache for 91 out of 91 tokens (skip_leading_tokens=0) for request chatcmpl-e1a382aea9d4410e8ccf0cf8f5456866 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,000] LMCache INFO:[0m Stored 91 out of total 91 tokens. size: 0.0024 gb, cost 0.6661 ms, throughput: 3.6479 GB/s; offload_time: 0.5953 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,000] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-bb892d27b8f140d6af826f54f6ae529b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,001] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.0102 ms, throughput: 3.3833 GB/s; offload_time: 0.9452 ms, put_time: 0.0650 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,007] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,033] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,036] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 2.5465 ms, throughput: 1.3422 GB/s; offload_time: 2.4660 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,040] LMCache INFO:[0m Reqid: chatcmpl-43087c21797a4e0684ca359c10e9e2b5, Total tokens 379, LMCache hit tokens: 256, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,050] LMCache INFO:[0m Reqid: chatcmpl-43087c21797a4e0684ca359c10e9e2b5, Total tokens 379, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,066] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-13324f7edabc4e4396a2cc4a1a3045f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,068] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.7015 ms, throughput: 2.0088 GB/s; offload_time: 1.6179 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,072] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 442, LMCache hit tokens: 436, need to load: 100 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,079] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,081] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.4395 ms, throughput: 2.3744 GB/s; offload_time: 1.3610 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,085] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 442, LMCache hit tokens: 436, need to load: 196 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,086] LMCache INFO:[0m Reqid: chatcmpl-43087c21797a4e0684ca359c10e9e2b5, Total tokens 379, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,097] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fcc9ccf0f93b47e1bebcda73082fe563 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,099] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3295 ms, throughput: 2.5710 GB/s; offload_time: 1.2461 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,110] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-d0a1ac8ca00e4085872f7bd7cc777229 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,111] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3633 ms, throughput: 2.5070 GB/s; offload_time: 1.2861 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,116] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 443, LMCache hit tokens: 436, need to load: 148 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,124] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-275273a6ddeb474584e6c537996aadb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,127] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.5147 ms, throughput: 1.3592 GB/s; offload_time: 2.4274 ms, put_time: 0.0872 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,133] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 443, LMCache hit tokens: 436, need to load: 212 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,140] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d79a62ac46374b368ffca5d366347beb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,142] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3175 ms, throughput: 2.5942 GB/s; offload_time: 1.2386 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,147] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 443, LMCache hit tokens: 436, need to load: 340 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,153] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,155] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3425 ms, throughput: 2.5459 GB/s; offload_time: 1.2652 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,155] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8c1b3822f886404cba9747e1e74d878a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,157] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.7136 ms, throughput: 1.9946 GB/s; offload_time: 1.4940 ms, put_time: 0.2196 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,162] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 443, LMCache hit tokens: 436, need to load: 388 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,169] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-595b20f1c0524f6a9d7a170456913c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,170] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3497 ms, throughput: 2.5323 GB/s; offload_time: 1.2651 ms, put_time: 0.0846 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,182] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,183] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3817 ms, throughput: 2.4737 GB/s; offload_time: 1.3032 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,188] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 474, LMCache hit tokens: 384, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,198] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 474, LMCache hit tokens: 384, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,205] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-d0c89d724d1b4f46b38f44b081d88ed7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,206] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.5084 ms, throughput: 2.2660 GB/s; offload_time: 1.4234 ms, put_time: 0.0850 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,211] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 474, LMCache hit tokens: 384, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,218] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,219] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3794 ms, throughput: 2.4779 GB/s; offload_time: 1.2766 ms, put_time: 0.1028 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,224] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 474, LMCache hit tokens: 384, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,240] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b5b0ee60309b43458801c119a7cbaac5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,242] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3933 ms, throughput: 2.4532 GB/s; offload_time: 1.3140 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,246] LMCache INFO:[0m Reqid: chatcmpl-0f3ae536d3d3478f855f391272808e33, Total tokens 357, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,247] LMCache INFO:[0m Reqid: chatcmpl-603861a8d2b840c4bac653d106572f87, Total tokens 474, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,248] LMCache INFO:[0m Reqid: chatcmpl-d77b08749d1a4b0495eadb8de83ec00f, Total tokens 443, LMCache hit tokens: 436, need to load: 388 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,248] LMCache INFO:[0m Reqid: chatcmpl-43087c21797a4e0684ca359c10e9e2b5, Total tokens 379, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,249] LMCache INFO:[0m Reqid: chatcmpl-e1a382aea9d4410e8ccf0cf8f5456866, Total tokens 93, LMCache hit tokens: 91, need to load: 43 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,249] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,268] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,278] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,285] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-23ea871b792b4fe180bbc799b84d51db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,286] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.4575 ms, throughput: 2.3451 GB/s; offload_time: 1.3745 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,291] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,301] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,308] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-30ee7f7de03f42cd884efc559dad7008 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,309] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.3530 ms, throughput: 2.5262 GB/s; offload_time: 1.2749 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,314] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,321] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9e4f96d0467b4496b5f3a60dc87cfb3f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,322] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3618 ms, throughput: 2.5100 GB/s; offload_time: 1.2847 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,323] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-43087c21797a4e0684ca359c10e9e2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,325] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7056 ms, throughput: 2.0040 GB/s; offload_time: 1.6315 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,332] LMCache INFO:[0m Reqid: chatcmpl-7905163d1c254c37965a8085c943ef53, Total tokens 1124, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,333] LMCache INFO:[0m Reqid: chatcmpl-687b5507569541dcbcc0e8f167cfdeb9, Total tokens 1381, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,366] LMCache INFO:[0m Storing KV cache for 228 out of 1124 tokens (skip_leading_tokens=896) for request chatcmpl-7905163d1c254c37965a8085c943ef53 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,367] LMCache INFO:[0m Stored 228 out of total 1124 tokens. size: 0.0061 gb, cost 1.0034 ms, throughput: 6.0677 GB/s; offload_time: 0.8928 ms, put_time: 0.1106 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,375] LMCache INFO:[0m Reqid: chatcmpl-687b5507569541dcbcc0e8f167cfdeb9, Total tokens 1381, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,386] LMCache INFO:[0m Reqid: chatcmpl-687b5507569541dcbcc0e8f167cfdeb9, Total tokens 1381, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,396] LMCache INFO:[0m Reqid: chatcmpl-687b5507569541dcbcc0e8f167cfdeb9, Total tokens 1381, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,397] LMCache INFO:[0m Reqid: chatcmpl-e1a4427dcd764f5b8be37102928de3de, Total tokens 786, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,431] LMCache INFO:[0m Storing KV cache for 357 out of 1381 tokens (skip_leading_tokens=1024) for request chatcmpl-687b5507569541dcbcc0e8f167cfdeb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,432] LMCache INFO:[0m Stored 357 out of total 1381 tokens. size: 0.0095 gb, cost 1.1197 ms, throughput: 8.5140 GB/s; offload_time: 0.9008 ms, put_time: 0.2188 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,432] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-caa45cc719244bd696b51e36782fea94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,434] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.8344 ms, throughput: 1.8633 GB/s; offload_time: 1.7411 ms, put_time: 0.0933 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,435] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-98787553dd974ea097e5fcf882d8948c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,436] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7271 ms, throughput: 4.7010 GB/s; offload_time: 0.6588 ms, put_time: 0.0683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,442] LMCache INFO:[0m Reqid: chatcmpl-e1a4427dcd764f5b8be37102928de3de, Total tokens 786, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,451] LMCache INFO:[0m Reqid: chatcmpl-e1a4427dcd764f5b8be37102928de3de, Total tokens 786, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,458] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,459] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5505 ms, throughput: 6.2093 GB/s; offload_time: 0.4722 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,463] LMCache INFO:[0m Reqid: chatcmpl-e1a4427dcd764f5b8be37102928de3de, Total tokens 786, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,470] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,471] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4597 ms, throughput: 7.4354 GB/s; offload_time: 0.3832 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,476] LMCache INFO:[0m Reqid: chatcmpl-e1a4427dcd764f5b8be37102928de3de, Total tokens 786, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,477] LMCache INFO:[0m Reqid: chatcmpl-0657288c24bf4cd8a3efcc6d0e4a208f, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,478] LMCache INFO:[0m Reqid: chatcmpl-93407fc1f79149688d7a4f214f8b8a3b, Total tokens 517, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,504] LMCache INFO:[0m Storing KV cache for 146 out of 786 tokens (skip_leading_tokens=640) for request chatcmpl-e1a4427dcd764f5b8be37102928de3de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,505] LMCache INFO:[0m Stored 146 out of total 786 tokens. size: 0.0039 gb, cost 0.7257 ms, throughput: 5.3725 GB/s; offload_time: 0.6232 ms, put_time: 0.1025 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,505] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-0657288c24bf4cd8a3efcc6d0e4a208f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,506] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.8371 ms, throughput: 2.9348 GB/s; offload_time: 0.5885 ms, put_time: 0.2486 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,507] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-74b796e34bf54ed4a8c039bc67e04f7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,508] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9803 ms, throughput: 3.4865 GB/s; offload_time: 0.9206 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,508] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,509] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6676 ms, throughput: 5.1199 GB/s; offload_time: 0.6114 ms, put_time: 0.0561 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,515] LMCache INFO:[0m Reqid: chatcmpl-93407fc1f79149688d7a4f214f8b8a3b, Total tokens 517, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,515] LMCache INFO:[0m Reqid: chatcmpl-1d1a7d85ba6d4d0aacb7e84ea541a703, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,516] LMCache INFO:[0m Reqid: chatcmpl-de23ad0cb879488f9ba95b367855b8e3, Total tokens 1962, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,535] LMCache INFO:[0m Storing KV cache for 261 out of 517 tokens (skip_leading_tokens=256) for request chatcmpl-93407fc1f79149688d7a4f214f8b8a3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,537] LMCache INFO:[0m Stored 261 out of total 517 tokens. size: 0.0070 gb, cost 1.4201 ms, throughput: 4.9078 GB/s; offload_time: 0.7539 ms, put_time: 0.6662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,538] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-1d1a7d85ba6d4d0aacb7e84ea541a703 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,540] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 2.0965 ms, throughput: 1.2482 GB/s; offload_time: 2.0311 ms, put_time: 0.0655 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,546] LMCache INFO:[0m Reqid: chatcmpl-de23ad0cb879488f9ba95b367855b8e3, Total tokens 1962, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,554] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,556] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.8106 ms, throughput: 1.8878 GB/s; offload_time: 1.7365 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,556] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b5efb67e7d9a4749a145569b389ffdbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,558] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8330 ms, throughput: 1.8647 GB/s; offload_time: 1.7543 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,563] LMCache INFO:[0m Reqid: chatcmpl-de23ad0cb879488f9ba95b367855b8e3, Total tokens 1962, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,573] LMCache INFO:[0m Reqid: chatcmpl-de23ad0cb879488f9ba95b367855b8e3, Total tokens 1962, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,575] LMCache INFO:[0m Reqid: chatcmpl-470591f6fbce48e3aba192024f34042d, Total tokens 503, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,575] LMCache INFO:[0m Reqid: chatcmpl-950b93aa63504c95a4891a96046aacf6, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,637] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,637] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5970 ms, throughput: 5.7248 GB/s; offload_time: 0.5262 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,638] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,638] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6645 ms, throughput: 5.1437 GB/s; offload_time: 0.5994 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,644] LMCache INFO:[0m Reqid: chatcmpl-470591f6fbce48e3aba192024f34042d, Total tokens 504, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,654] LMCache INFO:[0m Reqid: chatcmpl-470591f6fbce48e3aba192024f34042d, Total tokens 504, LMCache hit tokens: 384, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,654] LMCache INFO:[0m Reqid: chatcmpl-950b93aa63504c95a4891a96046aacf6, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,655] LMCache INFO:[0m Reqid: chatcmpl-864ecdb3fb844626906aa69a0c7023a1, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,668] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-950b93aa63504c95a4891a96046aacf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,668] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.4323 ms, throughput: 5.8684 GB/s; offload_time: 0.3499 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,673] LMCache INFO:[0m Reqid: chatcmpl-864ecdb3fb844626906aa69a0c7023a1, Total tokens 684, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,674] LMCache INFO:[0m Reqid: chatcmpl-eb74cb60f6bd471caa2c277635dd7290, Total tokens 774, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,699] LMCache INFO:[0m Reqid: chatcmpl-eb74cb60f6bd471caa2c277635dd7290, Total tokens 774, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,700] LMCache INFO:[0m Reqid: chatcmpl-2ff2e07a0c394906a1334bac80fb857c, Total tokens 674, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,720] LMCache INFO:[0m Storing KV cache for 134 out of 774 tokens (skip_leading_tokens=640) for request chatcmpl-eb74cb60f6bd471caa2c277635dd7290 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,721] LMCache INFO:[0m Stored 134 out of total 774 tokens. size: 0.0036 gb, cost 0.7618 ms, throughput: 4.6972 GB/s; offload_time: 0.6573 ms, put_time: 0.1045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,721] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-65d842ad537a42578c13543a778e5b6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,723] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.9400 ms, throughput: 1.7619 GB/s; offload_time: 1.8510 ms, put_time: 0.0890 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,731] LMCache INFO:[0m Reqid: chatcmpl-2ff2e07a0c394906a1334bac80fb857c, Total tokens 674, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,733] LMCache INFO:[0m Reqid: chatcmpl-edff6753093845dda64e35caf5a7df04, Total tokens 1261, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,753] LMCache INFO:[0m Storing KV cache for 418 out of 674 tokens (skip_leading_tokens=256) for request chatcmpl-2ff2e07a0c394906a1334bac80fb857c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,755] LMCache INFO:[0m Stored 418 out of total 674 tokens. size: 0.0112 gb, cost 1.4965 ms, throughput: 7.4585 GB/s; offload_time: 1.2684 ms, put_time: 0.2281 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,762] LMCache INFO:[0m Reqid: chatcmpl-edff6753093845dda64e35caf5a7df04, Total tokens 1261, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,763] LMCache INFO:[0m Reqid: chatcmpl-8dab322ffbca4c8f81e4cb71e5378e5d, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,794] LMCache INFO:[0m Storing KV cache for 1261 out of 1261 tokens (skip_leading_tokens=0) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,798] LMCache INFO:[0m Stored 1261 out of total 1261 tokens. size: 0.0337 gb, cost 4.4244 ms, throughput: 7.6106 GB/s; offload_time: 3.7431 ms, put_time: 0.6814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,814] LMCache INFO:[0m Reqid: chatcmpl-8dab322ffbca4c8f81e4cb71e5378e5d, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,824] LMCache INFO:[0m Reqid: chatcmpl-8dab322ffbca4c8f81e4cb71e5378e5d, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,825] LMCache INFO:[0m Reqid: chatcmpl-9455b1fc07b04084ab848c93b20e47d2, Total tokens 1175, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:23,851] LMCache INFO:[0m Storing KV cache for 130 out of 1026 tokens (skip_leading_tokens=896) for request chatcmpl-8dab322ffbca4c8f81e4cb71e5378e5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,852] LMCache INFO:[0m Stored 130 out of total 1026 tokens. size: 0.0035 gb, cost 0.7674 ms, throughput: 4.5236 GB/s; offload_time: 0.6548 ms, put_time: 0.1125 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:23,858] LMCache INFO:[0m Reqid: chatcmpl-9455b1fc07b04084ab848c93b20e47d2, Total tokens 1175, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,859] LMCache INFO:[0m Reqid: chatcmpl-6e6524f6bed54d36be2d3eef71285ae6, Total tokens 215, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,860] LMCache INFO:[0m Reqid: chatcmpl-b0050f87a78343e880648adfc77f44d8, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,860] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 512, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,861] LMCache INFO:[0m Reqid: chatcmpl-53a664b1f29f4720aa54f89a2fc24bb8, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,862] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:23,899] LMCache INFO:[0m Storing KV cache for 279 out of 1175 tokens (skip_leading_tokens=896) for request chatcmpl-9455b1fc07b04084ab848c93b20e47d2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58548 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:24,555] LMCache INFO:[0m Stored 279 out of total 1175 tokens. size: 0.0075 gb, cost 655.4637 ms, throughput: 0.0114 GB/s; offload_time: 0.8396 ms, put_time: 654.6241 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:24,560] LMCache INFO:[0m Storing KV cache for 115 out of 115 tokens (skip_leading_tokens=0) for request chatcmpl-b0050f87a78343e880648adfc77f44d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,564] LMCache INFO:[0m Stored 115 out of total 115 tokens. size: 0.0031 gb, cost 3.3370 ms, throughput: 0.9202 GB/s; offload_time: 3.2078 ms, put_time: 0.1293 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,565] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b31f70b76d734ba69dd484c25fae7787 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,567] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.0244 ms, throughput: 3.3367 GB/s; offload_time: 0.6767 ms, put_time: 0.3477 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,567] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-53a664b1f29f4720aa54f89a2fc24bb8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,568] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 1.0423 ms, throughput: 2.6900 GB/s; offload_time: 0.8539 ms, put_time: 0.1885 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,568] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0f3ae536d3d3478f855f391272808e33 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,570] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.1221 ms, throughput: 3.0459 GB/s; offload_time: 0.9610 ms, put_time: 0.1611 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,578] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,587] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,587] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7493 ms, throughput: 4.5617 GB/s; offload_time: 0.6398 ms, put_time: 0.1094 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,615] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6d1f9afaf70e45f696e2bffb799b39b8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,623] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 7.9594 ms, throughput: 0.4294 GB/s; offload_time: 7.8468 ms, put_time: 0.1126 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,628] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 515, LMCache hit tokens: 512, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,629] LMCache INFO:[0m Reqid: chatcmpl-53a664b1f29f4720aa54f89a2fc24bb8, Total tokens 107, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,630] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,651] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-45550a4853a84599a9ed50b7ce1327ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,653] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.8699 ms, throughput: 1.8279 GB/s; offload_time: 1.7838 ms, put_time: 0.0861 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,653] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,655] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.9514 ms, throughput: 1.7515 GB/s; offload_time: 1.8680 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,660] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 516, LMCache hit tokens: 512, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,670] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 516, LMCache hit tokens: 512, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,677] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-7905163d1c254c37965a8085c943ef53 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,679] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6630 ms, throughput: 2.0554 GB/s; offload_time: 1.5913 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,683] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 516, LMCache hit tokens: 512, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,693] LMCache INFO:[0m Reqid: chatcmpl-b31f70b76d734ba69dd484c25fae7787, Total tokens 516, LMCache hit tokens: 512, need to load: 352 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,693] LMCache INFO:[0m Reqid: chatcmpl-53a664b1f29f4720aa54f89a2fc24bb8, Total tokens 108, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,694] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,705] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-687b5507569541dcbcc0e8f167cfdeb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,707] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.7233 ms, throughput: 1.9833 GB/s; offload_time: 1.6259 ms, put_time: 0.0975 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,713] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,720] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0b65b00e9af5435fb1581f7f4fd8d684 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,722] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5819 ms, throughput: 2.1607 GB/s; offload_time: 1.4979 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,729] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,738] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b988865ccb11495da32c68e6b8f082fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,743] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 4.8461 ms, throughput: 0.7053 GB/s; offload_time: 4.7561 ms, put_time: 0.0901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,743] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,745] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7442 ms, throughput: 1.9596 GB/s; offload_time: 1.6671 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,746] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-603861a8d2b840c4bac653d106572f87 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,747] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.7406 ms, throughput: 1.9637 GB/s; offload_time: 1.6634 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,755] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,762] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-75ab689c314b4c94ae42709b42bcd2f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,763] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4471 ms, throughput: 2.3619 GB/s; offload_time: 1.3717 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,764] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7b880a91c9c34d71b9f3124f958a621b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,765] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4779 ms, throughput: 2.3127 GB/s; offload_time: 1.4123 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,766] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c0e7aef7f1004413af9e8a5433b29b47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,767] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5872 ms, throughput: 2.1535 GB/s; offload_time: 1.4620 ms, put_time: 0.1252 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,774] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,782] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-b0050f87a78343e880648adfc77f44d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,783] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3819 ms, throughput: 2.4733 GB/s; offload_time: 1.3012 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,789] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,796] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,798] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6222 ms, throughput: 2.1070 GB/s; offload_time: 1.5377 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,803] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,810] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-bf942b9a41c04c428b34f6ede8105f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,812] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5287 ms, throughput: 2.2359 GB/s; offload_time: 1.4538 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,817] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,824] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,826] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4055 ms, throughput: 2.4319 GB/s; offload_time: 1.3277 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,826] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,828] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.6259 ms, throughput: 2.1022 GB/s; offload_time: 1.5500 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,833] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,840] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1d1a7d85ba6d4d0aacb7e84ea541a703 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,842] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4294 ms, throughput: 2.3912 GB/s; offload_time: 1.3356 ms, put_time: 0.0938 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,847] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,858] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,865] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8d2aca6fc8c94df0b0ebc37669fbb4e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,867] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4653 ms, throughput: 2.3326 GB/s; offload_time: 1.3884 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,872] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,882] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,889] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,891] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.6044 ms, throughput: 2.1304 GB/s; offload_time: 1.5209 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,896] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,906] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,916] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,926] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,934] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-5084650039974a68936dd3af8bb5fa1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,935] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4444 ms, throughput: 2.3663 GB/s; offload_time: 1.3554 ms, put_time: 0.0891 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,936] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2159a66075e0490d8f68e6da54767a3a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,938] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4859 ms, throughput: 2.3002 GB/s; offload_time: 1.4065 ms, put_time: 0.0794 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,943] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,950] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-950b93aa63504c95a4891a96046aacf6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,952] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4039 ms, throughput: 2.4346 GB/s; offload_time: 1.3287 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:24,956] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,967] LMCache INFO:[0m Reqid: chatcmpl-2f1561858dcf49d5bca351138debda74, Total tokens 2289, LMCache hit tokens: 2176, need to load: 2128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:24,969] LMCache INFO:[0m Reqid: chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,023] LMCache INFO:[0m Reqid: chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,030] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-53a664b1f29f4720aa54f89a2fc24bb8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,030] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4840 ms, throughput: 7.0625 GB/s; offload_time: 0.4133 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,036] LMCache INFO:[0m Reqid: chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,046] LMCache INFO:[0m Reqid: chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,047] LMCache INFO:[0m Reqid: chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4, Total tokens 1061, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,077] LMCache INFO:[0m Reqid: chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4, Total tokens 1061, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,078] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,102] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,112] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,122] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,132] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,139] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-d9bef1da41b8469584b438df15793925 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,140] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5520 ms, throughput: 6.1917 GB/s; offload_time: 0.4765 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,140] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,141] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.9868 ms, throughput: 3.4639 GB/s; offload_time: 0.9157 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,146] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,156] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,164] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,164] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.7249 ms, throughput: 4.7148 GB/s; offload_time: 0.6428 ms, put_time: 0.0822 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,165] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2a1857ff39ec499ebdd4c8943e762d83 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,166] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7427 ms, throughput: 4.6021 GB/s; offload_time: 0.6779 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,166] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c3a1d0631ce2416fb9a0c60aa4886fea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,167] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6174 ms, throughput: 5.5358 GB/s; offload_time: 0.5531 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,172] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,182] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,189] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9448e17cd6fd4880a4f71d9911d7d06b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,190] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5892 ms, throughput: 5.8012 GB/s; offload_time: 0.5079 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,201] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6e6524f6bed54d36be2d3eef71285ae6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,202] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4759 ms, throughput: 7.1814 GB/s; offload_time: 0.4034 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,207] LMCache INFO:[0m Reqid: chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,216] LMCache INFO:[0m Reqid: chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4, Total tokens 1070, LMCache hit tokens: 1024, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,217] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,229] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-2f1561858dcf49d5bca351138debda74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,230] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.7085 ms, throughput: 4.8245 GB/s; offload_time: 0.6311 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,235] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,243] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-bddfe569413947dfb065edce0f140bf4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,243] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.7374 ms, throughput: 4.6352 GB/s; offload_time: 0.6547 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,248] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,255] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8e60d4da9bb74f7da7ab77ecd16f307c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,256] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5202 ms, throughput: 6.5699 GB/s; offload_time: 0.4490 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,260] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,270] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,280] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,290] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,297] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,298] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5830 ms, throughput: 5.8624 GB/s; offload_time: 0.5029 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,302] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,312] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,321] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,331] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,338] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b7e7f00a870241be955655c627abe2a3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,339] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5604 ms, throughput: 6.0990 GB/s; offload_time: 0.4843 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,343] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,350] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7f26801420f143c3b5bf0f5b473bf728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,351] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4892 ms, throughput: 6.9866 GB/s; offload_time: 0.4150 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,355] LMCache INFO:[0m Reqid: chatcmpl-8502eb66649144b596615aebce6f97a2, Total tokens 1274, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,356] LMCache INFO:[0m Reqid: chatcmpl-5a9ef4c787ac4c34b7cd78f2596d55da, Total tokens 778, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58672 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,386] LMCache INFO:[0m Storing KV cache for 1274 out of 1274 tokens (skip_leading_tokens=0) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,395] LMCache INFO:[0m Stored 1274 out of total 1274 tokens. size: 0.0340 gb, cost 8.8778 ms, throughput: 3.8320 GB/s; offload_time: 6.5829 ms, put_time: 2.2949 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,403] LMCache INFO:[0m Reqid: chatcmpl-5a9ef4c787ac4c34b7cd78f2596d55da, Total tokens 778, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,404] LMCache INFO:[0m Reqid: chatcmpl-52a36d57340341fd8307eb34339bdd21, Total tokens 137, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,405] LMCache INFO:[0m Reqid: chatcmpl-539c0c256c2d43d0852c51b1f88e3f6f, Total tokens 852, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,432] LMCache INFO:[0m Storing KV cache for 394 out of 778 tokens (skip_leading_tokens=384) for request chatcmpl-5a9ef4c787ac4c34b7cd78f2596d55da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,434] LMCache INFO:[0m Stored 394 out of total 778 tokens. size: 0.0105 gb, cost 1.2956 ms, throughput: 8.1203 GB/s; offload_time: 0.9592 ms, put_time: 0.3365 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,434] LMCache INFO:[0m Storing KV cache for 137 out of 137 tokens (skip_leading_tokens=0) for request chatcmpl-52a36d57340341fd8307eb34339bdd21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,437] LMCache INFO:[0m Stored 137 out of total 137 tokens. size: 0.0037 gb, cost 2.4825 ms, throughput: 1.4736 GB/s; offload_time: 2.3302 ms, put_time: 0.1523 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,437] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,440] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.9925 ms, throughput: 1.1422 GB/s; offload_time: 2.8980 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,441] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2fe0fef3ef764b588c6c4fe490a75cff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,443] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.8036 ms, throughput: 1.8951 GB/s; offload_time: 1.7293 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,447] LMCache INFO:[0m Reqid: chatcmpl-539c0c256c2d43d0852c51b1f88e3f6f, Total tokens 852, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,455] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-acad9f47d63c46f789c60f168343db7b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,456] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5439 ms, throughput: 2.2138 GB/s; offload_time: 1.4495 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,457] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-338fa4ecae4e4126912df84a26dee2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,459] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6703 ms, throughput: 2.0463 GB/s; offload_time: 1.6008 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,463] LMCache INFO:[0m Reqid: chatcmpl-539c0c256c2d43d0852c51b1f88e3f6f, Total tokens 852, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,465] LMCache INFO:[0m Reqid: chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7, Total tokens 2089, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,494] LMCache INFO:[0m Reqid: chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7, Total tokens 2089, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,504] LMCache INFO:[0m Reqid: chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7, Total tokens 2089, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,514] LMCache INFO:[0m Reqid: chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7, Total tokens 2089, LMCache hit tokens: 2048, need to load: 2000 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,516] LMCache INFO:[0m Reqid: chatcmpl-c0a71294ac2d42528961c38e10e7701b, Total tokens 652, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,516] LMCache INFO:[0m Reqid: chatcmpl-f924958d0f2642debec5fedaf7059fb2, Total tokens 174, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,517] LMCache INFO:[0m Reqid: chatcmpl-89f4556cd44b46c591d87071decdd09f, Total tokens 1208, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,566] LMCache INFO:[0m Storing KV cache for 140 out of 652 tokens (skip_leading_tokens=512) for request chatcmpl-c0a71294ac2d42528961c38e10e7701b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,567] LMCache INFO:[0m Stored 140 out of total 652 tokens. size: 0.0037 gb, cost 0.6743 ms, throughput: 5.5441 GB/s; offload_time: 0.5721 ms, put_time: 0.1022 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,568] LMCache INFO:[0m Storing KV cache for 174 out of 174 tokens (skip_leading_tokens=0) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,569] LMCache INFO:[0m Stored 174 out of total 174 tokens. size: 0.0046 gb, cost 1.6760 ms, throughput: 2.7723 GB/s; offload_time: 1.4978 ms, put_time: 0.1782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,570] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,572] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5821 ms, throughput: 2.1604 GB/s; offload_time: 1.5198 ms, put_time: 0.0623 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58746 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,577] LMCache INFO:[0m Reqid: chatcmpl-89f4556cd44b46c591d87071decdd09f, Total tokens 1208, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,587] LMCache INFO:[0m Reqid: chatcmpl-89f4556cd44b46c591d87071decdd09f, Total tokens 1208, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,594] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9a3e29b74e154d83996f2f3fd05582d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,595] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4984 ms, throughput: 6.8577 GB/s; offload_time: 0.4264 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,599] LMCache INFO:[0m Reqid: chatcmpl-89f4556cd44b46c591d87071decdd09f, Total tokens 1208, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,601] LMCache INFO:[0m Reqid: chatcmpl-9f3b365d378e437cb777bea43a16c32b, Total tokens 116, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,602] LMCache INFO:[0m Reqid: chatcmpl-7f2da4ca315c4edca4505601c71bc5eb, Total tokens 606, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,602] LMCache INFO:[0m Reqid: chatcmpl-452b976c9ac94884bee923725e75f86b, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,603] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58758 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,634] LMCache INFO:[0m Storing KV cache for 184 out of 1208 tokens (skip_leading_tokens=1024) for request chatcmpl-89f4556cd44b46c591d87071decdd09f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,635] LMCache INFO:[0m Stored 184 out of total 1208 tokens. size: 0.0049 gb, cost 0.7507 ms, throughput: 6.5452 GB/s; offload_time: 0.6415 ms, put_time: 0.1092 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,635] LMCache INFO:[0m Storing KV cache for 116 out of 116 tokens (skip_leading_tokens=0) for request chatcmpl-9f3b365d378e437cb777bea43a16c32b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,638] LMCache INFO:[0m Stored 116 out of total 116 tokens. size: 0.0031 gb, cost 0.5900 ms, throughput: 5.2498 GB/s; offload_time: 0.5188 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,638] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-452b976c9ac94884bee923725e75f86b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,639] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.3712 ms, throughput: 7.3370 GB/s; offload_time: 0.3169 ms, put_time: 0.0543 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,645] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,652] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,653] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5028 ms, throughput: 6.7977 GB/s; offload_time: 0.4334 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,657] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,664] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-93d102cfe51744e69e86e1ec6b7becd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,665] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5289 ms, throughput: 6.4618 GB/s; offload_time: 0.4569 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,669] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,676] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-06cc306c443c4e20be5a58038f1b572c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,677] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5683 ms, throughput: 6.0142 GB/s; offload_time: 0.4896 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,681] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,688] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-41ad16f9c17d4044aa44ec2183b41a66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,690] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.0849 ms, throughput: 3.1506 GB/s; offload_time: 0.9871 ms, put_time: 0.0978 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,690] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,691] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6656 ms, throughput: 5.1355 GB/s; offload_time: 0.6023 ms, put_time: 0.0633 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:25,696] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,705] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,713] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e0af191e26284584bc421525c69cd0ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,713] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5426 ms, throughput: 6.2990 GB/s; offload_time: 0.4605 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,718] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,727] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,737] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,746] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,753] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4713112eda7f4ed18fe820e405be30f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,754] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5566 ms, throughput: 6.1403 GB/s; offload_time: 0.4815 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,759] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,768] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,775] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-778c8381176b4a87b157641e0e9a8013 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,776] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5382 ms, throughput: 6.3502 GB/s; offload_time: 0.4623 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,776] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-de23ad0cb879488f9ba95b367855b8e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,777] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.8876 ms, throughput: 3.8509 GB/s; offload_time: 0.8159 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,778] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9f3b365d378e437cb777bea43a16c32b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,779] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.6232 ms, throughput: 2.1057 GB/s; offload_time: 1.5510 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,793] LMCache INFO:[0m Reqid: chatcmpl-452b976c9ac94884bee923725e75f86b, Total tokens 115, LMCache hit tokens: 102, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,794] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,805] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1e3d385b12df41cda95978f55af2b04c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,806] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4994 ms, throughput: 2.2796 GB/s; offload_time: 1.4165 ms, put_time: 0.0829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,811] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,821] LMCache INFO:[0m Reqid: chatcmpl-04e0bffcbc1148b19ae5900296c34356, Total tokens 841, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,822] LMCache INFO:[0m Reqid: chatcmpl-13c132030d354d5cb3a20a3bd0d22c4e, Total tokens 531, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,823] LMCache INFO:[0m Reqid: chatcmpl-a415e95c5f68450ab46c114dfc16b0af, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,823] LMCache INFO:[0m Reqid: chatcmpl-a9c031e7414d4606a0b1ed07971b6074, Total tokens 570, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,849] LMCache INFO:[0m Storing KV cache for 147 out of 531 tokens (skip_leading_tokens=384) for request chatcmpl-13c132030d354d5cb3a20a3bd0d22c4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,850] LMCache INFO:[0m Stored 147 out of total 531 tokens. size: 0.0039 gb, cost 0.7471 ms, throughput: 5.2543 GB/s; offload_time: 0.6268 ms, put_time: 0.1203 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,850] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-a415e95c5f68450ab46c114dfc16b0af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,852] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 1.0973 ms, throughput: 2.3849 GB/s; offload_time: 0.9554 ms, put_time: 0.1419 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,852] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-83664632731343008d10b16867e22a36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,853] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.2902 ms, throughput: 2.6491 GB/s; offload_time: 1.1249 ms, put_time: 0.1653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,877] LMCache INFO:[0m Reqid: chatcmpl-13c132030d354d5cb3a20a3bd0d22c4e, Total tokens 533, LMCache hit tokens: 531, need to load: 115 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,886] LMCache INFO:[0m Reqid: chatcmpl-13c132030d354d5cb3a20a3bd0d22c4e, Total tokens 533, LMCache hit tokens: 531, need to load: 131 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,886] LMCache INFO:[0m Reqid: chatcmpl-a415e95c5f68450ab46c114dfc16b0af, Total tokens 99, LMCache hit tokens: 98, need to load: 50 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,887] LMCache INFO:[0m Reqid: chatcmpl-a9c031e7414d4606a0b1ed07971b6074, Total tokens 570, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,887] LMCache INFO:[0m Reqid: chatcmpl-66588120f7fa4db1ace30b1edf982d14, Total tokens 162, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,888] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1702, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,908] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,909] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6229 ms, throughput: 5.4874 GB/s; offload_time: 0.5468 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,913] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1702, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,923] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1702, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,933] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1702, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,942] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1702, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,943] LMCache INFO:[0m Reqid: chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,944] LMCache INFO:[0m Reqid: chatcmpl-4c6001914fe94923935cfbb588ed4056, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,983] LMCache INFO:[0m Storing KV cache for 166 out of 1702 tokens (skip_leading_tokens=1536) for request chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,984] LMCache INFO:[0m Stored 166 out of total 1702 tokens. size: 0.0044 gb, cost 0.8954 ms, throughput: 4.9505 GB/s; offload_time: 0.7782 ms, put_time: 0.1172 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,984] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,985] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 1.1919 ms, throughput: 2.2405 GB/s; offload_time: 1.0516 ms, put_time: 0.1403 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:25,986] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-c5e6cdb1728245e0ba9a15e51a3f3608 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:25,987] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.0709 ms, throughput: 3.1916 GB/s; offload_time: 0.7280 ms, put_time: 0.3429 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,008] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2ff2e07a0c394906a1334bac80fb857c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,008] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5426 ms, throughput: 6.2988 GB/s; offload_time: 0.4501 ms, put_time: 0.0925 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,009] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,010] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6987 ms, throughput: 4.8917 GB/s; offload_time: 0.6323 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,014] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1704, LMCache hit tokens: 1702, need to load: 134 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,021] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-452b976c9ac94884bee923725e75f86b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,022] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4794 ms, throughput: 7.1301 GB/s; offload_time: 0.4018 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,026] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1704, LMCache hit tokens: 1702, need to load: 230 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,027] LMCache INFO:[0m Reqid: chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6, Total tokens 101, LMCache hit tokens: 100, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,028] LMCache INFO:[0m Reqid: chatcmpl-4c6001914fe94923935cfbb588ed4056, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,028] LMCache INFO:[0m Reqid: chatcmpl-f35fd8406a3f47d8aed0057bbb2440a8, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,029] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58836 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,041] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-4c6001914fe94923935cfbb588ed4056 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,042] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 0.4462 ms, throughput: 6.7630 GB/s; offload_time: 0.3634 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,042] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-f35fd8406a3f47d8aed0057bbb2440a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,043] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.5351 ms, throughput: 4.6908 GB/s; offload_time: 0.4723 ms, put_time: 0.0628 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,043] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d79a62ac46374b368ffca5d366347beb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,044] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5715 ms, throughput: 5.9809 GB/s; offload_time: 0.5039 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,050] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,057] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,057] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5910 ms, throughput: 5.7835 GB/s; offload_time: 0.5075 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,062] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,071] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,078] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,079] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5911 ms, throughput: 5.7826 GB/s; offload_time: 0.5140 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,084] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,091] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e1a4427dcd764f5b8be37102928de3de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,092] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6118 ms, throughput: 5.5866 GB/s; offload_time: 0.5279 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,112] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,113] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5431 ms, throughput: 6.2934 GB/s; offload_time: 0.4667 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,126] LMCache INFO:[0m Reqid: chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d, Total tokens 1711, LMCache hit tokens: 1702, need to load: 22 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,127] LMCache INFO:[0m Reqid: chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6, Total tokens 107, LMCache hit tokens: 100, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,127] LMCache INFO:[0m Reqid: chatcmpl-4c6001914fe94923935cfbb588ed4056, Total tokens 119, LMCache hit tokens: 113, need to load: 65 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,128] LMCache INFO:[0m Reqid: chatcmpl-f35fd8406a3f47d8aed0057bbb2440a8, Total tokens 99, LMCache hit tokens: 94, need to load: 46 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,128] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,151] LMCache INFO:[0m Reqid: chatcmpl-4c6001914fe94923935cfbb588ed4056, Total tokens 120, LMCache hit tokens: 113, need to load: 65 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,152] LMCache INFO:[0m Reqid: chatcmpl-f35fd8406a3f47d8aed0057bbb2440a8, Total tokens 100, LMCache hit tokens: 94, need to load: 46 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,152] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,163] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-539c0c256c2d43d0852c51b1f88e3f6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,164] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6083 ms, throughput: 5.6185 GB/s; offload_time: 0.5213 ms, put_time: 0.0871 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,168] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,176] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-23ea871b792b4fe180bbc799b84d51db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,178] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6393 ms, throughput: 2.0851 GB/s; offload_time: 1.5611 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,182] LMCache INFO:[0m Reqid: chatcmpl-b532920569c3493f82c47cb2257de812, Total tokens 1234, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,183] LMCache INFO:[0m Reqid: chatcmpl-19b89b7558274ea7877e35eed6f5508f, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,184] LMCache INFO:[0m Reqid: chatcmpl-6225cc1d5d054d8aa93558ef27d04565, Total tokens 115, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,184] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,217] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-19b89b7558274ea7877e35eed6f5508f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,218] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.4159 ms, throughput: 6.2274 GB/s; offload_time: 0.3430 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,219] LMCache INFO:[0m Storing KV cache for 115 out of 115 tokens (skip_leading_tokens=0) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,221] LMCache INFO:[0m Stored 115 out of total 115 tokens. size: 0.0031 gb, cost 1.5503 ms, throughput: 1.9808 GB/s; offload_time: 1.3907 ms, put_time: 0.1596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58852 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,248] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-43087c21797a4e0684ca359c10e9e2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,248] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5352 ms, throughput: 6.3865 GB/s; offload_time: 0.4585 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,253] LMCache INFO:[0m Reqid: chatcmpl-19b89b7558274ea7877e35eed6f5508f, Total tokens 99, LMCache hit tokens: 97, need to load: 49 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,254] LMCache INFO:[0m Reqid: chatcmpl-6225cc1d5d054d8aa93558ef27d04565, Total tokens 116, LMCache hit tokens: 115, need to load: 67 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,254] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,268] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,277] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,287] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,294] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-93407fc1f79149688d7a4f214f8b8a3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,295] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5522 ms, throughput: 6.1900 GB/s; offload_time: 0.4810 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,295] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-4c6001914fe94923935cfbb588ed4056 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,296] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6051 ms, throughput: 5.6486 GB/s; offload_time: 0.5381 ms, put_time: 0.0669 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,301] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,310] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,317] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,318] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6483 ms, throughput: 5.2724 GB/s; offload_time: 0.5630 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,322] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,330] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,331] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4951 ms, throughput: 6.9038 GB/s; offload_time: 0.4230 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,331] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a415e95c5f68450ab46c114dfc16b0af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,332] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7080 ms, throughput: 4.8279 GB/s; offload_time: 0.6330 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,337] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,344] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,345] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5993 ms, throughput: 2.1372 GB/s; offload_time: 1.5187 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,351] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,360] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1179, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,362] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1044, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,393] LMCache INFO:[0m Storing KV cache for 155 out of 1179 tokens (skip_leading_tokens=1024) for request chatcmpl-4e69c0b829d74b8b918c355920ae85dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,394] LMCache INFO:[0m Stored 155 out of total 1179 tokens. size: 0.0041 gb, cost 1.1809 ms, throughput: 3.5051 GB/s; offload_time: 0.9060 ms, put_time: 0.2749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,395] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f371a6637aa84f1d9b10e11d75331f89 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,396] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.3566 ms, throughput: 2.5196 GB/s; offload_time: 1.2854 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,408] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-eb74cb60f6bd471caa2c277635dd7290 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,409] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5737 ms, throughput: 5.9573 GB/s; offload_time: 0.4939 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,414] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1180, LMCache hit tokens: 1179, need to load: 139 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,424] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1180, LMCache hit tokens: 1179, need to load: 219 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,424] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1044, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,425] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 474, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,426] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,455] LMCache INFO:[0m Storing KV cache for 148 out of 1044 tokens (skip_leading_tokens=896) for request chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,456] LMCache INFO:[0m Stored 148 out of total 1044 tokens. size: 0.0040 gb, cost 0.8337 ms, throughput: 4.7403 GB/s; offload_time: 0.7181 ms, put_time: 0.1157 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,457] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,458] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.2316 ms, throughput: 2.7752 GB/s; offload_time: 1.1640 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,459] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,460] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7392 ms, throughput: 4.6240 GB/s; offload_time: 0.6703 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,460] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,461] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.8748 ms, throughput: 3.9069 GB/s; offload_time: 0.8097 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,466] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,476] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,483] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,484] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4906 ms, throughput: 6.9676 GB/s; offload_time: 0.4161 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,488] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,498] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,506] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-65d842ad537a42578c13543a778e5b6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,507] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.7916 ms, throughput: 4.3176 GB/s; offload_time: 0.7113 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,511] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,528] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,529] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6632 ms, throughput: 5.1534 GB/s; offload_time: 0.5898 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,533] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 480, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,536] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 496, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,537] LMCache INFO:[0m Reqid: chatcmpl-3ec47526397842d8a7066a7914e1662a, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,538] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,563] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-3ec47526397842d8a7066a7914e1662a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,563] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.5615 ms, throughput: 5.0408 GB/s; offload_time: 0.4793 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,569] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,579] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,587] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0f3ae536d3d3478f855f391272808e33 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,587] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5268 ms, throughput: 6.4887 GB/s; offload_time: 0.4498 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,592] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,599] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,600] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5755 ms, throughput: 5.9396 GB/s; offload_time: 0.4994 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,605] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,612] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f35fd8406a3f47d8aed0057bbb2440a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,613] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5050 ms, throughput: 6.7678 GB/s; offload_time: 0.4251 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,626] LMCache INFO:[0m Reqid: chatcmpl-3ec47526397842d8a7066a7914e1662a, Total tokens 111, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,643] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-45550a4853a84599a9ed50b7ce1327ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,646] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 2.2296 ms, throughput: 1.5330 GB/s; offload_time: 2.1514 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,646] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,650] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 3.6464 ms, throughput: 0.9374 GB/s; offload_time: 3.5707 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,650] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b31f70b76d734ba69dd484c25fae7787 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,652] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7657 ms, throughput: 1.9358 GB/s; offload_time: 1.6769 ms, put_time: 0.0888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,657] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 503, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,666] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 503, LMCache hit tokens: 384, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,667] LMCache INFO:[0m Reqid: chatcmpl-3ec47526397842d8a7066a7914e1662a, Total tokens 111, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,668] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,681] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-04e0bffcbc1148b19ae5900296c34356 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,682] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.7000 ms, throughput: 2.0106 GB/s; offload_time: 1.6239 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,687] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,695] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-89f4556cd44b46c591d87071decdd09f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,697] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.7671 ms, throughput: 1.9342 GB/s; offload_time: 1.6864 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,697] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-19b89b7558274ea7877e35eed6f5508f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,699] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.7260 ms, throughput: 1.9803 GB/s; offload_time: 1.6381 ms, put_time: 0.0879 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,704] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,712] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-687b5507569541dcbcc0e8f167cfdeb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,713] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5874 ms, throughput: 2.1532 GB/s; offload_time: 1.5058 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,718] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,728] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,735] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b988865ccb11495da32c68e6b8f082fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,737] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4925 ms, throughput: 2.2901 GB/s; offload_time: 1.4017 ms, put_time: 0.0908 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,737] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,739] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6751 ms, throughput: 2.0404 GB/s; offload_time: 1.6016 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,739] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-603861a8d2b840c4bac653d106572f87 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,741] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6200 ms, throughput: 2.1098 GB/s; offload_time: 1.5434 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,746] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,756] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,773] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-ac6b72a2fd9f43fb960c592341e76d44 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,775] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.6373 ms, throughput: 2.0875 GB/s; offload_time: 1.5490 ms, put_time: 0.0883 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,787] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-bf942b9a41c04c428b34f6ede8105f41 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,788] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5322 ms, throughput: 2.2307 GB/s; offload_time: 1.4437 ms, put_time: 0.0885 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,789] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,791] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7607 ms, throughput: 1.9413 GB/s; offload_time: 1.6869 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,795] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,803] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4e1ebf74f7c74f8bbfc4b1f0d3ee4415 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,805] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4871 ms, throughput: 2.2985 GB/s; offload_time: 1.4136 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,805] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,808] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.5403 ms, throughput: 1.3455 GB/s; offload_time: 2.4347 ms, put_time: 0.1056 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,813] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,823] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,832] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,841] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,848] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,850] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.6528 ms, throughput: 2.0680 GB/s; offload_time: 1.5764 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,854] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,862] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-4b04dd4e303a4e57a3dc04a684d343a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,864] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.6596 ms, throughput: 2.0596 GB/s; offload_time: 1.5709 ms, put_time: 0.0887 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,875] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b532920569c3493f82c47cb2257de812 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,877] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5217 ms, throughput: 2.2461 GB/s; offload_time: 1.4454 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:58976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,881] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:58992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:26,891] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,900] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,907] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-5084650039974a68936dd3af8bb5fa1f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,909] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5158 ms, throughput: 2.2549 GB/s; offload_time: 1.4382 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,909] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2159a66075e0490d8f68e6da54767a3a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,911] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7759 ms, throughput: 1.9246 GB/s; offload_time: 1.6950 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:26,915] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,925] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,935] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,954] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,963] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 116 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,973] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 212 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,982] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 276 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:26,991] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 372 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,001] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 452 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,010] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 468 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,017] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-6b8ba6af9cae476f8ae81c40c81cd1ca [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,019] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.8111 ms, throughput: 1.8873 GB/s; offload_time: 1.7261 ms, put_time: 0.0849 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,023] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 548 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,033] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 644 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,040] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,042] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.8596 ms, throughput: 1.8381 GB/s; offload_time: 1.7751 ms, put_time: 0.0844 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,047] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 724 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,057] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 804 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,067] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 852 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,076] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 932 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,085] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,092] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-2f1561858dcf49d5bca351138debda74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,094] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.9729 ms, throughput: 1.7325 GB/s; offload_time: 1.8914 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,099] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,108] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,115] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8e60d4da9bb74f7da7ab77ecd16f307c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,117] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.8176 ms, throughput: 1.8805 GB/s; offload_time: 1.7366 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,121] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,131] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,138] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-52a36d57340341fd8307eb34339bdd21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,140] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5860 ms, throughput: 2.1551 GB/s; offload_time: 1.5085 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,153] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1237, LMCache hit tokens: 1179, need to load: 59 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,161] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c5c3a9fd92ff43d688174d0986140d36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,162] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5631 ms, throughput: 2.1866 GB/s; offload_time: 1.4823 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,163] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c0a71294ac2d42528961c38e10e7701b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,165] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.8376 ms, throughput: 1.8600 GB/s; offload_time: 1.7632 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,169] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1237, LMCache hit tokens: 1179, need to load: 155 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,176] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,178] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4175 ms, throughput: 2.4113 GB/s; offload_time: 1.3431 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,182] LMCache INFO:[0m Reqid: chatcmpl-4e69c0b829d74b8b918c355920ae85dd, Total tokens 1237, LMCache hit tokens: 1179, need to load: 219 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,183] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,197] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,207] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,214] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,216] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5914 ms, throughput: 2.1478 GB/s; offload_time: 1.5129 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,220] LMCache INFO:[0m Reqid: chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f, Total tokens 1082, LMCache hit tokens: 1044, need to load: 996 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,221] LMCache INFO:[0m Reqid: chatcmpl-7a69b955d04f4c399663f181b0f18c13, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,222] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,235] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7f26801420f143c3b5bf0f5b473bf728 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,236] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4067 ms, throughput: 2.4298 GB/s; offload_time: 1.3311 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,240] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,250] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,257] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-fa867745fa4a4b9081d724cd709a63e0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,258] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.4913 ms, throughput: 2.2920 GB/s; offload_time: 1.4068 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:59046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,263] LMCache INFO:[0m Reqid: chatcmpl-f950b7fac9b64690967962f55aa8ef72, Total tokens 511, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,263] LMCache INFO:[0m Reqid: chatcmpl-3ec47526397842d8a7066a7914e1662a, Total tokens 118, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,264] LMCache INFO:[0m Reqid: chatcmpl-9479857b4b944270860a9b1b28bd32b0, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,265] LMCache INFO:[0m Reqid: chatcmpl-58ca0ecb8546404ab725e3e2815b0e98, Total tokens 997, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,301] LMCache INFO:[0m Storing KV cache for 143 out of 1295 tokens (skip_leading_tokens=1152) for request chatcmpl-9479857b4b944270860a9b1b28bd32b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,302] LMCache INFO:[0m Stored 143 out of total 1295 tokens. size: 0.0038 gb, cost 0.8366 ms, throughput: 4.5642 GB/s; offload_time: 0.7252 ms, put_time: 0.1114 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,302] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-338fa4ecae4e4126912df84a26dee2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,304] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.8089 ms, throughput: 1.8895 GB/s; offload_time: 1.7405 ms, put_time: 0.0684 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,309] LMCache INFO:[0m Reqid: chatcmpl-58ca0ecb8546404ab725e3e2815b0e98, Total tokens 997, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,316] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f950b7fac9b64690967962f55aa8ef72 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,317] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5029 ms, throughput: 6.7963 GB/s; offload_time: 0.4297 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,321] LMCache INFO:[0m Reqid: chatcmpl-58ca0ecb8546404ab725e3e2815b0e98, Total tokens 997, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,322] LMCache INFO:[0m Reqid: chatcmpl-2d3b54f9e1b545c08fe86dc63285601a, Total tokens 966, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,348] LMCache INFO:[0m Reqid: chatcmpl-2d3b54f9e1b545c08fe86dc63285601a, Total tokens 966, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,357] LMCache INFO:[0m Reqid: chatcmpl-2d3b54f9e1b545c08fe86dc63285601a, Total tokens 966, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,365] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,366] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5947 ms, throughput: 5.7469 GB/s; offload_time: 0.5202 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,370] LMCache INFO:[0m Reqid: chatcmpl-2d3b54f9e1b545c08fe86dc63285601a, Total tokens 966, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,371] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,395] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7a69b955d04f4c399663f181b0f18c13 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,395] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5060 ms, throughput: 6.7550 GB/s; offload_time: 0.4246 ms, put_time: 0.0814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,400] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,407] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9a3e29b74e154d83996f2f3fd05582d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,408] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5422 ms, throughput: 6.3041 GB/s; offload_time: 0.4630 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,408] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-13c132030d354d5cb3a20a3bd0d22c4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,409] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7731 ms, throughput: 4.4214 GB/s; offload_time: 0.7041 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,414] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,424] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,431] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,431] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5487 ms, throughput: 6.2296 GB/s; offload_time: 0.4631 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,435] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,442] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-93d102cfe51744e69e86e1ec6b7becd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,443] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5275 ms, throughput: 6.4795 GB/s; offload_time: 0.4487 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,447] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,454] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-06cc306c443c4e20be5a58038f1b572c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,455] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5796 ms, throughput: 5.8973 GB/s; offload_time: 0.5024 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,456] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-3ec47526397842d8a7066a7914e1662a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,456] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5425 ms, throughput: 6.2999 GB/s; offload_time: 0.4613 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,461] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,468] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-616d6d0ed1424eaaab7cb857aa7283fb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,469] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5484 ms, throughput: 2.2074 GB/s; offload_time: 1.4583 ms, put_time: 0.0901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,474] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,483] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,490] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e0af191e26284584bc421525c69cd0ba [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,492] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5026 ms, throughput: 2.2747 GB/s; offload_time: 1.4223 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,496] LMCache INFO:[0m Reqid: chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df, Total tokens 956, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,497] LMCache INFO:[0m Reqid: chatcmpl-7ad254cfd03849df9779b3c9e96e3c11, Total tokens 396, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,497] LMCache INFO:[0m Reqid: chatcmpl-84f1376e08a2476cbc63c0dd2fb4e1c0, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,499] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,528] LMCache INFO:[0m Storing KV cache for 140 out of 396 tokens (skip_leading_tokens=256) for request chatcmpl-7ad254cfd03849df9779b3c9e96e3c11 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,529] LMCache INFO:[0m Stored 140 out of total 396 tokens. size: 0.0037 gb, cost 0.6851 ms, throughput: 5.4564 GB/s; offload_time: 0.5723 ms, put_time: 0.1128 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,530] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-84f1376e08a2476cbc63c0dd2fb4e1c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,531] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.8137 ms, throughput: 3.3144 GB/s; offload_time: 0.7331 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,537] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,546] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,556] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,563] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-4713112eda7f4ed18fe820e405be30f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,564] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5535 ms, throughput: 6.1753 GB/s; offload_time: 0.4649 ms, put_time: 0.0886 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,568] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,577] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1928, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,579] LMCache INFO:[0m Reqid: chatcmpl-fa26e659229a4c4b9e1e5b8582291e77, Total tokens 117, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,579] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,622] LMCache INFO:[0m Storing KV cache for 136 out of 1928 tokens (skip_leading_tokens=1792) for request chatcmpl-9f0a08aa546d49fb993582bd1d99dcab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,623] LMCache INFO:[0m Stored 136 out of total 1928 tokens. size: 0.0036 gb, cost 0.8296 ms, throughput: 4.3776 GB/s; offload_time: 0.6942 ms, put_time: 0.1354 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,624] LMCache INFO:[0m Storing KV cache for 117 out of 117 tokens (skip_leading_tokens=0) for request chatcmpl-fa26e659229a4c4b9e1e5b8582291e77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,625] LMCache INFO:[0m Stored 117 out of total 117 tokens. size: 0.0031 gb, cost 1.2971 ms, throughput: 2.4087 GB/s; offload_time: 1.0702 ms, put_time: 0.2269 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,626] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-de23ad0cb879488f9ba95b367855b8e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,627] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.1722 ms, throughput: 2.9160 GB/s; offload_time: 1.0937 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,633] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,642] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,652] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,662] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,671] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,680] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,705] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-2f374e3a8dab438b8eba8ef48526041e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,706] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5853 ms, throughput: 5.8396 GB/s; offload_time: 0.5093 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:59104 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,713] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1936, LMCache hit tokens: 1928, need to load: 72 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,723] LMCache INFO:[0m Reqid: chatcmpl-9f0a08aa546d49fb993582bd1d99dcab, Total tokens 1936, LMCache hit tokens: 1928, need to load: 168 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,724] LMCache INFO:[0m Reqid: chatcmpl-fa26e659229a4c4b9e1e5b8582291e77, Total tokens 124, LMCache hit tokens: 117, need to load: 69 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,724] LMCache INFO:[0m Reqid: chatcmpl-8caad36d43274496baddb5c5b39d557f, Total tokens 1055, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,725] LMCache INFO:[0m Reqid: chatcmpl-1c2c62f902d644b7aec7f223d79de488, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,726] LMCache INFO:[0m Reqid: chatcmpl-efef00c81c3a4429857146adc1e5c1fd, Total tokens 226, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,726] LMCache INFO:[0m Reqid: chatcmpl-b8d415b829e54263aa465ab2458b4473, Total tokens 151, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,752] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-1c2c62f902d644b7aec7f223d79de488 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,753] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.4343 ms, throughput: 6.0249 GB/s; offload_time: 0.3546 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,753] LMCache INFO:[0m Storing KV cache for 226 out of 226 tokens (skip_leading_tokens=0) for request chatcmpl-efef00c81c3a4429857146adc1e5c1fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,755] LMCache INFO:[0m Stored 226 out of total 226 tokens. size: 0.0060 gb, cost 1.1303 ms, throughput: 5.3391 GB/s; offload_time: 1.0111 ms, put_time: 0.1192 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,755] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,757] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.1145 ms, throughput: 3.0668 GB/s; offload_time: 1.0407 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,771] LMCache INFO:[0m Reqid: chatcmpl-efef00c81c3a4429857146adc1e5c1fd, Total tokens 227, LMCache hit tokens: 226, need to load: 114 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,771] LMCache INFO:[0m Reqid: chatcmpl-b8d415b829e54263aa465ab2458b4473, Total tokens 151, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,772] LMCache INFO:[0m Reqid: chatcmpl-6e994d6be9f944e9aecf7afea1fa8312, Total tokens 144, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,772] LMCache INFO:[0m Reqid: chatcmpl-00ea22f74bd2420890d7037e9c466778, Total tokens 433, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,772] LMCache INFO:[0m Reqid: chatcmpl-84f5592061484b928853be4fec6cd33d, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,773] LMCache INFO:[0m Reqid: chatcmpl-896909973aa24a3d8a1c716ea09c8bf5, Total tokens 127, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,773] LMCache INFO:[0m Reqid: chatcmpl-4f37b1fe4b834780a375f53987a68a74, Total tokens 254, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,774] LMCache INFO:[0m Reqid: chatcmpl-f5326018c9124e0b917fc82b0f2d664b, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,774] LMCache INFO:[0m Reqid: chatcmpl-8013e83cbda947eaba9210775891d2eb, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,801] LMCache INFO:[0m Storing KV cache for 151 out of 151 tokens (skip_leading_tokens=0) for request chatcmpl-b8d415b829e54263aa465ab2458b4473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,802] LMCache INFO:[0m Stored 151 out of total 151 tokens. size: 0.0040 gb, cost 0.7171 ms, throughput: 5.6225 GB/s; offload_time: 0.6001 ms, put_time: 0.1171 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,803] LMCache INFO:[0m Storing KV cache for 144 out of 144 tokens (skip_leading_tokens=0) for request chatcmpl-6e994d6be9f944e9aecf7afea1fa8312 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,804] LMCache INFO:[0m Stored 144 out of total 144 tokens. size: 0.0038 gb, cost 1.3138 ms, throughput: 2.9268 GB/s; offload_time: 1.2017 ms, put_time: 0.1121 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,804] LMCache INFO:[0m Storing KV cache for 433 out of 433 tokens (skip_leading_tokens=0) for request chatcmpl-00ea22f74bd2420890d7037e9c466778 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,808] LMCache INFO:[0m Stored 433 out of total 433 tokens. size: 0.0116 gb, cost 3.0761 ms, throughput: 3.7588 GB/s; offload_time: 2.8758 ms, put_time: 0.2002 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,808] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-84f5592061484b928853be4fec6cd33d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,810] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 1.9656 ms, throughput: 1.3993 GB/s; offload_time: 1.5899 ms, put_time: 0.3757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,811] LMCache INFO:[0m Storing KV cache for 127 out of 127 tokens (skip_leading_tokens=0) for request chatcmpl-896909973aa24a3d8a1c716ea09c8bf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,811] LMCache INFO:[0m Stored 127 out of total 127 tokens. size: 0.0034 gb, cost 0.4165 ms, throughput: 8.1415 GB/s; offload_time: 0.3413 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,812] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-f5326018c9124e0b917fc82b0f2d664b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,813] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.8557 ms, throughput: 3.2453 GB/s; offload_time: 0.7747 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,818] LMCache INFO:[0m Reqid: chatcmpl-8013e83cbda947eaba9210775891d2eb, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,825] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-896909973aa24a3d8a1c716ea09c8bf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,826] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5154 ms, throughput: 6.6321 GB/s; offload_time: 0.4363 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,838] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2ff2e07a0c394906a1334bac80fb857c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,839] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6039 ms, throughput: 5.6599 GB/s; offload_time: 0.5208 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,839] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,841] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.8985 ms, throughput: 1.8003 GB/s; offload_time: 1.8211 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,841] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-fa26e659229a4c4b9e1e5b8582291e77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,843] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.8450 ms, throughput: 1.8525 GB/s; offload_time: 1.6472 ms, put_time: 0.1978 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,843] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4f37b1fe4b834780a375f53987a68a74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,845] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5554 ms, throughput: 2.1975 GB/s; offload_time: 1.4619 ms, put_time: 0.0935 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:59110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,860] LMCache INFO:[0m Reqid: chatcmpl-4f37b1fe4b834780a375f53987a68a74, Total tokens 257, LMCache hit tokens: 128, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,860] LMCache INFO:[0m Reqid: chatcmpl-f5326018c9124e0b917fc82b0f2d664b, Total tokens 106, LMCache hit tokens: 104, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,860] LMCache INFO:[0m Reqid: chatcmpl-8013e83cbda947eaba9210775891d2eb, Total tokens 135, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,861] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,875] LMCache INFO:[0m Storing KV cache for 135 out of 135 tokens (skip_leading_tokens=0) for request chatcmpl-8013e83cbda947eaba9210775891d2eb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,877] LMCache INFO:[0m Stored 135 out of total 135 tokens. size: 0.0036 gb, cost 1.6519 ms, throughput: 2.1823 GB/s; offload_time: 1.5286 ms, put_time: 0.1233 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,878] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d79a62ac46374b368ffca5d366347beb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,880] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.1388 ms, throughput: 1.5981 GB/s; offload_time: 2.0038 ms, put_time: 0.1350 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,885] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,892] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,894] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5458 ms, throughput: 2.2111 GB/s; offload_time: 1.4635 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,899] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59170 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,906] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-4e69c0b829d74b8b918c355920ae85dd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,907] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5505 ms, throughput: 2.2044 GB/s; offload_time: 1.4636 ms, put_time: 0.0869 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,912] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,919] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,921] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5010 ms, throughput: 2.2772 GB/s; offload_time: 1.4114 ms, put_time: 0.0896 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,926] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,936] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:27,945] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,952] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-be681d2cac1e402f985b21803df6c36b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,954] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4872 ms, throughput: 2.2983 GB/s; offload_time: 1.4054 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,954] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-84f1376e08a2476cbc63c0dd2fb4e1c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,956] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5155 ms, throughput: 2.2553 GB/s; offload_time: 1.4366 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:27,961] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,970] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,980] LMCache INFO:[0m Reqid: chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b, Total tokens 654, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,980] LMCache INFO:[0m Reqid: chatcmpl-14147d931b2a4697a9dbdc5e9a74acb3, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,981] LMCache INFO:[0m Reqid: chatcmpl-ea901d9d049240ed85cee74f4b3ad3a5, Total tokens 1180, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:27,982] LMCache INFO:[0m Reqid: chatcmpl-91f43fbeb3eb4aa68352801a8758b602, Total tokens 161, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,021] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-14147d931b2a4697a9dbdc5e9a74acb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,022] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.4242 ms, throughput: 6.3576 GB/s; offload_time: 0.3437 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,026] LMCache INFO:[0m Reqid: chatcmpl-91f43fbeb3eb4aa68352801a8758b602, Total tokens 161, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,027] LMCache INFO:[0m Reqid: chatcmpl-ea4ae162a71b4f7da5d368e8d4ebc7ad, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,027] LMCache INFO:[0m Reqid: chatcmpl-04ceca33dab04488be568ae0f7d179d7, Total tokens 342, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,028] LMCache INFO:[0m Reqid: chatcmpl-9fb52d27fd154424ba7de27bd7c90bce, Total tokens 373, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,029] LMCache INFO:[0m Reqid: chatcmpl-0c855f1fbf574bddb3141cb24f405f47, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,029] LMCache INFO:[0m Reqid: chatcmpl-ee218fc1b6924e51865b6e3366a8004b, Total tokens 572, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,030] LMCache INFO:[0m Reqid: chatcmpl-30551052c79c44d48140cb52fceb8b19, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,030] LMCache INFO:[0m Reqid: chatcmpl-823e7077793c40fab97c4e3778ce8bbe, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,031] LMCache INFO:[0m Reqid: chatcmpl-d50a47d025954568be9ee366dfb9c5b5, Total tokens 1283, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:40872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,062] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-ea4ae162a71b4f7da5d368e8d4ebc7ad [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,063] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.4381 ms, throughput: 6.0952 GB/s; offload_time: 0.3580 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,063] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-0c855f1fbf574bddb3141cb24f405f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,064] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.6416 ms, throughput: 3.9953 GB/s; offload_time: 0.5735 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,064] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-30551052c79c44d48140cb52fceb8b19 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,071] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 6.7459 ms, throughput: 0.3958 GB/s; offload_time: 6.4408 ms, put_time: 0.3051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,072] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-823e7077793c40fab97c4e3778ce8bbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,073] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.8659 ms, throughput: 3.2996 GB/s; offload_time: 0.7871 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,079] LMCache INFO:[0m Reqid: chatcmpl-d50a47d025954568be9ee366dfb9c5b5, Total tokens 1283, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:40900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,087] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-23ea871b792b4fe180bbc799b84d51db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,087] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6350 ms, throughput: 5.3827 GB/s; offload_time: 0.5442 ms, put_time: 0.0908 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:40910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,093] LMCache INFO:[0m Reqid: chatcmpl-d50a47d025954568be9ee366dfb9c5b5, Total tokens 1283, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,103] LMCache INFO:[0m Reqid: chatcmpl-d50a47d025954568be9ee366dfb9c5b5, Total tokens 1283, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,113] LMCache INFO:[0m Reqid: chatcmpl-d50a47d025954568be9ee366dfb9c5b5, Total tokens 1283, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,114] LMCache INFO:[0m Reqid: chatcmpl-d119b9bfed1c4514b3569c4f13ca9125, Total tokens 471, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,115] LMCache INFO:[0m Reqid: chatcmpl-164b8090475d45bd93f969ccdbdbc6f9, Total tokens 774, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,115] LMCache INFO:[0m Reqid: chatcmpl-02b27809042c4c5c8631c1bdad42fb41, Total tokens 301, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,116] LMCache INFO:[0m Reqid: chatcmpl-0bc65998c3564e0a83d81c7d6b08bd7b, Total tokens 428, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,117] LMCache INFO:[0m Reqid: chatcmpl-5253f95a298f4a208a849a18da53a171, Total tokens 879, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,117] LMCache INFO:[0m Reqid: chatcmpl-106d4f3a5a954f0ca94853d7e81d123f, Total tokens 171, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,118] LMCache INFO:[0m Reqid: chatcmpl-253d5a51a4d541fdb121c4672fcad749, Total tokens 170, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,118] LMCache INFO:[0m Reqid: chatcmpl-74663a0d46dc49d298abcda97fbd8a57, Total tokens 109, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,119] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,178] LMCache INFO:[0m Storing KV cache for 131 out of 1283 tokens (skip_leading_tokens=1152) for request chatcmpl-d50a47d025954568be9ee366dfb9c5b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,179] LMCache INFO:[0m Stored 131 out of total 1283 tokens. size: 0.0035 gb, cost 0.7919 ms, throughput: 4.4174 GB/s; offload_time: 0.6852 ms, put_time: 0.1067 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,179] LMCache INFO:[0m Storing KV cache for 390 out of 774 tokens (skip_leading_tokens=384) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:40938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,182] LMCache INFO:[0m Stored 390 out of total 774 tokens. size: 0.0104 gb, cost 2.8804 ms, throughput: 3.6155 GB/s; offload_time: 2.3843 ms, put_time: 0.4961 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:40948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,184] LMCache INFO:[0m Storing KV cache for 109 out of 109 tokens (skip_leading_tokens=0) for request chatcmpl-74663a0d46dc49d298abcda97fbd8a57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:40966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,185] LMCache INFO:[0m Stored 109 out of total 109 tokens. size: 0.0029 gb, cost 1.1039 ms, throughput: 2.6367 GB/s; offload_time: 1.0106 ms, put_time: 0.0933 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,192] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,201] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,211] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,221] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,227] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-93407fc1f79149688d7a4f214f8b8a3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,228] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5368 ms, throughput: 6.3679 GB/s; offload_time: 0.4641 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,228] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4c6001914fe94923935cfbb588ed4056 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,229] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6067 ms, throughput: 5.6333 GB/s; offload_time: 0.5443 ms, put_time: 0.0624 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,234] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,244] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,251] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,251] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6501 ms, throughput: 5.2575 GB/s; offload_time: 0.5733 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,256] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,264] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ea746406ca984b64b7af4d7e3c14c8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,264] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5305 ms, throughput: 6.4435 GB/s; offload_time: 0.4531 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,265] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a415e95c5f68450ab46c114dfc16b0af [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,266] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6555 ms, throughput: 5.2145 GB/s; offload_time: 0.5341 ms, put_time: 0.1214 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,266] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-84f5592061484b928853be4fec6cd33d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,267] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5005 ms, throughput: 2.2779 GB/s; offload_time: 1.4317 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,268] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9fb52d27fd154424ba7de27bd7c90bce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,270] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.8763 ms, throughput: 1.8216 GB/s; offload_time: 1.7774 ms, put_time: 0.0990 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,275] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,282] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,283] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5220 ms, throughput: 2.2458 GB/s; offload_time: 1.4259 ms, put_time: 0.0961 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,284] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f5326018c9124e0b917fc82b0f2d664b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,285] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5786 ms, throughput: 2.1652 GB/s; offload_time: 1.4993 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,300] LMCache INFO:[0m Reqid: chatcmpl-74663a0d46dc49d298abcda97fbd8a57, Total tokens 118, LMCache hit tokens: 109, need to load: 61 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,301] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,312] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1c2c62f902d644b7aec7f223d79de488 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,313] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4014 ms, throughput: 2.4390 GB/s; offload_time: 1.3258 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,318] LMCache INFO:[0m Reqid: chatcmpl-05ba7704b8f74d68888f0a4e48b8223c, Total tokens 1260, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,319] LMCache INFO:[0m Reqid: chatcmpl-5a44c97241424509bb197cc0f2dab23c, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,320] LMCache INFO:[0m Reqid: chatcmpl-fb92b9c070694dca8b8f29765e250468, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,320] LMCache INFO:[0m Reqid: chatcmpl-31b18b932d0d40a3b5d2f7380018a6b6, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,321] LMCache INFO:[0m Reqid: chatcmpl-1fd71c4362124830ba2a80798d0b63d9, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,321] LMCache INFO:[0m Reqid: chatcmpl-f189c0337cb347299bcb7dfd65792067, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,360] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-5a44c97241424509bb197cc0f2dab23c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,360] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.4338 ms, throughput: 6.7713 GB/s; offload_time: 0.3599 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,361] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-fb92b9c070694dca8b8f29765e250468 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,361] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.4928 ms, throughput: 5.6890 GB/s; offload_time: 0.4227 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,362] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-1fd71c4362124830ba2a80798d0b63d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,362] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.4728 ms, throughput: 5.4783 GB/s; offload_time: 0.4136 ms, put_time: 0.0592 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,362] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-eb74cb60f6bd471caa2c277635dd7290 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,363] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6200 ms, throughput: 5.5131 GB/s; offload_time: 0.5382 ms, put_time: 0.0817 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,364] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-efef00c81c3a4429857146adc1e5c1fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,365] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9039 ms, throughput: 3.7813 GB/s; offload_time: 0.8284 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,370] LMCache INFO:[0m Reqid: chatcmpl-f189c0337cb347299bcb7dfd65792067, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,380] LMCache INFO:[0m Reqid: chatcmpl-f189c0337cb347299bcb7dfd65792067, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,387] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,388] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6591 ms, throughput: 5.1858 GB/s; offload_time: 0.5785 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,389] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ce9ca4a21fed4f6fbb9895ea16e00edc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,390] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7557 ms, throughput: 4.5227 GB/s; offload_time: 0.6850 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,390] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,391] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.8246 ms, throughput: 4.1449 GB/s; offload_time: 0.7439 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,396] LMCache INFO:[0m Reqid: chatcmpl-f189c0337cb347299bcb7dfd65792067, Total tokens 960, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,397] LMCache INFO:[0m Reqid: chatcmpl-a4ffee15c3ff458cbdd7ec6078a004a7, Total tokens 964, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,420] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2d3b54f9e1b545c08fe86dc63285601a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,421] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5390 ms, throughput: 6.3416 GB/s; offload_time: 0.4668 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,425] LMCache INFO:[0m Reqid: chatcmpl-a4ffee15c3ff458cbdd7ec6078a004a7, Total tokens 964, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,426] LMCache INFO:[0m Reqid: chatcmpl-8f7155d1d5fd4dc1ba0cced2a6d0fb08, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,451] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,452] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4933 ms, throughput: 6.9286 GB/s; offload_time: 0.3998 ms, put_time: 0.0935 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,466] LMCache INFO:[0m Reqid: chatcmpl-a4ffee15c3ff458cbdd7ec6078a004a7, Total tokens 965, LMCache hit tokens: 896, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,467] LMCache INFO:[0m Reqid: chatcmpl-8f7155d1d5fd4dc1ba0cced2a6d0fb08, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,480] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-65d842ad537a42578c13543a778e5b6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,481] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.6742 ms, throughput: 5.0698 GB/s; offload_time: 0.5998 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,481] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-823e7077793c40fab97c4e3778ce8bbe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,482] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5649 ms, throughput: 6.0501 GB/s; offload_time: 0.4928 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,482] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5253f95a298f4a208a849a18da53a171 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,483] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6230 ms, throughput: 5.4861 GB/s; offload_time: 0.5612 ms, put_time: 0.0618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,495] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,496] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6016 ms, throughput: 5.6819 GB/s; offload_time: 0.5284 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,501] LMCache INFO:[0m Reqid: chatcmpl-a4ffee15c3ff458cbdd7ec6078a004a7, Total tokens 966, LMCache hit tokens: 896, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,502] LMCache INFO:[0m Reqid: chatcmpl-8f7155d1d5fd4dc1ba0cced2a6d0fb08, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,515] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,516] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6170 ms, throughput: 5.5397 GB/s; offload_time: 0.5448 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,520] LMCache INFO:[0m Reqid: chatcmpl-8f7155d1d5fd4dc1ba0cced2a6d0fb08, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,528] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-74663a0d46dc49d298abcda97fbd8a57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,529] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4886 ms, throughput: 6.9949 GB/s; offload_time: 0.4122 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,533] LMCache INFO:[0m Reqid: chatcmpl-8f7155d1d5fd4dc1ba0cced2a6d0fb08, Total tokens 1221, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,535] LMCache INFO:[0m Reqid: chatcmpl-eb7bb3cac4554b1a8ee624ec34db1c96, Total tokens 589, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,535] LMCache INFO:[0m Reqid: chatcmpl-7e1a13998bcf436c8232c990b49166a2, Total tokens 888, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,576] LMCache INFO:[0m Reqid: chatcmpl-7e1a13998bcf436c8232c990b49166a2, Total tokens 888, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,577] LMCache INFO:[0m Reqid: chatcmpl-a9923554461e4f3baa3a159c8abe32c0, Total tokens 95, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,578] LMCache INFO:[0m Reqid: chatcmpl-50c1240b51e046a9be24f8c4aecd428b, Total tokens 648, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,598] LMCache INFO:[0m Storing KV cache for 95 out of 95 tokens (skip_leading_tokens=0) for request chatcmpl-a9923554461e4f3baa3a159c8abe32c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,598] LMCache INFO:[0m Stored 95 out of total 95 tokens. size: 0.0025 gb, cost 0.4429 ms, throughput: 5.7282 GB/s; offload_time: 0.3627 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,599] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-14147d931b2a4697a9dbdc5e9a74acb3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,599] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5895 ms, throughput: 5.7981 GB/s; offload_time: 0.5112 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:40970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:40982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,604] LMCache INFO:[0m Reqid: chatcmpl-50c1240b51e046a9be24f8c4aecd428b, Total tokens 648, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,611] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,612] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5223 ms, throughput: 6.5440 GB/s; offload_time: 0.4495 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,617] LMCache INFO:[0m Reqid: chatcmpl-50c1240b51e046a9be24f8c4aecd428b, Total tokens 648, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,618] LMCache INFO:[0m Reqid: chatcmpl-af1887a474334f9cb5e5e2b0e948c91c, Total tokens 869, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,619] LMCache INFO:[0m Reqid: chatcmpl-f2e44645dda2411bbdf7ec2887f7f770, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,620] LMCache INFO:[0m Reqid: chatcmpl-3c5f2d8ef7af485f936ae61fca2629e7, Total tokens 1213, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,650] LMCache INFO:[0m Storing KV cache for 392 out of 648 tokens (skip_leading_tokens=256) for request chatcmpl-50c1240b51e046a9be24f8c4aecd428b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,651] LMCache INFO:[0m Stored 392 out of total 648 tokens. size: 0.0105 gb, cost 1.2258 ms, throughput: 8.5392 GB/s; offload_time: 0.9825 ms, put_time: 0.2433 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,652] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-f2e44645dda2411bbdf7ec2887f7f770 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,654] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 2.3465 ms, throughput: 1.1380 GB/s; offload_time: 2.2004 ms, put_time: 0.1461 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,655] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-30551052c79c44d48140cb52fceb8b19 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,656] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0858 ms, throughput: 3.1479 GB/s; offload_time: 1.0073 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:40984 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,672] LMCache INFO:[0m Reqid: chatcmpl-af1887a474334f9cb5e5e2b0e948c91c, Total tokens 870, LMCache hit tokens: 768, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,683] LMCache INFO:[0m Reqid: chatcmpl-af1887a474334f9cb5e5e2b0e948c91c, Total tokens 870, LMCache hit tokens: 768, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,683] LMCache INFO:[0m Reqid: chatcmpl-f2e44645dda2411bbdf7ec2887f7f770, Total tokens 101, LMCache hit tokens: 100, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,684] LMCache INFO:[0m Reqid: chatcmpl-3c5f2d8ef7af485f936ae61fca2629e7, Total tokens 1213, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,685] LMCache INFO:[0m Reqid: chatcmpl-faa292f90a7942a69211a21afc1d198c, Total tokens 305, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,686] LMCache INFO:[0m Reqid: chatcmpl-efee9b72ee1e4a0d89380fcc5cd2102c, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,686] LMCache INFO:[0m Reqid: chatcmpl-0e459e9ea8c846b1905b9fbe9ad3988d, Total tokens 637, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,720] LMCache INFO:[0m Storing KV cache for 445 out of 1213 tokens (skip_leading_tokens=768) for request chatcmpl-3c5f2d8ef7af485f936ae61fca2629e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,722] LMCache INFO:[0m Stored 445 out of total 1213 tokens. size: 0.0119 gb, cost 1.1794 ms, throughput: 10.0756 GB/s; offload_time: 1.0067 ms, put_time: 0.1727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,722] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-efee9b72ee1e4a0d89380fcc5cd2102c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,723] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 1.2326 ms, throughput: 2.1663 GB/s; offload_time: 1.0279 ms, put_time: 0.2047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,724] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-45550a4853a84599a9ed50b7ce1327ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,725] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9739 ms, throughput: 3.5097 GB/s; offload_time: 0.8955 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,725] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-916317cd7fbe4412a99d6ed7cd14fc5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,727] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5442 ms, throughput: 2.2135 GB/s; offload_time: 1.2449 ms, put_time: 0.2993 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,733] LMCache INFO:[0m Reqid: chatcmpl-0e459e9ea8c846b1905b9fbe9ad3988d, Total tokens 637, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,740] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-0c855f1fbf574bddb3141cb24f405f47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,742] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3306 ms, throughput: 2.5688 GB/s; offload_time: 1.2605 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,747] LMCache INFO:[0m Reqid: chatcmpl-0e459e9ea8c846b1905b9fbe9ad3988d, Total tokens 637, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,747] LMCache INFO:[0m Reqid: chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,748] LMCache INFO:[0m Reqid: chatcmpl-e2ac9830f3664ec08d9a8f3b89db8331, Total tokens 1169, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41048 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41078 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,772] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,773] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.4343 ms, throughput: 6.7628 GB/s; offload_time: 0.3628 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,773] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5a44c97241424509bb197cc0f2dab23c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,774] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6166 ms, throughput: 5.5430 GB/s; offload_time: 0.5536 ms, put_time: 0.0630 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,785] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7e1a13998bcf436c8232c990b49166a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,786] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5991 ms, throughput: 5.7050 GB/s; offload_time: 0.5154 ms, put_time: 0.0838 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,791] LMCache INFO:[0m Reqid: chatcmpl-0e459e9ea8c846b1905b9fbe9ad3988d, Total tokens 638, LMCache hit tokens: 512, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,791] LMCache INFO:[0m Reqid: chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3, Total tokens 111, LMCache hit tokens: 110, need to load: 62 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,792] LMCache INFO:[0m Reqid: chatcmpl-e2ac9830f3664ec08d9a8f3b89db8331, Total tokens 1169, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,794] LMCache INFO:[0m Reqid: chatcmpl-e29cc192a2174615adf5d9b86ac2acc0, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,825] LMCache INFO:[0m Storing KV cache for 145 out of 1169 tokens (skip_leading_tokens=1024) for request chatcmpl-e2ac9830f3664ec08d9a8f3b89db8331 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,826] LMCache INFO:[0m Stored 145 out of total 1169 tokens. size: 0.0039 gb, cost 0.8428 ms, throughput: 4.5943 GB/s; offload_time: 0.6705 ms, put_time: 0.1723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,827] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-05ba7704b8f74d68888f0a4e48b8223c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,828] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.7384 ms, throughput: 4.6288 GB/s; offload_time: 0.6708 ms, put_time: 0.0676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,833] LMCache INFO:[0m Reqid: chatcmpl-e29cc192a2174615adf5d9b86ac2acc0, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,843] LMCache INFO:[0m Reqid: chatcmpl-e29cc192a2174615adf5d9b86ac2acc0, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:28,851] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,851] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5400 ms, throughput: 6.3296 GB/s; offload_time: 0.4686 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,852] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-603861a8d2b840c4bac653d106572f87 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,852] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.7367 ms, throughput: 4.6394 GB/s; offload_time: 0.6675 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,853] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,854] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7358 ms, throughput: 4.6454 GB/s; offload_time: 0.6767 ms, put_time: 0.0591 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,854] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0e459e9ea8c846b1905b9fbe9ad3988d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,855] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8590 ms, throughput: 3.9790 GB/s; offload_time: 0.6504 ms, put_time: 0.2086 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,860] LMCache INFO:[0m Reqid: chatcmpl-e29cc192a2174615adf5d9b86ac2acc0, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,868] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-fb92b9c070694dca8b8f29765e250468 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,868] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4813 ms, throughput: 7.1010 GB/s; offload_time: 0.4108 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,873] LMCache INFO:[0m Reqid: chatcmpl-e29cc192a2174615adf5d9b86ac2acc0, Total tokens 1026, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,874] LMCache INFO:[0m Reqid: chatcmpl-c3bea5c7e1ac40d3bb577f644e1bbb39, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,875] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2011, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,904] LMCache INFO:[0m Storing KV cache for 130 out of 1026 tokens (skip_leading_tokens=896) for request chatcmpl-e29cc192a2174615adf5d9b86ac2acc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,905] LMCache INFO:[0m Stored 130 out of total 1026 tokens. size: 0.0035 gb, cost 0.7214 ms, throughput: 4.8121 GB/s; offload_time: 0.6149 ms, put_time: 0.1065 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,905] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-c3bea5c7e1ac40d3bb577f644e1bbb39 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,906] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.8186 ms, throughput: 3.1968 GB/s; offload_time: 0.7200 ms, put_time: 0.0985 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,913] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2011, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,923] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2011, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,930] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,931] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5409 ms, throughput: 6.3195 GB/s; offload_time: 0.4619 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,935] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2011, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,944] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,944] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6397 ms, throughput: 5.3431 GB/s; offload_time: 0.5617 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,945] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,946] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7117 ms, throughput: 4.8029 GB/s; offload_time: 0.6454 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:28,951] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2011, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,952] LMCache INFO:[0m Reqid: chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31, Total tokens 204, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,953] LMCache INFO:[0m Reqid: chatcmpl-9fbcd6af7e894dd78a84302e0c68fd9d, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,953] LMCache INFO:[0m Reqid: chatcmpl-2ecef6815c0a4e308ed976fa37d38821, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:28,954] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 565, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,001] LMCache INFO:[0m Storing KV cache for 219 out of 2011 tokens (skip_leading_tokens=1792) for request chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,002] LMCache INFO:[0m Stored 219 out of total 2011 tokens. size: 0.0058 gb, cost 0.8722 ms, throughput: 6.7045 GB/s; offload_time: 0.7598 ms, put_time: 0.1124 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,002] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-9fbcd6af7e894dd78a84302e0c68fd9d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,003] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.6997 ms, throughput: 3.7019 GB/s; offload_time: 0.5503 ms, put_time: 0.1494 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,004] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,005] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.5864 ms, throughput: 4.5537 GB/s; offload_time: 0.5202 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41124 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,027] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d119b9bfed1c4514b3569c4f13ca9125 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,028] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5395 ms, throughput: 6.3356 GB/s; offload_time: 0.4494 ms, put_time: 0.0901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,032] LMCache INFO:[0m Reqid: chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31, Total tokens 206, LMCache hit tokens: 128, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41160 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,040] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,041] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.6873 ms, throughput: 4.9731 GB/s; offload_time: 0.6105 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,041] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1fd71c4362124830ba2a80798d0b63d9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,042] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7709 ms, throughput: 4.4335 GB/s; offload_time: 0.6862 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,047] LMCache INFO:[0m Reqid: chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31, Total tokens 206, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,057] LMCache INFO:[0m Reqid: chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31, Total tokens 206, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,076] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2017, LMCache hit tokens: 2011, need to load: 203 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,087] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2017, LMCache hit tokens: 2011, need to load: 283 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,097] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2017, LMCache hit tokens: 2011, need to load: 347 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,103] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,104] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4655 ms, throughput: 7.3430 GB/s; offload_time: 0.3924 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,109] LMCache INFO:[0m Reqid: chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640, Total tokens 2017, LMCache hit tokens: 2011, need to load: 427 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,110] LMCache INFO:[0m Reqid: chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31, Total tokens 206, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,111] LMCache INFO:[0m Reqid: chatcmpl-9fbcd6af7e894dd78a84302e0c68fd9d, Total tokens 99, LMCache hit tokens: 97, need to load: 49 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,112] LMCache INFO:[0m Reqid: chatcmpl-2ecef6815c0a4e308ed976fa37d38821, Total tokens 101, LMCache hit tokens: 100, need to load: 52 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,112] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 565, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,128] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 565, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,138] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 565, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,139] LMCache INFO:[0m Reqid: chatcmpl-570e5555df804b19affddab98c507d01, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,140] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,157] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-570e5555df804b19affddab98c507d01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,157] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.4426 ms, throughput: 6.1537 GB/s; offload_time: 0.3696 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,162] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,172] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,182] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,189] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f2e44645dda2411bbdf7ec2887f7f770 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,189] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4629 ms, throughput: 7.3842 GB/s; offload_time: 0.3827 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,194] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,201] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a9923554461e4f3baa3a159c8abe32c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,201] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4664 ms, throughput: 7.3279 GB/s; offload_time: 0.3926 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,202] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-efee9b72ee1e4a0d89380fcc5cd2102c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,203] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.7199 ms, throughput: 4.7479 GB/s; offload_time: 0.6520 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,217] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 570, LMCache hit tokens: 512, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,218] LMCache INFO:[0m Reqid: chatcmpl-570e5555df804b19affddab98c507d01, Total tokens 107, LMCache hit tokens: 102, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,235] LMCache INFO:[0m Reqid: chatcmpl-570e5555df804b19affddab98c507d01, Total tokens 107, LMCache hit tokens: 102, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,236] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,266] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,267] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 0.6419 ms, throughput: 5.3248 GB/s; offload_time: 0.5723 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,271] LMCache INFO:[0m Reqid: chatcmpl-c091239aebb546d6897436df819945d5, Total tokens 573, LMCache hit tokens: 512, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,272] LMCache INFO:[0m Reqid: chatcmpl-570e5555df804b19affddab98c507d01, Total tokens 108, LMCache hit tokens: 102, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,273] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 400, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,274] LMCache INFO:[0m Reqid: chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,274] LMCache INFO:[0m Reqid: chatcmpl-9deece25ed724cb797e70f5bd049c73b, Total tokens 170, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,293] LMCache INFO:[0m Storing KV cache for 144 out of 400 tokens (skip_leading_tokens=256) for request chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,294] LMCache INFO:[0m Stored 144 out of total 400 tokens. size: 0.0038 gb, cost 0.6922 ms, throughput: 5.5548 GB/s; offload_time: 0.5823 ms, put_time: 0.1099 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,294] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,295] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.9499 ms, throughput: 3.0080 GB/s; offload_time: 0.8276 ms, put_time: 0.1223 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,296] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-00ea22f74bd2420890d7037e9c466778 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,297] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.2699 ms, throughput: 2.6916 GB/s; offload_time: 1.2005 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,312] LMCache INFO:[0m Reqid: chatcmpl-fcc59d21554643eeb2a2ea4e6b0db06e, Total tokens 401, LMCache hit tokens: 400, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,312] LMCache INFO:[0m Reqid: chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7, Total tokens 108, LMCache hit tokens: 107, need to load: 59 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,313] LMCache INFO:[0m Reqid: chatcmpl-9deece25ed724cb797e70f5bd049c73b, Total tokens 170, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,313] LMCache INFO:[0m Reqid: chatcmpl-86d1af3a78a74af8b2d275f86a5858e8, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,314] LMCache INFO:[0m Reqid: chatcmpl-e3588585e719473f86ee229f8979c361, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,328] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-86d1af3a78a74af8b2d275f86a5858e8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,329] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4614 ms, throughput: 5.3244 GB/s; offload_time: 0.3889 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,340] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-9479857b4b944270860a9b1b28bd32b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,341] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6162 ms, throughput: 5.5467 GB/s; offload_time: 0.5437 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,346] LMCache INFO:[0m Reqid: chatcmpl-86d1af3a78a74af8b2d275f86a5858e8, Total tokens 93, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,353] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-2f1561858dcf49d5bca351138debda74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,355] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 1.7111 ms, throughput: 1.9975 GB/s; offload_time: 1.6326 ms, put_time: 0.0786 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,355] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c3bea5c7e1ac40d3bb577f644e1bbb39 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,357] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5937 ms, throughput: 2.1447 GB/s; offload_time: 1.4801 ms, put_time: 0.1136 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,371] LMCache INFO:[0m Reqid: chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7, Total tokens 111, LMCache hit tokens: 107, need to load: 27 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,371] LMCache INFO:[0m Reqid: chatcmpl-9deece25ed724cb797e70f5bd049c73b, Total tokens 173, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,385] LMCache INFO:[0m Reqid: chatcmpl-9deece25ed724cb797e70f5bd049c73b, Total tokens 173, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,385] LMCache INFO:[0m Reqid: chatcmpl-86d1af3a78a74af8b2d275f86a5858e8, Total tokens 93, LMCache hit tokens: 92, need to load: 44 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,386] LMCache INFO:[0m Reqid: chatcmpl-e3588585e719473f86ee229f8979c361, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,386] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 962, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,399] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-e3588585e719473f86ee229f8979c361 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,400] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.4926 ms, throughput: 5.7457 GB/s; offload_time: 0.4060 ms, put_time: 0.0867 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,405] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 962, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,412] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-52a36d57340341fd8307eb34339bdd21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,413] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3629 ms, throughput: 2.5079 GB/s; offload_time: 1.2819 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,418] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 962, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,428] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 962, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,435] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c0a71294ac2d42528961c38e10e7701b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,436] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4195 ms, throughput: 2.4079 GB/s; offload_time: 1.3415 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,441] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 962, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,442] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,469] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,470] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4505 ms, throughput: 7.5869 GB/s; offload_time: 0.3793 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,470] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-eb7bb3cac4554b1a8ee624ec34db1c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,471] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7377 ms, throughput: 4.6335 GB/s; offload_time: 0.6731 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,476] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,486] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,502] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-29a1fc422ba54c4589ccd09aa1c7fd6d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,503] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.5713 ms, throughput: 5.9826 GB/s; offload_time: 0.5029 ms, put_time: 0.0684 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,507] LMCache INFO:[0m Reqid: chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a, Total tokens 965, LMCache hit tokens: 896, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,508] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,521] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,521] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4526 ms, throughput: 7.5526 GB/s; offload_time: 0.3814 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,526] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,533] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-8caad36d43274496baddb5c5b39d557f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,534] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5606 ms, throughput: 6.0974 GB/s; offload_time: 0.4877 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,534] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-a4ffee15c3ff458cbdd7ec6078a004a7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,535] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6991 ms, throughput: 4.8893 GB/s; offload_time: 0.6315 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,540] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,548] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f189c0337cb347299bcb7dfd65792067 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,548] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5758 ms, throughput: 5.9358 GB/s; offload_time: 0.5012 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,553] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,561] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-338fa4ecae4e4126912df84a26dee2b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,563] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.5804 ms, throughput: 2.1627 GB/s; offload_time: 1.5005 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,568] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,570] LMCache INFO:[0m Reqid: chatcmpl-fec69aa647664f54969e2853a68c982c, Total tokens 1040, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,602] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-6e58bf4dd0c74ce7ac95c16cf7ccd640 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,603] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.6342 ms, throughput: 5.3893 GB/s; offload_time: 0.5670 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,608] LMCache INFO:[0m Reqid: chatcmpl-fec69aa647664f54969e2853a68c982c, Total tokens 1040, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,616] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7ad254cfd03849df9779b3c9e96e3c11 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,616] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5112 ms, throughput: 6.6866 GB/s; offload_time: 0.4284 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,617] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-570e5555df804b19affddab98c507d01 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,617] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5316 ms, throughput: 6.4291 GB/s; offload_time: 0.4154 ms, put_time: 0.1163 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,632] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1222, LMCache hit tokens: 1152, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,639] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,639] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6211 ms, throughput: 5.5030 GB/s; offload_time: 0.5376 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,644] LMCache INFO:[0m Reqid: chatcmpl-820219768dfc40799ba3e47b4f7e70b0, Total tokens 1222, LMCache hit tokens: 1152, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,645] LMCache INFO:[0m Reqid: chatcmpl-fec69aa647664f54969e2853a68c982c, Total tokens 1040, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,661] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-7a69b955d04f4c399663f181b0f18c13 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,661] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5021 ms, throughput: 6.8080 GB/s; offload_time: 0.4278 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,662] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,663] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6304 ms, throughput: 5.4218 GB/s; offload_time: 0.5618 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,667] LMCache INFO:[0m Reqid: chatcmpl-fec69aa647664f54969e2853a68c982c, Total tokens 1040, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,675] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-106d4f3a5a954f0ca94853d7e81d123f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,675] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4616 ms, throughput: 7.4038 GB/s; offload_time: 0.3895 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,680] LMCache INFO:[0m Reqid: chatcmpl-fec69aa647664f54969e2853a68c982c, Total tokens 1040, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,681] LMCache INFO:[0m Reqid: chatcmpl-390ece15a8764696bf185dd70b27b2c5, Total tokens 256, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,682] LMCache INFO:[0m Reqid: chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,682] LMCache INFO:[0m Reqid: chatcmpl-ee16b33874494b628ff239902b31717c, Total tokens 529, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,683] LMCache INFO:[0m Reqid: chatcmpl-6360badc7787439895c9924a3d04a4c8, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,718] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,719] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4349 ms, throughput: 7.8600 GB/s; offload_time: 0.3640 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,719] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,720] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.7559 ms, throughput: 3.6386 GB/s; offload_time: 0.6867 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,726] LMCache INFO:[0m Reqid: chatcmpl-6360badc7787439895c9924a3d04a4c8, Total tokens 679, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,727] LMCache INFO:[0m Reqid: chatcmpl-76d32d046c94494f9e87bc085520d673, Total tokens 762, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,728] LMCache INFO:[0m Reqid: chatcmpl-5389000701cb49818998e9be0f6582b3, Total tokens 179, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,728] LMCache INFO:[0m Reqid: chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3, Total tokens 957, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,729] LMCache INFO:[0m Reqid: chatcmpl-082806fea8554eaebce6967ee67e4a24, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,730] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,770] LMCache INFO:[0m Storing KV cache for 378 out of 762 tokens (skip_leading_tokens=384) for request chatcmpl-76d32d046c94494f9e87bc085520d673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,771] LMCache INFO:[0m Stored 378 out of total 762 tokens. size: 0.0101 gb, cost 1.1023 ms, throughput: 9.1567 GB/s; offload_time: 0.7915 ms, put_time: 0.3109 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41182 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,772] LMCache INFO:[0m Storing KV cache for 179 out of 179 tokens (skip_leading_tokens=0) for request chatcmpl-5389000701cb49818998e9be0f6582b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,777] LMCache INFO:[0m Stored 179 out of total 179 tokens. size: 0.0048 gb, cost 4.6633 ms, throughput: 1.0250 GB/s; offload_time: 4.5590 ms, put_time: 0.1044 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,777] LMCache INFO:[0m Storing KV cache for 189 out of 957 tokens (skip_leading_tokens=768) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,779] LMCache INFO:[0m Stored 189 out of total 957 tokens. size: 0.0050 gb, cost 1.8496 ms, throughput: 2.7286 GB/s; offload_time: 1.5514 ms, put_time: 0.2983 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,780] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-082806fea8554eaebce6967ee67e4a24 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,781] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 1.2896 ms, throughput: 2.1949 GB/s; offload_time: 1.2118 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,782] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,783] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.3485 ms, throughput: 2.5346 GB/s; offload_time: 1.2455 ms, put_time: 0.1030 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,783] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b8d415b829e54263aa465ab2458b4473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,785] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7317 ms, throughput: 1.9738 GB/s; offload_time: 1.6280 ms, put_time: 0.1036 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,791] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,798] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-93d102cfe51744e69e86e1ec6b7becd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,799] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4282 ms, throughput: 2.3932 GB/s; offload_time: 1.3528 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,804] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41200 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,811] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-06cc306c443c4e20be5a58038f1b572c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,813] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6491 ms, throughput: 2.0726 GB/s; offload_time: 1.5701 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,813] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3ec47526397842d8a7066a7914e1662a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,815] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5327 ms, throughput: 2.2301 GB/s; offload_time: 1.4621 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,821] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,831] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,837] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-91f43fbeb3eb4aa68352801a8758b602 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,839] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3651 ms, throughput: 2.5039 GB/s; offload_time: 1.2908 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,844] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,851] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-9f0a08aa546d49fb993582bd1d99dcab [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,853] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.5681 ms, throughput: 2.1796 GB/s; offload_time: 1.4869 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41214 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,859] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,866] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-76d32d046c94494f9e87bc085520d673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,867] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4549 ms, throughput: 2.3493 GB/s; offload_time: 1.3728 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,872] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,880] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6e994d6be9f944e9aecf7afea1fa8312 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,881] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3551 ms, throughput: 2.5223 GB/s; offload_time: 1.2784 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,881] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-3c5f2d8ef7af485f936ae61fca2629e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,883] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.7287 ms, throughput: 1.9772 GB/s; offload_time: 1.6551 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,889] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1275, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,890] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 939, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,935] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,945] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,955] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,962] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,963] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5008 ms, throughput: 6.8243 GB/s; offload_time: 0.4111 ms, put_time: 0.0897 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:29,967] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:29,977] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,987] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 368 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:29,997] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,010] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 608 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,020] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 704 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,030] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 752 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,037] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-faa292f90a7942a69211a21afc1d198c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,039] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2240 ms, throughput: 2.7924 GB/s; offload_time: 1.0993 ms, put_time: 0.1247 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,044] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 832 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,054] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 896 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,061] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,062] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.9046 ms, throughput: 3.7784 GB/s; offload_time: 0.8041 ms, put_time: 0.1005 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,069] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 960 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,076] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,077] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5065 ms, throughput: 6.7488 GB/s; offload_time: 0.4356 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,077] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-082806fea8554eaebce6967ee67e4a24 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,078] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5960 ms, throughput: 5.7353 GB/s; offload_time: 0.5060 ms, put_time: 0.0900 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,084] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,094] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,101] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-896909973aa24a3d8a1c716ea09c8bf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,101] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4759 ms, throughput: 7.1824 GB/s; offload_time: 0.3971 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,102] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,102] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6622 ms, throughput: 5.1617 GB/s; offload_time: 0.6002 ms, put_time: 0.0620 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,108] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,115] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-2ff2e07a0c394906a1334bac80fb857c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,116] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5110 ms, throughput: 6.6884 GB/s; offload_time: 0.4396 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,116] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,117] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7584 ms, throughput: 4.5065 GB/s; offload_time: 0.6903 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,122] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,129] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4f37b1fe4b834780a375f53987a68a74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,131] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5291 ms, throughput: 2.2353 GB/s; offload_time: 1.4560 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,135] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,146] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,153] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-205abb7f668c49c8b5ad49ad89716b7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,155] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.3915 ms, throughput: 2.4563 GB/s; offload_time: 1.3177 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,159] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,170] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,178] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,180] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4987 ms, throughput: 2.2806 GB/s; offload_time: 1.4246 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,184] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,210] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-84f1376e08a2476cbc63c0dd2fb4e1c0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,212] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3579 ms, throughput: 2.5170 GB/s; offload_time: 1.2842 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,217] LMCache INFO:[0m Reqid: chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3, Total tokens 990, LMCache hit tokens: 957, need to load: 141 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,227] LMCache INFO:[0m Reqid: chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3, Total tokens 990, LMCache hit tokens: 957, need to load: 189 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,234] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,236] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4619 ms, throughput: 2.3381 GB/s; offload_time: 1.3879 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,240] LMCache INFO:[0m Reqid: chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3, Total tokens 990, LMCache hit tokens: 957, need to load: 253 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,241] LMCache INFO:[0m Reqid: chatcmpl-082806fea8554eaebce6967ee67e4a24, Total tokens 138, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,242] LMCache INFO:[0m Reqid: chatcmpl-3697f4d493154eb494e15eb85504cb70, Total tokens 1276, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,243] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 939, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,260] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 939, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,261] LMCache INFO:[0m Reqid: chatcmpl-119d4f9cdd2c4213a89e31502c71ea66, Total tokens 128, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,262] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,287] LMCache INFO:[0m Storing KV cache for 299 out of 939 tokens (skip_leading_tokens=640) for request chatcmpl-b73b60eb8250453d922a74a9084fc644 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,289] LMCache INFO:[0m Stored 299 out of total 939 tokens. size: 0.0080 gb, cost 1.0290 ms, throughput: 7.7595 GB/s; offload_time: 0.7916 ms, put_time: 0.2374 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,289] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-119d4f9cdd2c4213a89e31502c71ea66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,292] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4687 ms, throughput: 2.3272 GB/s; offload_time: 1.3708 ms, put_time: 0.0979 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,298] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41330 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,305] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-d50a47d025954568be9ee366dfb9c5b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41368 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,306] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7931 ms, throughput: 4.3097 GB/s; offload_time: 0.7093 ms, put_time: 0.0837 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,312] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,322] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,329] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-3697f4d493154eb494e15eb85504cb70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,331] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.7036 ms, throughput: 2.0063 GB/s; offload_time: 1.6188 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,343] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c091239aebb546d6897436df819945d5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,345] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6111 ms, throughput: 2.1216 GB/s; offload_time: 1.5233 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,359] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 944, LMCache hit tokens: 939, need to load: 235 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,369] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 944, LMCache hit tokens: 939, need to load: 251 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,379] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 944, LMCache hit tokens: 939, need to load: 315 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,389] LMCache INFO:[0m Reqid: chatcmpl-b73b60eb8250453d922a74a9084fc644, Total tokens 944, LMCache hit tokens: 939, need to load: 363 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,390] LMCache INFO:[0m Reqid: chatcmpl-119d4f9cdd2c4213a89e31502c71ea66, Total tokens 132, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,391] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,404] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,411] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,413] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5077 ms, throughput: 2.2670 GB/s; offload_time: 1.4264 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,417] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,425] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-9fb52d27fd154424ba7de27bd7c90bce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,427] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4663 ms, throughput: 2.3310 GB/s; offload_time: 1.3723 ms, put_time: 0.0940 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,427] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-f0596fcfdb4d4cb68879f12f224eca7a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,429] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7248 ms, throughput: 1.9817 GB/s; offload_time: 1.6430 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,441] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,442] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5672 ms, throughput: 2.1809 GB/s; offload_time: 1.4795 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,447] LMCache INFO:[0m Reqid: chatcmpl-119d4f9cdd2c4213a89e31502c71ea66, Total tokens 135, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,448] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 738, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,448] LMCache INFO:[0m Reqid: chatcmpl-41045c7c9c5c49b783177abfccc99933, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,449] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 636, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,450] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,481] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-41045c7c9c5c49b783177abfccc99933 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,482] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.4761 ms, throughput: 5.5520 GB/s; offload_time: 0.3882 ms, put_time: 0.0880 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,482] LMCache INFO:[0m Storing KV cache for 252 out of 636 tokens (skip_leading_tokens=384) for request chatcmpl-3dcb42665e6542e8be2d101e8518f89b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,484] LMCache INFO:[0m Stored 252 out of total 636 tokens. size: 0.0067 gb, cost 1.2146 ms, throughput: 5.5401 GB/s; offload_time: 0.9749 ms, put_time: 0.2397 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,490] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,499] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,507] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-eb74cb60f6bd471caa2c277635dd7290 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,507] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5710 ms, throughput: 5.9855 GB/s; offload_time: 0.4680 ms, put_time: 0.1031 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,508] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-efef00c81c3a4429857146adc1e5c1fd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,509] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.8028 ms, throughput: 4.2574 GB/s; offload_time: 0.7301 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,524] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 108 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,531] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-f9ad70b924fb4694808333631e63b8c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,532] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.6541 ms, throughput: 5.2251 GB/s; offload_time: 0.5681 ms, put_time: 0.0861 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,532] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,534] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.8375 ms, throughput: 1.8601 GB/s; offload_time: 1.7594 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,539] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 236 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,547] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2d3b54f9e1b545c08fe86dc63285601a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,548] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4730 ms, throughput: 2.3204 GB/s; offload_time: 1.3838 ms, put_time: 0.0892 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,549] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-820219768dfc40799ba3e47b4f7e70b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,551] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.8243 ms, throughput: 1.8735 GB/s; offload_time: 1.7510 ms, put_time: 0.0734 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,556] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 300 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,563] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a1d66f1bc44c4e8d887c72622e9751c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,564] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4478 ms, throughput: 2.3608 GB/s; offload_time: 1.3581 ms, put_time: 0.0897 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,569] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 364 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,576] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-50c1240b51e046a9be24f8c4aecd428b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,578] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4210 ms, throughput: 2.4053 GB/s; offload_time: 1.3412 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,582] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 476 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,590] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-65d842ad537a42578c13543a778e5b6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,592] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.8235 ms, throughput: 1.8744 GB/s; offload_time: 1.7410 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,593] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-5253f95a298f4a208a849a18da53a171 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,594] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7588 ms, throughput: 1.9433 GB/s; offload_time: 1.6836 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,607] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,608] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.4820 ms, throughput: 2.3063 GB/s; offload_time: 1.3950 ms, put_time: 0.0870 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,613] LMCache INFO:[0m Reqid: chatcmpl-41045c7c9c5c49b783177abfccc99933, Total tokens 108, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,620] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-00a8b5dd081d40598378a2ff4d17a1e4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,622] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5490 ms, throughput: 2.2066 GB/s; offload_time: 1.4616 ms, put_time: 0.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,636] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 749, LMCache hit tokens: 640, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,646] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 749, LMCache hit tokens: 640, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,656] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 749, LMCache hit tokens: 640, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,663] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,664] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5071 ms, throughput: 2.2679 GB/s; offload_time: 1.4243 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,669] LMCache INFO:[0m Reqid: chatcmpl-24436898aa744bea89b23757b3d2a6db, Total tokens 749, LMCache hit tokens: 640, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,670] LMCache INFO:[0m Reqid: chatcmpl-41045c7c9c5c49b783177abfccc99933, Total tokens 108, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,671] LMCache INFO:[0m Reqid: chatcmpl-3dcb42665e6542e8be2d101e8518f89b, Total tokens 639, LMCache hit tokens: 636, need to load: 588 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,672] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,685] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-30551052c79c44d48140cb52fceb8b19 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,686] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4152 ms, throughput: 2.4151 GB/s; offload_time: 1.3368 ms, put_time: 0.0784 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,691] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,698] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-3dcb42665e6542e8be2d101e8518f89b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,700] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4590 ms, throughput: 2.3427 GB/s; offload_time: 1.3816 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,705] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,715] LMCache INFO:[0m Reqid: chatcmpl-1c16694c3de34290bf3e8e3ac7e69537, Total tokens 1120, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,716] LMCache INFO:[0m Reqid: chatcmpl-dbfcac06a56048cbb284fcca33cd1f8d, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,717] LMCache INFO:[0m Reqid: chatcmpl-43ef1673ff6747278581096fd91a84af, Total tokens 152, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,717] LMCache INFO:[0m Reqid: chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c, Total tokens 875, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,718] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,760] LMCache INFO:[0m Storing KV cache for 224 out of 1120 tokens (skip_leading_tokens=896) for request chatcmpl-1c16694c3de34290bf3e8e3ac7e69537 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,761] LMCache INFO:[0m Stored 224 out of total 1120 tokens. size: 0.0060 gb, cost 1.1650 ms, throughput: 5.1341 GB/s; offload_time: 1.0347 ms, put_time: 0.1304 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,762] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-dbfcac06a56048cbb284fcca33cd1f8d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,763] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 0.9289 ms, throughput: 3.1621 GB/s; offload_time: 0.8312 ms, put_time: 0.0978 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,764] LMCache INFO:[0m Storing KV cache for 363 out of 875 tokens (skip_leading_tokens=512) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,765] LMCache INFO:[0m Stored 363 out of total 875 tokens. size: 0.0097 gb, cost 1.5524 ms, throughput: 6.2439 GB/s; offload_time: 1.4200 ms, put_time: 0.1324 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,765] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-45550a4853a84599a9ed50b7ce1327ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,769] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 3.6897 ms, throughput: 0.9264 GB/s; offload_time: 3.3699 ms, put_time: 0.3198 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,776] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,786] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,793] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,794] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5667 ms, throughput: 6.0312 GB/s; offload_time: 0.4764 ms, put_time: 0.0903 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,799] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,809] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,819] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,829] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,836] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-fdbd6bc468064ffbb0246b33c3a607d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,837] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5414 ms, throughput: 6.3131 GB/s; offload_time: 0.4629 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,838] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,839] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6608 ms, throughput: 2.0581 GB/s; offload_time: 1.5845 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,840] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-e29cc192a2174615adf5d9b86ac2acc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,842] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.2102 ms, throughput: 1.5464 GB/s; offload_time: 2.1222 ms, put_time: 0.0880 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,847] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,857] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,868] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,875] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5389000701cb49818998e9be0f6582b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,877] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4030 ms, throughput: 2.4363 GB/s; offload_time: 1.3194 ms, put_time: 0.0836 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,882] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,889] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,890] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5777 ms, throughput: 2.1665 GB/s; offload_time: 1.4932 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,895] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,903] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,905] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6848 ms, throughput: 2.0288 GB/s; offload_time: 1.5949 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,905] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,907] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8590 ms, throughput: 1.8387 GB/s; offload_time: 1.7748 ms, put_time: 0.0842 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,913] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:30,924] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,934] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,941] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-d119b9bfed1c4514b3569c4f13ca9125 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,943] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6304 ms, throughput: 2.0964 GB/s; offload_time: 1.5476 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,948] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,955] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-d9ed09c657b94810a486dd3a2f2d56f7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,957] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 1.7928 ms, throughput: 1.9065 GB/s; offload_time: 1.7065 ms, put_time: 0.0863 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,963] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,970] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-24436898aa744bea89b23757b3d2a6db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,972] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.6264 ms, throughput: 2.1016 GB/s; offload_time: 1.5438 ms, put_time: 0.0826 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,977] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,985] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-41045c7c9c5c49b783177abfccc99933 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,986] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3917 ms, throughput: 2.4560 GB/s; offload_time: 1.3155 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:30,991] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:30,998] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-dbfcac06a56048cbb284fcca33cd1f8d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,002] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 3.3518 ms, throughput: 1.0197 GB/s; offload_time: 3.2566 ms, put_time: 0.0952 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,006] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,017] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,027] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,034] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,035] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3922 ms, throughput: 2.4551 GB/s; offload_time: 1.3112 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,036] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6360badc7787439895c9924a3d04a4c8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,038] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.7356 ms, throughput: 1.9693 GB/s; offload_time: 1.6576 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,038] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,040] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5828 ms, throughput: 2.1594 GB/s; offload_time: 1.5125 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,045] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,055] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,065] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,074] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,084] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,094] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,101] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-f2e44645dda2411bbdf7ec2887f7f770 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,102] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4212 ms, throughput: 2.4049 GB/s; offload_time: 1.3444 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,116] LMCache INFO:[0m Reqid: chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c, Total tokens 903, LMCache hit tokens: 875, need to load: 75 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,126] LMCache INFO:[0m Reqid: chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c, Total tokens 903, LMCache hit tokens: 875, need to load: 155 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,127] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,143] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,153] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,160] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1c16694c3de34290bf3e8e3ac7e69537 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,163] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.3277 ms, throughput: 1.4684 GB/s; offload_time: 2.2362 ms, put_time: 0.0914 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41454 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,168] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1391, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,169] LMCache INFO:[0m Reqid: chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b, Total tokens 229, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,203] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-03ba5e3808374bc0be4698715bb3e1a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,204] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.6789 ms, throughput: 5.0342 GB/s; offload_time: 0.5957 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,208] LMCache INFO:[0m Reqid: chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b, Total tokens 229, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,209] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,224] LMCache INFO:[0m Storing KV cache for 229 out of 229 tokens (skip_leading_tokens=0) for request chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,225] LMCache INFO:[0m Stored 229 out of total 229 tokens. size: 0.0061 gb, cost 0.7458 ms, throughput: 8.1992 GB/s; offload_time: 0.6189 ms, put_time: 0.1269 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,225] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-00ea22f74bd2420890d7037e9c466778 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,227] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8303 ms, throughput: 4.1163 GB/s; offload_time: 0.7584 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,241] LMCache INFO:[0m Reqid: chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b, Total tokens 230, LMCache hit tokens: 229, need to load: 117 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,250] LMCache INFO:[0m Reqid: chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b, Total tokens 230, LMCache hit tokens: 229, need to load: 181 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,257] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-9479857b4b944270860a9b1b28bd32b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,258] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6348 ms, throughput: 5.3841 GB/s; offload_time: 0.5557 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,269] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-2f1561858dcf49d5bca351138debda74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,270] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 0.7309 ms, throughput: 4.6766 GB/s; offload_time: 0.6411 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,275] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,285] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,295] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,305] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,312] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ee16b33874494b628ff239902b31717c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,312] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5767 ms, throughput: 5.9273 GB/s; offload_time: 0.4892 ms, put_time: 0.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,317] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,324] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-fec69aa647664f54969e2853a68c982c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,325] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6588 ms, throughput: 5.1879 GB/s; offload_time: 0.5711 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,329] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,336] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c0a71294ac2d42528961c38e10e7701b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,337] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6343 ms, throughput: 5.3883 GB/s; offload_time: 0.5398 ms, put_time: 0.0945 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,342] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 512 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,349] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,350] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5558 ms, throughput: 6.1495 GB/s; offload_time: 0.4671 ms, put_time: 0.0887 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,350] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-eb7bb3cac4554b1a8ee624ec34db1c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,351] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6242 ms, throughput: 5.4756 GB/s; offload_time: 0.5603 ms, put_time: 0.0639 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,356] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 576 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,366] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 608 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41476 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,375] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 656 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,385] LMCache INFO:[0m Reqid: chatcmpl-63b0da48f45842d59d0448055ec06bc8, Total tokens 1396, LMCache hit tokens: 1280, need to load: 752 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,386] LMCache INFO:[0m Reqid: chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b, Total tokens 230, LMCache hit tokens: 229, need to load: 181 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,386] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,399] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,401] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4789 ms, throughput: 2.3111 GB/s; offload_time: 1.3930 ms, put_time: 0.0859 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,406] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,413] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8caad36d43274496baddb5c5b39d557f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,415] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5050 ms, throughput: 2.2710 GB/s; offload_time: 1.4288 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,419] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,428] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,438] LMCache INFO:[0m Reqid: chatcmpl-a24637207eca4bbda09a9167d4b00996, Total tokens 1327, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,439] LMCache INFO:[0m Reqid: chatcmpl-4edb5320c3e5418591f0109491fed1f2, Total tokens 131, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,439] LMCache INFO:[0m Reqid: chatcmpl-bd9674d6af704965b1c5317f4dc9e8b5, Total tokens 189, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,440] LMCache INFO:[0m Reqid: chatcmpl-c06d3fc50966439b9c9589d71ecede66, Total tokens 767, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,440] LMCache INFO:[0m Reqid: chatcmpl-d9f947fe12ce4b1ca05d0dfac4815531, Total tokens 192, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,441] LMCache INFO:[0m Reqid: chatcmpl-f81cc785de9d40209f215da29646a1da, Total tokens 125, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,441] LMCache INFO:[0m Reqid: chatcmpl-2d9480ba93634862832ba1bc11ca3f66, Total tokens 1295, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,442] LMCache INFO:[0m Reqid: chatcmpl-8ee53076d2964cd1a6905e0132c86867, Total tokens 769, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,503] LMCache INFO:[0m Storing KV cache for 131 out of 131 tokens (skip_leading_tokens=0) for request chatcmpl-4edb5320c3e5418591f0109491fed1f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,504] LMCache INFO:[0m Stored 131 out of total 131 tokens. size: 0.0035 gb, cost 0.6532 ms, throughput: 5.3551 GB/s; offload_time: 0.5343 ms, put_time: 0.1189 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,504] LMCache INFO:[0m Storing KV cache for 189 out of 189 tokens (skip_leading_tokens=0) for request chatcmpl-bd9674d6af704965b1c5317f4dc9e8b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,509] LMCache INFO:[0m Stored 189 out of total 189 tokens. size: 0.0050 gb, cost 3.9437 ms, throughput: 1.2797 GB/s; offload_time: 3.8255 ms, put_time: 0.1182 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,509] LMCache INFO:[0m Storing KV cache for 125 out of 125 tokens (skip_leading_tokens=0) for request chatcmpl-f81cc785de9d40209f215da29646a1da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,510] LMCache INFO:[0m Stored 125 out of total 125 tokens. size: 0.0033 gb, cost 0.7628 ms, throughput: 4.3759 GB/s; offload_time: 0.7030 ms, put_time: 0.0598 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,510] LMCache INFO:[0m Storing KV cache for 143 out of 1295 tokens (skip_leading_tokens=1152) for request chatcmpl-2d9480ba93634862832ba1bc11ca3f66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,511] LMCache INFO:[0m Stored 143 out of total 1295 tokens. size: 0.0038 gb, cost 1.1876 ms, throughput: 3.2153 GB/s; offload_time: 1.0725 ms, put_time: 0.1151 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,518] LMCache INFO:[0m Reqid: chatcmpl-8ee53076d2964cd1a6905e0132c86867, Total tokens 769, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,525] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c06d3fc50966439b9c9589d71ecede66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,526] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5102 ms, throughput: 6.6997 GB/s; offload_time: 0.4354 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,530] LMCache INFO:[0m Reqid: chatcmpl-8ee53076d2964cd1a6905e0132c86867, Total tokens 769, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,540] LMCache INFO:[0m Reqid: chatcmpl-8ee53076d2964cd1a6905e0132c86867, Total tokens 769, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,547] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,548] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6570 ms, throughput: 5.2025 GB/s; offload_time: 0.5693 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,548] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f81cc785de9d40209f215da29646a1da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,549] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6308 ms, throughput: 5.4186 GB/s; offload_time: 0.5568 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,554] LMCache INFO:[0m Reqid: chatcmpl-8ee53076d2964cd1a6905e0132c86867, Total tokens 769, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,555] LMCache INFO:[0m Reqid: chatcmpl-876a5d9fe13b4516965719d83b53c20f, Total tokens 374, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,555] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 574, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,556] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,588] LMCache INFO:[0m Storing KV cache for 385 out of 769 tokens (skip_leading_tokens=384) for request chatcmpl-8ee53076d2964cd1a6905e0132c86867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,589] LMCache INFO:[0m Stored 385 out of total 769 tokens. size: 0.0103 gb, cost 1.3810 ms, throughput: 7.4442 GB/s; offload_time: 0.9857 ms, put_time: 0.3953 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,590] LMCache INFO:[0m Storing KV cache for 190 out of 574 tokens (skip_leading_tokens=384) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,594] LMCache INFO:[0m Stored 190 out of total 574 tokens. size: 0.0051 gb, cost 2.9045 ms, throughput: 1.7468 GB/s; offload_time: 2.7945 ms, put_time: 0.1100 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,594] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-7a69b955d04f4c399663f181b0f18c13 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,597] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 2.9558 ms, throughput: 1.1564 GB/s; offload_time: 2.7789 ms, put_time: 0.1769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,598] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,600] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.9893 ms, throughput: 1.7182 GB/s; offload_time: 1.8992 ms, put_time: 0.0901 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,605] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,612] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-106d4f3a5a954f0ca94853d7e81d123f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,613] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5313 ms, throughput: 2.2320 GB/s; offload_time: 1.4507 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,614] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-b73b60eb8250453d922a74a9084fc644 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,616] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.6462 ms, throughput: 2.0762 GB/s; offload_time: 1.5658 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,621] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,627] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,629] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4226 ms, throughput: 2.4027 GB/s; offload_time: 1.3381 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,633] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,640] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,642] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4333 ms, throughput: 2.3847 GB/s; offload_time: 1.3540 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,642] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b8d415b829e54263aa465ab2458b4473 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,644] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5018 ms, throughput: 2.2759 GB/s; offload_time: 1.4242 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,656] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-93d102cfe51744e69e86e1ec6b7becd8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,657] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4924 ms, throughput: 2.2902 GB/s; offload_time: 1.3923 ms, put_time: 0.1001 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,658] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,659] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6652 ms, throughput: 2.0526 GB/s; offload_time: 1.5869 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,664] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 578, LMCache hit tokens: 574, need to load: 126 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,671] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3ec47526397842d8a7066a7914e1662a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,673] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4902 ms, throughput: 2.2936 GB/s; offload_time: 1.4057 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,677] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 578, LMCache hit tokens: 574, need to load: 158 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,687] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 578, LMCache hit tokens: 574, need to load: 206 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41524 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41538 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,693] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-91f43fbeb3eb4aa68352801a8758b602 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,695] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4250 ms, throughput: 2.3986 GB/s; offload_time: 1.3372 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,699] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 578, LMCache hit tokens: 574, need to load: 270 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,700] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,714] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,721] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-76d32d046c94494f9e87bc085520d673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,723] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5237 ms, throughput: 2.2432 GB/s; offload_time: 1.4403 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,734] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6e994d6be9f944e9aecf7afea1fa8312 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,736] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3979 ms, throughput: 2.4451 GB/s; offload_time: 1.3205 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,736] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-876a5d9fe13b4516965719d83b53c20f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,738] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5649 ms, throughput: 2.1842 GB/s; offload_time: 1.4926 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,742] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 580, LMCache hit tokens: 574, need to load: 110 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,752] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 580, LMCache hit tokens: 574, need to load: 174 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,761] LMCache INFO:[0m Reqid: chatcmpl-ee64fd4e90b44df2b70f69ddda217e94, Total tokens 580, LMCache hit tokens: 574, need to load: 270 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,762] LMCache INFO:[0m Reqid: chatcmpl-7e30118e271347c39b9139ff0cdbd881, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,763] LMCache INFO:[0m Reqid: chatcmpl-0d16c4e0e2454ce294e27c33ee7402b4, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,764] LMCache INFO:[0m Reqid: chatcmpl-a171fb15096d4b79b0c38d5e8d660b1a, Total tokens 1418, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,764] LMCache INFO:[0m Reqid: chatcmpl-81d23d22f9844b20944b654fb6c619a9, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO 07-11 15:21:31 [loggers.py:118] Engine 000: Avg prompt throughput: 10713.6 tokens/s, Avg generation throughput: 4706.6 tokens/s, Running: 79 reqs, Waiting: 63 reqs, GPU KV cache usage: 95.9%, Prefix cache hit rate: 18.1%
[32;20m[2025-07-11 15:21:31,809] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-0d16c4e0e2454ce294e27c33ee7402b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,810] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.4521 ms, throughput: 5.5524 GB/s; offload_time: 0.3688 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,810] LMCache INFO:[0m Storing KV cache for 138 out of 1418 tokens (skip_leading_tokens=1280) for request chatcmpl-a171fb15096d4b79b0c38d5e8d660b1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,811] LMCache INFO:[0m Stored 138 out of total 1418 tokens. size: 0.0037 gb, cost 1.0252 ms, throughput: 3.5944 GB/s; offload_time: 0.9168 ms, put_time: 0.1084 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,817] LMCache INFO:[0m Reqid: chatcmpl-81d23d22f9844b20944b654fb6c619a9, Total tokens 132, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,817] LMCache INFO:[0m Reqid: chatcmpl-dd35d0a4f605422191cff264ec8e99ce, Total tokens 811, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,830] LMCache INFO:[0m Storing KV cache for 132 out of 132 tokens (skip_leading_tokens=0) for request chatcmpl-81d23d22f9844b20944b654fb6c619a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,831] LMCache INFO:[0m Stored 132 out of total 132 tokens. size: 0.0035 gb, cost 0.6850 ms, throughput: 5.1455 GB/s; offload_time: 0.5565 ms, put_time: 0.1285 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,837] LMCache INFO:[0m Reqid: chatcmpl-dd35d0a4f605422191cff264ec8e99ce, Total tokens 811, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,844] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6db02670fc7a40f484f9bdfbfdb05d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,844] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4903 ms, throughput: 6.9710 GB/s; offload_time: 0.4116 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,849] LMCache INFO:[0m Reqid: chatcmpl-dd35d0a4f605422191cff264ec8e99ce, Total tokens 811, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,859] LMCache INFO:[0m Reqid: chatcmpl-dd35d0a4f605422191cff264ec8e99ce, Total tokens 811, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,869] LMCache INFO:[0m Reqid: chatcmpl-dd35d0a4f605422191cff264ec8e99ce, Total tokens 811, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,870] LMCache INFO:[0m Reqid: chatcmpl-0e2d486282044514b478642d58315247, Total tokens 337, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,870] LMCache INFO:[0m Reqid: chatcmpl-e43dfa11e5b141768fe1254c3318d3ea, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,894] LMCache INFO:[0m Storing KV cache for 171 out of 811 tokens (skip_leading_tokens=640) for request chatcmpl-dd35d0a4f605422191cff264ec8e99ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,894] LMCache INFO:[0m Stored 171 out of total 811 tokens. size: 0.0046 gb, cost 0.8084 ms, throughput: 5.6485 GB/s; offload_time: 0.6706 ms, put_time: 0.1378 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,895] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,896] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.0072 ms, throughput: 3.3937 GB/s; offload_time: 0.9155 ms, put_time: 0.0917 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,904] LMCache INFO:[0m Reqid: chatcmpl-e43dfa11e5b141768fe1254c3318d3ea, Total tokens 108, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,904] LMCache INFO:[0m Reqid: chatcmpl-8c452f2e275b41abb449fa30b9cec134, Total tokens 138, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,905] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,919] LMCache INFO:[0m Storing KV cache for 108 out of 108 tokens (skip_leading_tokens=0) for request chatcmpl-e43dfa11e5b141768fe1254c3318d3ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,919] LMCache INFO:[0m Stored 108 out of total 108 tokens. size: 0.0029 gb, cost 0.4714 ms, throughput: 6.1182 GB/s; offload_time: 0.3906 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,920] LMCache INFO:[0m Storing KV cache for 138 out of 138 tokens (skip_leading_tokens=0) for request chatcmpl-8c452f2e275b41abb449fa30b9cec134 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,921] LMCache INFO:[0m Stored 138 out of total 138 tokens. size: 0.0037 gb, cost 0.8675 ms, throughput: 4.2476 GB/s; offload_time: 0.7327 ms, put_time: 0.1349 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,927] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,937] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,946] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:31,953] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-faa292f90a7942a69211a21afc1d198c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,954] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6637 ms, throughput: 5.1497 GB/s; offload_time: 0.5754 ms, put_time: 0.0883 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,958] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,968] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,975] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,975] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6036 ms, throughput: 5.6625 GB/s; offload_time: 0.5210 ms, put_time: 0.0826 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,980] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,987] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6f2a626ef0644e27ba574a64d1e5d87b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:31,987] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5418 ms, throughput: 6.3090 GB/s; offload_time: 0.4650 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:31,994] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,005] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,012] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-896909973aa24a3d8a1c716ea09c8bf5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,014] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7430 ms, throughput: 1.9609 GB/s; offload_time: 1.6565 ms, put_time: 0.0865 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,014] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,016] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7725 ms, throughput: 1.9284 GB/s; offload_time: 1.6769 ms, put_time: 0.0955 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,021] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,029] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-2ff2e07a0c394906a1334bac80fb857c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,031] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7065 ms, throughput: 2.0029 GB/s; offload_time: 1.6197 ms, put_time: 0.0868 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,032] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,034] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 2.0196 ms, throughput: 1.6924 GB/s; offload_time: 1.9291 ms, put_time: 0.0905 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,039] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,046] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-082806fea8554eaebce6967ee67e4a24 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,048] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5818 ms, throughput: 2.1608 GB/s; offload_time: 1.5038 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,052] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,062] LMCache INFO:[0m Reqid: chatcmpl-cf0c1dac7c794905b3eb8121eafef867, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,063] LMCache INFO:[0m Reqid: chatcmpl-0771ed5c78634680af10150b90ea46fe, Total tokens 795, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,092] LMCache INFO:[0m Reqid: chatcmpl-0771ed5c78634680af10150b90ea46fe, Total tokens 795, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,093] LMCache INFO:[0m Reqid: chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7, Total tokens 963, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,118] LMCache INFO:[0m Reqid: chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7, Total tokens 963, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,118] LMCache INFO:[0m Reqid: chatcmpl-dfd0b592410f4547b9022781d0368c57, Total tokens 156, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,119] LMCache INFO:[0m Reqid: chatcmpl-37cc1918d7574c2286da45d2cdfc374f, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,119] LMCache INFO:[0m Reqid: chatcmpl-fb2db65a125746d9893a871055ce19a5, Total tokens 179, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,120] LMCache INFO:[0m Reqid: chatcmpl-ef038a3d90994c2fba2728c3eab408de, Total tokens 195, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,120] LMCache INFO:[0m Reqid: chatcmpl-cec5e3d5a0eb4bb0858bbc3f789ddf40, Total tokens 706, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,121] LMCache INFO:[0m Reqid: chatcmpl-611a0512c6974a64add15bbbf86e7c47, Total tokens 93, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,121] LMCache INFO:[0m Reqid: chatcmpl-0bdc7e9539904f8987d27d7e01030ebd, Total tokens 175, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,121] LMCache INFO:[0m Reqid: chatcmpl-94649e6195344dbca8bd534528e86829, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,122] LMCache INFO:[0m Reqid: chatcmpl-e56e94e3e58f4d328834520714afa839, Total tokens 124, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,122] LMCache INFO:[0m Reqid: chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3, Total tokens 749, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,161] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-37cc1918d7574c2286da45d2cdfc374f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,162] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.4231 ms, throughput: 7.0692 GB/s; offload_time: 0.3469 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,162] LMCache INFO:[0m Storing KV cache for 179 out of 179 tokens (skip_leading_tokens=0) for request chatcmpl-fb2db65a125746d9893a871055ce19a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,164] LMCache INFO:[0m Stored 179 out of total 179 tokens. size: 0.0048 gb, cost 1.2876 ms, throughput: 3.7122 GB/s; offload_time: 1.1734 ms, put_time: 0.1142 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,164] LMCache INFO:[0m Storing KV cache for 93 out of 93 tokens (skip_leading_tokens=0) for request chatcmpl-611a0512c6974a64add15bbbf86e7c47 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,165] LMCache INFO:[0m Stored 93 out of total 93 tokens. size: 0.0025 gb, cost 0.9269 ms, throughput: 2.6791 GB/s; offload_time: 0.7391 ms, put_time: 0.1878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,167] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-94649e6195344dbca8bd534528e86829 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,168] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.9340 ms, throughput: 2.9161 GB/s; offload_time: 0.8473 ms, put_time: 0.0867 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,169] LMCache INFO:[0m Storing KV cache for 124 out of 124 tokens (skip_leading_tokens=0) for request chatcmpl-e56e94e3e58f4d328834520714afa839 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,170] LMCache INFO:[0m Stored 124 out of total 124 tokens. size: 0.0033 gb, cost 0.9968 ms, throughput: 3.3218 GB/s; offload_time: 0.9253 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,170] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-23d3f88f0e234dbc8435cccdb8fa0909 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,171] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.9953 ms, throughput: 3.4339 GB/s; offload_time: 0.8634 ms, put_time: 0.1320 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,178] LMCache INFO:[0m Reqid: chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3, Total tokens 749, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,187] LMCache INFO:[0m Reqid: chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3, Total tokens 749, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,197] LMCache INFO:[0m Reqid: chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3, Total tokens 749, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,207] LMCache INFO:[0m Reqid: chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3, Total tokens 749, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,207] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 528, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,208] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 449, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,239] LMCache INFO:[0m Storing KV cache for 144 out of 528 tokens (skip_leading_tokens=384) for request chatcmpl-72f78707161f4ab2b2a34512b4b22e51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,240] LMCache INFO:[0m Stored 144 out of total 528 tokens. size: 0.0038 gb, cost 0.7721 ms, throughput: 4.9800 GB/s; offload_time: 0.6571 ms, put_time: 0.1151 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,240] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e56e94e3e58f4d328834520714afa839 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,241] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9718 ms, throughput: 3.5170 GB/s; offload_time: 0.8889 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,246] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 449, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,254] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,255] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6016 ms, throughput: 5.6816 GB/s; offload_time: 0.5168 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,259] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 449, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,260] LMCache INFO:[0m Reqid: chatcmpl-2e970c546d614e04ab302a0b95ffa673, Total tokens 188, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,279] LMCache INFO:[0m Storing KV cache for 321 out of 449 tokens (skip_leading_tokens=128) for request chatcmpl-8fa0aea8164c4e40abac40538f8f190a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,280] LMCache INFO:[0m Stored 321 out of total 449 tokens. size: 0.0086 gb, cost 1.3505 ms, throughput: 6.3468 GB/s; offload_time: 0.7486 ms, put_time: 0.6019 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,281] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e43dfa11e5b141768fe1254c3318d3ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,283] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.6833 ms, throughput: 2.0305 GB/s; offload_time: 1.6072 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,298] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 145 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,305] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d50a47d025954568be9ee366dfb9c5b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,307] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5608 ms, throughput: 2.1899 GB/s; offload_time: 1.4600 ms, put_time: 0.1008 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,312] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 289 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,321] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 369 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,329] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-3697f4d493154eb494e15eb85504cb70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,330] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5229 ms, throughput: 2.2444 GB/s; offload_time: 1.4463 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,334] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 401 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,345] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 401 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,355] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 401 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,374] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,384] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,391] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-37cc1918d7574c2286da45d2cdfc374f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,393] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.6622 ms, throughput: 2.0563 GB/s; offload_time: 1.5292 ms, put_time: 0.1330 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,397] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,404] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c745167344af47909fe691e143e72d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,406] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5277 ms, throughput: 2.2373 GB/s; offload_time: 1.4428 ms, put_time: 0.0849 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,410] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 416 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,418] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9fb52d27fd154424ba7de27bd7c90bce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,419] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4741 ms, throughput: 2.3188 GB/s; offload_time: 1.3962 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,424] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,431] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-a21a5a8f5fde4927b8ac5734ad663e57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,432] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4808 ms, throughput: 2.3082 GB/s; offload_time: 1.4065 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,437] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,447] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,457] LMCache INFO:[0m Reqid: chatcmpl-72f78707161f4ab2b2a34512b4b22e51, Total tokens 538, LMCache hit tokens: 528, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,457] LMCache INFO:[0m Reqid: chatcmpl-8fa0aea8164c4e40abac40538f8f190a, Total tokens 450, LMCache hit tokens: 449, need to load: 401 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,458] LMCache INFO:[0m Reqid: chatcmpl-2e970c546d614e04ab302a0b95ffa673, Total tokens 188, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,458] LMCache INFO:[0m Reqid: chatcmpl-90467bbcea9948e48fbd950d9ffc0fa1, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,459] LMCache INFO:[0m Reqid: chatcmpl-f73721a9bc724e34883adcdbf6b9fe6e, Total tokens 634, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,460] LMCache INFO:[0m Reqid: chatcmpl-24cb56dc0be34bcfa5e654c240436c1e, Total tokens 1346, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,485] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-90467bbcea9948e48fbd950d9ffc0fa1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,486] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.4465 ms, throughput: 6.0999 GB/s; offload_time: 0.3613 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,486] LMCache INFO:[0m Storing KV cache for 250 out of 634 tokens (skip_leading_tokens=384) for request chatcmpl-f73721a9bc724e34883adcdbf6b9fe6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,488] LMCache INFO:[0m Stored 250 out of total 634 tokens. size: 0.0067 gb, cost 1.2356 ms, throughput: 5.4030 GB/s; offload_time: 1.1222 ms, put_time: 0.1134 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,488] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-eb74cb60f6bd471caa2c277635dd7290 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,490] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5999 ms, throughput: 2.1364 GB/s; offload_time: 1.5314 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,496] LMCache INFO:[0m Reqid: chatcmpl-24cb56dc0be34bcfa5e654c240436c1e, Total tokens 1346, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,503] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,505] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4644 ms, throughput: 2.3340 GB/s; offload_time: 1.3890 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,509] LMCache INFO:[0m Reqid: chatcmpl-24cb56dc0be34bcfa5e654c240436c1e, Total tokens 1346, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,516] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,518] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4586 ms, throughput: 2.3433 GB/s; offload_time: 1.3712 ms, put_time: 0.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,523] LMCache INFO:[0m Reqid: chatcmpl-24cb56dc0be34bcfa5e654c240436c1e, Total tokens 1346, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,530] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-2d3b54f9e1b545c08fe86dc63285601a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,532] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5548 ms, throughput: 2.1984 GB/s; offload_time: 1.4789 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,532] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-820219768dfc40799ba3e47b4f7e70b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,534] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.7176 ms, throughput: 1.9900 GB/s; offload_time: 1.6487 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,539] LMCache INFO:[0m Reqid: chatcmpl-24cb56dc0be34bcfa5e654c240436c1e, Total tokens 1346, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,540] LMCache INFO:[0m Reqid: chatcmpl-3ee3d46cdba64de78e720d37dd26865c, Total tokens 171, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,540] LMCache INFO:[0m Reqid: chatcmpl-a65daf8b93eb41fd8d49551212038187, Total tokens 244, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,576] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-94649e6195344dbca8bd534528e86829 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,577] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4656 ms, throughput: 7.3415 GB/s; offload_time: 0.3788 ms, put_time: 0.0867 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,582] LMCache INFO:[0m Reqid: chatcmpl-a65daf8b93eb41fd8d49551212038187, Total tokens 244, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,582] LMCache INFO:[0m Reqid: chatcmpl-a49473a0c52449f7904f232ba6e33e59, Total tokens 120, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,583] LMCache INFO:[0m Reqid: chatcmpl-c25b123b9f134c71b45a81130e61472b, Total tokens 512, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,584] LMCache INFO:[0m Reqid: chatcmpl-5ac861930d3642c7a8caf0b72138771c, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,585] LMCache INFO:[0m Reqid: chatcmpl-dcb4de26086b4dbca291a64dd9190ec1, Total tokens 1955, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,611] LMCache INFO:[0m Storing KV cache for 120 out of 120 tokens (skip_leading_tokens=0) for request chatcmpl-a49473a0c52449f7904f232ba6e33e59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,611] LMCache INFO:[0m Stored 120 out of total 120 tokens. size: 0.0032 gb, cost 0.4624 ms, throughput: 6.9296 GB/s; offload_time: 0.3765 ms, put_time: 0.0859 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,612] LMCache INFO:[0m Storing KV cache for 512 out of 512 tokens (skip_leading_tokens=0) for request chatcmpl-c25b123b9f134c71b45a81130e61472b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,621] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0137 gb, cost 9.0796 ms, throughput: 1.5058 GB/s; offload_time: 1.2006 ms, put_time: 7.8791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,622] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d9f947fe12ce4b1ca05d0dfac4815531 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,623] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9237 ms, throughput: 3.7002 GB/s; offload_time: 0.8524 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,629] LMCache INFO:[0m Reqid: chatcmpl-dcb4de26086b4dbca291a64dd9190ec1, Total tokens 1955, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,637] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f73721a9bc724e34883adcdbf6b9fe6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,638] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5643 ms, throughput: 6.0566 GB/s; offload_time: 0.4865 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,643] LMCache INFO:[0m Reqid: chatcmpl-dcb4de26086b4dbca291a64dd9190ec1, Total tokens 1955, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,650] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,651] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5946 ms, throughput: 5.7479 GB/s; offload_time: 0.5137 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,656] LMCache INFO:[0m Reqid: chatcmpl-dcb4de26086b4dbca291a64dd9190ec1, Total tokens 1955, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,663] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-bd9674d6af704965b1c5317f4dc9e8b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,664] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5140 ms, throughput: 6.6504 GB/s; offload_time: 0.4242 ms, put_time: 0.0897 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,669] LMCache INFO:[0m Reqid: chatcmpl-dcb4de26086b4dbca291a64dd9190ec1, Total tokens 1955, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,670] LMCache INFO:[0m Reqid: chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc, Total tokens 917, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,718] LMCache INFO:[0m Reqid: chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc, Total tokens 917, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,725] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-7e30118e271347c39b9139ff0cdbd881 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,726] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5778 ms, throughput: 5.9159 GB/s; offload_time: 0.4966 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,726] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0e2d486282044514b478642d58315247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,727] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4725 ms, throughput: 7.2337 GB/s; offload_time: 0.4063 ms, put_time: 0.0662 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,732] LMCache INFO:[0m Reqid: chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc, Total tokens 917, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,742] LMCache INFO:[0m Reqid: chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc, Total tokens 917, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,743] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 485, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,765] LMCache INFO:[0m Storing KV cache for 149 out of 917 tokens (skip_leading_tokens=768) for request chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,766] LMCache INFO:[0m Stored 149 out of total 917 tokens. size: 0.0040 gb, cost 0.7328 ms, throughput: 5.4292 GB/s; offload_time: 0.6070 ms, put_time: 0.1259 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,767] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,768] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8026 ms, throughput: 4.2588 GB/s; offload_time: 0.7211 ms, put_time: 0.0814 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,774] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 485, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,781] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a49473a0c52449f7904f232ba6e33e59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,781] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4402 ms, throughput: 7.7649 GB/s; offload_time: 0.3704 ms, put_time: 0.0698 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,786] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 485, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,786] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 204, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,787] LMCache INFO:[0m Reqid: chatcmpl-85426b06a5a54747bd0b71fa2d41e935, Total tokens 118, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,787] LMCache INFO:[0m Reqid: chatcmpl-061b381996be4c3d8ceaf22c315f33b2, Total tokens 172, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,787] LMCache INFO:[0m Reqid: chatcmpl-5859e8f1f1ff47dd89c55cdfd6a35d78, Total tokens 163, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,789] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,813] LMCache INFO:[0m Storing KV cache for 118 out of 118 tokens (skip_leading_tokens=0) for request chatcmpl-85426b06a5a54747bd0b71fa2d41e935 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,813] LMCache INFO:[0m Stored 118 out of total 118 tokens. size: 0.0032 gb, cost 0.4349 ms, throughput: 7.2451 GB/s; offload_time: 0.3539 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,819] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,829] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,840] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,846] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a65daf8b93eb41fd8d49551212038187 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,847] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4714 ms, throughput: 7.2512 GB/s; offload_time: 0.3948 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,852] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,860] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:32,863] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.4260 ms, throughput: 1.4089 GB/s; offload_time: 2.3421 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,863] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,864] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6864 ms, throughput: 4.9798 GB/s; offload_time: 0.6200 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,870] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,880] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,889] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,899] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,907] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c2df73dd89a44f4cb743f94bbd32b6df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,908] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5787 ms, throughput: 5.9058 GB/s; offload_time: 0.5043 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,908] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-e29cc192a2174615adf5d9b86ac2acc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,909] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6043 ms, throughput: 5.6562 GB/s; offload_time: 0.5383 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,909] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,910] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.7532 ms, throughput: 4.5380 GB/s; offload_time: 0.6928 ms, put_time: 0.0604 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,926] LMCache INFO:[0m Reqid: chatcmpl-061b381996be4c3d8ceaf22c315f33b2, Total tokens 181, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,933] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-85426b06a5a54747bd0b71fa2d41e935 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,934] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4932 ms, throughput: 6.9309 GB/s; offload_time: 0.4047 ms, put_time: 0.0884 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,945] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5389000701cb49818998e9be0f6582b3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,945] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4977 ms, throughput: 6.8682 GB/s; offload_time: 0.4231 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,958] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,959] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6954 ms, throughput: 4.9154 GB/s; offload_time: 0.6059 ms, put_time: 0.0895 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,959] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-90467bbcea9948e48fbd950d9ffc0fa1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,960] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6501 ms, throughput: 5.2578 GB/s; offload_time: 0.5818 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,965] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 216, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,972] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,975] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 2.3405 ms, throughput: 1.4603 GB/s; offload_time: 2.2606 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,975] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,977] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6416 ms, throughput: 2.0820 GB/s; offload_time: 1.5691 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:32,991] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 499, LMCache hit tokens: 384, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,991] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 216, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:32,992] LMCache INFO:[0m Reqid: chatcmpl-85426b06a5a54747bd0b71fa2d41e935, Total tokens 129, LMCache hit tokens: 118, need to load: 70 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,019] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 217, LMCache hit tokens: 128, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,019] LMCache INFO:[0m Reqid: chatcmpl-85426b06a5a54747bd0b71fa2d41e935, Total tokens 129, LMCache hit tokens: 118, need to load: 70 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,041] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-24436898aa744bea89b23757b3d2a6db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,043] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5356 ms, throughput: 2.2258 GB/s; offload_time: 1.4612 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,047] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 218, LMCache hit tokens: 128, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,054] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-41045c7c9c5c49b783177abfccc99933 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,056] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4804 ms, throughput: 2.3088 GB/s; offload_time: 1.4068 ms, put_time: 0.0736 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,061] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 218, LMCache hit tokens: 128, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,067] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-dbfcac06a56048cbb284fcca33cd1f8d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,069] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4055 ms, throughput: 2.4318 GB/s; offload_time: 1.3260 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,084] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 505, LMCache hit tokens: 384, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,094] LMCache INFO:[0m Reqid: chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944, Total tokens 505, LMCache hit tokens: 384, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,094] LMCache INFO:[0m Reqid: chatcmpl-4db3458eb6e242fe9450f9fe484eb809, Total tokens 218, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,095] LMCache INFO:[0m Reqid: chatcmpl-85426b06a5a54747bd0b71fa2d41e935, Total tokens 129, LMCache hit tokens: 118, need to load: 70 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,095] LMCache INFO:[0m Reqid: chatcmpl-061b381996be4c3d8ceaf22c315f33b2, Total tokens 181, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,096] LMCache INFO:[0m Reqid: chatcmpl-5859e8f1f1ff47dd89c55cdfd6a35d78, Total tokens 172, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,097] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,113] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,115] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6749 ms, throughput: 2.0407 GB/s; offload_time: 1.5875 ms, put_time: 0.0874 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,116] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6360badc7787439895c9924a3d04a4c8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,118] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 2.0261 ms, throughput: 1.6870 GB/s; offload_time: 1.9433 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,125] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,132] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,134] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5104 ms, throughput: 2.2629 GB/s; offload_time: 1.4348 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,139] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,147] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,149] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5105 ms, throughput: 2.2627 GB/s; offload_time: 1.4297 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,149] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,151] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5804 ms, throughput: 2.1628 GB/s; offload_time: 1.5111 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,151] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-ef038a3d90994c2fba2728c3eab408de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,153] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.9011 ms, throughput: 1.7979 GB/s; offload_time: 1.8254 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,158] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,168] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,178] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,188] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,194] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-f2e44645dda2411bbdf7ec2887f7f770 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,196] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4648 ms, throughput: 2.3335 GB/s; offload_time: 1.3846 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,201] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,208] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,210] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4399 ms, throughput: 2.3737 GB/s; offload_time: 1.3685 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,214] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,224] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,234] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,244] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1975, LMCache hit tokens: 1920, need to load: 1872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,245] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,290] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-dd35d0a4f605422191cff264ec8e99ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,290] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5787 ms, throughput: 5.9066 GB/s; offload_time: 0.5001 ms, put_time: 0.0786 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,295] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,305] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,314] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,324] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,343] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1980, LMCache hit tokens: 1920, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,350] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-2f1561858dcf49d5bca351138debda74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,351] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 0.7877 ms, throughput: 4.3392 GB/s; offload_time: 0.7089 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,352] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-2d9480ba93634862832ba1bc11ca3f66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,353] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6262 ms, throughput: 5.4585 GB/s; offload_time: 0.5614 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,358] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1980, LMCache hit tokens: 1920, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,359] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,377] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,387] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,403] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ee16b33874494b628ff239902b31717c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,404] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5882 ms, throughput: 5.8109 GB/s; offload_time: 0.5036 ms, put_time: 0.0846 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,409] LMCache INFO:[0m Reqid: chatcmpl-ec99baedd4ad427e89e393eb0dd9054f, Total tokens 1983, LMCache hit tokens: 1920, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,410] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,425] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-fec69aa647664f54969e2853a68c982c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,426] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6221 ms, throughput: 5.4941 GB/s; offload_time: 0.5483 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,426] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0bdc7e9539904f8987d27d7e01030ebd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,427] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6318 ms, throughput: 5.4095 GB/s; offload_time: 0.5652 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,432] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,442] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,449] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,450] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5169 ms, throughput: 6.6127 GB/s; offload_time: 0.4423 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,450] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-eb7bb3cac4554b1a8ee624ec34db1c96 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,451] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7611 ms, throughput: 4.4906 GB/s; offload_time: 0.6947 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,456] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,463] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-8fa0aea8164c4e40abac40538f8f190a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,464] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5203 ms, throughput: 6.5698 GB/s; offload_time: 0.4434 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,468] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,478] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,487] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,494] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,495] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5000 ms, throughput: 6.8366 GB/s; offload_time: 0.4253 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,499] LMCache INFO:[0m Reqid: chatcmpl-5fa75b0dead348a391e894f59dcd91cd, Total tokens 1131, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,501] LMCache INFO:[0m Reqid: chatcmpl-37f59dc8758747b49e78b10d2ea80f68, Total tokens 221, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,501] LMCache INFO:[0m Reqid: chatcmpl-954bcb9f39b346b5852999097a717f77, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,502] LMCache INFO:[0m Reqid: chatcmpl-c4b593be2cf74d8dab97c112965087d6, Total tokens 1258, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,534] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-954bcb9f39b346b5852999097a717f77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,535] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.4494 ms, throughput: 6.5958 GB/s; offload_time: 0.3714 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,535] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-8caad36d43274496baddb5c5b39d557f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,536] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.8984 ms, throughput: 3.8046 GB/s; offload_time: 0.8280 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,541] LMCache INFO:[0m Reqid: chatcmpl-c4b593be2cf74d8dab97c112965087d6, Total tokens 1258, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,542] LMCache INFO:[0m Reqid: chatcmpl-36268309084742b1a875d6f2d2f96cc3, Total tokens 152, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,543] LMCache INFO:[0m Reqid: chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e, Total tokens 517, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,544] LMCache INFO:[0m Reqid: chatcmpl-65e2f210cfba4c44b58d82c6248791d1, Total tokens 252, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,544] LMCache INFO:[0m Reqid: chatcmpl-41004555783f4b34b624b77a9bd776ed, Total tokens 117, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,544] LMCache INFO:[0m Reqid: chatcmpl-495e8409ac164e3fa2068a21c76bc0b7, Total tokens 178, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,545] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1096, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,587] LMCache INFO:[0m Storing KV cache for 152 out of 152 tokens (skip_leading_tokens=0) for request chatcmpl-36268309084742b1a875d6f2d2f96cc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,588] LMCache INFO:[0m Stored 152 out of total 152 tokens. size: 0.0041 gb, cost 0.6818 ms, throughput: 5.9534 GB/s; offload_time: 0.5458 ms, put_time: 0.1359 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,589] LMCache INFO:[0m Storing KV cache for 517 out of 517 tokens (skip_leading_tokens=0) for request chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,592] LMCache INFO:[0m Stored 517 out of total 517 tokens. size: 0.0138 gb, cost 3.2788 ms, throughput: 4.2104 GB/s; offload_time: 2.8718 ms, put_time: 0.4071 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,593] LMCache INFO:[0m Storing KV cache for 117 out of 117 tokens (skip_leading_tokens=0) for request chatcmpl-41004555783f4b34b624b77a9bd776ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,595] LMCache INFO:[0m Stored 117 out of total 117 tokens. size: 0.0031 gb, cost 1.4848 ms, throughput: 2.1042 GB/s; offload_time: 1.3299 ms, put_time: 0.1549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,601] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1096, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,608] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2e970c546d614e04ab302a0b95ffa673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,608] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4806 ms, throughput: 7.1121 GB/s; offload_time: 0.4081 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,613] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1096, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,623] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1096, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,624] LMCache INFO:[0m Reqid: chatcmpl-8d7fde35dec94b318364a7d3d8b166db, Total tokens 660, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,652] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c06d3fc50966439b9c9589d71ecede66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,653] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5223 ms, throughput: 6.5444 GB/s; offload_time: 0.4498 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,658] LMCache INFO:[0m Reqid: chatcmpl-8d7fde35dec94b318364a7d3d8b166db, Total tokens 660, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,665] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-65e2f210cfba4c44b58d82c6248791d1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,665] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4934 ms, throughput: 6.9276 GB/s; offload_time: 0.4187 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,677] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,678] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6306 ms, throughput: 5.4200 GB/s; offload_time: 0.5596 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,678] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8ee53076d2964cd1a6905e0132c86867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,679] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.7130 ms, throughput: 4.7938 GB/s; offload_time: 0.6452 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,684] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1098, LMCache hit tokens: 1024, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,691] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,692] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4881 ms, throughput: 7.0023 GB/s; offload_time: 0.4164 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,696] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1098, LMCache hit tokens: 1024, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,703] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b73b60eb8250453d922a74a9084fc644 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,704] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5667 ms, throughput: 6.0314 GB/s; offload_time: 0.4941 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,708] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1098, LMCache hit tokens: 1024, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,715] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,716] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5067 ms, throughput: 6.7454 GB/s; offload_time: 0.4332 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,716] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-4db3458eb6e242fe9450f9fe484eb809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,717] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5800 ms, throughput: 5.8932 GB/s; offload_time: 0.5183 ms, put_time: 0.0617 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,722] LMCache INFO:[0m Reqid: chatcmpl-0f72040bd12841108e22539e8bb1b1ed, Total tokens 1098, LMCache hit tokens: 1024, need to load: 416 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,723] LMCache INFO:[0m Reqid: chatcmpl-8d7fde35dec94b318364a7d3d8b166db, Total tokens 660, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,723] LMCache INFO:[0m Reqid: chatcmpl-d9b7008f9dd74b7b8aa726d8a0c73dfe, Total tokens 263, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,724] LMCache INFO:[0m Reqid: chatcmpl-338d4f820ea04507a7b2027c9dbb807c, Total tokens 143, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,750] LMCache INFO:[0m Storing KV cache for 135 out of 263 tokens (skip_leading_tokens=128) for request chatcmpl-d9b7008f9dd74b7b8aa726d8a0c73dfe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,750] LMCache INFO:[0m Stored 135 out of total 263 tokens. size: 0.0036 gb, cost 0.6767 ms, throughput: 5.3268 GB/s; offload_time: 0.5773 ms, put_time: 0.0994 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,751] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-5f0661cec68142b697b693733c623aef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,753] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.8695 ms, throughput: 1.8282 GB/s; offload_time: 1.6818 ms, put_time: 0.1878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,753] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-a171fb15096d4b79b0c38d5e8d660b1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,754] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2849 ms, throughput: 2.6600 GB/s; offload_time: 1.2139 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,766] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,767] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7113 ms, throughput: 4.8049 GB/s; offload_time: 0.6251 ms, put_time: 0.0862 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,771] LMCache INFO:[0m Reqid: chatcmpl-d9b7008f9dd74b7b8aa726d8a0c73dfe, Total tokens 264, LMCache hit tokens: 263, need to load: 151 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,772] LMCache INFO:[0m Reqid: chatcmpl-338d4f820ea04507a7b2027c9dbb807c, Total tokens 143, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,772] LMCache INFO:[0m Reqid: chatcmpl-ffff9f2a61214e77bba733dbc961c551, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,773] LMCache INFO:[0m Reqid: chatcmpl-1a812f673eab4accb36f93153ae217e1, Total tokens 245, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,773] LMCache INFO:[0m Reqid: chatcmpl-587ec8adcd014bfdb5f2f70556271ccc, Total tokens 263, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,774] LMCache INFO:[0m Reqid: chatcmpl-2613347d2ee5408a93e94b209699e907, Total tokens 160, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,774] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 681, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,801] LMCache INFO:[0m Storing KV cache for 143 out of 143 tokens (skip_leading_tokens=0) for request chatcmpl-338d4f820ea04507a7b2027c9dbb807c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,802] LMCache INFO:[0m Stored 143 out of total 143 tokens. size: 0.0038 gb, cost 0.6886 ms, throughput: 5.5456 GB/s; offload_time: 0.5870 ms, put_time: 0.1015 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,803] LMCache INFO:[0m Storing KV cache for 263 out of 263 tokens (skip_leading_tokens=0) for request chatcmpl-587ec8adcd014bfdb5f2f70556271ccc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,806] LMCache INFO:[0m Stored 263 out of total 263 tokens. size: 0.0070 gb, cost 3.4581 ms, throughput: 2.0308 GB/s; offload_time: 3.3067 ms, put_time: 0.1514 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,807] LMCache INFO:[0m Storing KV cache for 160 out of 160 tokens (skip_leading_tokens=0) for request chatcmpl-2613347d2ee5408a93e94b209699e907 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,810] LMCache INFO:[0m Stored 160 out of total 160 tokens. size: 0.0043 gb, cost 2.3841 ms, throughput: 1.7921 GB/s; offload_time: 2.2925 ms, put_time: 0.0916 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,810] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-0771ed5c78634680af10150b90ea46fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,813] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.6739 ms, throughput: 2.0419 GB/s; offload_time: 1.6093 ms, put_time: 0.0646 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,813] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-dfd0b592410f4547b9022781d0368c57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,815] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.0220 ms, throughput: 1.6904 GB/s; offload_time: 1.9539 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,815] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-41004555783f4b34b624b77a9bd776ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,817] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5419 ms, throughput: 2.2168 GB/s; offload_time: 1.4696 ms, put_time: 0.0723 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,822] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 681, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,823] LMCache INFO:[0m Reqid: chatcmpl-6b312c9894c5484cba9e9fd44f10061a, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,823] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 287, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,824] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,848] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-6b312c9894c5484cba9e9fd44f10061a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,848] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 0.4320 ms, throughput: 6.1191 GB/s; offload_time: 0.3514 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,853] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,864] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,874] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,881] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-76d32d046c94494f9e87bc085520d673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,881] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5793 ms, throughput: 5.9003 GB/s; offload_time: 0.4974 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,882] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-8c452f2e275b41abb449fa30b9cec134 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,882] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6295 ms, throughput: 5.4295 GB/s; offload_time: 0.5676 ms, put_time: 0.0619 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,888] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,894] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-954bcb9f39b346b5852999097a717f77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,896] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4469 ms, throughput: 2.3622 GB/s; offload_time: 1.3678 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,900] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:41936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,920] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 293, LMCache hit tokens: 256, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,936] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-5fa75b0dead348a391e894f59dcd91cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,938] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4925 ms, throughput: 2.2901 GB/s; offload_time: 1.4178 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,943] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 689, LMCache hit tokens: 640, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,953] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 689, LMCache hit tokens: 640, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,960] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-3ee3d46cdba64de78e720d37dd26865c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,961] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.3784 ms, throughput: 2.4798 GB/s; offload_time: 1.3036 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,961] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c4b593be2cf74d8dab97c112965087d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,963] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.7497 ms, throughput: 1.9535 GB/s; offload_time: 1.6732 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,964] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1a812f673eab4accb36f93153ae217e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,966] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.8212 ms, throughput: 1.8767 GB/s; offload_time: 1.7481 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:33,971] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 689, LMCache hit tokens: 640, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,971] LMCache INFO:[0m Reqid: chatcmpl-6b312c9894c5484cba9e9fd44f10061a, Total tokens 107, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,972] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 293, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,973] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41952 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:33,988] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,995] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:33,997] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4589 ms, throughput: 2.3429 GB/s; offload_time: 1.3839 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,002] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,021] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 296, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,030] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 296, LMCache hit tokens: 256, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,031] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,046] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5ac861930d3642c7a8caf0b72138771c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,047] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4780 ms, throughput: 2.3126 GB/s; offload_time: 1.4005 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,052] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,059] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ffff9f2a61214e77bba733dbc961c551 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,061] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4595 ms, throughput: 2.3419 GB/s; offload_time: 1.3847 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,066] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,073] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,075] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5961 ms, throughput: 2.1415 GB/s; offload_time: 1.5183 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,079] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,089] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,099] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,106] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,108] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4784 ms, throughput: 2.3119 GB/s; offload_time: 1.3995 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:41956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,119] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,121] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5893 ms, throughput: 2.1506 GB/s; offload_time: 1.5076 ms, put_time: 0.0818 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,121] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-37f59dc8758747b49e78b10d2ea80f68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,123] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6071 ms, throughput: 2.1267 GB/s; offload_time: 1.5390 ms, put_time: 0.0682 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,129] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 302, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,137] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-082806fea8554eaebce6967ee67e4a24 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,139] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7626 ms, throughput: 1.9392 GB/s; offload_time: 1.6804 ms, put_time: 0.0822 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,139] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-72f78707161f4ab2b2a34512b4b22e51 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,141] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6132 ms, throughput: 2.1187 GB/s; offload_time: 1.5407 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,141] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-dcb4de26086b4dbca291a64dd9190ec1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,144] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 2.2811 ms, throughput: 1.4984 GB/s; offload_time: 1.9542 ms, put_time: 0.3270 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,168] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,178] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,187] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,197] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 384 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,206] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,216] LMCache INFO:[0m Reqid: chatcmpl-fa9f6777e3c54166a12269a4992fc809, Total tokens 703, LMCache hit tokens: 640, need to load: 528 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,216] LMCache INFO:[0m Reqid: chatcmpl-6b312c9894c5484cba9e9fd44f10061a, Total tokens 120, LMCache hit tokens: 99, need to load: 51 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,217] LMCache INFO:[0m Reqid: chatcmpl-079ce9ebfdf7439b8fefe15935833e6a, Total tokens 302, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,218] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,233] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,240] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,242] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5415 ms, throughput: 2.2172 GB/s; offload_time: 1.4623 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,247] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,254] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-061b381996be4c3d8ceaf22c315f33b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,256] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4131 ms, throughput: 2.4188 GB/s; offload_time: 1.3374 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,261] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,271] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,278] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-d50a47d025954568be9ee366dfb9c5b5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,280] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.5361 ms, throughput: 2.2251 GB/s; offload_time: 1.4599 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,285] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,294] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,302] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-3697f4d493154eb494e15eb85504cb70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,303] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5436 ms, throughput: 2.2143 GB/s; offload_time: 1.4686 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,308] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,318] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,325] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-6b312c9894c5484cba9e9fd44f10061a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,326] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4290 ms, throughput: 2.3919 GB/s; offload_time: 1.3450 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,331] LMCache INFO:[0m Reqid: chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31, Total tokens 1392, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,332] LMCache INFO:[0m Reqid: chatcmpl-741ae5cdc401455ca258840940f2aeb4, Total tokens 123, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,333] LMCache INFO:[0m Reqid: chatcmpl-f46c19b32fb0425d9e457d07f6637516, Total tokens 632, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,333] LMCache INFO:[0m Reqid: chatcmpl-348f752a200a4f37b4aa5c92d9a2b32b, Total tokens 223, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,334] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1095, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,379] LMCache INFO:[0m Storing KV cache for 240 out of 1392 tokens (skip_leading_tokens=1152) for request chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,380] LMCache INFO:[0m Stored 240 out of total 1392 tokens. size: 0.0064 gb, cost 0.9191 ms, throughput: 6.9725 GB/s; offload_time: 0.7255 ms, put_time: 0.1937 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,381] LMCache INFO:[0m Storing KV cache for 123 out of 123 tokens (skip_leading_tokens=0) for request chatcmpl-741ae5cdc401455ca258840940f2aeb4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,382] LMCache INFO:[0m Stored 123 out of total 123 tokens. size: 0.0033 gb, cost 0.4658 ms, throughput: 7.0518 GB/s; offload_time: 0.4058 ms, put_time: 0.0599 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,382] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,383] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5639 ms, throughput: 6.0617 GB/s; offload_time: 0.5051 ms, put_time: 0.0587 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,389] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1095, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,399] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1095, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,409] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1095, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,419] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1095, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,419] LMCache INFO:[0m Reqid: chatcmpl-117a9d6400244cdf96043f31fdeb95a9, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,456] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-9fb52d27fd154424ba7de27bd7c90bce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,456] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5171 ms, throughput: 6.6102 GB/s; offload_time: 0.4422 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,457] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-ec99baedd4ad427e89e393eb0dd9054f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,458] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.8448 ms, throughput: 4.0460 GB/s; offload_time: 0.7786 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,458] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-741ae5cdc401455ca258840940f2aeb4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,459] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3978 ms, throughput: 8.5920 GB/s; offload_time: 0.3343 ms, put_time: 0.0635 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,464] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1096, LMCache hit tokens: 1024, need to load: 112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,474] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1096, LMCache hit tokens: 1024, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:41998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,484] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1096, LMCache hit tokens: 1024, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,485] LMCache INFO:[0m Reqid: chatcmpl-117a9d6400244cdf96043f31fdeb95a9, Total tokens 105, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,485] LMCache INFO:[0m Reqid: chatcmpl-1d084d1708e64f7d83c8ea32ea5af162, Total tokens 171, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,498] LMCache INFO:[0m Storing KV cache for 105 out of 105 tokens (skip_leading_tokens=0) for request chatcmpl-117a9d6400244cdf96043f31fdeb95a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,499] LMCache INFO:[0m Stored 105 out of total 105 tokens. size: 0.0028 gb, cost 0.4837 ms, throughput: 5.7964 GB/s; offload_time: 0.4072 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,499] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-f46c19b32fb0425d9e457d07f6637516 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,500] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8318 ms, throughput: 4.1093 GB/s; offload_time: 0.7639 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,522] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,522] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5591 ms, throughput: 6.1132 GB/s; offload_time: 0.4854 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,527] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1098, LMCache hit tokens: 1024, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,534] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,535] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5526 ms, throughput: 6.1855 GB/s; offload_time: 0.4752 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,535] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0f72040bd12841108e22539e8bb1b1ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,536] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.7648 ms, throughput: 4.4691 GB/s; offload_time: 0.6946 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,541] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1098, LMCache hit tokens: 1024, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,548] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-820219768dfc40799ba3e47b4f7e70b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,550] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5879 ms, throughput: 2.1525 GB/s; offload_time: 1.5110 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,555] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1098, LMCache hit tokens: 1024, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,556] LMCache INFO:[0m Reqid: chatcmpl-117a9d6400244cdf96043f31fdeb95a9, Total tokens 106, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,556] LMCache INFO:[0m Reqid: chatcmpl-1d084d1708e64f7d83c8ea32ea5af162, Total tokens 171, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,571] LMCache INFO:[0m Reqid: chatcmpl-1d084d1708e64f7d83c8ea32ea5af162, Total tokens 171, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,578] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d9f947fe12ce4b1ca05d0dfac4815531 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,581] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.8664 ms, throughput: 1.8313 GB/s; offload_time: 1.7739 ms, put_time: 0.0925 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,581] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c25b123b9f134c71b45a81130e61472b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,583] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7899 ms, throughput: 1.9096 GB/s; offload_time: 1.7088 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,594] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f73721a9bc724e34883adcdbf6b9fe6e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,596] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4896 ms, throughput: 2.2945 GB/s; offload_time: 1.4107 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,600] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1100, LMCache hit tokens: 1024, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,601] LMCache INFO:[0m Reqid: chatcmpl-117a9d6400244cdf96043f31fdeb95a9, Total tokens 108, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,601] LMCache INFO:[0m Reqid: chatcmpl-1d084d1708e64f7d83c8ea32ea5af162, Total tokens 171, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,615] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-bb054c7e75db45f3be5fa3b0c071b23f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,621] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 4.8744 ms, throughput: 0.7012 GB/s; offload_time: 3.6396 ms, put_time: 1.2348 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,622] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-813b38ca13c04aeba7ad44d6f5c83d31 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,624] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 2.1453 ms, throughput: 1.5932 GB/s; offload_time: 2.0412 ms, put_time: 0.1041 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,642] LMCache INFO:[0m Reqid: chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7, Total tokens 1101, LMCache hit tokens: 1024, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,643] LMCache INFO:[0m Reqid: chatcmpl-117a9d6400244cdf96043f31fdeb95a9, Total tokens 109, LMCache hit tokens: 105, need to load: 57 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,643] LMCache INFO:[0m Reqid: chatcmpl-1d084d1708e64f7d83c8ea32ea5af162, Total tokens 171, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,644] LMCache INFO:[0m Reqid: chatcmpl-e4c2f65d1ea54728a33f05ee755c4f35, Total tokens 1117, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,660] LMCache INFO:[0m Storing KV cache for 171 out of 171 tokens (skip_leading_tokens=0) for request chatcmpl-1d084d1708e64f7d83c8ea32ea5af162 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,662] LMCache INFO:[0m Stored 171 out of total 171 tokens. size: 0.0046 gb, cost 1.7470 ms, throughput: 2.6137 GB/s; offload_time: 1.5787 ms, put_time: 0.1683 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,667] LMCache INFO:[0m Reqid: chatcmpl-e4c2f65d1ea54728a33f05ee755c4f35, Total tokens 1117, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,669] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,700] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-7e30118e271347c39b9139ff0cdbd881 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,700] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4967 ms, throughput: 6.8812 GB/s; offload_time: 0.4257 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,701] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0e2d486282044514b478642d58315247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,701] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6982 ms, throughput: 4.8951 GB/s; offload_time: 0.6370 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,706] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,716] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,723] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,723] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5866 ms, throughput: 5.8268 GB/s; offload_time: 0.5008 ms, put_time: 0.0858 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,728] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,735] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a49473a0c52449f7904f232ba6e33e59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,735] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4697 ms, throughput: 7.2768 GB/s; offload_time: 0.3941 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,740] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,750] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,759] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,769] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,776] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a65daf8b93eb41fd8d49551212038187 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,776] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4794 ms, throughput: 7.1295 GB/s; offload_time: 0.4054 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,777] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-495e8409ac164e3fa2068a21c76bc0b7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,778] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4030 ms, throughput: 8.4810 GB/s; offload_time: 0.3285 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,782] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,789] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,790] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6015 ms, throughput: 5.6826 GB/s; offload_time: 0.5241 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,790] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,791] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6458 ms, throughput: 5.2930 GB/s; offload_time: 0.5790 ms, put_time: 0.0668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,796] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,806] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,816] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,826] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,833] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-e29cc192a2174615adf5d9b86ac2acc0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,835] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6065 ms, throughput: 2.1276 GB/s; offload_time: 1.5232 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,835] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,837] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5991 ms, throughput: 2.1374 GB/s; offload_time: 1.5302 ms, put_time: 0.0690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,842] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,852] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,859] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-348f752a200a4f37b4aa5c92d9a2b32b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,861] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4108 ms, throughput: 2.4227 GB/s; offload_time: 1.3287 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,865] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,875] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42048 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:34,882] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f924958d0f2642debec5fedaf7059fb2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,884] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4706 ms, throughput: 2.3242 GB/s; offload_time: 1.3931 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,884] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-90467bbcea9948e48fbd950d9ffc0fa1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,886] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6611 ms, throughput: 2.0577 GB/s; offload_time: 1.5832 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,891] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,898] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,900] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.5934 ms, throughput: 2.1451 GB/s; offload_time: 1.5127 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,900] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,902] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.3933 ms, throughput: 2.4532 GB/s; offload_time: 1.3198 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,907] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,914] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-117a9d6400244cdf96043f31fdeb95a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,915] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4815 ms, throughput: 2.3071 GB/s; offload_time: 1.4003 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,920] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,930] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,939] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,950] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,957] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-24436898aa744bea89b23757b3d2a6db [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,958] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5274 ms, throughput: 2.2377 GB/s; offload_time: 1.4527 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,963] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,973] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,980] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dbfcac06a56048cbb284fcca33cd1f8d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,982] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4519 ms, throughput: 2.3541 GB/s; offload_time: 1.3729 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:34,987] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:34,997] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,004] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-85426b06a5a54747bd0b71fa2d41e935 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,005] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4521 ms, throughput: 2.3538 GB/s; offload_time: 1.3751 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,010] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,017] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-7df284d4e3d748dcb1d4fbc597de62f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,019] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4927 ms, throughput: 2.2898 GB/s; offload_time: 1.4116 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,024] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,031] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,032] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4760 ms, throughput: 2.3156 GB/s; offload_time: 1.3985 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,038] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,045] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,047] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6549 ms, throughput: 2.0654 GB/s; offload_time: 1.5721 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,047] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,049] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5973 ms, throughput: 2.1399 GB/s; offload_time: 1.5104 ms, put_time: 0.0868 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,049] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-ef038a3d90994c2fba2728c3eab408de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,051] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.7740 ms, throughput: 1.9267 GB/s; offload_time: 1.6856 ms, put_time: 0.0884 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,056] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,066] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,077] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,087] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,094] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-36268309084742b1a875d6f2d2f96cc3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,095] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4511 ms, throughput: 2.3555 GB/s; offload_time: 1.3707 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,100] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,107] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,109] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5010 ms, throughput: 2.2772 GB/s; offload_time: 1.4219 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,114] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,122] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-e4c2f65d1ea54728a33f05ee755c4f35 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,123] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5478 ms, throughput: 2.2083 GB/s; offload_time: 1.4644 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,128] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,135] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-2613347d2ee5408a93e94b209699e907 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,137] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4435 ms, throughput: 2.3679 GB/s; offload_time: 1.3607 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,142] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,149] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-fa9f6777e3c54166a12269a4992fc809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,151] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4848 ms, throughput: 2.3020 GB/s; offload_time: 1.3970 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,155] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,162] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-dd35d0a4f605422191cff264ec8e99ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,164] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4852 ms, throughput: 2.3013 GB/s; offload_time: 1.4044 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,169] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,179] LMCache INFO:[0m Reqid: chatcmpl-aae36f2c1b644c20a1e4bff0626bc325, Total tokens 1587, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,180] LMCache INFO:[0m Reqid: chatcmpl-b02281a4820b48a4b8ce5358d47a389c, Total tokens 720, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,181] LMCache INFO:[0m Reqid: chatcmpl-9a94630043fc4cd1acee35682761d75a, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,181] LMCache INFO:[0m Reqid: chatcmpl-ce8a56318d5745d8b81125d144c6b2d7, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,182] LMCache INFO:[0m Reqid: chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1, Total tokens 1217, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,229] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-9a94630043fc4cd1acee35682761d75a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,230] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 0.4376 ms, throughput: 6.2238 GB/s; offload_time: 0.3586 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,230] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-ce8a56318d5745d8b81125d144c6b2d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,231] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.5016 ms, throughput: 4.8975 GB/s; offload_time: 0.4285 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,237] LMCache INFO:[0m Reqid: chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1, Total tokens 1217, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,247] LMCache INFO:[0m Reqid: chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1, Total tokens 1217, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,256] LMCache INFO:[0m Reqid: chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1, Total tokens 1217, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,257] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 541, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,258] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 270, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,258] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,293] LMCache INFO:[0m Storing KV cache for 833 out of 1217 tokens (skip_leading_tokens=384) for request chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,295] LMCache INFO:[0m Stored 833 out of total 1217 tokens. size: 0.0222 gb, cost 1.8894 ms, throughput: 11.7730 GB/s; offload_time: 1.4746 ms, put_time: 0.4147 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,298] LMCache INFO:[0m Storing KV cache for 157 out of 541 tokens (skip_leading_tokens=384) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,302] LMCache INFO:[0m Stored 157 out of total 541 tokens. size: 0.0042 gb, cost 3.0252 ms, throughput: 1.3858 GB/s; offload_time: 2.8634 ms, put_time: 0.1618 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,302] LMCache INFO:[0m Storing KV cache for 270 out of 270 tokens (skip_leading_tokens=0) for request chatcmpl-a39aba9cb7de4b6da0f340f6b1792786 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,305] LMCache INFO:[0m Stored 270 out of total 270 tokens. size: 0.0072 gb, cost 2.3537 ms, throughput: 3.0632 GB/s; offload_time: 1.7646 ms, put_time: 0.5891 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,312] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,320] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-2d9480ba93634862832ba1bc11ca3f66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,320] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6122 ms, throughput: 5.5828 GB/s; offload_time: 0.5372 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,325] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,335] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,344] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,354] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,363] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,370] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0bdc7e9539904f8987d27d7e01030ebd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,372] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5269 ms, throughput: 2.2385 GB/s; offload_time: 1.4493 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42078 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:35,383] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-a45c2cb7e45d4ea2af7c6b630b74efd7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:35,385] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6246 ms, throughput: 2.1039 GB/s; offload_time: 1.5479 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,390] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 277, LMCache hit tokens: 270, need to load: 142 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,397] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,398] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4493 ms, throughput: 2.3584 GB/s; offload_time: 1.3734 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,402] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 277, LMCache hit tokens: 270, need to load: 206 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,409] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8fa0aea8164c4e40abac40538f8f190a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,411] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4412 ms, throughput: 2.3717 GB/s; offload_time: 1.3672 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,411] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,413] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5361 ms, throughput: 2.2250 GB/s; offload_time: 1.4608 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,418] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 277, LMCache hit tokens: 270, need to load: 222 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,425] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-338d4f820ea04507a7b2027c9dbb807c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,427] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5081 ms, throughput: 2.2664 GB/s; offload_time: 1.4338 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,438] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-079ce9ebfdf7439b8fefe15935833e6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,440] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5095 ms, throughput: 2.2643 GB/s; offload_time: 1.4284 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,444] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 552, LMCache hit tokens: 541, need to load: 109 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,445] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 277, LMCache hit tokens: 270, need to load: 222 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,456] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,457] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.4509 ms, throughput: 2.3557 GB/s; offload_time: 1.3739 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,471] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 141 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,480] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 173 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,487] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-2e970c546d614e04ab302a0b95ffa673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,489] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4724 ms, throughput: 2.3213 GB/s; offload_time: 1.3965 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,493] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 237 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,503] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 317 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,510] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c06d3fc50966439b9c9589d71ecede66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,512] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5102 ms, throughput: 2.2633 GB/s; offload_time: 1.4369 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,512] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d9b7008f9dd74b7b8aa726d8a0c73dfe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,514] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6030 ms, throughput: 2.1323 GB/s; offload_time: 1.5332 ms, put_time: 0.0698 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,518] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 477 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,528] LMCache INFO:[0m Reqid: chatcmpl-718002a0335348c88afa426e749abdd0, Total tokens 553, LMCache hit tokens: 541, need to load: 493 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,528] LMCache INFO:[0m Reqid: chatcmpl-a39aba9cb7de4b6da0f340f6b1792786, Total tokens 277, LMCache hit tokens: 270, need to load: 222 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,529] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 734, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,530] LMCache INFO:[0m Reqid: chatcmpl-528a033eb46d4c1386c91f60fb32bb34, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,530] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,556] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-528a033eb46d4c1386c91f60fb32bb34 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,556] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.4331 ms, throughput: 6.8437 GB/s; offload_time: 0.3588 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,557] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-8502eb66649144b596615aebce6f97a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,558] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.8397 ms, throughput: 4.0707 GB/s; offload_time: 0.7756 ms, put_time: 0.0640 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,558] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-8ee53076d2964cd1a6905e0132c86867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,559] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8702 ms, throughput: 3.9280 GB/s; offload_time: 0.7963 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,571] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-95aa0cdd7ba04c74909dc09fc8d9b6e7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,571] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5603 ms, throughput: 6.1001 GB/s; offload_time: 0.4710 ms, put_time: 0.0893 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,583] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b73b60eb8250453d922a74a9084fc644 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,584] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6446 ms, throughput: 5.3022 GB/s; offload_time: 0.5549 ms, put_time: 0.0897 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,588] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 736, LMCache hit tokens: 640, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,595] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,596] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6225 ms, throughput: 5.4911 GB/s; offload_time: 0.5183 ms, put_time: 0.1041 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,596] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-4db3458eb6e242fe9450f9fe484eb809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,598] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6228 ms, throughput: 2.1063 GB/s; offload_time: 1.5506 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:35,603] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 736, LMCache hit tokens: 640, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:35,610] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-a171fb15096d4b79b0c38d5e8d660b1a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,612] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6061 ms, throughput: 2.1281 GB/s; offload_time: 1.5173 ms, put_time: 0.0888 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,617] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 736, LMCache hit tokens: 640, need to load: 224 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,617] LMCache INFO:[0m Reqid: chatcmpl-528a033eb46d4c1386c91f60fb32bb34, Total tokens 112, LMCache hit tokens: 111, need to load: 63 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,618] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,631] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,632] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6160 ms, throughput: 2.1150 GB/s; offload_time: 1.5176 ms, put_time: 0.0985 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,638] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,645] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0771ed5c78634680af10150b90ea46fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,647] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5712 ms, throughput: 2.1753 GB/s; offload_time: 1.4884 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,647] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dfd0b592410f4547b9022781d0368c57 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,649] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.6490 ms, throughput: 2.0727 GB/s; offload_time: 1.5750 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,653] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,663] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,673] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,682] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,692] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,699] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-954bcb9f39b346b5852999097a717f77 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,700] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4837 ms, throughput: 2.3036 GB/s; offload_time: 1.4058 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,704] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,714] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,724] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,740] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-5fa75b0dead348a391e894f59dcd91cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,742] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5555 ms, throughput: 2.1974 GB/s; offload_time: 1.4788 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,747] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 746, LMCache hit tokens: 640, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,756] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 746, LMCache hit tokens: 640, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,763] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-3ee3d46cdba64de78e720d37dd26865c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,765] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4684 ms, throughput: 2.3276 GB/s; offload_time: 1.3908 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,765] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-c4b593be2cf74d8dab97c112965087d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,767] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6439 ms, throughput: 2.0791 GB/s; offload_time: 1.5732 ms, put_time: 0.0707 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,767] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-1a812f673eab4accb36f93153ae217e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,770] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.9706 ms, throughput: 1.7345 GB/s; offload_time: 1.8144 ms, put_time: 0.1562 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,775] LMCache INFO:[0m Reqid: chatcmpl-c553555acc5f4ceab8715c5a335bee76, Total tokens 746, LMCache hit tokens: 640, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,775] LMCache INFO:[0m Reqid: chatcmpl-528a033eb46d4c1386c91f60fb32bb34, Total tokens 122, LMCache hit tokens: 111, need to load: 63 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,776] LMCache INFO:[0m Reqid: chatcmpl-0dd21f76fcab43e7be8218a442ad979d, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,777] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,808] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,815] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c3c85df9ee2f4e7e8b724341f0bb704b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,815] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5107 ms, throughput: 6.6929 GB/s; offload_time: 0.4299 ms, put_time: 0.0807 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,820] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:35,830] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,840] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,847] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-1d084d1708e64f7d83c8ea32ea5af162 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,848] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4685 ms, throughput: 7.2958 GB/s; offload_time: 0.3954 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,852] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,859] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5ac861930d3642c7a8caf0b72138771c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,860] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4936 ms, throughput: 6.9251 GB/s; offload_time: 0.4172 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,865] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1197, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,866] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,893] LMCache INFO:[0m Storing KV cache for 173 out of 1197 tokens (skip_leading_tokens=1024) for request chatcmpl-67ab76f3b9264b65b1187c9fc3514f95 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,894] LMCache INFO:[0m Stored 173 out of total 1197 tokens. size: 0.0046 gb, cost 0.8374 ms, throughput: 5.5167 GB/s; offload_time: 0.7277 ms, put_time: 0.1097 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,895] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ffff9f2a61214e77bba733dbc961c551 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,896] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4703 ms, throughput: 2.3247 GB/s; offload_time: 1.3842 ms, put_time: 0.0861 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,897] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-528a033eb46d4c1386c91f60fb32bb34 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,897] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6356 ms, throughput: 5.3773 GB/s; offload_time: 0.5693 ms, put_time: 0.0663 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,903] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,910] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,911] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6285 ms, throughput: 5.4386 GB/s; offload_time: 0.5529 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,915] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,922] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b02281a4820b48a4b8ce5358d47a389c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,923] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5570 ms, throughput: 6.1363 GB/s; offload_time: 0.4798 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,927] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,944] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-50e3820fcfea4fa8b2d4b5443e23de6f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,945] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5479 ms, throughput: 6.2387 GB/s; offload_time: 0.4545 ms, put_time: 0.0933 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,950] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1201, LMCache hit tokens: 1197, need to load: 45 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,957] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-731f7ce2f25942ca8f6fcafb9a8b42df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,958] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6370 ms, throughput: 5.3654 GB/s; offload_time: 0.5629 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,958] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-37f59dc8758747b49e78b10d2ea80f68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,959] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5978 ms, throughput: 5.7177 GB/s; offload_time: 0.5283 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,964] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1201, LMCache hit tokens: 1197, need to load: 109 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,971] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-082806fea8554eaebce6967ee67e4a24 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,973] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5442 ms, throughput: 2.2135 GB/s; offload_time: 1.4565 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,973] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-dcb4de26086b4dbca291a64dd9190ec1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,975] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.7647 ms, throughput: 1.9369 GB/s; offload_time: 1.6804 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:35,980] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1201, LMCache hit tokens: 1197, need to load: 221 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,989] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1201, LMCache hit tokens: 1197, need to load: 317 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:35,999] LMCache INFO:[0m Reqid: chatcmpl-67ab76f3b9264b65b1187c9fc3514f95, Total tokens 1201, LMCache hit tokens: 1197, need to load: 365 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,000] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,013] LMCache INFO:[0m Reqid: chatcmpl-a4a55da16bb24380a9325fcbc4767c66, Total tokens 811, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,014] LMCache INFO:[0m Reqid: chatcmpl-1ef129d441ed4c3988f270b9b1268b05, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,014] LMCache INFO:[0m Reqid: chatcmpl-84697ad7c2f248fd9cc7be112b98b137, Total tokens 437, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42138 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,036] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-1ef129d441ed4c3988f270b9b1268b05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,037] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.4340 ms, throughput: 6.3982 GB/s; offload_time: 0.3630 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,042] LMCache INFO:[0m Reqid: chatcmpl-84697ad7c2f248fd9cc7be112b98b137, Total tokens 437, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,043] LMCache INFO:[0m Reqid: chatcmpl-7fac1ec0384c47408a7f94da2a443f8e, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,043] LMCache INFO:[0m Reqid: chatcmpl-cbfc55bf08c74f409129c82582e34545, Total tokens 270, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,044] LMCache INFO:[0m Reqid: chatcmpl-0e3a936234c548998b13235805422dd8, Total tokens 167, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,044] LMCache INFO:[0m Reqid: chatcmpl-f1afb7b029dc473786e56a1de0d1247a, Total tokens 125, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,044] LMCache INFO:[0m Reqid: chatcmpl-7219c025d76f420baa3029cb4b0553ff, Total tokens 124, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,045] LMCache INFO:[0m Reqid: chatcmpl-c6a5e4b01cae4e45845432b6efafbd9a, Total tokens 454, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,071] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-7fac1ec0384c47408a7f94da2a443f8e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,072] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.4639 ms, throughput: 5.9292 GB/s; offload_time: 0.3805 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,072] LMCache INFO:[0m Storing KV cache for 142 out of 270 tokens (skip_leading_tokens=128) for request chatcmpl-cbfc55bf08c74f409129c82582e34545 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,074] LMCache INFO:[0m Stored 142 out of total 270 tokens. size: 0.0038 gb, cost 1.1501 ms, throughput: 3.2969 GB/s; offload_time: 1.0520 ms, put_time: 0.0981 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,074] LMCache INFO:[0m Storing KV cache for 125 out of 125 tokens (skip_leading_tokens=0) for request chatcmpl-f1afb7b029dc473786e56a1de0d1247a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,075] LMCache INFO:[0m Stored 125 out of total 125 tokens. size: 0.0033 gb, cost 0.9077 ms, throughput: 3.6771 GB/s; offload_time: 0.8480 ms, put_time: 0.0597 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,077] LMCache INFO:[0m Storing KV cache for 124 out of 124 tokens (skip_leading_tokens=0) for request chatcmpl-7219c025d76f420baa3029cb4b0553ff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,079] LMCache INFO:[0m Stored 124 out of total 124 tokens. size: 0.0033 gb, cost 2.0010 ms, throughput: 1.6548 GB/s; offload_time: 1.9350 ms, put_time: 0.0659 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,084] LMCache INFO:[0m Reqid: chatcmpl-c6a5e4b01cae4e45845432b6efafbd9a, Total tokens 454, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,084] LMCache INFO:[0m Reqid: chatcmpl-358991dc75d24d96b3c9b552df4d3cbc, Total tokens 111, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,085] LMCache INFO:[0m Reqid: chatcmpl-dcda0417d4f84668b467a612389b2d1c, Total tokens 1391, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,105] LMCache INFO:[0m Storing KV cache for 111 out of 111 tokens (skip_leading_tokens=0) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,105] LMCache INFO:[0m Stored 111 out of total 111 tokens. size: 0.0030 gb, cost 0.4303 ms, throughput: 6.8886 GB/s; offload_time: 0.3471 ms, put_time: 0.0832 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,110] LMCache INFO:[0m Reqid: chatcmpl-dcda0417d4f84668b467a612389b2d1c, Total tokens 1391, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,120] LMCache INFO:[0m Reqid: chatcmpl-dcda0417d4f84668b467a612389b2d1c, Total tokens 1391, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,127] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-f1afb7b029dc473786e56a1de0d1247a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,128] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5106 ms, throughput: 6.6943 GB/s; offload_time: 0.4223 ms, put_time: 0.0882 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,132] LMCache INFO:[0m Reqid: chatcmpl-dcda0417d4f84668b467a612389b2d1c, Total tokens 1391, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,134] LMCache INFO:[0m Reqid: chatcmpl-123ca33f27a0404fb383c65f2a5275b4, Total tokens 746, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,168] LMCache INFO:[0m Storing KV cache for 239 out of 1391 tokens (skip_leading_tokens=1152) for request chatcmpl-dcda0417d4f84668b467a612389b2d1c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,169] LMCache INFO:[0m Stored 239 out of total 1391 tokens. size: 0.0064 gb, cost 0.7839 ms, throughput: 8.1412 GB/s; offload_time: 0.6694 ms, put_time: 0.1145 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,169] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,170] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.9199 ms, throughput: 3.7155 GB/s; offload_time: 0.8441 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,171] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-7219c025d76f420baa3029cb4b0553ff [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,172] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4337 ms, throughput: 7.8813 GB/s; offload_time: 0.3725 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,178] LMCache INFO:[0m Reqid: chatcmpl-123ca33f27a0404fb383c65f2a5275b4, Total tokens 746, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,179] LMCache INFO:[0m Reqid: chatcmpl-5823ac8245f3409f97906c835e396e36, Total tokens 1172, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,201] LMCache INFO:[0m Reqid: chatcmpl-5823ac8245f3409f97906c835e396e36, Total tokens 1172, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,211] LMCache INFO:[0m Reqid: chatcmpl-5823ac8245f3409f97906c835e396e36, Total tokens 1172, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,221] LMCache INFO:[0m Reqid: chatcmpl-5823ac8245f3409f97906c835e396e36, Total tokens 1172, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,230] LMCache INFO:[0m Reqid: chatcmpl-5823ac8245f3409f97906c835e396e36, Total tokens 1172, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,231] LMCache INFO:[0m Reqid: chatcmpl-659e98618a4e4cd59577cc184510432a, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,232] LMCache INFO:[0m Reqid: chatcmpl-5ac7e7ed983a463f94c9638e1ea36dc9, Total tokens 227, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,232] LMCache INFO:[0m Reqid: chatcmpl-c941798525144ccb9375d987ebcc765e, Total tokens 920, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42160 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,261] LMCache INFO:[0m Storing KV cache for 148 out of 1172 tokens (skip_leading_tokens=1024) for request chatcmpl-5823ac8245f3409f97906c835e396e36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,262] LMCache INFO:[0m Stored 148 out of total 1172 tokens. size: 0.0040 gb, cost 0.7679 ms, throughput: 5.1468 GB/s; offload_time: 0.6625 ms, put_time: 0.1053 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,262] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-659e98618a4e4cd59577cc184510432a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,263] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.5423 ms, throughput: 4.5297 GB/s; offload_time: 0.4666 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,264] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c54a20d5ca0f4f12ab70a2de6b21b6c1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,265] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.0240 ms, throughput: 3.3378 GB/s; offload_time: 0.9664 ms, put_time: 0.0576 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,271] LMCache INFO:[0m Reqid: chatcmpl-c941798525144ccb9375d987ebcc765e, Total tokens 920, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,272] LMCache INFO:[0m Reqid: chatcmpl-dfb88c495f6c4085a5ae1ed230020028, Total tokens 1123, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,273] LMCache INFO:[0m Reqid: chatcmpl-a73b408a28c345aaac1f4cf331114f47, Total tokens 466, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,305] LMCache INFO:[0m Storing KV cache for 152 out of 920 tokens (skip_leading_tokens=768) for request chatcmpl-c941798525144ccb9375d987ebcc765e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,306] LMCache INFO:[0m Stored 152 out of total 920 tokens. size: 0.0041 gb, cost 0.8460 ms, throughput: 4.7976 GB/s; offload_time: 0.6620 ms, put_time: 0.1840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,311] LMCache INFO:[0m Reqid: chatcmpl-a73b408a28c345aaac1f4cf331114f47, Total tokens 466, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,318] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6b312c9894c5484cba9e9fd44f10061a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,319] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5335 ms, throughput: 6.4069 GB/s; offload_time: 0.4425 ms, put_time: 0.0910 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,330] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-a978aa8c263e4e68be3feaa3da3d19bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,331] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6234 ms, throughput: 5.4828 GB/s; offload_time: 0.5351 ms, put_time: 0.0883 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,336] LMCache INFO:[0m Reqid: chatcmpl-dfb88c495f6c4085a5ae1ed230020028, Total tokens 1125, LMCache hit tokens: 1024, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,337] LMCache INFO:[0m Reqid: chatcmpl-a73b408a28c345aaac1f4cf331114f47, Total tokens 466, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,337] LMCache INFO:[0m Reqid: chatcmpl-38504b82be154ec8996ead7e4737e4aa, Total tokens 384, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,338] LMCache INFO:[0m Reqid: chatcmpl-4008202106ff423fa2a57bc6f93edae2, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,338] LMCache INFO:[0m Reqid: chatcmpl-b0b1fa6c97a34c3aa8346cee55f87808, Total tokens 181, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,338] LMCache INFO:[0m Reqid: chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4, Total tokens 358, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,364] LMCache INFO:[0m Storing KV cache for 256 out of 384 tokens (skip_leading_tokens=128) for request chatcmpl-38504b82be154ec8996ead7e4737e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,365] LMCache INFO:[0m Stored 256 out of total 384 tokens. size: 0.0068 gb, cost 0.7158 ms, throughput: 9.5494 GB/s; offload_time: 0.6074 ms, put_time: 0.1085 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,366] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-4008202106ff423fa2a57bc6f93edae2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,367] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 1.0600 ms, throughput: 2.3177 GB/s; offload_time: 0.9942 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,373] LMCache INFO:[0m Reqid: chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4, Total tokens 358, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,383] LMCache INFO:[0m Reqid: chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4, Total tokens 358, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,393] LMCache INFO:[0m Reqid: chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4, Total tokens 358, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42170 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,409] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-9fb52d27fd154424ba7de27bd7c90bce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,410] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5885 ms, throughput: 5.8083 GB/s; offload_time: 0.4990 ms, put_time: 0.0895 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,410] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-ec99baedd4ad427e89e393eb0dd9054f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,411] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.7828 ms, throughput: 4.3661 GB/s; offload_time: 0.7172 ms, put_time: 0.0656 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,416] LMCache INFO:[0m Reqid: chatcmpl-b0b1fa6c97a34c3aa8346cee55f87808, Total tokens 185, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,417] LMCache INFO:[0m Reqid: chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4, Total tokens 358, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,417] LMCache INFO:[0m Reqid: chatcmpl-15ca1ca3ba4d40bcba33754ad8c799a4, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,417] LMCache INFO:[0m Reqid: chatcmpl-477ae66218074dd5aeda126f0a8efde3, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,418] LMCache INFO:[0m Reqid: chatcmpl-e51376f64f194a28b2ecec8e7d57d826, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,418] LMCache INFO:[0m Reqid: chatcmpl-11597f2f09d0425ba7d05dc23385010f, Total tokens 184, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,418] LMCache INFO:[0m Reqid: chatcmpl-00741ca94004437a8782f93d7321d385, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,419] LMCache INFO:[0m Reqid: chatcmpl-8bb8e4226c0c45c98feda9a7d141aea3, Total tokens 258, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,419] LMCache INFO:[0m Reqid: chatcmpl-352d3c5130c742de95f1aab262dbfdeb, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,420] LMCache INFO:[0m Reqid: chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf, Total tokens 1445, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,446] LMCache INFO:[0m Storing KV cache for 230 out of 358 tokens (skip_leading_tokens=128) for request chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,447] LMCache INFO:[0m Stored 230 out of total 358 tokens. size: 0.0061 gb, cost 0.7210 ms, throughput: 8.5184 GB/s; offload_time: 0.6133 ms, put_time: 0.1077 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,447] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-15ca1ca3ba4d40bcba33754ad8c799a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,448] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.5264 ms, throughput: 5.0729 GB/s; offload_time: 0.4496 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,449] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-477ae66218074dd5aeda126f0a8efde3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,449] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.5671 ms, throughput: 4.6142 GB/s; offload_time: 0.5105 ms, put_time: 0.0566 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,450] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-e51376f64f194a28b2ecec8e7d57d826 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,451] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 1.1693 ms, throughput: 2.4435 GB/s; offload_time: 1.0658 ms, put_time: 0.1036 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,451] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-00741ca94004437a8782f93d7321d385 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,452] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.6166 ms, throughput: 3.9844 GB/s; offload_time: 0.5499 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,452] LMCache INFO:[0m Storing KV cache for 130 out of 258 tokens (skip_leading_tokens=128) for request chatcmpl-8bb8e4226c0c45c98feda9a7d141aea3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,455] LMCache INFO:[0m Stored 130 out of total 258 tokens. size: 0.0035 gb, cost 2.6696 ms, throughput: 1.3003 GB/s; offload_time: 2.5053 ms, put_time: 0.1643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,456] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-352d3c5130c742de95f1aab262dbfdeb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,456] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.5487 ms, throughput: 4.8663 GB/s; offload_time: 0.4685 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,457] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,459] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.7253 ms, throughput: 1.9811 GB/s; offload_time: 1.6531 ms, put_time: 0.0722 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,464] LMCache INFO:[0m Reqid: chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf, Total tokens 1445, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,474] LMCache INFO:[0m Reqid: chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf, Total tokens 1445, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,481] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-f46c19b32fb0425d9e457d07f6637516 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,483] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5438 ms, throughput: 2.2140 GB/s; offload_time: 1.4667 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,483] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-aae36f2c1b644c20a1e4bff0626bc325 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,485] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6857 ms, throughput: 2.0276 GB/s; offload_time: 1.6141 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,490] LMCache INFO:[0m Reqid: chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf, Total tokens 1445, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,491] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,525] LMCache INFO:[0m Storing KV cache for 165 out of 1445 tokens (skip_leading_tokens=1280) for request chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42198 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,527] LMCache INFO:[0m Stored 165 out of total 1445 tokens. size: 0.0044 gb, cost 0.9898 ms, throughput: 4.4515 GB/s; offload_time: 0.8745 ms, put_time: 0.1153 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,527] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-dcda0417d4f84668b467a612389b2d1c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42214 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,529] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.3501 ms, throughput: 2.5317 GB/s; offload_time: 1.2840 ms, put_time: 0.0661 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,535] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,541] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-57cf3c06e0cb4c78b6becb11ef8f6dd3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,542] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5295 ms, throughput: 6.4546 GB/s; offload_time: 0.4574 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,547] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,554] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,555] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5750 ms, throughput: 5.9439 GB/s; offload_time: 0.4894 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,555] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-0f72040bd12841108e22539e8bb1b1ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,556] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6574 ms, throughput: 5.1995 GB/s; offload_time: 0.5949 ms, put_time: 0.0625 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,556] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1ef129d441ed4c3988f270b9b1268b05 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,557] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6333 ms, throughput: 5.3967 GB/s; offload_time: 0.5669 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,562] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,569] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-820219768dfc40799ba3e47b4f7e70b0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,569] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6609 ms, throughput: 5.1714 GB/s; offload_time: 0.5762 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,574] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,584] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,591] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c25b123b9f134c71b45a81130e61472b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,592] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5159 ms, throughput: 6.6255 GB/s; offload_time: 0.4421 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,596] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,604] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-123ca33f27a0404fb383c65f2a5275b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,605] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5420 ms, throughput: 6.3061 GB/s; offload_time: 0.4678 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,609] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,619] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,629] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,639] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,647] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-7e30118e271347c39b9139ff0cdbd881 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,647] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6327 ms, throughput: 5.4026 GB/s; offload_time: 0.5467 ms, put_time: 0.0859 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,648] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0e2d486282044514b478642d58315247 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,650] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6991 ms, throughput: 2.0117 GB/s; offload_time: 1.6176 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,655] LMCache INFO:[0m Reqid: chatcmpl-8a316371df5443debff479fb5c46bb5c, Total tokens 1118, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,656] LMCache INFO:[0m Reqid: chatcmpl-2aecb0a0d37540b986a099bfb136bde2, Total tokens 518, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,656] LMCache INFO:[0m Reqid: chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e, Total tokens 624, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,657] LMCache INFO:[0m Reqid: chatcmpl-9842a449d6c847dfae7a669779d99d4a, Total tokens 104, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,657] LMCache INFO:[0m Reqid: chatcmpl-9ba16f1c104a4ff4a4d99c1d0d9c919b, Total tokens 268, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,701] LMCache INFO:[0m Storing KV cache for 134 out of 518 tokens (skip_leading_tokens=384) for request chatcmpl-2aecb0a0d37540b986a099bfb136bde2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,701] LMCache INFO:[0m Stored 134 out of total 518 tokens. size: 0.0036 gb, cost 0.6927 ms, throughput: 5.1653 GB/s; offload_time: 0.5809 ms, put_time: 0.1118 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,702] LMCache INFO:[0m Storing KV cache for 104 out of 104 tokens (skip_leading_tokens=0) for request chatcmpl-9842a449d6c847dfae7a669779d99d4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,703] LMCache INFO:[0m Stored 104 out of total 104 tokens. size: 0.0028 gb, cost 0.7713 ms, throughput: 3.6006 GB/s; offload_time: 0.6968 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,715] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-470591f6fbce48e3aba192024f34042d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,716] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6305 ms, throughput: 5.4213 GB/s; offload_time: 0.5514 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,720] LMCache INFO:[0m Reqid: chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e, Total tokens 625, LMCache hit tokens: 512, need to load: -32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,727] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a49473a0c52449f7904f232ba6e33e59 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,728] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4669 ms, throughput: 7.3200 GB/s; offload_time: 0.3926 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,733] LMCache INFO:[0m Reqid: chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e, Total tokens 625, LMCache hit tokens: 512, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,742] LMCache INFO:[0m Reqid: chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e, Total tokens 625, LMCache hit tokens: 512, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,752] LMCache INFO:[0m Reqid: chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e, Total tokens 625, LMCache hit tokens: 512, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,753] LMCache INFO:[0m Reqid: chatcmpl-9842a449d6c847dfae7a669779d99d4a, Total tokens 105, LMCache hit tokens: 104, need to load: 56 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,753] LMCache INFO:[0m Reqid: chatcmpl-9ba16f1c104a4ff4a4d99c1d0d9c919b, Total tokens 268, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,754] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,772] LMCache INFO:[0m Storing KV cache for 140 out of 268 tokens (skip_leading_tokens=128) for request chatcmpl-9ba16f1c104a4ff4a4d99c1d0d9c919b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,773] LMCache INFO:[0m Stored 140 out of total 268 tokens. size: 0.0037 gb, cost 0.6838 ms, throughput: 5.4669 GB/s; offload_time: 0.5778 ms, put_time: 0.1060 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,778] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,785] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a65daf8b93eb41fd8d49551212038187 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,786] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4911 ms, throughput: 6.9593 GB/s; offload_time: 0.4175 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,786] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5ac7e7ed983a463f94c9638e1ea36dc9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,787] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5317 ms, throughput: 6.4285 GB/s; offload_time: 0.4662 ms, put_time: 0.0655 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,792] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,800] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,800] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.5794 ms, throughput: 5.8994 GB/s; offload_time: 0.5074 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,801] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,802] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5892 ms, throughput: 2.1508 GB/s; offload_time: 1.5196 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,803] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-e51376f64f194a28b2ecec8e7d57d826 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,805] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 2.0532 ms, throughput: 1.6647 GB/s; offload_time: 1.9596 ms, put_time: 0.0937 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,811] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,821] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,830] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,840] LMCache INFO:[0m Reqid: chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,842] LMCache INFO:[0m Reqid: chatcmpl-8891c8804ff84b5f8a26b4adae181196, Total tokens 1375, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,843] LMCache INFO:[0m Reqid: chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17, Total tokens 1441, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:36,894] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,895] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.7504 ms, throughput: 4.5548 GB/s; offload_time: 0.6462 ms, put_time: 0.1042 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,902] LMCache INFO:[0m Reqid: chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17, Total tokens 1441, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,902] LMCache INFO:[0m Reqid: chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,903] LMCache INFO:[0m Reqid: chatcmpl-780968a859634fc9b6a83b528605a446, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,929] LMCache INFO:[0m Storing KV cache for 161 out of 1441 tokens (skip_leading_tokens=1280) for request chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,930] LMCache INFO:[0m Stored 161 out of total 1441 tokens. size: 0.0043 gb, cost 0.7921 ms, throughput: 5.4277 GB/s; offload_time: 0.6823 ms, put_time: 0.1098 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,931] LMCache INFO:[0m Storing KV cache for 107 out of 107 tokens (skip_leading_tokens=0) for request chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,932] LMCache INFO:[0m Stored 107 out of total 107 tokens. size: 0.0029 gb, cost 0.8208 ms, throughput: 3.4810 GB/s; offload_time: 0.6257 ms, put_time: 0.1951 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,932] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,933] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7020 ms, throughput: 4.8690 GB/s; offload_time: 0.6164 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,938] LMCache INFO:[0m Reqid: chatcmpl-780968a859634fc9b6a83b528605a446, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,939] LMCache INFO:[0m Reqid: chatcmpl-eae9b5303a7e47f0899d3465047c4095, Total tokens 123, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,940] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,953] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-780968a859634fc9b6a83b528605a446 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,954] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.4556 ms, throughput: 7.1501 GB/s; offload_time: 0.3826 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,954] LMCache INFO:[0m Storing KV cache for 123 out of 123 tokens (skip_leading_tokens=0) for request chatcmpl-eae9b5303a7e47f0899d3465047c4095 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,955] LMCache INFO:[0m Stored 123 out of total 123 tokens. size: 0.0033 gb, cost 0.6007 ms, throughput: 5.4677 GB/s; offload_time: 0.5267 ms, put_time: 0.0740 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,955] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-348f752a200a4f37b4aa5c92d9a2b32b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,956] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4533 ms, throughput: 7.5403 GB/s; offload_time: 0.3921 ms, put_time: 0.0612 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,961] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,968] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-15ca1ca3ba4d40bcba33754ad8c799a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,969] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4645 ms, throughput: 7.3589 GB/s; offload_time: 0.3914 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,969] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-352d3c5130c742de95f1aab262dbfdeb [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,969] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.3894 ms, throughput: 8.7778 GB/s; offload_time: 0.3268 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,974] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,981] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-90467bbcea9948e48fbd950d9ffc0fa1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,981] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5075 ms, throughput: 6.7344 GB/s; offload_time: 0.4269 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,993] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,994] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 0.6530 ms, throughput: 5.2346 GB/s; offload_time: 0.5726 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,994] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,996] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.8963 ms, throughput: 1.8024 GB/s; offload_time: 1.8244 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:36,996] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-477ae66218074dd5aeda126f0a8efde3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:36,998] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5102 ms, throughput: 2.2632 GB/s; offload_time: 1.4355 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,012] LMCache INFO:[0m Reqid: chatcmpl-780968a859634fc9b6a83b528605a446, Total tokens 126, LMCache hit tokens: 122, need to load: 74 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,032] LMCache INFO:[0m Reqid: chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c, Total tokens 114, LMCache hit tokens: 107, need to load: 59 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,032] LMCache INFO:[0m Reqid: chatcmpl-780968a859634fc9b6a83b528605a446, Total tokens 126, LMCache hit tokens: 122, need to load: 74 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,032] LMCache INFO:[0m Reqid: chatcmpl-eae9b5303a7e47f0899d3465047c4095, Total tokens 126, LMCache hit tokens: 123, need to load: 75 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,033] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,044] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,046] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4543 ms, throughput: 2.3503 GB/s; offload_time: 1.3828 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,046] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,048] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5795 ms, throughput: 2.1640 GB/s; offload_time: 1.5143 ms, put_time: 0.0651 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,053] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,063] LMCache INFO:[0m Reqid: chatcmpl-870c116c795e4f369cc278cb5e9b353f, Total tokens 937, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,064] LMCache INFO:[0m Reqid: chatcmpl-cb36c770d48643c3a38671bff259f7fe, Total tokens 229, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,064] LMCache INFO:[0m Reqid: chatcmpl-0ac532e795c4449f8e947d21aa1bb6fa, Total tokens 472, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,065] LMCache INFO:[0m Reqid: chatcmpl-d6a863d028bf458f9be13aa8a8a5b7d4, Total tokens 112, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,065] LMCache INFO:[0m Reqid: chatcmpl-5f1b8eb662c546cea132b9500025a300, Total tokens 370, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,066] LMCache INFO:[0m Reqid: chatcmpl-51701e2aae1b4477b3b72298c04be25a, Total tokens 846, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,067] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,119] LMCache INFO:[0m Storing KV cache for 229 out of 229 tokens (skip_leading_tokens=0) for request chatcmpl-cb36c770d48643c3a38671bff259f7fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,120] LMCache INFO:[0m Stored 229 out of total 229 tokens. size: 0.0061 gb, cost 0.7050 ms, throughput: 8.6732 GB/s; offload_time: 0.5905 ms, put_time: 0.1145 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,121] LMCache INFO:[0m Storing KV cache for 216 out of 472 tokens (skip_leading_tokens=256) for request chatcmpl-0ac532e795c4449f8e947d21aa1bb6fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,122] LMCache INFO:[0m Stored 216 out of total 472 tokens. size: 0.0058 gb, cost 1.2125 ms, throughput: 4.7568 GB/s; offload_time: 1.0657 ms, put_time: 0.1469 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,122] LMCache INFO:[0m Storing KV cache for 112 out of 112 tokens (skip_leading_tokens=0) for request chatcmpl-d6a863d028bf458f9be13aa8a8a5b7d4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,123] LMCache INFO:[0m Stored 112 out of total 112 tokens. size: 0.0030 gb, cost 0.8175 ms, throughput: 3.6584 GB/s; offload_time: 0.7496 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,124] LMCache INFO:[0m Storing KV cache for 370 out of 370 tokens (skip_leading_tokens=0) for request chatcmpl-5f1b8eb662c546cea132b9500025a300 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,126] LMCache INFO:[0m Stored 370 out of total 370 tokens. size: 0.0099 gb, cost 1.7738 ms, throughput: 5.5699 GB/s; offload_time: 1.6516 ms, put_time: 0.1222 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,126] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-780968a859634fc9b6a83b528605a446 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,129] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 2.4547 ms, throughput: 1.3924 GB/s; offload_time: 2.3848 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,129] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-eae9b5303a7e47f0899d3465047c4095 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,131] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5736 ms, throughput: 2.1721 GB/s; offload_time: 1.5024 ms, put_time: 0.0712 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,137] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,146] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,156] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,165] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,175] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,182] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,184] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5008 ms, throughput: 2.2774 GB/s; offload_time: 1.4160 ms, put_time: 0.0848 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,184] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c6a5e4b01cae4e45845432b6efafbd9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,186] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.6408 ms, throughput: 2.0831 GB/s; offload_time: 1.5688 ms, put_time: 0.0720 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,191] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,198] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,200] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5327 ms, throughput: 2.2300 GB/s; offload_time: 1.4558 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,200] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,202] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5832 ms, throughput: 2.1589 GB/s; offload_time: 1.5135 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,202] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ef038a3d90994c2fba2728c3eab408de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,205] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.0148 ms, throughput: 1.6964 GB/s; offload_time: 1.9459 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,205] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-9842a449d6c847dfae7a669779d99d4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,207] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.7992 ms, throughput: 1.8997 GB/s; offload_time: 1.7289 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,212] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,221] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,231] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,240] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,249] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,256] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,258] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5531 ms, throughput: 2.2008 GB/s; offload_time: 1.4773 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,262] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,270] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-8a316371df5443debff479fb5c46bb5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,272] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5301 ms, throughput: 2.2338 GB/s; offload_time: 1.4553 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,272] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,274] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5868 ms, throughput: 2.1540 GB/s; offload_time: 1.5174 ms, put_time: 0.0694 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,279] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,289] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,296] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5f1b8eb662c546cea132b9500025a300 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,297] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5010 ms, throughput: 2.2771 GB/s; offload_time: 1.4241 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,301] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,309] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-dd35d0a4f605422191cff264ec8e99ce [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,311] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7320 ms, throughput: 1.9734 GB/s; offload_time: 1.6404 ms, put_time: 0.0916 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42454 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,316] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,323] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d6a863d028bf458f9be13aa8a8a5b7d4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,325] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4308 ms, throughput: 2.3888 GB/s; offload_time: 1.3538 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,330] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,339] LMCache INFO:[0m Reqid: chatcmpl-db5b6cacd4d14501a0dd99d86c132c60, Total tokens 1011, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,340] LMCache INFO:[0m Reqid: chatcmpl-76409cc1f3534dfca9067a028a9881c5, Total tokens 486, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,368] LMCache INFO:[0m Storing KV cache for 371 out of 1011 tokens (skip_leading_tokens=640) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,369] LMCache INFO:[0m Stored 371 out of total 1011 tokens. size: 0.0099 gb, cost 1.5241 ms, throughput: 6.5002 GB/s; offload_time: 0.8236 ms, put_time: 0.7005 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,370] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a39aba9cb7de4b6da0f340f6b1792786 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,371] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.0632 ms, throughput: 3.2147 GB/s; offload_time: 0.9972 ms, put_time: 0.0660 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,377] LMCache INFO:[0m Reqid: chatcmpl-76409cc1f3534dfca9067a028a9881c5, Total tokens 486, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,378] LMCache INFO:[0m Reqid: chatcmpl-b310ef7357e84bacadcfecac0cf97202, Total tokens 275, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,378] LMCache INFO:[0m Reqid: chatcmpl-09f85861f15b46dc9d0b088992967ba2, Total tokens 186, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,401] LMCache INFO:[0m Storing KV cache for 147 out of 275 tokens (skip_leading_tokens=128) for request chatcmpl-b310ef7357e84bacadcfecac0cf97202 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,402] LMCache INFO:[0m Stored 147 out of total 275 tokens. size: 0.0039 gb, cost 0.6940 ms, throughput: 5.6557 GB/s; offload_time: 0.5862 ms, put_time: 0.1079 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,407] LMCache INFO:[0m Reqid: chatcmpl-09f85861f15b46dc9d0b088992967ba2, Total tokens 186, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,417] LMCache INFO:[0m Reqid: chatcmpl-09f85861f15b46dc9d0b088992967ba2, Total tokens 186, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,424] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-2d9480ba93634862832ba1bc11ca3f66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,425] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.7170 ms, throughput: 4.7669 GB/s; offload_time: 0.6317 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,439] LMCache INFO:[0m Reqid: chatcmpl-b310ef7357e84bacadcfecac0cf97202, Total tokens 278, LMCache hit tokens: 275, need to load: 163 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,446] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-67ab76f3b9264b65b1187c9fc3514f95 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,447] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6139 ms, throughput: 5.5680 GB/s; offload_time: 0.5354 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,451] LMCache INFO:[0m Reqid: chatcmpl-b310ef7357e84bacadcfecac0cf97202, Total tokens 278, LMCache hit tokens: 275, need to load: 227 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,451] LMCache INFO:[0m Reqid: chatcmpl-09f85861f15b46dc9d0b088992967ba2, Total tokens 186, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,452] LMCache INFO:[0m Reqid: chatcmpl-be2a14c5605c4c00b29d77ccab34e42e, Total tokens 152, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,453] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42508 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,473] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,483] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,493] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,500] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-cb36c770d48643c3a38671bff259f7fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,500] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5133 ms, throughput: 6.6594 GB/s; offload_time: 0.4334 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,511] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,518] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,520] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5891 ms, throughput: 2.1509 GB/s; offload_time: 1.5103 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,524] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,532] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8fa0aea8164c4e40abac40538f8f190a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,534] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5100 ms, throughput: 2.2635 GB/s; offload_time: 1.4310 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,534] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,536] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.6082 ms, throughput: 2.1254 GB/s; offload_time: 1.5344 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,541] LMCache INFO:[0m Reqid: chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f, Total tokens 2600, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,542] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,594] LMCache INFO:[0m Storing KV cache for 2600 out of 2600 tokens (skip_leading_tokens=0) for request chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42558 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,615] LMCache INFO:[0m Stored 2600 out of total 2600 tokens. size: 0.0694 gb, cost 20.3244 ms, throughput: 3.4160 GB/s; offload_time: 19.1317 ms, put_time: 1.1928 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,616] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-338d4f820ea04507a7b2027c9dbb807c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,620] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 3.3276 ms, throughput: 1.0271 GB/s; offload_time: 3.0839 ms, put_time: 0.2438 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,631] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,639] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-079ce9ebfdf7439b8fefe15935833e6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,640] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5756 ms, throughput: 2.1693 GB/s; offload_time: 1.4852 ms, put_time: 0.0905 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,641] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,643] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7598 ms, throughput: 1.9423 GB/s; offload_time: 1.6783 ms, put_time: 0.0815 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,648] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,655] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2ecef6815c0a4e308ed976fa37d38821 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,657] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5463 ms, throughput: 2.2104 GB/s; offload_time: 1.4676 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,657] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-0dd21f76fcab43e7be8218a442ad979d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,659] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.6740 ms, throughput: 2.0418 GB/s; offload_time: 1.5919 ms, put_time: 0.0821 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,664] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,674] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,683] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,691] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-2e970c546d614e04ab302a0b95ffa673 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,692] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5222 ms, throughput: 2.2454 GB/s; offload_time: 1.4404 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,693] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-b0b1fa6c97a34c3aa8346cee55f87808 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,694] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7708 ms, throughput: 1.9302 GB/s; offload_time: 1.6869 ms, put_time: 0.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,699] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1036, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,700] LMCache INFO:[0m Reqid: chatcmpl-a01ee906faa0428b941fe4ea266314a8, Total tokens 324, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,701] LMCache INFO:[0m Reqid: chatcmpl-c694b0b2decf4325a45b95546a20db9d, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,735] LMCache INFO:[0m Storing KV cache for 140 out of 1036 tokens (skip_leading_tokens=896) for request chatcmpl-0e682089b9444827af096e87dedaa05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,736] LMCache INFO:[0m Stored 140 out of total 1036 tokens. size: 0.0037 gb, cost 0.7886 ms, throughput: 4.7405 GB/s; offload_time: 0.6643 ms, put_time: 0.1243 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,737] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-11597f2f09d0425ba7d05dc23385010f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,738] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4758 ms, throughput: 2.3160 GB/s; offload_time: 1.3860 ms, put_time: 0.0898 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,753] LMCache INFO:[0m Reqid: chatcmpl-a01ee906faa0428b941fe4ea266314a8, Total tokens 325, LMCache hit tokens: 256, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,763] LMCache INFO:[0m Reqid: chatcmpl-a01ee906faa0428b941fe4ea266314a8, Total tokens 325, LMCache hit tokens: 256, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,779] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0ac532e795c4449f8e947d21aa1bb6fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,780] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5567 ms, throughput: 6.1397 GB/s; offload_time: 0.4647 ms, put_time: 0.0920 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,785] LMCache INFO:[0m Reqid: chatcmpl-0e682089b9444827af096e87dedaa05a, Total tokens 1040, LMCache hit tokens: 1036, need to load: 60 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,785] LMCache INFO:[0m Reqid: chatcmpl-a01ee906faa0428b941fe4ea266314a8, Total tokens 325, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,786] LMCache INFO:[0m Reqid: chatcmpl-c694b0b2decf4325a45b95546a20db9d, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,786] LMCache INFO:[0m Reqid: chatcmpl-0b1b31e7ca0b425ba2ba6e4c28cfe0a5, Total tokens 397, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,787] LMCache INFO:[0m Reqid: chatcmpl-161a8a2ea7aa4dceabd45b8e9d172fbf, Total tokens 376, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,806] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-c694b0b2decf4325a45b95546a20db9d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,806] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.4245 ms, throughput: 6.6681 GB/s; offload_time: 0.3460 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,807] LMCache INFO:[0m Storing KV cache for 141 out of 397 tokens (skip_leading_tokens=256) for request chatcmpl-0b1b31e7ca0b425ba2ba6e4c28cfe0a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,808] LMCache INFO:[0m Stored 141 out of total 397 tokens. size: 0.0038 gb, cost 1.2121 ms, throughput: 3.1063 GB/s; offload_time: 1.1076 ms, put_time: 0.1045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,814] LMCache INFO:[0m Reqid: chatcmpl-161a8a2ea7aa4dceabd45b8e9d172fbf, Total tokens 376, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,814] LMCache INFO:[0m Reqid: chatcmpl-aa746a2e36d04760acaa38604cdb43c6, Total tokens 96, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,815] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1600, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,832] LMCache INFO:[0m Storing KV cache for 96 out of 96 tokens (skip_leading_tokens=0) for request chatcmpl-aa746a2e36d04760acaa38604cdb43c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,832] LMCache INFO:[0m Stored 96 out of total 96 tokens. size: 0.0026 gb, cost 0.4444 ms, throughput: 5.7687 GB/s; offload_time: 0.3670 ms, put_time: 0.0774 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,833] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,834] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.0622 ms, throughput: 3.2178 GB/s; offload_time: 0.9925 ms, put_time: 0.0697 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,834] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-4db3458eb6e242fe9450f9fe484eb809 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,835] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.7647 ms, throughput: 4.4698 GB/s; offload_time: 0.6950 ms, put_time: 0.0696 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,840] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1600, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,851] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1600, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,852] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,892] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,893] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5887 ms, throughput: 5.8061 GB/s; offload_time: 0.5107 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,898] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,905] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-76409cc1f3534dfca9067a028a9881c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,906] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5761 ms, throughput: 5.9326 GB/s; offload_time: 0.4909 ms, put_time: 0.0853 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,910] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,920] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,930] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,940] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,950] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,958] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-51701e2aae1b4477b3b72298c04be25a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,959] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.9047 ms, throughput: 3.7779 GB/s; offload_time: 0.8004 ms, put_time: 0.1044 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:37,960] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-161a8a2ea7aa4dceabd45b8e9d172fbf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,961] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.9343 ms, throughput: 3.6581 GB/s; offload_time: 0.8652 ms, put_time: 0.0692 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:37,977] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1607, LMCache hit tokens: 1536, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,987] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1607, LMCache hit tokens: 1536, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,997] LMCache INFO:[0m Reqid: chatcmpl-52229877befd4fee9de20f85dd9ab718, Total tokens 1607, LMCache hit tokens: 1536, need to load: 176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:37,998] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,011] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-5fa75b0dead348a391e894f59dcd91cd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,012] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6079 ms, throughput: 5.6226 GB/s; offload_time: 0.5278 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,016] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,026] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,033] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1a812f673eab4accb36f93153ae217e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,034] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5595 ms, throughput: 6.1090 GB/s; offload_time: 0.4803 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42734 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,039] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,049] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,056] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-8cf843ea5fc44db7ae1e14aa0ce095cf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,057] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6558 ms, throughput: 5.2118 GB/s; offload_time: 0.5759 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,062] LMCache INFO:[0m Reqid: chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4, Total tokens 829, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,063] LMCache INFO:[0m Reqid: chatcmpl-8e2e0e43e64a4547b5f21715238081fc, Total tokens 797, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,063] LMCache INFO:[0m Reqid: chatcmpl-20fba5e27abb4e38b80ac9bbc6a09783, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,064] LMCache INFO:[0m Reqid: chatcmpl-2f67c630f6e0490ea9a89a2d1a4e2061, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,095] LMCache INFO:[0m Storing KV cache for 157 out of 797 tokens (skip_leading_tokens=640) for request chatcmpl-8e2e0e43e64a4547b5f21715238081fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,096] LMCache INFO:[0m Stored 157 out of total 797 tokens. size: 0.0042 gb, cost 0.7030 ms, throughput: 5.9635 GB/s; offload_time: 0.5942 ms, put_time: 0.1088 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,097] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-20fba5e27abb4e38b80ac9bbc6a09783 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,098] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.8571 ms, throughput: 3.3025 GB/s; offload_time: 0.7860 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,103] LMCache INFO:[0m Reqid: chatcmpl-2f67c630f6e0490ea9a89a2d1a4e2061, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,110] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-cbfc55bf08c74f409129c82582e34545 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,111] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5631 ms, throughput: 6.0700 GB/s; offload_time: 0.4807 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,111] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c941798525144ccb9375d987ebcc765e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,112] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.7101 ms, throughput: 4.8137 GB/s; offload_time: 0.6344 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,126] LMCache INFO:[0m Reqid: chatcmpl-8e2e0e43e64a4547b5f21715238081fc, Total tokens 799, LMCache hit tokens: 797, need to load: 109 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,127] LMCache INFO:[0m Reqid: chatcmpl-20fba5e27abb4e38b80ac9bbc6a09783, Total tokens 108, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,127] LMCache INFO:[0m Reqid: chatcmpl-2f67c630f6e0490ea9a89a2d1a4e2061, Total tokens 300, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,128] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,145] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-5ac861930d3642c7a8caf0b72138771c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,146] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5045 ms, throughput: 6.7751 GB/s; offload_time: 0.4281 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,150] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,158] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-ffff9f2a61214e77bba733dbc961c551 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,159] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5915 ms, throughput: 5.7782 GB/s; offload_time: 0.5025 ms, put_time: 0.0890 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,159] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-528a033eb46d4c1386c91f60fb32bb34 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:42742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42764 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,160] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7319 ms, throughput: 4.6700 GB/s; offload_time: 0.4629 ms, put_time: 0.2690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,160] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-5823ac8245f3409f97906c835e396e36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,163] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.2543 ms, throughput: 1.5162 GB/s; offload_time: 2.1762 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,163] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c694b0b2decf4325a45b95546a20db9d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,165] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.5952 ms, throughput: 2.1426 GB/s; offload_time: 1.5175 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,170] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,177] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-58ca0ecb8546404ab725e3e2815b0e98 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,179] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6454 ms, throughput: 2.0773 GB/s; offload_time: 1.5691 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,184] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,191] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-b02281a4820b48a4b8ce5358d47a389c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,193] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5802 ms, throughput: 2.1630 GB/s; offload_time: 1.5033 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,197] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,207] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,217] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,224] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-37f59dc8758747b49e78b10d2ea80f68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,226] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5165 ms, throughput: 2.2538 GB/s; offload_time: 1.4380 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,230] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,238] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-dcb4de26086b4dbca291a64dd9190ec1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,240] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.6981 ms, throughput: 2.0128 GB/s; offload_time: 1.6240 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:42770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,245] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,255] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,265] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,276] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,286] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,293] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-aa746a2e36d04760acaa38604cdb43c6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,294] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4994 ms, throughput: 2.2796 GB/s; offload_time: 1.4222 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,299] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 939, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,300] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,323] LMCache INFO:[0m Storing KV cache for 171 out of 939 tokens (skip_leading_tokens=768) for request chatcmpl-168f1fb35ca1459f88cd688ba3a689ec [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,324] LMCache INFO:[0m Stored 171 out of total 939 tokens. size: 0.0046 gb, cost 0.8324 ms, throughput: 5.4858 GB/s; offload_time: 0.6241 ms, put_time: 0.2083 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,330] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,341] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,350] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,358] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,359] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.8027 ms, throughput: 4.2583 GB/s; offload_time: 0.5015 ms, put_time: 0.3012 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,364] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,383] LMCache INFO:[0m Reqid: chatcmpl-168f1fb35ca1459f88cd688ba3a689ec, Total tokens 944, LMCache hit tokens: 939, need to load: 155 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,384] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,398] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,405] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-20fba5e27abb4e38b80ac9bbc6a09783 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,405] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4483 ms, throughput: 7.6251 GB/s; offload_time: 0.3684 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,410] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,420] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,430] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,438] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,439] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6496 ms, throughput: 5.2613 GB/s; offload_time: 0.5608 ms, put_time: 0.0889 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,443] LMCache INFO:[0m Reqid: chatcmpl-a3e7bfa1193e4acfa5f79354c0939605, Total tokens 1636, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,445] LMCache INFO:[0m Reqid: chatcmpl-1588da3d0376481480988ac2cce331da, Total tokens 1304, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,488] LMCache INFO:[0m Reqid: chatcmpl-1588da3d0376481480988ac2cce331da, Total tokens 1304, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,488] LMCache INFO:[0m Reqid: chatcmpl-c4d0fe16c63d41da83d1a0e711dadb94, Total tokens 136, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,489] LMCache INFO:[0m Reqid: chatcmpl-989514b1a417457ebaf236c3dff220f9, Total tokens 350, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,490] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,526] LMCache INFO:[0m Storing KV cache for 1176 out of 1304 tokens (skip_leading_tokens=128) for request chatcmpl-1588da3d0376481480988ac2cce331da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,528] LMCache INFO:[0m Stored 1176 out of total 1304 tokens. size: 0.0314 gb, cost 2.5206 ms, throughput: 12.4583 GB/s; offload_time: 1.9356 ms, put_time: 0.5850 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,529] LMCache INFO:[0m Storing KV cache for 136 out of 136 tokens (skip_leading_tokens=0) for request chatcmpl-c4d0fe16c63d41da83d1a0e711dadb94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,532] LMCache INFO:[0m Stored 136 out of total 136 tokens. size: 0.0036 gb, cost 2.9076 ms, throughput: 1.2490 GB/s; offload_time: 2.5565 ms, put_time: 0.3511 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,533] LMCache INFO:[0m Storing KV cache for 350 out of 350 tokens (skip_leading_tokens=0) for request chatcmpl-989514b1a417457ebaf236c3dff220f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,537] LMCache INFO:[0m Stored 350 out of total 350 tokens. size: 0.0093 gb, cost 3.1623 ms, throughput: 2.9555 GB/s; offload_time: 2.3746 ms, put_time: 0.7877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,537] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-38504b82be154ec8996ead7e4737e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,541] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 3.3904 ms, throughput: 1.0081 GB/s; offload_time: 2.8726 ms, put_time: 0.5177 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,542] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,544] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 2.1301 ms, throughput: 1.6046 GB/s; offload_time: 2.0289 ms, put_time: 0.1012 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,544] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-870c116c795e4f369cc278cb5e9b353f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,547] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.9552 ms, throughput: 1.7482 GB/s; offload_time: 1.8806 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,552] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,562] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,571] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,581] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,590] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,598] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,599] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6391 ms, throughput: 2.0853 GB/s; offload_time: 1.5505 ms, put_time: 0.0886 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,605] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,615] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,622] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-aae36f2c1b644c20a1e4bff0626bc325 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,624] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5847 ms, throughput: 2.1568 GB/s; offload_time: 1.5103 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,624] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-09f85861f15b46dc9d0b088992967ba2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,626] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6431 ms, throughput: 2.0802 GB/s; offload_time: 1.5270 ms, put_time: 0.1161 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,630] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,638] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-dcda0417d4f84668b467a612389b2d1c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,640] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.5702 ms, throughput: 2.1768 GB/s; offload_time: 1.4968 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,644] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,654] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1438, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,655] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,690] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-6225cc1d5d054d8aa93558ef27d04565 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,691] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5085 ms, throughput: 6.7221 GB/s; offload_time: 0.4345 ms, put_time: 0.0739 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,696] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,705] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,715] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,723] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-2aecb0a0d37540b986a099bfb136bde2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,723] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5134 ms, throughput: 6.6573 GB/s; offload_time: 0.4382 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,724] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-a01ee906faa0428b941fe4ea266314a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,724] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5839 ms, throughput: 5.8539 GB/s; offload_time: 0.5135 ms, put_time: 0.0704 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,729] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,739] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,748] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,767] LMCache INFO:[0m Reqid: chatcmpl-d292c180b5724f6e91c63890cb9734c4, Total tokens 1445, LMCache hit tokens: 1408, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,768] LMCache INFO:[0m Reqid: chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f, Total tokens 1048, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,769] LMCache INFO:[0m Reqid: chatcmpl-654c138c801f4c5f9613e43d2e43a57e, Total tokens 544, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,770] LMCache INFO:[0m Reqid: chatcmpl-14dd0d74153e45eaaf3c49b458592d2a, Total tokens 174, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,770] LMCache INFO:[0m Reqid: chatcmpl-63043814e2db42c8aab14f08215b7c91, Total tokens 787, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,771] LMCache INFO:[0m Reqid: chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c, Total tokens 454, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,809] LMCache INFO:[0m Storing KV cache for 174 out of 174 tokens (skip_leading_tokens=0) for request chatcmpl-14dd0d74153e45eaaf3c49b458592d2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,810] LMCache INFO:[0m Stored 174 out of total 174 tokens. size: 0.0046 gb, cost 0.7026 ms, throughput: 6.6134 GB/s; offload_time: 0.5929 ms, put_time: 0.1097 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,811] LMCache INFO:[0m Storing KV cache for 147 out of 787 tokens (skip_leading_tokens=640) for request chatcmpl-63043814e2db42c8aab14f08215b7c91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,812] LMCache INFO:[0m Stored 147 out of total 787 tokens. size: 0.0039 gb, cost 1.1512 ms, throughput: 3.4099 GB/s; offload_time: 1.0526 ms, put_time: 0.0986 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,812] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-7e30118e271347c39b9139ff0cdbd881 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,815] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 2.3775 ms, throughput: 1.4377 GB/s; offload_time: 1.9599 ms, put_time: 0.4176 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,820] LMCache INFO:[0m Reqid: chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c, Total tokens 454, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,830] LMCache INFO:[0m Reqid: chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c, Total tokens 454, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:38,839] LMCache INFO:[0m Reqid: chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c, Total tokens 454, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,859] LMCache INFO:[0m Reqid: chatcmpl-63043814e2db42c8aab14f08215b7c91, Total tokens 791, LMCache hit tokens: 787, need to load: 67 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,868] LMCache INFO:[0m Reqid: chatcmpl-63043814e2db42c8aab14f08215b7c91, Total tokens 791, LMCache hit tokens: 787, need to load: 163 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,876] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-52229877befd4fee9de20f85dd9ab718 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,876] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5833 ms, throughput: 5.8602 GB/s; offload_time: 0.5076 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,881] LMCache INFO:[0m Reqid: chatcmpl-63043814e2db42c8aab14f08215b7c91, Total tokens 791, LMCache hit tokens: 787, need to load: 307 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,882] LMCache INFO:[0m Reqid: chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c, Total tokens 454, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,882] LMCache INFO:[0m Reqid: chatcmpl-0adcecc782db4b3eb985d0ee5bcbe0a1, Total tokens 591, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,883] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,906] LMCache INFO:[0m Storing KV cache for 326 out of 454 tokens (skip_leading_tokens=128) for request chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,907] LMCache INFO:[0m Stored 326 out of total 454 tokens. size: 0.0087 gb, cost 0.9056 ms, throughput: 9.6125 GB/s; offload_time: 0.7691 ms, put_time: 0.1365 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,913] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,922] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-7e6c339e790f4cf2b4e71ffe96e095f3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,922] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6182 ms, throughput: 5.5289 GB/s; offload_time: 0.5250 ms, put_time: 0.0932 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,923] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,924] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.8548 ms, throughput: 3.9985 GB/s; offload_time: 0.7874 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,924] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e51376f64f194a28b2ecec8e7d57d826 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,926] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.7137 ms, throughput: 1.9945 GB/s; offload_time: 1.6357 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,930] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,940] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,950] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,960] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,967] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,969] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6042 ms, throughput: 2.1307 GB/s; offload_time: 1.5177 ms, put_time: 0.0864 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:38,973] LMCache INFO:[0m Reqid: chatcmpl-353de32886364fbabe4f37535f54aa9f, Total tokens 546, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,974] LMCache INFO:[0m Reqid: chatcmpl-13c21c26d5d14ffdba5438bd00aa6462, Total tokens 469, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,975] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 444, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:38,976] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60534 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,010] LMCache INFO:[0m Storing KV cache for 444 out of 444 tokens (skip_leading_tokens=0) for request chatcmpl-e69b6449e1a34cccb82c471a8c734c08 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,012] LMCache INFO:[0m Stored 444 out of total 444 tokens. size: 0.0119 gb, cost 1.0859 ms, throughput: 10.9182 GB/s; offload_time: 0.9158 ms, put_time: 0.1701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,012] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,016] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8938 ms, throughput: 1.8048 GB/s; offload_time: 1.7225 ms, put_time: 0.1713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,017] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,019] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 2.2226 ms, throughput: 1.5378 GB/s; offload_time: 2.1407 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,034] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 108 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,044] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 124 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,051] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-989514b1a417457ebaf236c3dff220f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,052] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4120 ms, throughput: 2.4206 GB/s; offload_time: 1.3364 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,056] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 204 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,065] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-edff6753093845dda64e35caf5a7df04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,066] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 1.5436 ms, throughput: 2.2143 GB/s; offload_time: 1.4667 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,067] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-04ceca33dab04488be568ae0f7d179d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,068] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4446 ms, throughput: 2.3660 GB/s; offload_time: 1.3663 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,073] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 284 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,083] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 332 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,102] LMCache INFO:[0m Reqid: chatcmpl-13c21c26d5d14ffdba5438bd00aa6462, Total tokens 476, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,109] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,111] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4469 ms, throughput: 2.3623 GB/s; offload_time: 1.3476 ms, put_time: 0.0993 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,111] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8e2f66c7b0534ff98c08bdbf18fd044e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,113] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5919 ms, throughput: 2.1471 GB/s; offload_time: 1.5149 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,113] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,115] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5776 ms, throughput: 2.1665 GB/s; offload_time: 1.4086 ms, put_time: 0.1690 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,120] LMCache INFO:[0m Reqid: chatcmpl-13c21c26d5d14ffdba5438bd00aa6462, Total tokens 476, LMCache hit tokens: 384, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,130] LMCache INFO:[0m Reqid: chatcmpl-13c21c26d5d14ffdba5438bd00aa6462, Total tokens 476, LMCache hit tokens: 384, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,130] LMCache INFO:[0m Reqid: chatcmpl-e69b6449e1a34cccb82c471a8c734c08, Total tokens 445, LMCache hit tokens: 444, need to load: 396 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,131] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,144] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-780968a859634fc9b6a83b528605a446 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,146] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4280 ms, throughput: 2.3935 GB/s; offload_time: 1.3475 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,146] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-be2a14c5605c4c00b29d77ccab34e42e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,148] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6274 ms, throughput: 2.1003 GB/s; offload_time: 1.5524 ms, put_time: 0.0750 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,153] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,163] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,170] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b310ef7357e84bacadcfecac0cf97202 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,172] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4476 ms, throughput: 2.3612 GB/s; offload_time: 1.3589 ms, put_time: 0.0887 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,176] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,187] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,197] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,204] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,206] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.4705 ms, throughput: 2.3243 GB/s; offload_time: 1.3850 ms, put_time: 0.0856 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,206] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c6a5e4b01cae4e45845432b6efafbd9a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,208] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5490 ms, throughput: 2.2065 GB/s; offload_time: 1.4705 ms, put_time: 0.0785 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,212] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,220] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,222] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5509 ms, throughput: 2.2038 GB/s; offload_time: 1.4641 ms, put_time: 0.0869 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,222] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,224] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.4887 ms, throughput: 2.2959 GB/s; offload_time: 1.4170 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,224] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ef038a3d90994c2fba2728c3eab408de [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,226] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6710 ms, throughput: 2.0455 GB/s; offload_time: 1.6066 ms, put_time: 0.0644 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,226] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-9842a449d6c847dfae7a669779d99d4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,229] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.0295 ms, throughput: 1.6841 GB/s; offload_time: 1.7604 ms, put_time: 0.2691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,234] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,244] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,254] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,264] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,274] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,281] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,283] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4683 ms, throughput: 2.3279 GB/s; offload_time: 1.3908 ms, put_time: 0.0775 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,288] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,295] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-8a316371df5443debff479fb5c46bb5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,297] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.4697 ms, throughput: 2.3256 GB/s; offload_time: 1.3910 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,297] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,299] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4320 ms, throughput: 2.3868 GB/s; offload_time: 1.3508 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,303] LMCache INFO:[0m Reqid: chatcmpl-21f9e36e9d704fc29cea1acc6b78c4e1, Total tokens 1220, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,305] LMCache INFO:[0m Reqid: chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4, Total tokens 514, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,342] LMCache INFO:[0m Reqid: chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4, Total tokens 514, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,343] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 935, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,360] LMCache INFO:[0m Storing KV cache for 130 out of 514 tokens (skip_leading_tokens=384) for request chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,361] LMCache INFO:[0m Stored 130 out of total 514 tokens. size: 0.0035 gb, cost 0.6820 ms, throughput: 5.0899 GB/s; offload_time: 0.5762 ms, put_time: 0.1058 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,366] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 935, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,376] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 935, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,384] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d6a863d028bf458f9be13aa8a8a5b7d4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,384] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.7355 ms, throughput: 4.6470 GB/s; offload_time: 0.5357 ms, put_time: 0.1998 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,389] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 935, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,399] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 935, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,400] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,423] LMCache INFO:[0m Storing KV cache for 167 out of 935 tokens (skip_leading_tokens=768) for request chatcmpl-1f9cb3ba366746a498abaad8efd2b368 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,423] LMCache INFO:[0m Stored 167 out of total 935 tokens. size: 0.0045 gb, cost 0.7457 ms, throughput: 5.9800 GB/s; offload_time: 0.6293 ms, put_time: 0.1165 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,424] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a39aba9cb7de4b6da0f340f6b1792786 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,425] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.9490 ms, throughput: 3.6016 GB/s; offload_time: 0.8730 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,430] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,440] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,450] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,458] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-2d9480ba93634862832ba1bc11ca3f66 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,458] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5894 ms, throughput: 5.7995 GB/s; offload_time: 0.5131 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,463] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,473] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,482] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,492] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,500] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0e682089b9444827af096e87dedaa05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,500] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5404 ms, throughput: 6.3249 GB/s; offload_time: 0.4658 ms, put_time: 0.0746 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,505] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,515] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,522] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-cb36c770d48643c3a38671bff259f7fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,522] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4851 ms, throughput: 7.0454 GB/s; offload_time: 0.4088 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,527] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,534] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-66588120f7fa4db1ace30b1edf982d14 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,535] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5296 ms, throughput: 6.4535 GB/s; offload_time: 0.4530 ms, put_time: 0.0767 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,535] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0b1b31e7ca0b425ba2ba6e4c28cfe0a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,536] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4107 ms, throughput: 8.3216 GB/s; offload_time: 0.3475 ms, put_time: 0.0632 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,542] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,549] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8fa0aea8164c4e40abac40538f8f190a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,551] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5427 ms, throughput: 2.2156 GB/s; offload_time: 1.4647 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,551] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,552] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4968 ms, throughput: 6.8802 GB/s; offload_time: 0.4293 ms, put_time: 0.0674 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,557] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,566] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,574] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-079ce9ebfdf7439b8fefe15935833e6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,576] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4355 ms, throughput: 2.3810 GB/s; offload_time: 1.3582 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,576] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,578] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6221 ms, throughput: 2.1072 GB/s; offload_time: 1.5503 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,578] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-8e2e0e43e64a4547b5f21715238081fc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,580] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.8466 ms, throughput: 1.8509 GB/s; offload_time: 1.7658 ms, put_time: 0.0808 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60664 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,592] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-0dd21f76fcab43e7be8218a442ad979d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,594] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5048 ms, throughput: 2.2714 GB/s; offload_time: 1.4176 ms, put_time: 0.0872 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,598] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 949, LMCache hit tokens: 935, need to load: 71 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,606] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0adcecc782db4b3eb985d0ee5bcbe0a1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,607] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4512 ms, throughput: 2.3552 GB/s; offload_time: 1.3739 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,612] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 949, LMCache hit tokens: 935, need to load: 183 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,622] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 949, LMCache hit tokens: 935, need to load: 247 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,629] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-b0b1fa6c97a34c3aa8346cee55f87808 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,630] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.3998 ms, throughput: 2.4418 GB/s; offload_time: 1.3164 ms, put_time: 0.0834 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,635] LMCache INFO:[0m Reqid: chatcmpl-1f9cb3ba366746a498abaad8efd2b368, Total tokens 949, LMCache hit tokens: 935, need to load: 279 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,636] LMCache INFO:[0m Reqid: chatcmpl-e9c3dc72438e4178aaafd535332b2629, Total tokens 1270, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,637] LMCache INFO:[0m Reqid: chatcmpl-28071c9355934752ae6eb08471f9e44b, Total tokens 295, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,638] LMCache INFO:[0m Reqid: chatcmpl-c5fb695b995a4162ab7c2e50ca262d60, Total tokens 278, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,639] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60672 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,678] LMCache INFO:[0m Storing KV cache for 278 out of 278 tokens (skip_leading_tokens=0) for request chatcmpl-c5fb695b995a4162ab7c2e50ca262d60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,679] LMCache INFO:[0m Stored 278 out of total 278 tokens. size: 0.0074 gb, cost 1.0516 ms, throughput: 7.0591 GB/s; offload_time: 0.7331 ms, put_time: 0.3185 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,680] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-11597f2f09d0425ba7d05dc23385010f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,681] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.2334 ms, throughput: 2.7711 GB/s; offload_time: 1.1646 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,682] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-13c21c26d5d14ffdba5438bd00aa6462 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,683] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.1449 ms, throughput: 2.9854 GB/s; offload_time: 1.0662 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,689] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,698] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,709] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,718] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,728] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,738] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,745] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,746] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5518 ms, throughput: 6.1941 GB/s; offload_time: 0.4669 ms, put_time: 0.0850 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,746] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,747] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6215 ms, throughput: 5.4995 GB/s; offload_time: 0.5456 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,752] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,762] LMCache INFO:[0m Reqid: chatcmpl-4c277ca6d6a04ba58995780469a2245b, Total tokens 1541, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,763] LMCache INFO:[0m Reqid: chatcmpl-1d9cac269a7d4e60859e29d547d5e3b4, Total tokens 1314, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,764] LMCache INFO:[0m Reqid: chatcmpl-50123025e53f4e1a9c330fcebddf6ebf, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,764] LMCache INFO:[0m Reqid: chatcmpl-6e5dff07b4da4f03a342f836bd6d6639, Total tokens 130, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,765] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,817] LMCache INFO:[0m Storing KV cache for 133 out of 1541 tokens (skip_leading_tokens=1408) for request chatcmpl-4c277ca6d6a04ba58995780469a2245b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,817] LMCache INFO:[0m Stored 133 out of total 1541 tokens. size: 0.0036 gb, cost 0.7934 ms, throughput: 4.4761 GB/s; offload_time: 0.6750 ms, put_time: 0.1184 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,818] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-50123025e53f4e1a9c330fcebddf6ebf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,819] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 1.3091 ms, throughput: 2.1621 GB/s; offload_time: 1.2262 ms, put_time: 0.0829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,819] LMCache INFO:[0m Storing KV cache for 130 out of 130 tokens (skip_leading_tokens=0) for request chatcmpl-6e5dff07b4da4f03a342f836bd6d6639 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,821] LMCache INFO:[0m Stored 130 out of total 130 tokens. size: 0.0035 gb, cost 1.2016 ms, throughput: 2.8891 GB/s; offload_time: 1.0339 ms, put_time: 0.1676 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,823] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,824] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.5222 ms, throughput: 2.2454 GB/s; offload_time: 1.4367 ms, put_time: 0.0854 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,830] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,837] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-76409cc1f3534dfca9067a028a9881c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,838] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5229 ms, throughput: 6.5371 GB/s; offload_time: 0.4413 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,843] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,850] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-e9c3dc72438e4178aaafd535332b2629 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,851] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.5628 ms, throughput: 6.0733 GB/s; offload_time: 0.4825 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,855] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,865] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,875] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,885] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,892] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-51701e2aae1b4477b3b72298c04be25a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,893] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.6045 ms, throughput: 5.6546 GB/s; offload_time: 0.5148 ms, put_time: 0.0896 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,897] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,907] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,917] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,927] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,936] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:39,947] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,954] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1a812f673eab4accb36f93153ae217e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,955] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5825 ms, throughput: 5.8674 GB/s; offload_time: 0.4923 ms, put_time: 0.0902 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,959] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,969] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,978] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,985] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-14dd0d74153e45eaaf3c49b458592d2a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:39,986] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5247 ms, throughput: 6.5142 GB/s; offload_time: 0.4367 ms, put_time: 0.0880 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:39,990] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,000] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1744, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,002] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,044] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,051] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-5ac861930d3642c7a8caf0b72138771c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,052] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5398 ms, throughput: 6.3316 GB/s; offload_time: 0.4505 ms, put_time: 0.0894 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,056] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,064] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-5823ac8245f3409f97906c835e396e36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,065] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6265 ms, throughput: 5.4554 GB/s; offload_time: 0.5358 ms, put_time: 0.0907 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,065] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1588da3d0376481480988ac2cce331da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,066] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.4853 ms, throughput: 7.0428 GB/s; offload_time: 0.4123 ms, put_time: 0.0730 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,070] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,080] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,096] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-50123025e53f4e1a9c330fcebddf6ebf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,097] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4963 ms, throughput: 6.8864 GB/s; offload_time: 0.4109 ms, put_time: 0.0854 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,101] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,111] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,118] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-37f59dc8758747b49e78b10d2ea80f68 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,119] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5197 ms, throughput: 6.5769 GB/s; offload_time: 0.4378 ms, put_time: 0.0819 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,119] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d292c180b5724f6e91c63890cb9734c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,120] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7569 ms, throughput: 4.5160 GB/s; offload_time: 0.6890 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,125] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,132] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-dcb4de26086b4dbca291a64dd9190ec1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,133] LMCache INFO:[0m Stored 128 out of total 2432 tokens. size: 0.0034 gb, cost 0.6848 ms, throughput: 4.9910 GB/s; offload_time: 0.5928 ms, put_time: 0.0921 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,138] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,147] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,157] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 384 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,166] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,173] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-654c138c801f4c5f9613e43d2e43a57e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,176] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 2.3762 ms, throughput: 1.4384 GB/s; offload_time: 2.2921 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,180] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 480 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,190] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 560 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,200] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 608 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,210] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,219] LMCache INFO:[0m Reqid: chatcmpl-7d1054aa546e4448a0d049ab8483f9bc, Total tokens 1749, LMCache hit tokens: 1664, need to load: 768 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,221] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,233] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-164b8090475d45bd93f969ccdbdbc6f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,234] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5984 ms, throughput: 5.7122 GB/s; offload_time: 0.5228 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,239] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,247] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c4d0fe16c63d41da83d1a0e711dadb94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,247] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5234 ms, throughput: 6.5309 GB/s; offload_time: 0.4031 ms, put_time: 0.1202 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,252] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,261] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,268] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,269] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6090 ms, throughput: 5.6122 GB/s; offload_time: 0.5225 ms, put_time: 0.0865 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,274] LMCache INFO:[0m Reqid: chatcmpl-ec409da573b843f1aab380ef224b2aa5, Total tokens 1964, LMCache hit tokens: 1408, need to load: 1360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,275] LMCache INFO:[0m Reqid: chatcmpl-cb91b9f8a1374c8c91f3964c4e5fdf8b, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,276] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,319] LMCache INFO:[0m Storing KV cache for 556 out of 1964 tokens (skip_leading_tokens=1408) for request chatcmpl-ec409da573b843f1aab380ef224b2aa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,320] LMCache INFO:[0m Stored 556 out of total 1964 tokens. size: 0.0148 gb, cost 1.4018 ms, throughput: 10.5910 GB/s; offload_time: 1.1913 ms, put_time: 0.2106 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,321] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-cb91b9f8a1374c8c91f3964c4e5fdf8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,325] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 1.1553 ms, throughput: 2.2651 GB/s; offload_time: 0.9947 ms, put_time: 0.1606 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,331] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,340] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,347] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-353de32886364fbabe4f37535f54aa9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,348] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5534 ms, throughput: 6.1760 GB/s; offload_time: 0.4710 ms, put_time: 0.0824 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,352] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,360] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,361] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6790 ms, throughput: 5.0335 GB/s; offload_time: 0.5905 ms, put_time: 0.0886 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,365] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,374] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,382] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-38504b82be154ec8996ead7e4737e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,383] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5852 ms, throughput: 5.8410 GB/s; offload_time: 0.4887 ms, put_time: 0.0965 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,383] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,384] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5791 ms, throughput: 5.9021 GB/s; offload_time: 0.5085 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,384] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-870c116c795e4f369cc278cb5e9b353f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,385] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6478 ms, throughput: 5.2763 GB/s; offload_time: 0.5789 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,389] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,400] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,408] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-63043814e2db42c8aab14f08215b7c91 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,409] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.6823 ms, throughput: 5.0094 GB/s; offload_time: 0.5870 ms, put_time: 0.0953 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,414] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,423] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,433] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,440] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,442] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 2.2341 ms, throughput: 1.5299 GB/s; offload_time: 2.1508 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,446] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,456] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,466] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,476] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,485] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,495] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,504] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,514] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,522] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-2aecb0a0d37540b986a099bfb136bde2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,524] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 2.4333 ms, throughput: 1.4047 GB/s; offload_time: 2.3500 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,525] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a01ee906faa0428b941fe4ea266314a8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,527] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.7650 ms, throughput: 1.9366 GB/s; offload_time: 1.6952 ms, put_time: 0.0698 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,531] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,541] LMCache INFO:[0m Reqid: chatcmpl-689f7e55e3994331b23083df9300b128, Total tokens 1459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,542] LMCache INFO:[0m Reqid: chatcmpl-71df15ba62cf41af88fe97a48de69421, Total tokens 110, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,543] LMCache INFO:[0m Reqid: chatcmpl-dab270922c62427b91a0350f60a9d037, Total tokens 205, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,543] LMCache INFO:[0m Reqid: chatcmpl-d0571632621c4f4a9be75e3e4228128b, Total tokens 864, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,582] LMCache INFO:[0m Storing KV cache for 1075 out of 1459 tokens (skip_leading_tokens=384) for request chatcmpl-689f7e55e3994331b23083df9300b128 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,589] LMCache INFO:[0m Stored 1075 out of total 1459 tokens. size: 0.0287 gb, cost 6.9546 ms, throughput: 4.1276 GB/s; offload_time: 5.8447 ms, put_time: 1.1099 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,591] LMCache INFO:[0m Storing KV cache for 110 out of 110 tokens (skip_leading_tokens=0) for request chatcmpl-71df15ba62cf41af88fe97a48de69421 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,593] LMCache INFO:[0m Stored 110 out of total 110 tokens. size: 0.0029 gb, cost 2.5684 ms, throughput: 1.1436 GB/s; offload_time: 2.3728 ms, put_time: 0.1956 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,594] LMCache INFO:[0m Storing KV cache for 205 out of 205 tokens (skip_leading_tokens=0) for request chatcmpl-dab270922c62427b91a0350f60a9d037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,597] LMCache INFO:[0m Stored 205 out of total 205 tokens. size: 0.0055 gb, cost 2.9012 ms, throughput: 1.8868 GB/s; offload_time: 2.6144 ms, put_time: 0.2868 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,605] LMCache INFO:[0m Reqid: chatcmpl-d0571632621c4f4a9be75e3e4228128b, Total tokens 864, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,605] LMCache INFO:[0m Reqid: chatcmpl-c669349e161940d781d70ae3f4a681e1, Total tokens 538, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,606] LMCache INFO:[0m Reqid: chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b, Total tokens 459, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,607] LMCache INFO:[0m Reqid: chatcmpl-7b7b7ce0259445d0bb025517f1b169e6, Total tokens 208, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,607] LMCache INFO:[0m Reqid: chatcmpl-7486c0058db344d88f9b95eadb09935c, Total tokens 292, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,608] LMCache INFO:[0m Reqid: chatcmpl-e9718d34bb754146829997734d3f129c, Total tokens 365, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,608] LMCache INFO:[0m Reqid: chatcmpl-e962b4f1532142cf836ff9d522403529, Total tokens 129, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,609] LMCache INFO:[0m Reqid: chatcmpl-e5c04a2414c84dd2b934921675f628e8, Total tokens 129, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,609] LMCache INFO:[0m Reqid: chatcmpl-42e53462c96c4baa9fb0c73a0b8a71f5, Total tokens 102, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,609] LMCache INFO:[0m Reqid: chatcmpl-53c00f94c859426eb2d2b6cfaa366d3b, Total tokens 299, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,659] LMCache INFO:[0m Storing KV cache for 154 out of 538 tokens (skip_leading_tokens=384) for request chatcmpl-c669349e161940d781d70ae3f4a681e1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,659] LMCache INFO:[0m Stored 154 out of total 538 tokens. size: 0.0041 gb, cost 0.6972 ms, throughput: 5.8981 GB/s; offload_time: 0.5890 ms, put_time: 0.1082 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,660] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-e962b4f1532142cf836ff9d522403529 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,661] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 1.5521 ms, throughput: 2.2194 GB/s; offload_time: 1.4256 ms, put_time: 0.1265 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,662] LMCache INFO:[0m Storing KV cache for 129 out of 129 tokens (skip_leading_tokens=0) for request chatcmpl-e5c04a2414c84dd2b934921675f628e8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,664] LMCache INFO:[0m Stored 129 out of total 129 tokens. size: 0.0034 gb, cost 2.4448 ms, throughput: 1.4090 GB/s; offload_time: 2.0784 ms, put_time: 0.3665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,665] LMCache INFO:[0m Storing KV cache for 102 out of 102 tokens (skip_leading_tokens=0) for request chatcmpl-42e53462c96c4baa9fb0c73a0b8a71f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,666] LMCache INFO:[0m Stored 102 out of total 102 tokens. size: 0.0027 gb, cost 1.6328 ms, throughput: 1.6681 GB/s; offload_time: 1.3118 ms, put_time: 0.3210 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:60902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,691] LMCache INFO:[0m Reqid: chatcmpl-e5c04a2414c84dd2b934921675f628e8, Total tokens 131, LMCache hit tokens: 129, need to load: 81 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,692] LMCache INFO:[0m Reqid: chatcmpl-42e53462c96c4baa9fb0c73a0b8a71f5, Total tokens 103, LMCache hit tokens: 102, need to load: 54 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,692] LMCache INFO:[0m Reqid: chatcmpl-53c00f94c859426eb2d2b6cfaa366d3b, Total tokens 299, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,693] LMCache INFO:[0m Reqid: chatcmpl-c5706fcb2df84f2e8390769c62f4b734, Total tokens 412, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:40,712] LMCache INFO:[0m Reqid: chatcmpl-c5706fcb2df84f2e8390769c62f4b734, Total tokens 412, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,712] LMCache INFO:[0m Reqid: chatcmpl-40a48e30876c4987901be12de4a84e72, Total tokens 248, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,713] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,733] LMCache INFO:[0m Storing KV cache for 248 out of 248 tokens (skip_leading_tokens=0) for request chatcmpl-40a48e30876c4987901be12de4a84e72 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,734] LMCache INFO:[0m Stored 248 out of total 248 tokens. size: 0.0066 gb, cost 0.7131 ms, throughput: 9.2872 GB/s; offload_time: 0.5974 ms, put_time: 0.1156 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,740] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,751] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,761] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,771] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,779] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-52229877befd4fee9de20f85dd9ab718 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,779] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6450 ms, throughput: 5.2993 GB/s; offload_time: 0.5638 ms, put_time: 0.0812 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,780] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-1f9cb3ba366746a498abaad8efd2b368 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,782] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7617 ms, throughput: 1.9401 GB/s; offload_time: 1.6831 ms, put_time: 0.0787 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,789] LMCache INFO:[0m Reqid: chatcmpl-1a326804748141e4b4d1fb42209281d7, Total tokens 1129, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,790] LMCache INFO:[0m Reqid: chatcmpl-0e4a9cbb356e4160b150d43a10d5ec4a, Total tokens 149, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,790] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 561, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,826] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 561, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,834] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ee64fd4e90b44df2b70f69ddda217e94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,835] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5946 ms, throughput: 5.7485 GB/s; offload_time: 0.5158 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,835] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e51376f64f194a28b2ecec8e7d57d826 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,836] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6692 ms, throughput: 5.1078 GB/s; offload_time: 0.6028 ms, put_time: 0.0664 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,841] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 561, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,851] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 561, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,858] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-40a48e30876c4987901be12de4a84e72 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,859] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5498 ms, throughput: 6.2170 GB/s; offload_time: 0.4670 ms, put_time: 0.0828 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,863] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 561, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,864] LMCache INFO:[0m Reqid: chatcmpl-8322b2fdbc9c4307b75df598fc9b85bc, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,895] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,896] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6367 ms, throughput: 5.3680 GB/s; offload_time: 0.5522 ms, put_time: 0.0845 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,900] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 562, LMCache hit tokens: 512, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,908] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,909] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5210 ms, throughput: 6.5609 GB/s; offload_time: 0.4454 ms, put_time: 0.0756 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,909] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-d6ae72b0d6024e2ba07f435dd0b6c26f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,910] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 0.8764 ms, throughput: 3.9000 GB/s; offload_time: 0.8138 ms, put_time: 0.0626 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,915] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 562, LMCache hit tokens: 512, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,926] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 562, LMCache hit tokens: 512, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,933] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-71df15ba62cf41af88fe97a48de69421 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,933] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4406 ms, throughput: 7.7568 GB/s; offload_time: 0.3696 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,938] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 562, LMCache hit tokens: 512, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,947] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-989514b1a417457ebaf236c3dff220f9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,947] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5040 ms, throughput: 6.7815 GB/s; offload_time: 0.4293 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,948] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-7d1054aa546e4448a0d049ab8483f9bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,949] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.5561 ms, throughput: 2.1965 GB/s; offload_time: 1.4835 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,954] LMCache INFO:[0m Reqid: chatcmpl-b8bdba02758843ea986916bbe4b5c962, Total tokens 562, LMCache hit tokens: 512, need to load: 400 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,955] LMCache INFO:[0m Reqid: chatcmpl-8322b2fdbc9c4307b75df598fc9b85bc, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,955] LMCache INFO:[0m Reqid: chatcmpl-60f572dae7d34d399023cfb46428ebef, Total tokens 192, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,956] LMCache INFO:[0m Reqid: chatcmpl-70c361c368e348b2ba700419d17db057, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,956] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,974] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-8322b2fdbc9c4307b75df598fc9b85bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,975] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 0.4276 ms, throughput: 5.7448 GB/s; offload_time: 0.3612 ms, put_time: 0.0665 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,975] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-70c361c368e348b2ba700419d17db057 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,976] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 0.5704 ms, throughput: 5.7116 GB/s; offload_time: 0.5009 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,976] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e9718d34bb754146829997734d3f129c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,978] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5511 ms, throughput: 2.2036 GB/s; offload_time: 1.4836 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:40,992] LMCache INFO:[0m Reqid: chatcmpl-70c361c368e348b2ba700419d17db057, Total tokens 123, LMCache hit tokens: 122, need to load: 74 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:40,993] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,004] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,014] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,021] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,023] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4826 ms, throughput: 2.3054 GB/s; offload_time: 1.4121 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,023] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-a8db9a18e2db4f6ab1163187b2eb41c4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,025] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.9332 ms, throughput: 1.7681 GB/s; offload_time: 1.8600 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,030] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,047] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-780968a859634fc9b6a83b528605a446 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,049] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4304 ms, throughput: 2.3895 GB/s; offload_time: 1.3603 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,053] LMCache INFO:[0m Reqid: chatcmpl-60f572dae7d34d399023cfb46428ebef, Total tokens 198, LMCache hit tokens: 128, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:60982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,063] LMCache INFO:[0m Reqid: chatcmpl-60f572dae7d34d399023cfb46428ebef, Total tokens 198, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,064] LMCache INFO:[0m Reqid: chatcmpl-70c361c368e348b2ba700419d17db057, Total tokens 127, LMCache hit tokens: 122, need to load: 74 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,064] LMCache INFO:[0m Reqid: chatcmpl-1a9bda062f284c019f122af07bc149e3, Total tokens 494, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,065] LMCache INFO:[0m Reqid: chatcmpl-a4f0f159143245f3928e7c7d4a197d30, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,087] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b310ef7357e84bacadcfecac0cf97202 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,088] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4875 ms, throughput: 7.0107 GB/s; offload_time: 0.4187 ms, put_time: 0.0688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,092] LMCache INFO:[0m Reqid: chatcmpl-a4f0f159143245f3928e7c7d4a197d30, Total tokens 97, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,093] LMCache INFO:[0m Reqid: chatcmpl-e453ef8ae7b64901b00b01f89ec7f677, Total tokens 656, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,108] LMCache INFO:[0m Storing KV cache for 97 out of 97 tokens (skip_leading_tokens=0) for request chatcmpl-a4f0f159143245f3928e7c7d4a197d30 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,109] LMCache INFO:[0m Stored 97 out of total 97 tokens. size: 0.0026 gb, cost 0.4431 ms, throughput: 5.8453 GB/s; offload_time: 0.3740 ms, put_time: 0.0691 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,109] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-42e53462c96c4baa9fb0c73a0b8a71f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,110] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.9161 ms, throughput: 3.7310 GB/s; offload_time: 0.8518 ms, put_time: 0.0643 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,111] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-70c361c368e348b2ba700419d17db057 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,111] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6766 ms, throughput: 5.0519 GB/s; offload_time: 0.6130 ms, put_time: 0.0636 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,117] LMCache INFO:[0m Reqid: chatcmpl-e453ef8ae7b64901b00b01f89ec7f677, Total tokens 656, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,127] LMCache INFO:[0m Reqid: chatcmpl-e453ef8ae7b64901b00b01f89ec7f677, Total tokens 656, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,135] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,137] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5293 ms, throughput: 2.2349 GB/s; offload_time: 1.4591 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,141] LMCache INFO:[0m Reqid: chatcmpl-e453ef8ae7b64901b00b01f89ec7f677, Total tokens 656, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,143] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,164] LMCache INFO:[0m Storing KV cache for 144 out of 656 tokens (skip_leading_tokens=512) for request chatcmpl-e453ef8ae7b64901b00b01f89ec7f677 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,165] LMCache INFO:[0m Stored 144 out of total 656 tokens. size: 0.0038 gb, cost 0.6863 ms, throughput: 5.6029 GB/s; offload_time: 0.5808 ms, put_time: 0.1055 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,165] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,167] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.9934 ms, throughput: 3.4407 GB/s; offload_time: 0.9338 ms, put_time: 0.0596 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,167] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,168] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.2806 ms, throughput: 2.6690 GB/s; offload_time: 1.2121 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,169] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9842a449d6c847dfae7a669779d99d4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,170] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5446 ms, throughput: 2.2129 GB/s; offload_time: 1.4483 ms, put_time: 0.0963 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,176] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,184] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-d0571632621c4f4a9be75e3e4228128b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,186] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.4930 ms, throughput: 2.2893 GB/s; offload_time: 1.4170 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,186] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1a326804748141e4b4d1fb42209281d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,188] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6732 ms, throughput: 2.0428 GB/s; offload_time: 1.6074 ms, put_time: 0.0658 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,194] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,204] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,215] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32800 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,223] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1d9cac269a7d4e60859e29d547d5e3b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,224] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5755 ms, throughput: 2.1695 GB/s; offload_time: 1.5008 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,229] LMCache INFO:[0m Reqid: chatcmpl-37a054a5b5e749748e97614a4385f073, Total tokens 1350, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,230] LMCache INFO:[0m Reqid: chatcmpl-e14ae39271a642a7a396a1c8faadba70, Total tokens 213, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,231] LMCache INFO:[0m Reqid: chatcmpl-24efff97d5184d93971c02a6ba28c9ac, Total tokens 833, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,232] LMCache INFO:[0m Reqid: chatcmpl-0178680da1a14672b902839123afc403, Total tokens 235, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,232] LMCache INFO:[0m Reqid: chatcmpl-c9c83e4ac64647db97a077a4208d5d0e, Total tokens 98, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,233] LMCache INFO:[0m Reqid: chatcmpl-af506d94ac9b411992b483e31194e2f2, Total tokens 1281, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,234] LMCache INFO:[0m Reqid: chatcmpl-25e8388266dc4442998d00e289588a7e, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,296] LMCache INFO:[0m Storing KV cache for 98 out of 98 tokens (skip_leading_tokens=0) for request chatcmpl-c9c83e4ac64647db97a077a4208d5d0e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,297] LMCache INFO:[0m Stored 98 out of total 98 tokens. size: 0.0026 gb, cost 0.4567 ms, throughput: 5.7306 GB/s; offload_time: 0.3743 ms, put_time: 0.0823 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,297] LMCache INFO:[0m Storing KV cache for 129 out of 1281 tokens (skip_leading_tokens=1152) for request chatcmpl-af506d94ac9b411992b483e31194e2f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,298] LMCache INFO:[0m Stored 129 out of total 1281 tokens. size: 0.0034 gb, cost 0.8994 ms, throughput: 3.8299 GB/s; offload_time: 0.8003 ms, put_time: 0.0991 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,299] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-c2cb024d68414f78a3d2bdc1b5bd2944 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,301] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.6401 ms, throughput: 2.0840 GB/s; offload_time: 1.5673 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:32822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,306] LMCache INFO:[0m Reqid: chatcmpl-25e8388266dc4442998d00e289588a7e, Total tokens 860, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,307] LMCache INFO:[0m Reqid: chatcmpl-c475002352324a0b9268221578433f70, Total tokens 94, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,309] LMCache INFO:[0m Reqid: chatcmpl-0943c499e87742859795d00307b54cb0, Total tokens 1781, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,327] LMCache INFO:[0m Storing KV cache for 94 out of 94 tokens (skip_leading_tokens=0) for request chatcmpl-c475002352324a0b9268221578433f70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,328] LMCache INFO:[0m Stored 94 out of total 94 tokens. size: 0.0025 gb, cost 0.4442 ms, throughput: 5.6503 GB/s; offload_time: 0.3625 ms, put_time: 0.0817 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,328] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,329] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.7226 ms, throughput: 4.7299 GB/s; offload_time: 0.6437 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,330] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,330] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.8144 ms, throughput: 4.1969 GB/s; offload_time: 0.7491 ms, put_time: 0.0653 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,342] LMCache INFO:[0m Reqid: chatcmpl-0943c499e87742859795d00307b54cb0, Total tokens 1781, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,353] LMCache INFO:[0m Reqid: chatcmpl-0943c499e87742859795d00307b54cb0, Total tokens 1781, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,361] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c5fb695b995a4162ab7c2e50ca262d60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,361] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5285 ms, throughput: 6.4674 GB/s; offload_time: 0.4491 ms, put_time: 0.0794 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,366] LMCache INFO:[0m Reqid: chatcmpl-0943c499e87742859795d00307b54cb0, Total tokens 1781, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,376] LMCache INFO:[0m Reqid: chatcmpl-0943c499e87742859795d00307b54cb0, Total tokens 1781, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,377] LMCache INFO:[0m Reqid: chatcmpl-85b519e1f7e6401499041f731192546e, Total tokens 152, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,378] LMCache INFO:[0m Reqid: chatcmpl-9e8f7cdd6fff4fc2a066119fda6868dc, Total tokens 537, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,415] LMCache INFO:[0m Storing KV cache for 152 out of 152 tokens (skip_leading_tokens=0) for request chatcmpl-85b519e1f7e6401499041f731192546e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,416] LMCache INFO:[0m Stored 152 out of total 152 tokens. size: 0.0041 gb, cost 0.6389 ms, throughput: 6.3530 GB/s; offload_time: 0.5367 ms, put_time: 0.1022 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,422] LMCache INFO:[0m Reqid: chatcmpl-9e8f7cdd6fff4fc2a066119fda6868dc, Total tokens 537, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,432] LMCache INFO:[0m Reqid: chatcmpl-9e8f7cdd6fff4fc2a066119fda6868dc, Total tokens 537, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,433] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1715, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,451] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a39aba9cb7de4b6da0f340f6b1792786 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,452] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.4755 ms, throughput: 7.1879 GB/s; offload_time: 0.4071 ms, put_time: 0.0684 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,457] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1715, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,467] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1715, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,469] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,502] LMCache INFO:[0m Storing KV cache for 691 out of 1715 tokens (skip_leading_tokens=1024) for request chatcmpl-e00f650981bb4057ab7b45a96179ed5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,504] LMCache INFO:[0m Stored 691 out of total 1715 tokens. size: 0.0185 gb, cost 1.8365 ms, throughput: 10.0471 GB/s; offload_time: 1.3002 ms, put_time: 0.5363 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,505] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1a9bda062f284c019f122af07bc149e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,508] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8719 ms, throughput: 1.8259 GB/s; offload_time: 1.8071 ms, put_time: 0.0648 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,514] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32890 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,525] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,545] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 99 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,556] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 147 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,563] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-0e682089b9444827af096e87dedaa05a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,564] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.6020 ms, throughput: 5.6780 GB/s; offload_time: 0.5256 ms, put_time: 0.0763 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,564] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-dab270922c62427b91a0350f60a9d037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,565] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6416 ms, throughput: 5.3277 GB/s; offload_time: 0.5701 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,570] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 259 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,581] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 371 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,588] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-cb36c770d48643c3a38671bff259f7fe [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,589] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5343 ms, throughput: 6.3975 GB/s; offload_time: 0.4563 ms, put_time: 0.0780 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,589] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-0943c499e87742859795d00307b54cb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,590] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5544 ms, throughput: 6.1657 GB/s; offload_time: 0.4872 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,596] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 435 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,603] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-0b1b31e7ca0b425ba2ba6e4c28cfe0a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,605] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5049 ms, throughput: 2.2712 GB/s; offload_time: 1.4233 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,605] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,607] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5994 ms, throughput: 2.1371 GB/s; offload_time: 1.5283 ms, put_time: 0.0711 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,611] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 547 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,619] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-cf1b1df8a4d74297b539b1fc3809cd4e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,620] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4966 ms, throughput: 2.2838 GB/s; offload_time: 1.4236 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,625] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 579 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,635] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 627 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,643] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-079ce9ebfdf7439b8fefe15935833e6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,645] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4552 ms, throughput: 2.3488 GB/s; offload_time: 1.3819 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,645] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,647] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.6767 ms, throughput: 2.0385 GB/s; offload_time: 1.6089 ms, put_time: 0.0679 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,652] LMCache INFO:[0m Reqid: chatcmpl-e00f650981bb4057ab7b45a96179ed5d, Total tokens 1718, LMCache hit tokens: 1715, need to load: 755 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,653] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,664] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0178680da1a14672b902839123afc403 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,666] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4084 ms, throughput: 2.4269 GB/s; offload_time: 1.3374 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,670] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,681] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,688] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a4f0f159143245f3928e7c7d4a197d30 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,689] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4035 ms, throughput: 2.4354 GB/s; offload_time: 1.3252 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,694] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,705] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,712] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-13c21c26d5d14ffdba5438bd00aa6462 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,713] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.4407 ms, throughput: 2.3724 GB/s; offload_time: 1.3700 ms, put_time: 0.0708 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,718] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,728] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,736] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-ec409da573b843f1aab380ef224b2aa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,738] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.6557 ms, throughput: 2.0644 GB/s; offload_time: 1.5436 ms, put_time: 0.1121 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,742] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,750] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-4c277ca6d6a04ba58995780469a2245b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,752] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.5168 ms, throughput: 2.2534 GB/s; offload_time: 1.4455 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,757] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,767] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,774] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c9c83e4ac64647db97a077a4208d5d0e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,776] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3725 ms, throughput: 2.4902 GB/s; offload_time: 1.3017 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,781] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,788] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-390ece15a8764696bf185dd70b27b2c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,790] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4696 ms, throughput: 2.3258 GB/s; offload_time: 1.3969 ms, put_time: 0.0728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,790] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO 07-11 15:21:41 [loggers.py:118] Engine 000: Avg prompt throughput: 11374.5 tokens/s, Avg generation throughput: 5187.1 tokens/s, Running: 78 reqs, Waiting: 69 reqs, GPU KV cache usage: 97.2%, Prefix cache hit rate: 15.6%
[32;20m[2025-07-11 15:21:41,792] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.6748 ms, throughput: 2.0408 GB/s; offload_time: 1.6047 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,792] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-6e5dff07b4da4f03a342f836bd6d6639 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,794] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5322 ms, throughput: 2.2308 GB/s; offload_time: 1.4607 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,799] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,810] LMCache INFO:[0m Reqid: chatcmpl-4d35de664cec442fb9b5148b6b03813c, Total tokens 2478, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,811] LMCache INFO:[0m Reqid: chatcmpl-fc8fec94fc3344b3b65a1b3f596a8822, Total tokens 92, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,811] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 575, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,862] LMCache INFO:[0m Storing KV cache for 2478 out of 2478 tokens (skip_leading_tokens=0) for request chatcmpl-4d35de664cec442fb9b5148b6b03813c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,881] LMCache INFO:[0m Stored 2478 out of total 2478 tokens. size: 0.0662 gb, cost 18.6064 ms, throughput: 3.5563 GB/s; offload_time: 17.6275 ms, put_time: 0.9790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,882] LMCache INFO:[0m Storing KV cache for 92 out of 92 tokens (skip_leading_tokens=0) for request chatcmpl-fc8fec94fc3344b3b65a1b3f596a8822 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,885] LMCache INFO:[0m Stored 92 out of total 92 tokens. size: 0.0025 gb, cost 2.6087 ms, throughput: 0.9417 GB/s; offload_time: 2.0399 ms, put_time: 0.5688 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,886] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,892] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 5.1306 ms, throughput: 0.6662 GB/s; offload_time: 4.9062 ms, put_time: 0.2244 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:32910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:41,901] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 575, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,908] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-76409cc1f3534dfca9067a028a9881c5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,910] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4864 ms, throughput: 2.2996 GB/s; offload_time: 1.4135 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,914] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 575, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,915] LMCache INFO:[0m Reqid: chatcmpl-601c05c2fb8e4c2cbc4fc8db2ca38a8b, Total tokens 423, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,939] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-c475002352324a0b9268221578433f70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,940] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4564 ms, throughput: 7.4891 GB/s; offload_time: 0.3798 ms, put_time: 0.0766 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,945] LMCache INFO:[0m Reqid: chatcmpl-601c05c2fb8e4c2cbc4fc8db2ca38a8b, Total tokens 423, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,955] LMCache INFO:[0m Reqid: chatcmpl-601c05c2fb8e4c2cbc4fc8db2ca38a8b, Total tokens 423, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,962] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-25e8388266dc4442998d00e289588a7e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,962] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5053 ms, throughput: 6.7643 GB/s; offload_time: 0.4308 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,976] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,984] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-51701e2aae1b4477b3b72298c04be25a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,984] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5169 ms, throughput: 6.6119 GB/s; offload_time: 0.4460 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:41,989] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,996] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-689f7e55e3994331b23083df9300b128 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:41,997] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5488 ms, throughput: 6.2276 GB/s; offload_time: 0.4773 ms, put_time: 0.0715 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,001] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,011] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 240 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,022] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 320 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,029] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e14ae39271a642a7a396a1c8faadba70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,031] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4408 ms, throughput: 2.3723 GB/s; offload_time: 1.3661 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,035] LMCache INFO:[0m Reqid: chatcmpl-44ca7037d2ef4a86bf949b39420ccf04, Total tokens 578, LMCache hit tokens: 512, need to load: 416 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,036] LMCache INFO:[0m Reqid: chatcmpl-601c05c2fb8e4c2cbc4fc8db2ca38a8b, Total tokens 423, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,037] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,060] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,070] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,080] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,089] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,099] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,106] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-60f572dae7d34d399023cfb46428ebef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,107] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5051 ms, throughput: 6.7676 GB/s; offload_time: 0.4286 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,111] LMCache INFO:[0m Reqid: chatcmpl-804a0c9334ca4abfa8226a9180e71572, Total tokens 716, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,112] LMCache INFO:[0m Reqid: chatcmpl-0ac3916e017e4cf18ec3ac1f482ec661, Total tokens 332, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,112] LMCache INFO:[0m Reqid: chatcmpl-715a251383114227ab68162307ebbe03, Total tokens 156, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,113] LMCache INFO:[0m Reqid: chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8, Total tokens 1234, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,144] LMCache INFO:[0m Reqid: chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8, Total tokens 1234, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,154] LMCache INFO:[0m Reqid: chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8, Total tokens 1234, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,155] LMCache INFO:[0m Reqid: chatcmpl-c4177b2845914b2f97a2c14dc27a3f21, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,184] LMCache INFO:[0m Storing KV cache for 1234 out of 1234 tokens (skip_leading_tokens=0) for request chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,190] LMCache INFO:[0m Stored 1234 out of total 1234 tokens. size: 0.0330 gb, cost 6.0087 ms, throughput: 5.4840 GB/s; offload_time: 5.0153 ms, put_time: 0.9934 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,192] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-5823ac8245f3409f97906c835e396e36 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,196] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 3.6056 ms, throughput: 0.9480 GB/s; offload_time: 3.5441 ms, put_time: 0.0615 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,196] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-53c00f94c859426eb2d2b6cfaa366d3b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,200] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 3.0674 ms, throughput: 1.1143 GB/s; offload_time: 2.7130 ms, put_time: 0.3544 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,204] LMCache INFO:[0m Reqid: chatcmpl-c4177b2845914b2f97a2c14dc27a3f21, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,205] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 489, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,206] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,230] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,240] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,247] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-50123025e53f4e1a9c330fcebddf6ebf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:32998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,248] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6228 ms, throughput: 5.4881 GB/s; offload_time: 0.5449 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,252] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,262] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,272] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,280] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-dcb4de26086b4dbca291a64dd9190ec1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,280] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 0.6982 ms, throughput: 4.8957 GB/s; offload_time: 0.6122 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,281] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-37a054a5b5e749748e97614a4385f073 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,282] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6086 ms, throughput: 5.6161 GB/s; offload_time: 0.5432 ms, put_time: 0.0654 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,286] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,296] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,313] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b8bdba02758843ea986916bbe4b5c962 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,315] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5595 ms, throughput: 2.1917 GB/s; offload_time: 1.4823 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,319] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 497, LMCache hit tokens: 384, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,327] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-654c138c801f4c5f9613e43d2e43a57e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,328] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5672 ms, throughput: 2.1810 GB/s; offload_time: 1.4918 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,333] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 497, LMCache hit tokens: 384, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,340] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-24efff97d5184d93971c02a6ba28c9ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,342] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5737 ms, throughput: 2.1719 GB/s; offload_time: 1.4958 ms, put_time: 0.0779 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,346] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 497, LMCache hit tokens: 384, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,356] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 497, LMCache hit tokens: 384, need to load: 272 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,366] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 497, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,366] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,382] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,392] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,400] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-c4d0fe16c63d41da83d1a0e711dadb94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,402] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.5121 ms, throughput: 2.2605 GB/s; offload_time: 1.4357 ms, put_time: 0.0764 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,402] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c5706fcb2df84f2e8390769c62f4b734 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,404] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.7069 ms, throughput: 2.0025 GB/s; offload_time: 1.6332 ms, put_time: 0.0737 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,409] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,419] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,427] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,428] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5909 ms, throughput: 2.1485 GB/s; offload_time: 1.5161 ms, put_time: 0.0747 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,433] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,443] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,460] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-353de32886364fbabe4f37535f54aa9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,461] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5326 ms, throughput: 2.2302 GB/s; offload_time: 1.4538 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,465] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,473] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-72fb1da1462f4ff3b36ee9ca5e33bd17 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,475] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6430 ms, throughput: 2.0803 GB/s; offload_time: 1.5699 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,480] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,491] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,499] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-38504b82be154ec8996ead7e4737e4aa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,501] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 2.5579 ms, throughput: 1.3362 GB/s; offload_time: 2.4797 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,502] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-c79428cac2c24b0eac3247a0f8d92cfd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,504] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 2.1426 ms, throughput: 1.5952 GB/s; offload_time: 2.0713 ms, put_time: 0.0713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,504] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-870c116c795e4f369cc278cb5e9b353f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,507] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.2742 ms, throughput: 1.5029 GB/s; offload_time: 2.2075 ms, put_time: 0.0667 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,513] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,523] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,533] LMCache INFO:[0m Reqid: chatcmpl-25242a416c5846e4b77b6989b54840b2, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,534] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,550] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,557] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-0e4a9cbb356e4160b150d43a10d5ec4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,559] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.0241 ms, throughput: 1.6887 GB/s; offload_time: 1.9363 ms, put_time: 0.0877 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,564] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,571] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,573] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.8913 ms, throughput: 1.8072 GB/s; offload_time: 1.8192 ms, put_time: 0.0721 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,578] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,589] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,599] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1369, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,600] LMCache INFO:[0m Reqid: chatcmpl-d4b0789a654447bd953f773c3c6c45d6, Total tokens 247, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,601] LMCache INFO:[0m Reqid: chatcmpl-6475802f389f4b5da6341821707d4d3a, Total tokens 291, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,602] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,653] LMCache INFO:[0m Reqid: chatcmpl-6475802f389f4b5da6341821707d4d3a, Total tokens 292, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,663] LMCache INFO:[0m Reqid: chatcmpl-6475802f389f4b5da6341821707d4d3a, Total tokens 292, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,670] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-25242a416c5846e4b77b6989b54840b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,671] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5332 ms, throughput: 6.4106 GB/s; offload_time: 0.4543 ms, put_time: 0.0789 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,684] LMCache INFO:[0m Reqid: chatcmpl-d4b0789a654447bd953f773c3c6c45d6, Total tokens 251, LMCache hit tokens: 128, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,691] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-2aecb0a0d37540b986a099bfb136bde2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,692] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5692 ms, throughput: 6.0049 GB/s; offload_time: 0.4910 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,695] LMCache INFO:[0m Reqid: chatcmpl-d4b0789a654447bd953f773c3c6c45d6, Total tokens 251, LMCache hit tokens: 128, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,715] LMCache INFO:[0m Reqid: chatcmpl-53f8caf24b19439c8abfffd3bd6aca86, Total tokens 1376, LMCache hit tokens: 1280, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,716] LMCache INFO:[0m Reqid: chatcmpl-d4b0789a654447bd953f773c3c6c45d6, Total tokens 251, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,716] LMCache INFO:[0m Reqid: chatcmpl-6475802f389f4b5da6341821707d4d3a, Total tokens 292, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,717] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,733] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-e5c04a2414c84dd2b934921675f628e8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,733] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5405 ms, throughput: 6.3240 GB/s; offload_time: 0.4622 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,738] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,747] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,757] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,764] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-e00f650981bb4057ab7b45a96179ed5d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,765] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6110 ms, throughput: 5.5944 GB/s; offload_time: 0.5359 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,769] LMCache INFO:[0m Reqid: chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8, Total tokens 1471, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,771] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,803] LMCache INFO:[0m Storing KV cache for 1471 out of 1471 tokens (skip_leading_tokens=0) for request chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,811] LMCache INFO:[0m Stored 1471 out of total 1471 tokens. size: 0.0393 gb, cost 7.9211 ms, throughput: 4.9589 GB/s; offload_time: 7.3896 ms, put_time: 0.5315 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,823] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,830] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-d4b0789a654447bd953f773c3c6c45d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,832] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4299 ms, throughput: 2.3903 GB/s; offload_time: 1.3547 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,836] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,844] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,845] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5319 ms, throughput: 2.2312 GB/s; offload_time: 1.4462 ms, put_time: 0.0857 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,849] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,860] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,867] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-1f9cb3ba366746a498abaad8efd2b368 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,869] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5189 ms, throughput: 2.2502 GB/s; offload_time: 1.4392 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,873] LMCache INFO:[0m Reqid: chatcmpl-85bad17859a24033a31f4b08c4485da0, Total tokens 1283, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,875] LMCache INFO:[0m Reqid: chatcmpl-f3c0d44649834be2b59791e34b826b4c, Total tokens 1140, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,876] LMCache INFO:[0m Reqid: chatcmpl-b6d8336660404d7e9124d70cd4eae04d, Total tokens 595, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,877] LMCache INFO:[0m Reqid: chatcmpl-83b6c231177144968aaa6a90a4127817, Total tokens 350, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,877] LMCache INFO:[0m Reqid: chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,927] LMCache INFO:[0m Storing KV cache for 387 out of 1283 tokens (skip_leading_tokens=896) for request chatcmpl-85bad17859a24033a31f4b08c4485da0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,929] LMCache INFO:[0m Stored 387 out of total 1283 tokens. size: 0.0103 gb, cost 1.3671 ms, throughput: 7.5593 GB/s; offload_time: 0.9594 ms, put_time: 0.4077 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,929] LMCache INFO:[0m Storing KV cache for 244 out of 1140 tokens (skip_leading_tokens=896) for request chatcmpl-f3c0d44649834be2b59791e34b826b4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,933] LMCache INFO:[0m Stored 244 out of total 1140 tokens. size: 0.0065 gb, cost 3.0097 ms, throughput: 2.1648 GB/s; offload_time: 2.7384 ms, put_time: 0.2713 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,938] LMCache INFO:[0m Reqid: chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,946] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-804a0c9334ca4abfa8226a9180e71572 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,947] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5263 ms, throughput: 6.4940 GB/s; offload_time: 0.4531 ms, put_time: 0.0732 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33096 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:42,961] LMCache INFO:[0m Reqid: chatcmpl-83b6c231177144968aaa6a90a4127817, Total tokens 352, LMCache hit tokens: 256, need to load: 0 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,968] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-40a48e30876c4987901be12de4a84e72 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,968] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4679 ms, throughput: 7.3048 GB/s; offload_time: 0.3976 ms, put_time: 0.0703 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,973] LMCache INFO:[0m Reqid: chatcmpl-83b6c231177144968aaa6a90a4127817, Total tokens 352, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,973] LMCache INFO:[0m Reqid: chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a, Total tokens 166, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,974] LMCache INFO:[0m Reqid: chatcmpl-5e57a568ebc642dca0b4f580b536b7ea, Total tokens 103, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,975] LMCache INFO:[0m Reqid: chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2, Total tokens 1801, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,992] LMCache INFO:[0m Storing KV cache for 103 out of 103 tokens (skip_leading_tokens=0) for request chatcmpl-5e57a568ebc642dca0b4f580b536b7ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:42,993] LMCache INFO:[0m Stored 103 out of total 103 tokens. size: 0.0028 gb, cost 0.4004 ms, throughput: 6.8692 GB/s; offload_time: 0.3324 ms, put_time: 0.0680 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:42,998] LMCache INFO:[0m Reqid: chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2, Total tokens 1801, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,006] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,008] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.6443 ms, throughput: 2.0786 GB/s; offload_time: 1.5683 ms, put_time: 0.0760 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,008] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-44ca7037d2ef4a86bf949b39420ccf04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,010] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5659 ms, throughput: 2.1827 GB/s; offload_time: 1.4960 ms, put_time: 0.0699 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,015] LMCache INFO:[0m Reqid: chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2, Total tokens 1801, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,023] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a2f63bc0a28b4fb681b07c7acd266fd4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,024] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.4601 ms, throughput: 2.3409 GB/s; offload_time: 1.3803 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,024] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-e453ef8ae7b64901b00b01f89ec7f677 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,026] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.6322 ms, throughput: 2.0941 GB/s; offload_time: 1.5622 ms, put_time: 0.0701 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,031] LMCache INFO:[0m Reqid: chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2, Total tokens 1801, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,041] LMCache INFO:[0m Reqid: chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2, Total tokens 1801, LMCache hit tokens: 1664, need to load: 1616 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,042] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1096, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,044] LMCache INFO:[0m Reqid: chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962, Total tokens 1481, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,102] LMCache INFO:[0m Storing KV cache for 137 out of 1801 tokens (skip_leading_tokens=1664) for request chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,103] LMCache INFO:[0m Stored 137 out of total 1801 tokens. size: 0.0037 gb, cost 0.7779 ms, throughput: 4.7029 GB/s; offload_time: 0.6727 ms, put_time: 0.1052 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,103] LMCache INFO:[0m Storing KV cache for 1096 out of 1096 tokens (skip_leading_tokens=0) for request chatcmpl-b96360d2ee724e0fb3568d988f30450c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33154 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33162 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,108] LMCache INFO:[0m Stored 1096 out of total 1096 tokens. size: 0.0293 gb, cost 4.3684 ms, throughput: 6.6996 GB/s; offload_time: 4.0120 ms, put_time: 0.3563 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,108] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-71df15ba62cf41af88fe97a48de69421 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,112] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.5288 ms, throughput: 1.3516 GB/s; offload_time: 2.4210 ms, put_time: 0.1078 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,112] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-85b519e1f7e6401499041f731192546e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,113] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6738 ms, throughput: 5.0730 GB/s; offload_time: 0.6053 ms, put_time: 0.0685 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,126] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-7d1054aa546e4448a0d049ab8483f9bc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,127] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6786 ms, throughput: 5.0367 GB/s; offload_time: 0.5913 ms, put_time: 0.0873 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,128] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-9e8f7cdd6fff4fc2a066119fda6868dc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,128] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.6266 ms, throughput: 5.4549 GB/s; offload_time: 0.5465 ms, put_time: 0.0801 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,133] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 120 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,140] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e9718d34bb754146829997734d3f129c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,142] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5688 ms, throughput: 2.1787 GB/s; offload_time: 1.4872 ms, put_time: 0.0816 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,146] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 248 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,156] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 296 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,163] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-f3c0d44649834be2b59791e34b826b4c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,165] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5948 ms, throughput: 2.1432 GB/s; offload_time: 1.5203 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,169] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 456 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,179] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 536 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,186] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,188] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5976 ms, throughput: 2.1395 GB/s; offload_time: 1.5172 ms, put_time: 0.0803 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,188] LMCache INFO:[0m Storing KV cache for 128 out of 2560 tokens (skip_leading_tokens=2432) for request chatcmpl-4d35de664cec442fb9b5148b6b03813c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,190] LMCache INFO:[0m Stored 128 out of total 2560 tokens. size: 0.0034 gb, cost 1.9294 ms, throughput: 1.7715 GB/s; offload_time: 1.8552 ms, put_time: 0.0742 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,196] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 600 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,205] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 696 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,215] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,225] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 792 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,234] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 856 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,242] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-42e53462c96c4baa9fb0c73a0b8a71f5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,243] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4963 ms, throughput: 2.2843 GB/s; offload_time: 1.4253 ms, put_time: 0.0709 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,243] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-70c361c368e348b2ba700419d17db057 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,245] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5639 ms, throughput: 2.1855 GB/s; offload_time: 1.4953 ms, put_time: 0.0686 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,250] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 936 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,260] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 1016 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,267] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-cf0c1dac7c794905b3eb8121eafef867 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,269] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6649 ms, throughput: 2.0530 GB/s; offload_time: 1.5905 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,273] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 1048 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,281] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-ac7b3b0aff9149889dbeb8c4b888f70c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,283] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6414 ms, throughput: 2.0823 GB/s; offload_time: 1.5616 ms, put_time: 0.0798 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,283] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,285] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.9083 ms, throughput: 1.7911 GB/s; offload_time: 1.8329 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,290] LMCache INFO:[0m Reqid: chatcmpl-b96360d2ee724e0fb3568d988f30450c, Total tokens 1097, LMCache hit tokens: 1096, need to load: 1048 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,291] LMCache INFO:[0m Reqid: chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962, Total tokens 1481, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,299] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1a326804748141e4b4d1fb42209281d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,301] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.6114 ms, throughput: 2.1211 GB/s; offload_time: 1.5358 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,301] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-53f8caf24b19439c8abfffd3bd6aca86 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,303] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.7705 ms, throughput: 1.9305 GB/s; offload_time: 1.7033 ms, put_time: 0.0672 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,307] LMCache INFO:[0m Reqid: chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962, Total tokens 1481, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,318] LMCache INFO:[0m Reqid: chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962, Total tokens 1481, LMCache hit tokens: 1152, need to load: 1104 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,318] LMCache INFO:[0m Reqid: chatcmpl-de494a07e73042fc83d21a6391a666fa, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,319] LMCache INFO:[0m Reqid: chatcmpl-62c6fb5d8f844b8a952570ba72f987a4, Total tokens 101, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,319] LMCache INFO:[0m Reqid: chatcmpl-1db73fd196044d5387ceedd876cc445d, Total tokens 658, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,320] LMCache INFO:[0m Reqid: chatcmpl-dc8715e942e3440495308d8f7bb86d6a, Total tokens 140, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,321] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,368] LMCache INFO:[0m Storing KV cache for 329 out of 1481 tokens (skip_leading_tokens=1152) for request chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,369] LMCache INFO:[0m Stored 329 out of total 1481 tokens. size: 0.0088 gb, cost 1.0114 ms, throughput: 8.6861 GB/s; offload_time: 0.8637 ms, put_time: 0.1478 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,369] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-de494a07e73042fc83d21a6391a666fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,371] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 1.3028 ms, throughput: 2.3160 GB/s; offload_time: 1.2070 ms, put_time: 0.0958 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,371] LMCache INFO:[0m Storing KV cache for 101 out of 101 tokens (skip_leading_tokens=0) for request chatcmpl-62c6fb5d8f844b8a952570ba72f987a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,372] LMCache INFO:[0m Stored 101 out of total 101 tokens. size: 0.0027 gb, cost 0.8264 ms, throughput: 3.2637 GB/s; offload_time: 0.7288 ms, put_time: 0.0976 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,373] LMCache INFO:[0m Storing KV cache for 146 out of 658 tokens (skip_leading_tokens=512) for request chatcmpl-1db73fd196044d5387ceedd876cc445d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,374] LMCache INFO:[0m Stored 146 out of total 658 tokens. size: 0.0039 gb, cost 1.2294 ms, throughput: 3.1712 GB/s; offload_time: 1.0206 ms, put_time: 0.2088 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,375] LMCache INFO:[0m Storing KV cache for 140 out of 140 tokens (skip_leading_tokens=0) for request chatcmpl-dc8715e942e3440495308d8f7bb86d6a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,377] LMCache INFO:[0m Stored 140 out of total 140 tokens. size: 0.0037 gb, cost 2.3647 ms, throughput: 1.5809 GB/s; offload_time: 2.1979 ms, put_time: 0.1668 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,382] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,390] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-1d9cac269a7d4e60859e29d547d5e3b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,391] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.6238 ms, throughput: 5.4789 GB/s; offload_time: 0.5469 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,391] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-af506d94ac9b411992b483e31194e2f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,392] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6612 ms, throughput: 5.1694 GB/s; offload_time: 0.5894 ms, put_time: 0.0718 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,397] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,407] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,415] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-fa3459d7b5ae4ce08ff11e233b71806c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,415] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5227 ms, throughput: 6.5396 GB/s; offload_time: 0.4459 ms, put_time: 0.0768 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,416] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,417] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.6895 ms, throughput: 2.0230 GB/s; offload_time: 1.6101 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,423] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,430] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-5e57a568ebc642dca0b4f580b536b7ea [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,431] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4847 ms, throughput: 2.3021 GB/s; offload_time: 1.3989 ms, put_time: 0.0858 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,436] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,455] LMCache INFO:[0m Reqid: chatcmpl-dc8715e942e3440495308d8f7bb86d6a, Total tokens 146, LMCache hit tokens: 140, need to load: 92 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,456] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1669, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,457] LMCache INFO:[0m Reqid: chatcmpl-838b761669014a6eb2568ba2f90ac055, Total tokens 809, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,496] LMCache INFO:[0m Storing KV cache for 133 out of 1669 tokens (skip_leading_tokens=1536) for request chatcmpl-2327e9117eb9400c95f80cc543638c22 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,497] LMCache INFO:[0m Stored 133 out of total 1669 tokens. size: 0.0036 gb, cost 0.7781 ms, throughput: 4.5641 GB/s; offload_time: 0.6730 ms, put_time: 0.1051 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,497] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-601c05c2fb8e4c2cbc4fc8db2ca38a8b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,499] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.3863 ms, throughput: 2.4655 GB/s; offload_time: 1.3222 ms, put_time: 0.0641 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,504] LMCache INFO:[0m Reqid: chatcmpl-838b761669014a6eb2568ba2f90ac055, Total tokens 809, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,521] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-a39aba9cb7de4b6da0f340f6b1792786 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,521] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5032 ms, throughput: 6.7924 GB/s; offload_time: 0.4299 ms, put_time: 0.0733 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,526] LMCache INFO:[0m Reqid: chatcmpl-2327e9117eb9400c95f80cc543638c22, Total tokens 1671, LMCache hit tokens: 1669, need to load: 101 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,527] LMCache INFO:[0m Reqid: chatcmpl-838b761669014a6eb2568ba2f90ac055, Total tokens 809, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,541] LMCache INFO:[0m Reqid: chatcmpl-838b761669014a6eb2568ba2f90ac055, Total tokens 809, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,548] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1a9bda062f284c019f122af07bc149e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,549] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5435 ms, throughput: 6.2893 GB/s; offload_time: 0.4598 ms, put_time: 0.0837 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,549] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-83b6c231177144968aaa6a90a4127817 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,550] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.6028 ms, throughput: 5.6700 GB/s; offload_time: 0.5397 ms, put_time: 0.0631 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,555] LMCache INFO:[0m Reqid: chatcmpl-838b761669014a6eb2568ba2f90ac055, Total tokens 809, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,555] LMCache INFO:[0m Reqid: chatcmpl-6b0e7f5901d14709af73b23f85bc914d, Total tokens 141, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,579] LMCache INFO:[0m Reqid: chatcmpl-6b0e7f5901d14709af73b23f85bc914d, Total tokens 141, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,580] LMCache INFO:[0m Reqid: chatcmpl-a49f384a9cb14220af6c7ed482e6c1a4, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,581] LMCache INFO:[0m Reqid: chatcmpl-82bf6ab90d7647508579a56959bebf5c, Total tokens 1898, LMCache hit tokens: 1792, need to load: 1744 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,582] LMCache INFO:[0m Reqid: chatcmpl-a124d6bdb28b429f90ebe2659606edef, Total tokens 533, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,582] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,625] LMCache INFO:[0m Storing KV cache for 141 out of 141 tokens (skip_leading_tokens=0) for request chatcmpl-6b0e7f5901d14709af73b23f85bc914d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,625] LMCache INFO:[0m Stored 141 out of total 141 tokens. size: 0.0038 gb, cost 0.6828 ms, throughput: 5.5140 GB/s; offload_time: 0.5708 ms, put_time: 0.1120 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,626] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-a49f384a9cb14220af6c7ed482e6c1a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,628] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 1.7399 ms, throughput: 1.5347 GB/s; offload_time: 1.6733 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,628] LMCache INFO:[0m Storing KV cache for 149 out of 533 tokens (skip_leading_tokens=384) for request chatcmpl-a124d6bdb28b429f90ebe2659606edef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,629] LMCache INFO:[0m Stored 149 out of total 533 tokens. size: 0.0040 gb, cost 0.8489 ms, throughput: 4.6872 GB/s; offload_time: 0.7346 ms, put_time: 0.1143 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,635] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,645] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,653] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-de494a07e73042fc83d21a6391a666fa [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,653] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.5154 ms, throughput: 6.6318 GB/s; offload_time: 0.4311 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,657] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,665] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-dab270922c62427b91a0350f60a9d037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,665] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5470 ms, throughput: 6.2491 GB/s; offload_time: 0.4666 ms, put_time: 0.0804 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,669] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,677] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c4177b2845914b2f97a2c14dc27a3f21 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,678] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.5194 ms, throughput: 6.5803 GB/s; offload_time: 0.4383 ms, put_time: 0.0811 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,682] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,689] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-0943c499e87742859795d00307b54cb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,690] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 0.6355 ms, throughput: 5.3782 GB/s; offload_time: 0.5559 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,694] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,702] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-0b1b31e7ca0b425ba2ba6e4c28cfe0a5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,702] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5730 ms, throughput: 5.9647 GB/s; offload_time: 0.4903 ms, put_time: 0.0827 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,703] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,703] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5712 ms, throughput: 5.9837 GB/s; offload_time: 0.5025 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,708] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,715] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-b6d8336660404d7e9124d70cd4eae04d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,716] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5845 ms, throughput: 5.8474 GB/s; offload_time: 0.4884 ms, put_time: 0.0961 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,720] LMCache INFO:[0m Reqid: chatcmpl-ee807fc8e3ab41518f78c9107a3883df, Total tokens 921, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,721] LMCache INFO:[0m Reqid: chatcmpl-1cf9d4c7647c441bb4235a88627ad436, Total tokens 846, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,743] LMCache INFO:[0m Reqid: chatcmpl-1cf9d4c7647c441bb4235a88627ad436, Total tokens 846, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,750] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,751] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.6307 ms, throughput: 5.4191 GB/s; offload_time: 0.5467 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,755] LMCache INFO:[0m Reqid: chatcmpl-1cf9d4c7647c441bb4235a88627ad436, Total tokens 846, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,765] LMCache INFO:[0m Reqid: chatcmpl-1cf9d4c7647c441bb4235a88627ad436, Total tokens 846, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,766] LMCache INFO:[0m Reqid: chatcmpl-329f6fc01d48415591fd8f43afc98216, Total tokens 1215, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,787] LMCache INFO:[0m Storing KV cache for 462 out of 846 tokens (skip_leading_tokens=384) for request chatcmpl-1cf9d4c7647c441bb4235a88627ad436 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,788] LMCache INFO:[0m Stored 462 out of total 846 tokens. size: 0.0123 gb, cost 1.3291 ms, throughput: 9.2822 GB/s; offload_time: 1.0016 ms, put_time: 0.3275 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,791] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-715a251383114227ab68162307ebbe03 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,792] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.5736 ms, throughput: 2.1721 GB/s; offload_time: 1.4812 ms, put_time: 0.0923 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,798] LMCache INFO:[0m Reqid: chatcmpl-329f6fc01d48415591fd8f43afc98216, Total tokens 1215, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,799] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1028, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,829] LMCache INFO:[0m Storing KV cache for 1215 out of 1215 tokens (skip_leading_tokens=0) for request chatcmpl-329f6fc01d48415591fd8f43afc98216 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,838] LMCache INFO:[0m Stored 1215 out of total 1215 tokens. size: 0.0324 gb, cost 9.5253 ms, throughput: 3.4061 GB/s; offload_time: 8.9526 ms, put_time: 0.5728 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,839] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a4f0f159143245f3928e7c7d4a197d30 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,842] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 2.9218 ms, throughput: 1.1698 GB/s; offload_time: 2.7684 ms, put_time: 0.1533 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,850] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1028, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,860] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1028, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,862] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,891] LMCache INFO:[0m Storing KV cache for 132 out of 1028 tokens (skip_leading_tokens=896) for request chatcmpl-19696318167c436d8bf42d3d723fa8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,892] LMCache INFO:[0m Stored 132 out of total 1028 tokens. size: 0.0035 gb, cost 0.7193 ms, throughput: 4.9005 GB/s; offload_time: 0.6179 ms, put_time: 0.1014 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,892] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-62c6fb5d8f844b8a952570ba72f987a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,893] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.1674 ms, throughput: 2.9277 GB/s; offload_time: 1.0653 ms, put_time: 0.1022 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,898] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,908] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,916] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-ec409da573b843f1aab380ef224b2aa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:43,917] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.8736 ms, throughput: 3.9126 GB/s; offload_time: 0.7899 ms, put_time: 0.0837 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,922] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,929] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-4c277ca6d6a04ba58995780469a2245b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,930] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5846 ms, throughput: 5.8463 GB/s; offload_time: 0.5063 ms, put_time: 0.0783 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,934] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,944] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,951] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c9c83e4ac64647db97a077a4208d5d0e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,952] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4584 ms, throughput: 7.4570 GB/s; offload_time: 0.3870 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,955] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,963] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-c914cf59968b4ccd8b405d40bbb41b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,964] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5041 ms, throughput: 6.7805 GB/s; offload_time: 0.4317 ms, put_time: 0.0724 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,964] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-6e5dff07b4da4f03a342f836bd6d6639 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,965] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5485 ms, throughput: 6.2310 GB/s; offload_time: 0.4877 ms, put_time: 0.0609 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,979] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1035, LMCache hit tokens: 1028, need to load: 84 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,987] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-63b0da48f45842d59d0448055ec06bc8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,991] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 2.9048 ms, throughput: 1.1767 GB/s; offload_time: 2.7450 ms, put_time: 0.1597 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,991] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,993] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.9795 ms, throughput: 1.7267 GB/s; offload_time: 1.9016 ms, put_time: 0.0778 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:43,993] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-82bf6ab90d7647508579a56959bebf5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:43,995] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.7052 ms, throughput: 2.0044 GB/s; offload_time: 1.6242 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,001] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1035, LMCache hit tokens: 1028, need to load: 244 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,012] LMCache INFO:[0m Reqid: chatcmpl-19696318167c436d8bf42d3d723fa8ed, Total tokens 1035, LMCache hit tokens: 1028, need to load: 276 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,012] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,024] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-c475002352324a0b9268221578433f70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,025] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4197 ms, throughput: 2.4075 GB/s; offload_time: 1.3426 ms, put_time: 0.0771 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,030] LMCache INFO:[0m Reqid: chatcmpl-2bea5d49dcdc4160bac4194e0a458db7, Total tokens 1559, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,032] LMCache INFO:[0m Reqid: chatcmpl-21f12b491e6043a3830e062280adefdf, Total tokens 913, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,033] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,081] LMCache INFO:[0m Storing KV cache for 1559 out of 1559 tokens (skip_leading_tokens=0) for request chatcmpl-2bea5d49dcdc4160bac4194e0a458db7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,088] LMCache INFO:[0m Stored 1559 out of total 1559 tokens. size: 0.0416 gb, cost 6.6530 ms, throughput: 6.2573 GB/s; offload_time: 6.2499 ms, put_time: 0.4031 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,090] LMCache INFO:[0m Storing KV cache for 145 out of 913 tokens (skip_leading_tokens=768) for request chatcmpl-21f12b491e6043a3830e062280adefdf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,094] LMCache INFO:[0m Stored 145 out of total 913 tokens. size: 0.0039 gb, cost 4.3408 ms, throughput: 0.8920 GB/s; offload_time: 3.7421 ms, put_time: 0.5988 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,109] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,117] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-25e8388266dc4442998d00e289588a7e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,118] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5524 ms, throughput: 2.2017 GB/s; offload_time: 1.4742 ms, put_time: 0.0782 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,123] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,133] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,140] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a49f384a9cb14220af6c7ed482e6c1a4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,142] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.3776 ms, throughput: 2.4812 GB/s; offload_time: 1.3038 ms, put_time: 0.0738 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,145] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,153] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-689f7e55e3994331b23083df9300b128 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,155] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.5256 ms, throughput: 2.2403 GB/s; offload_time: 1.4551 ms, put_time: 0.0706 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,159] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,178] LMCache INFO:[0m Reqid: chatcmpl-21f12b491e6043a3830e062280adefdf, Total tokens 919, LMCache hit tokens: 913, need to load: 129 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,186] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e14ae39271a642a7a396a1c8faadba70 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,187] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4350 ms, throughput: 2.3819 GB/s; offload_time: 1.3596 ms, put_time: 0.0753 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,191] LMCache INFO:[0m Reqid: chatcmpl-21f12b491e6043a3830e062280adefdf, Total tokens 919, LMCache hit tokens: 913, need to load: 193 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,201] LMCache INFO:[0m Reqid: chatcmpl-21f12b491e6043a3830e062280adefdf, Total tokens 919, LMCache hit tokens: 913, need to load: 273 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,202] LMCache INFO:[0m Reqid: chatcmpl-d91621ca1cb3451a980f314ce0cfab6e, Total tokens 1010, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,203] LMCache INFO:[0m Reqid: chatcmpl-ee03b069b0ef44f386c7850999a7a4bd, Total tokens 433, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,235] LMCache INFO:[0m Reqid: chatcmpl-ee03b069b0ef44f386c7850999a7a4bd, Total tokens 433, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,236] LMCache INFO:[0m Reqid: chatcmpl-666e9039fcfc46e5a808eae2ab28ca86, Total tokens 169, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,237] LMCache INFO:[0m Reqid: chatcmpl-148a7b713afa438a9709346c61ba9046, Total tokens 1191, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,254] LMCache INFO:[0m Storing KV cache for 169 out of 169 tokens (skip_leading_tokens=0) for request chatcmpl-666e9039fcfc46e5a808eae2ab28ca86 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,255] LMCache INFO:[0m Stored 169 out of total 169 tokens. size: 0.0045 gb, cost 0.6242 ms, throughput: 7.2297 GB/s; offload_time: 0.5194 ms, put_time: 0.1048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,260] LMCache INFO:[0m Reqid: chatcmpl-148a7b713afa438a9709346c61ba9046, Total tokens 1191, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,271] LMCache INFO:[0m Reqid: chatcmpl-148a7b713afa438a9709346c61ba9046, Total tokens 1191, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,272] LMCache INFO:[0m Reqid: chatcmpl-4df310098a0846c89ce9068e941f204a, Total tokens 1298, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,301] LMCache INFO:[0m Storing KV cache for 1191 out of 1191 tokens (skip_leading_tokens=0) for request chatcmpl-148a7b713afa438a9709346c61ba9046 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,306] LMCache INFO:[0m Stored 1191 out of total 1191 tokens. size: 0.0318 gb, cost 4.8074 ms, throughput: 6.6155 GB/s; offload_time: 4.1757 ms, put_time: 0.6317 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,318] LMCache INFO:[0m Reqid: chatcmpl-4df310098a0846c89ce9068e941f204a, Total tokens 1298, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,325] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-60f572dae7d34d399023cfb46428ebef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,327] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4543 ms, throughput: 2.3502 GB/s; offload_time: 1.3757 ms, put_time: 0.0786 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,332] LMCache INFO:[0m Reqid: chatcmpl-4df310098a0846c89ce9068e941f204a, Total tokens 1298, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,334] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,368] LMCache INFO:[0m Storing KV cache for 530 out of 1298 tokens (skip_leading_tokens=768) for request chatcmpl-4df310098a0846c89ce9068e941f204a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,370] LMCache INFO:[0m Stored 530 out of total 1298 tokens. size: 0.0142 gb, cost 1.6398 ms, throughput: 8.6307 GB/s; offload_time: 1.1069 ms, put_time: 0.5329 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,377] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,384] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-b96360d2ee724e0fb3568d988f30450c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,385] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5573 ms, throughput: 6.1330 GB/s; offload_time: 0.4816 ms, put_time: 0.0757 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,390] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,400] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,407] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,408] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5585 ms, throughput: 6.1200 GB/s; offload_time: 0.4841 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,412] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,422] LMCache INFO:[0m Reqid: chatcmpl-669c428331154f7d8e24a1812d9271f4, Total tokens 1323, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,423] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,456] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-50123025e53f4e1a9c330fcebddf6ebf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,457] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4389 ms, throughput: 7.7878 GB/s; offload_time: 0.3687 ms, put_time: 0.0702 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,461] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,471] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,480] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,488] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-37a054a5b5e749748e97614a4385f073 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,488] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5599 ms, throughput: 6.1047 GB/s; offload_time: 0.4864 ms, put_time: 0.0735 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,492] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,501] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,511] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,520] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,529] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,536] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-24efff97d5184d93971c02a6ba28c9ac [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,537] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 0.5282 ms, throughput: 6.4712 GB/s; offload_time: 0.4528 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,541] LMCache INFO:[0m Reqid: chatcmpl-836e8725ff724e8ebef59494c1f8eb1d, Total tokens 1048, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,542] LMCache INFO:[0m Reqid: chatcmpl-746d7975e3374881ab458dd919e95bd6, Total tokens 113, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,543] LMCache INFO:[0m Reqid: chatcmpl-59a57a3bd8004bcb9bee3935db4253d0, Total tokens 1409, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,569] LMCache INFO:[0m Storing KV cache for 1048 out of 1048 tokens (skip_leading_tokens=0) for request chatcmpl-836e8725ff724e8ebef59494c1f8eb1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,572] LMCache INFO:[0m Stored 1048 out of total 1048 tokens. size: 0.0280 gb, cost 3.1680 ms, throughput: 8.8335 GB/s; offload_time: 2.7242 ms, put_time: 0.4438 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,573] LMCache INFO:[0m Storing KV cache for 113 out of 113 tokens (skip_leading_tokens=0) for request chatcmpl-746d7975e3374881ab458dd919e95bd6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,576] LMCache INFO:[0m Stored 113 out of total 113 tokens. size: 0.0030 gb, cost 3.0765 ms, throughput: 0.9808 GB/s; offload_time: 2.9675 ms, put_time: 0.1089 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,583] LMCache INFO:[0m Reqid: chatcmpl-59a57a3bd8004bcb9bee3935db4253d0, Total tokens 1409, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,592] LMCache INFO:[0m Reqid: chatcmpl-59a57a3bd8004bcb9bee3935db4253d0, Total tokens 1409, LMCache hit tokens: 1280, need to load: 1232 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,594] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,628] LMCache INFO:[0m Storing KV cache for 129 out of 1409 tokens (skip_leading_tokens=1280) for request chatcmpl-59a57a3bd8004bcb9bee3935db4253d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,629] LMCache INFO:[0m Stored 129 out of total 1409 tokens. size: 0.0034 gb, cost 0.8731 ms, throughput: 3.9455 GB/s; offload_time: 0.6462 ms, put_time: 0.2269 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,634] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,642] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,643] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.4605 ms, throughput: 7.4230 GB/s; offload_time: 0.3861 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,647] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33454 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,654] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-c4d0fe16c63d41da83d1a0e711dadb94 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,655] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.5006 ms, throughput: 6.8279 GB/s; offload_time: 0.4201 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,655] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-c5706fcb2df84f2e8390769c62f4b734 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,656] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.7085 ms, throughput: 4.8241 GB/s; offload_time: 0.6390 ms, put_time: 0.0695 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,662] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,677] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,685] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-09c20abaaf3c4bccab09562d80f6fc7f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,686] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 0.8203 ms, throughput: 4.1666 GB/s; offload_time: 0.7115 ms, put_time: 0.1088 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,691] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,710] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1cf9d4c7647c441bb4235a88627ad436 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,713] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 3.1016 ms, throughput: 1.1020 GB/s; offload_time: 3.0123 ms, put_time: 0.0893 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,718] LMCache INFO:[0m Reqid: chatcmpl-59a57a3bd8004bcb9bee3935db4253d0, Total tokens 1415, LMCache hit tokens: 1409, need to load: 129 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,725] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-353de32886364fbabe4f37535f54aa9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,726] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5928 ms, throughput: 5.7654 GB/s; offload_time: 0.5038 ms, put_time: 0.0890 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,730] LMCache INFO:[0m Reqid: chatcmpl-59a57a3bd8004bcb9bee3935db4253d0, Total tokens 1415, LMCache hit tokens: 1409, need to load: 209 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,731] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,745] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,756] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,766] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,775] LMCache INFO:[0m Reqid: chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d, Total tokens 1688, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,777] LMCache INFO:[0m Reqid: chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c, Total tokens 1130, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,778] LMCache INFO:[0m Reqid: chatcmpl-b8e7121a76fd4350846389128ada7ca2, Total tokens 709, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,778] LMCache INFO:[0m Reqid: chatcmpl-d18127d5c2504fe4b6396c652ebbde81, Total tokens 121, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,779] LMCache INFO:[0m Reqid: chatcmpl-1088bb31ec424d5dacc59d7e49eb9971, Total tokens 127, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,780] LMCache INFO:[0m Reqid: chatcmpl-dddc59cba3854d31a7155cd0f419250c, Total tokens 987, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,842] LMCache INFO:[0m Storing KV cache for 152 out of 1688 tokens (skip_leading_tokens=1536) for request chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,843] LMCache INFO:[0m Stored 152 out of total 1688 tokens. size: 0.0041 gb, cost 0.8957 ms, throughput: 4.5316 GB/s; offload_time: 0.7724 ms, put_time: 0.1233 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,843] LMCache INFO:[0m Storing KV cache for 874 out of 1130 tokens (skip_leading_tokens=256) for request chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,849] LMCache INFO:[0m Stored 874 out of total 1130 tokens. size: 0.0233 gb, cost 5.3640 ms, throughput: 4.3510 GB/s; offload_time: 2.5413 ms, put_time: 2.8226 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,849] LMCache INFO:[0m Storing KV cache for 121 out of 121 tokens (skip_leading_tokens=0) for request chatcmpl-d18127d5c2504fe4b6396c652ebbde81 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33518 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:44,851] LMCache INFO:[0m Stored 121 out of total 121 tokens. size: 0.0032 gb, cost 1.7892 ms, throughput: 1.8058 GB/s; offload_time: 1.4727 ms, put_time: 0.3165 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,852] LMCache INFO:[0m Storing KV cache for 127 out of 127 tokens (skip_leading_tokens=0) for request chatcmpl-1088bb31ec424d5dacc59d7e49eb9971 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,852] LMCache INFO:[0m Stored 127 out of total 127 tokens. size: 0.0034 gb, cost 0.4900 ms, throughput: 6.9205 GB/s; offload_time: 0.4220 ms, put_time: 0.0681 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,862] LMCache INFO:[0m Reqid: chatcmpl-dddc59cba3854d31a7155cd0f419250c, Total tokens 987, LMCache hit tokens: 768, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,863] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,889] LMCache INFO:[0m Storing KV cache for 219 out of 987 tokens (skip_leading_tokens=768) for request chatcmpl-dddc59cba3854d31a7155cd0f419250c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,890] LMCache INFO:[0m Stored 219 out of total 987 tokens. size: 0.0058 gb, cost 0.8603 ms, throughput: 6.7978 GB/s; offload_time: 0.7464 ms, put_time: 0.1139 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,890] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-746d7975e3374881ab458dd919e95bd6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,892] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.0534 ms, throughput: 3.2447 GB/s; offload_time: 0.9039 ms, put_time: 0.1495 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,892] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-1088bb31ec424d5dacc59d7e49eb9971 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,893] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.6158 ms, throughput: 5.5502 GB/s; offload_time: 0.5550 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,898] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,905] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-0e4a9cbb356e4160b150d43a10d5ec4a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,906] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.5101 ms, throughput: 6.7010 GB/s; offload_time: 0.4328 ms, put_time: 0.0773 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,910] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,917] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-358991dc75d24d96b3c9b552df4d3cbc [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,918] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 0.5584 ms, throughput: 6.1208 GB/s; offload_time: 0.4815 ms, put_time: 0.0769 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,922] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,932] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,942] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,952] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1249, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,953] LMCache INFO:[0m Reqid: chatcmpl-a16069cee7a1415782df9a03731d9159, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,982] LMCache INFO:[0m Storing KV cache for 1249 out of 1249 tokens (skip_leading_tokens=0) for request chatcmpl-124b57334e834269a29c36fd5b62edbd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,992] LMCache INFO:[0m Stored 1249 out of total 1249 tokens. size: 0.0334 gb, cost 10.3576 ms, throughput: 3.2200 GB/s; offload_time: 9.4084 ms, put_time: 0.9491 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:44,993] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d18127d5c2504fe4b6396c652ebbde81 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:44,997] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 3.1322 ms, throughput: 1.0912 GB/s; offload_time: 3.0651 ms, put_time: 0.0671 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,005] LMCache INFO:[0m Reqid: chatcmpl-a16069cee7a1415782df9a03731d9159, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33538 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,023] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-25242a416c5846e4b77b6989b54840b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,025] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.7199 ms, throughput: 1.9874 GB/s; offload_time: 1.6483 ms, put_time: 0.0716 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,030] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 81 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,037] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-329f6fc01d48415591fd8f43afc98216 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,038] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5148 ms, throughput: 2.2563 GB/s; offload_time: 1.4319 ms, put_time: 0.0829 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,042] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 177 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,052] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 257 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,062] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 321 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,072] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 385 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,079] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-e5c04a2414c84dd2b934921675f628e8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,080] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4137 ms, throughput: 2.4177 GB/s; offload_time: 1.3361 ms, put_time: 0.0776 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,084] LMCache INFO:[0m Reqid: chatcmpl-124b57334e834269a29c36fd5b62edbd, Total tokens 1251, LMCache hit tokens: 1249, need to load: 449 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,085] LMCache INFO:[0m Reqid: chatcmpl-a16069cee7a1415782df9a03731d9159, Total tokens 122, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,086] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,101] LMCache INFO:[0m Storing KV cache for 122 out of 122 tokens (skip_leading_tokens=0) for request chatcmpl-a16069cee7a1415782df9a03731d9159 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,103] LMCache INFO:[0m Stored 122 out of total 122 tokens. size: 0.0033 gb, cost 1.4003 ms, throughput: 2.3264 GB/s; offload_time: 1.3172 ms, put_time: 0.0831 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,107] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,117] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,126] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,136] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,144] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-d4b0789a654447bd953f773c3c6c45d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,145] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4422 ms, throughput: 2.3700 GB/s; offload_time: 1.3673 ms, put_time: 0.0749 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,145] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-838b761669014a6eb2568ba2f90ac055 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,147] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.6235 ms, throughput: 2.1053 GB/s; offload_time: 1.5546 ms, put_time: 0.0689 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,152] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,159] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,161] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.4989 ms, throughput: 2.2803 GB/s; offload_time: 1.4208 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,165] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,172] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-a16069cee7a1415782df9a03731d9159 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,174] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4565 ms, throughput: 2.3467 GB/s; offload_time: 1.3769 ms, put_time: 0.0796 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,178] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,186] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-1f9cb3ba366746a498abaad8efd2b368 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,187] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 1.5180 ms, throughput: 2.2516 GB/s; offload_time: 1.4451 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,188] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,190] LMCache INFO:[0m Stored 128 out of total 1920 tokens. size: 0.0034 gb, cost 1.7939 ms, throughput: 1.9053 GB/s; offload_time: 1.7225 ms, put_time: 0.0714 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,190] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,192] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.7818 ms, throughput: 1.9183 GB/s; offload_time: 1.7140 ms, put_time: 0.0678 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,197] LMCache INFO:[0m Reqid: chatcmpl-5cf925307ee64695b11768b5c483df55, Total tokens 1597, LMCache hit tokens: 1536, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,198] LMCache INFO:[0m Reqid: chatcmpl-b252de372b0f4a1482790c3ebd765c78, Total tokens 408, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,198] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,242] LMCache INFO:[0m Storing KV cache for 152 out of 408 tokens (skip_leading_tokens=256) for request chatcmpl-b252de372b0f4a1482790c3ebd765c78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,242] LMCache INFO:[0m Stored 152 out of total 408 tokens. size: 0.0041 gb, cost 0.6727 ms, throughput: 6.0338 GB/s; offload_time: 0.5672 ms, put_time: 0.1055 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,248] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,255] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-804a0c9334ca4abfa8226a9180e71572 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,255] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.5273 ms, throughput: 6.4825 GB/s; offload_time: 0.4514 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,260] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33548 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,269] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33574 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,278] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,288] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,295] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-a24637207eca4bbda09a9167d4b00996 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,296] LMCache INFO:[0m Stored 128 out of total 2176 tokens. size: 0.0034 gb, cost 0.6272 ms, throughput: 5.4496 GB/s; offload_time: 0.5562 ms, put_time: 0.0710 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,296] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-44ca7037d2ef4a86bf949b39420ccf04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,297] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.6137 ms, throughput: 5.5692 GB/s; offload_time: 0.5530 ms, put_time: 0.0608 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,301] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,307] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-e453ef8ae7b64901b00b01f89ec7f677 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,308] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 0.4952 ms, throughput: 6.9021 GB/s; offload_time: 0.4226 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,312] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,319] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1db73fd196044d5387ceedd876cc445d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,319] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5155 ms, throughput: 6.6305 GB/s; offload_time: 0.4208 ms, put_time: 0.0947 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,323] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,330] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-85b519e1f7e6401499041f731192546e [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,331] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4721 ms, throughput: 7.2393 GB/s; offload_time: 0.4016 ms, put_time: 0.0705 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,334] LMCache INFO:[0m Reqid: chatcmpl-b80aa097db024d71a06dc19980772bc1, Total tokens 711, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,335] LMCache INFO:[0m Reqid: chatcmpl-9164ec554100413c9425cb3f547033a9, Total tokens 381, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,336] LMCache INFO:[0m Reqid: chatcmpl-466d57f5b6514df4a968d4e0ac931a54, Total tokens 106, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,336] LMCache INFO:[0m Reqid: chatcmpl-5821c45129524e0986572a116844b7a2, Total tokens 208, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,337] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 484, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,365] LMCache INFO:[0m Storing KV cache for 199 out of 711 tokens (skip_leading_tokens=512) for request chatcmpl-b80aa097db024d71a06dc19980772bc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,366] LMCache INFO:[0m Stored 199 out of total 711 tokens. size: 0.0053 gb, cost 0.7325 ms, throughput: 7.2541 GB/s; offload_time: 0.6251 ms, put_time: 0.1074 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,367] LMCache INFO:[0m Storing KV cache for 106 out of 106 tokens (skip_leading_tokens=0) for request chatcmpl-466d57f5b6514df4a968d4e0ac931a54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,368] LMCache INFO:[0m Stored 106 out of total 106 tokens. size: 0.0028 gb, cost 0.8719 ms, throughput: 3.2465 GB/s; offload_time: 0.6414 ms, put_time: 0.2305 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,368] LMCache INFO:[0m Storing KV cache for 208 out of 208 tokens (skip_leading_tokens=0) for request chatcmpl-5821c45129524e0986572a116844b7a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,370] LMCache INFO:[0m Stored 208 out of total 208 tokens. size: 0.0056 gb, cost 1.5932 ms, throughput: 3.4861 GB/s; offload_time: 0.6406 ms, put_time: 0.9526 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,376] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 484, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,385] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 484, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,394] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 484, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,401] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-9164ec554100413c9425cb3f547033a9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,401] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4950 ms, throughput: 6.9051 GB/s; offload_time: 0.4164 ms, put_time: 0.0786 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,413] LMCache INFO:[0m Reqid: chatcmpl-5821c45129524e0986572a116844b7a2, Total tokens 212, LMCache hit tokens: 208, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,421] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-718002a0335348c88afa426e749abdd0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,421] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.5974 ms, throughput: 5.7212 GB/s; offload_time: 0.5043 ms, put_time: 0.0931 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,422] LMCache INFO:[0m Storing KV cache for 128 out of 2688 tokens (skip_leading_tokens=2560) for request chatcmpl-4d35de664cec442fb9b5148b6b03813c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,423] LMCache INFO:[0m Stored 128 out of total 2688 tokens. size: 0.0034 gb, cost 0.7036 ms, throughput: 4.8580 GB/s; offload_time: 0.6370 ms, put_time: 0.0666 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,435] LMCache INFO:[0m Reqid: chatcmpl-9164ec554100413c9425cb3f547033a9, Total tokens 387, LMCache hit tokens: 256, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,444] LMCache INFO:[0m Reqid: chatcmpl-9164ec554100413c9425cb3f547033a9, Total tokens 387, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,444] LMCache INFO:[0m Reqid: chatcmpl-466d57f5b6514df4a968d4e0ac931a54, Total tokens 112, LMCache hit tokens: 106, need to load: 58 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,445] LMCache INFO:[0m Reqid: chatcmpl-5821c45129524e0986572a116844b7a2, Total tokens 212, LMCache hit tokens: 208, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,445] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 484, LMCache hit tokens: 128, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,446] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 195, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,446] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 336, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,470] LMCache INFO:[0m Storing KV cache for 356 out of 484 tokens (skip_leading_tokens=128) for request chatcmpl-a9977433a07d4aa1866de4289b4a6d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,472] LMCache INFO:[0m Stored 356 out of total 484 tokens. size: 0.0095 gb, cost 1.9386 ms, throughput: 4.9037 GB/s; offload_time: 1.7919 ms, put_time: 0.1466 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,473] LMCache INFO:[0m Storing KV cache for 195 out of 195 tokens (skip_leading_tokens=0) for request chatcmpl-890100f14f414df696bd740b4baaa601 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,475] LMCache INFO:[0m Stored 195 out of total 195 tokens. size: 0.0052 gb, cost 2.6857 ms, throughput: 1.9388 GB/s; offload_time: 2.5525 ms, put_time: 0.1332 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,476] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-a124d6bdb28b429f90ebe2659606edef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,480] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 3.4175 ms, throughput: 1.0001 GB/s; offload_time: 3.2824 ms, put_time: 0.1351 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,484] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 336, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,500] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-70c361c368e348b2ba700419d17db057 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,501] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 1.4461 ms, throughput: 2.3635 GB/s; offload_time: 1.3632 ms, put_time: 0.0830 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,505] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 197, LMCache hit tokens: 195, need to load: 131 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,521] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-ee807fc8e3ab41518f78c9107a3883df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,523] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.4782 ms, throughput: 2.3122 GB/s; offload_time: 1.4038 ms, put_time: 0.0744 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,527] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 488, LMCache hit tokens: 484, need to load: 116 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,528] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 197, LMCache hit tokens: 195, need to load: 147 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,528] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 336, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,540] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-bec9f0f87bbd40aab101f6fd51f10dc7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,542] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.9263 ms, throughput: 1.7744 GB/s; offload_time: 1.8457 ms, put_time: 0.0806 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,553] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1a326804748141e4b4d1fb42209281d7 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,555] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.6627 ms, throughput: 2.0557 GB/s; offload_time: 1.5786 ms, put_time: 0.0841 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,555] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-53f8caf24b19439c8abfffd3bd6aca86 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,557] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.6655 ms, throughput: 2.0522 GB/s; offload_time: 1.5896 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,562] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 198, LMCache hit tokens: 195, need to load: 83 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,562] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 336, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,563] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,583] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-ee03b069b0ef44f386c7850999a7a4bd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,584] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.4665 ms, throughput: 7.3276 GB/s; offload_time: 0.3977 ms, put_time: 0.0687 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,588] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,597] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,604] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-af506d94ac9b411992b483e31194e2f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,605] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.5949 ms, throughput: 5.7451 GB/s; offload_time: 0.5219 ms, put_time: 0.0731 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,608] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,617] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,625] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-a8666cbe7e0e40fa82c70b68af69e2b4 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,626] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5570 ms, throughput: 2.1953 GB/s; offload_time: 1.4745 ms, put_time: 0.0825 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,627] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-2327e9117eb9400c95f80cc543638c22 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,629] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 1.6839 ms, throughput: 2.0298 GB/s; offload_time: 1.6114 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,633] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,642] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,659] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 343, LMCache hit tokens: 256, need to load: -16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,666] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-666e9039fcfc46e5a808eae2ab28ca86 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,668] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.4575 ms, throughput: 2.3451 GB/s; offload_time: 1.3783 ms, put_time: 0.0792 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,671] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 343, LMCache hit tokens: 256, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,678] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-466d57f5b6514df4a968d4e0ac931a54 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,679] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.4572 ms, throughput: 2.3456 GB/s; offload_time: 1.3830 ms, put_time: 0.0743 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,683] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 343, LMCache hit tokens: 256, need to load: 96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,692] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 343, LMCache hit tokens: 256, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,693] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,710] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,717] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1a9bda062f284c019f122af07bc149e3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,719] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5602 ms, throughput: 2.1907 GB/s; offload_time: 1.4793 ms, put_time: 0.0809 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,719] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-83b6c231177144968aaa6a90a4127817 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,722] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 2.0072 ms, throughput: 1.7028 GB/s; offload_time: 1.9043 ms, put_time: 0.1029 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,722] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-148a7b713afa438a9709346c61ba9046 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,725] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.7165 ms, throughput: 1.2582 GB/s; offload_time: 2.4913 ms, put_time: 0.2252 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,725] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b8e7121a76fd4350846389128ada7ca2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,727] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5607 ms, throughput: 2.1901 GB/s; offload_time: 1.4952 ms, put_time: 0.0655 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,732] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,749] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 16 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,758] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,767] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,774] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-dab270922c62427b91a0350f60a9d037 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,775] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5152 ms, throughput: 2.2558 GB/s; offload_time: 1.4400 ms, put_time: 0.0752 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,779] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33682 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:45,791] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,798] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-0943c499e87742859795d00307b54cb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,800] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.6618 ms, throughput: 2.0567 GB/s; offload_time: 1.5863 ms, put_time: 0.0755 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,811] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,813] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.5048 ms, throughput: 2.2714 GB/s; offload_time: 1.4215 ms, put_time: 0.0833 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,816] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 218, LMCache hit tokens: 195, need to load: 131 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,834] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 100 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,840] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,842] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.6258 ms, throughput: 2.1023 GB/s; offload_time: 1.5499 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,846] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 164 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,855] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 196 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,862] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-21f12b491e6043a3830e062280adefdf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,863] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5809 ms, throughput: 2.1620 GB/s; offload_time: 1.4931 ms, put_time: 0.0878 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,867] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 276 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,876] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 308 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,883] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-19696318167c436d8bf42d3d723fa8ed [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,884] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.6089 ms, throughput: 2.1244 GB/s; offload_time: 1.5095 ms, put_time: 0.0994 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,888] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 420 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,906] LMCache INFO:[0m Reqid: chatcmpl-5821c45129524e0986572a116844b7a2, Total tokens 248, LMCache hit tokens: 208, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,913] LMCache INFO:[0m Storing KV cache for 128 out of 2304 tokens (skip_leading_tokens=2176) for request chatcmpl-ec409da573b843f1aab380ef224b2aa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,915] LMCache INFO:[0m Stored 128 out of total 2304 tokens. size: 0.0034 gb, cost 1.9401 ms, throughput: 1.7617 GB/s; offload_time: 1.8566 ms, put_time: 0.0835 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,918] LMCache INFO:[0m Reqid: chatcmpl-5821c45129524e0986572a116844b7a2, Total tokens 248, LMCache hit tokens: 208, need to load: 128 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,919] LMCache INFO:[0m Reqid: chatcmpl-a9977433a07d4aa1866de4289b4a6d55, Total tokens 512, LMCache hit tokens: 484, need to load: 436 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,920] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 218, LMCache hit tokens: 195, need to load: 147 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,921] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,936] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a9977433a07d4aa1866de4289b4a6d55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,938] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.6550 ms, throughput: 2.0653 GB/s; offload_time: 1.5744 ms, put_time: 0.0805 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,951] LMCache INFO:[0m Reqid: chatcmpl-890100f14f414df696bd740b4baaa601, Total tokens 219, LMCache hit tokens: 195, need to load: 35 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,952] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 346, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,953] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,968] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,974] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-6e5dff07b4da4f03a342f836bd6d6639 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,976] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5304 ms, throughput: 2.2334 GB/s; offload_time: 1.4494 ms, put_time: 0.0810 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,980] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,987] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-4df310098a0846c89ce9068e941f204a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:45,989] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5924 ms, throughput: 2.1464 GB/s; offload_time: 1.5111 ms, put_time: 0.0813 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:45,993] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,000] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-1386aff19a6e4dc3b6c49f2fb552e3f8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,002] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.7046 ms, throughput: 2.0051 GB/s; offload_time: 1.6255 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,002] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-82bf6ab90d7647508579a56959bebf5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,004] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.8228 ms, throughput: 1.8751 GB/s; offload_time: 1.7501 ms, put_time: 0.0727 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,017] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 350, LMCache hit tokens: 256, need to load: 32 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,025] LMCache INFO:[0m Reqid: chatcmpl-154d2e405fef4eb0869e1abd86344ff5, Total tokens 350, LMCache hit tokens: 256, need to load: 160 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,026] LMCache INFO:[0m Reqid: chatcmpl-8bb48364ce6745eb962a21b0183eff74, Total tokens 733, LMCache hit tokens: 640, need to load: 592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,027] LMCache INFO:[0m Reqid: chatcmpl-0efa015d7e0548a28f0e56fb7f0dd395, Total tokens 504, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,028] LMCache INFO:[0m Reqid: chatcmpl-e76ab00aa9964d2ca3f848561e5153da, Total tokens 550, LMCache hit tokens: 256, need to load: 208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,028] LMCache INFO:[0m Reqid: chatcmpl-d2669ec012e14a368977fece0de74509, Total tokens 99, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,029] LMCache INFO:[0m Reqid: chatcmpl-74069fab2faf400a8f43659fda11fc43, Total tokens 778, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,069] LMCache INFO:[0m Storing KV cache for 294 out of 550 tokens (skip_leading_tokens=256) for request chatcmpl-e76ab00aa9964d2ca3f848561e5153da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,070] LMCache INFO:[0m Stored 294 out of total 550 tokens. size: 0.0079 gb, cost 1.1728 ms, throughput: 6.6938 GB/s; offload_time: 0.8775 ms, put_time: 0.2953 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,070] LMCache INFO:[0m Storing KV cache for 99 out of 99 tokens (skip_leading_tokens=0) for request chatcmpl-d2669ec012e14a368977fece0de74509 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:46,072] LMCache INFO:[0m Stored 99 out of total 99 tokens. size: 0.0026 gb, cost 1.4033 ms, throughput: 1.8839 GB/s; offload_time: 1.3263 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,075] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-5821c45129524e0986572a116844b7a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,076] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.9523 ms, throughput: 3.5894 GB/s; offload_time: 0.8576 ms, put_time: 0.0947 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,082] LMCache INFO:[0m Reqid: chatcmpl-74069fab2faf400a8f43659fda11fc43, Total tokens 778, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,083] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 680, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,107] LMCache INFO:[0m Storing KV cache for 266 out of 778 tokens (skip_leading_tokens=512) for request chatcmpl-74069fab2faf400a8f43659fda11fc43 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,108] LMCache INFO:[0m Stored 266 out of total 778 tokens. size: 0.0071 gb, cost 1.0711 ms, throughput: 6.6314 GB/s; offload_time: 0.7606 ms, put_time: 0.3105 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,114] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 680, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,115] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,136] LMCache INFO:[0m Storing KV cache for 168 out of 680 tokens (skip_leading_tokens=512) for request chatcmpl-36324487fefb4e5fb7c09e3acc30e743 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,137] LMCache INFO:[0m Stored 168 out of total 680 tokens. size: 0.0045 gb, cost 0.7122 ms, throughput: 6.2993 GB/s; offload_time: 0.5894 ms, put_time: 0.1228 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,142] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:46,149] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-b80aa097db024d71a06dc19980772bc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,149] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5398 ms, throughput: 6.3315 GB/s; offload_time: 0.4621 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:46,161] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-689f7e55e3994331b23083df9300b128 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,162] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.6117 ms, throughput: 5.5872 GB/s; offload_time: 0.5270 ms, put_time: 0.0847 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,162] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-836e8725ff724e8ebef59494c1f8eb1d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,163] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 0.6753 ms, throughput: 5.0612 GB/s; offload_time: 0.6028 ms, put_time: 0.0725 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,163] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-5cf925307ee64695b11768b5c483df55 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,165] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.7483 ms, throughput: 1.9550 GB/s; offload_time: 1.6711 ms, put_time: 0.0772 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,170] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 120 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,179] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 200 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,187] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 248 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,196] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 312 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,203] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-0efa015d7e0548a28f0e56fb7f0dd395 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,205] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5788 ms, throughput: 2.1649 GB/s; offload_time: 1.5028 ms, put_time: 0.0761 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,209] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 392 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,218] LMCache INFO:[0m Reqid: chatcmpl-36324487fefb4e5fb7c09e3acc30e743, Total tokens 682, LMCache hit tokens: 680, need to load: 440 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,219] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,232] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,241] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,250] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,257] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-60f572dae7d34d399023cfb46428ebef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,259] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5271 ms, throughput: 2.2382 GB/s; offload_time: 1.4490 ms, put_time: 0.0781 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,263] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,272] LMCache INFO:[0m Reqid: chatcmpl-323f395e6e8449fd83da450ffe76cbc9, Total tokens 957, LMCache hit tokens: 896, need to load: 848 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,273] LMCache INFO:[0m Reqid: chatcmpl-4c98a20ab3cd40d6995f6a6bbb67e146, Total tokens 100, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,274] LMCache INFO:[0m Reqid: chatcmpl-a4bd0c4edd48432da54f9d7100bde36f, Total tokens 505, LMCache hit tokens: 384, need to load: 336 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,275] LMCache INFO:[0m Reqid: chatcmpl-22f8574668384cbf9fce7959d7b1b4d3, Total tokens 1158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,310] LMCache INFO:[0m Storing KV cache for 100 out of 100 tokens (skip_leading_tokens=0) for request chatcmpl-4c98a20ab3cd40d6995f6a6bbb67e146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,310] LMCache INFO:[0m Stored 100 out of total 100 tokens. size: 0.0027 gb, cost 0.4490 ms, throughput: 5.9476 GB/s; offload_time: 0.3630 ms, put_time: 0.0860 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,311] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-b96360d2ee724e0fb3568d988f30450c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,312] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 0.7593 ms, throughput: 4.5014 GB/s; offload_time: 0.6867 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,317] LMCache INFO:[0m Reqid: chatcmpl-22f8574668384cbf9fce7959d7b1b4d3, Total tokens 1158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,326] LMCache INFO:[0m Reqid: chatcmpl-22f8574668384cbf9fce7959d7b1b4d3, Total tokens 1158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,333] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-84b1d7fb6a7442ef9c0a9ed79e5ce962 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,334] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.6251 ms, throughput: 5.4678 GB/s; offload_time: 0.5408 ms, put_time: 0.0843 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,338] LMCache INFO:[0m Reqid: chatcmpl-22f8574668384cbf9fce7959d7b1b4d3, Total tokens 1158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,345] LMCache INFO:[0m Storing KV cache for 128 out of 1792 tokens (skip_leading_tokens=1664) for request chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,346] LMCache INFO:[0m Stored 128 out of total 1792 tokens. size: 0.0034 gb, cost 0.5846 ms, throughput: 5.8462 GB/s; offload_time: 0.5088 ms, put_time: 0.0759 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,350] LMCache INFO:[0m Reqid: chatcmpl-22f8574668384cbf9fce7959d7b1b4d3, Total tokens 1158, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,352] LMCache INFO:[0m Reqid: chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d, Total tokens 1203, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,380] LMCache INFO:[0m Storing KV cache for 1158 out of 1158 tokens (skip_leading_tokens=0) for request chatcmpl-22f8574668384cbf9fce7959d7b1b4d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,388] LMCache INFO:[0m Stored 1158 out of total 1158 tokens. size: 0.0309 gb, cost 7.7183 ms, throughput: 4.0063 GB/s; offload_time: 7.3634 ms, put_time: 0.3549 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,400] LMCache INFO:[0m Reqid: chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d, Total tokens 1203, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,409] LMCache INFO:[0m Reqid: chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d, Total tokens 1203, LMCache hit tokens: 1024, need to load: 976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,410] LMCache INFO:[0m Reqid: chatcmpl-3b25b329aac44cd59fa61e792a49b144, Total tokens 580, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,418] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,456] LMCache INFO:[0m Storing KV cache for 179 out of 1203 tokens (skip_leading_tokens=1024) for request chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,457] LMCache INFO:[0m Stored 179 out of total 1203 tokens. size: 0.0048 gb, cost 0.7799 ms, throughput: 6.1288 GB/s; offload_time: 0.6521 ms, put_time: 0.1278 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,464] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,471] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-37a054a5b5e749748e97614a4385f073 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,472] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 0.5828 ms, throughput: 5.8651 GB/s; offload_time: 0.5051 ms, put_time: 0.0777 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,472] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-a4bd0c4edd48432da54f9d7100bde36f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,473] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 0.6301 ms, throughput: 5.4249 GB/s; offload_time: 0.5512 ms, put_time: 0.0788 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,480] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,493] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,505] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,516] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,528] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,539] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,551] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,558] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-d2669ec012e14a368977fece0de74509 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,558] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 0.4474 ms, throughput: 7.6400 GB/s; offload_time: 0.3672 ms, put_time: 0.0802 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,565] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,576] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,583] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,584] LMCache INFO:[0m Stored 128 out of total 384 tokens. size: 0.0034 gb, cost 0.4808 ms, throughput: 7.1087 GB/s; offload_time: 0.4038 ms, put_time: 0.0770 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,584] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-59a57a3bd8004bcb9bee3935db4253d0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,585] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 0.7902 ms, throughput: 4.3256 GB/s; offload_time: 0.7226 ms, put_time: 0.0675 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,585] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-890100f14f414df696bd740b4baaa601 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,586] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 0.6818 ms, throughput: 5.0132 GB/s; offload_time: 0.5792 ms, put_time: 0.1026 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,593] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,606] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,618] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,630] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,637] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-8bb48364ce6745eb962a21b0183eff74 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,638] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 0.5774 ms, throughput: 5.9198 GB/s; offload_time: 0.4909 ms, put_time: 0.0865 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,645] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,656] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,663] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-353de32886364fbabe4f37535f54aa9f [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,665] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7716 ms, throughput: 1.9294 GB/s; offload_time: 1.6876 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,672] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,684] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,695] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,707] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,714] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-b252de372b0f4a1482790c3ebd765c78 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,716] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.7385 ms, throughput: 1.9661 GB/s; offload_time: 1.6545 ms, put_time: 0.0840 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,722] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,735] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,741] LMCache INFO:[0m Storing KV cache for 128 out of 128 tokens (skip_leading_tokens=0) for request chatcmpl-4c98a20ab3cd40d6995f6a6bbb67e146 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,743] LMCache INFO:[0m Stored 128 out of total 128 tokens. size: 0.0034 gb, cost 1.6777 ms, throughput: 2.0373 GB/s; offload_time: 1.5762 ms, put_time: 0.1015 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,750] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,762] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,774] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,786] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,798] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,810] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,822] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,833] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,840] LMCache INFO:[0m Storing KV cache for 128 out of 768 tokens (skip_leading_tokens=640) for request chatcmpl-25242a416c5846e4b77b6989b54840b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,842] LMCache INFO:[0m Stored 128 out of total 768 tokens. size: 0.0034 gb, cost 1.7036 ms, throughput: 2.0064 GB/s; offload_time: 1.6140 ms, put_time: 0.0896 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,849] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,855] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-329f6fc01d48415591fd8f43afc98216 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,857] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.8288 ms, throughput: 1.8690 GB/s; offload_time: 1.7417 ms, put_time: 0.0871 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:46,864] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,876] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,887] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:46,899] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33878 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,082] LMCache INFO:[0m Storing KV cache for 8182 out of 8182 tokens (skip_leading_tokens=0) for request chatcmpl-102619f92b8c47f7840ef2ba214e8cb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,144] LMCache INFO:[0m Stored 8182 out of total 8182 tokens. size: 0.2185 gb, cost 61.9056 ms, throughput: 3.5293 GB/s; offload_time: 58.8217 ms, put_time: 3.0839 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,145] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-e5c04a2414c84dd2b934921675f628e8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,149] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 3.4173 ms, throughput: 1.0002 GB/s; offload_time: 3.3377 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:33906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33894 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,190] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,203] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: -112 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,217] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: -96 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,230] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: -64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,237] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-d4b0789a654447bd953f773c3c6c45d6 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,239] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.6482 ms, throughput: 2.0738 GB/s; offload_time: 1.5724 ms, put_time: 0.0758 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,239] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-838b761669014a6eb2568ba2f90ac055 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,241] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.7769 ms, throughput: 1.9236 GB/s; offload_time: 1.7021 ms, put_time: 0.0748 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,250] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 64 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,256] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-d5028530bd7f40d8ae82ddb33998a4d8 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,258] LMCache INFO:[0m Stored 128 out of total 1536 tokens. size: 0.0034 gb, cost 1.6201 ms, throughput: 2.1098 GB/s; offload_time: 1.5472 ms, put_time: 0.0729 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,266] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 80 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,273] LMCache INFO:[0m Storing KV cache for 128 out of 256 tokens (skip_leading_tokens=128) for request chatcmpl-a16069cee7a1415782df9a03731d9159 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,275] LMCache INFO:[0m Stored 128 out of total 256 tokens. size: 0.0034 gb, cost 1.6874 ms, throughput: 2.0256 GB/s; offload_time: 1.5819 ms, put_time: 0.1055 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,286] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 192 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,293] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-1f9cb3ba366746a498abaad8efd2b368 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,295] LMCache INFO:[0m Stored 128 out of total 1408 tokens. size: 0.0034 gb, cost 1.5442 ms, throughput: 2.2134 GB/s; offload_time: 1.4680 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,295] LMCache INFO:[0m Storing KV cache for 128 out of 2048 tokens (skip_leading_tokens=1920) for request chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,297] LMCache INFO:[0m Stored 128 out of total 2048 tokens. size: 0.0034 gb, cost 1.8224 ms, throughput: 1.8755 GB/s; offload_time: 1.7459 ms, put_time: 0.0765 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,297] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,300] LMCache INFO:[0m Stored 128 out of total 1280 tokens. size: 0.0034 gb, cost 2.1090 ms, throughput: 1.6206 GB/s; offload_time: 2.0299 ms, put_time: 0.0791 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,308] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 288 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,323] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,339] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 384 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,353] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,368] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 496 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,382] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 560 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,388] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-44ca7037d2ef4a86bf949b39420ccf04 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,390] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5697 ms, throughput: 2.1775 GB/s; offload_time: 1.4902 ms, put_time: 0.0795 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,400] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 608 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,413] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 640 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,419] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1db73fd196044d5387ceedd876cc445d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,421] LMCache INFO:[0m Stored 128 out of total 896 tokens. size: 0.0034 gb, cost 1.5869 ms, throughput: 2.1538 GB/s; offload_time: 1.5071 ms, put_time: 0.0799 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,430] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 688 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,444] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 720 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,457] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 736 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,470] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 768 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,483] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 800 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,496] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 912 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,509] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 928 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,516] LMCache INFO:[0m Storing KV cache for 128 out of 2816 tokens (skip_leading_tokens=2688) for request chatcmpl-4d35de664cec442fb9b5148b6b03813c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,518] LMCache INFO:[0m Stored 128 out of total 2816 tokens. size: 0.0034 gb, cost 1.7330 ms, throughput: 1.9723 GB/s; offload_time: 1.6589 ms, put_time: 0.0741 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,527] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1024 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,540] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1120 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,546] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-3b25b329aac44cd59fa61e792a49b144 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,548] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5278 ms, throughput: 2.2371 GB/s; offload_time: 1.4516 ms, put_time: 0.0762 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,557] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1136 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,564] LMCache INFO:[0m Storing KV cache for 128 out of 1024 tokens (skip_leading_tokens=896) for request chatcmpl-323f395e6e8449fd83da450ffe76cbc9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,565] LMCache INFO:[0m Stored 128 out of total 1024 tokens. size: 0.0034 gb, cost 1.5576 ms, throughput: 2.1944 GB/s; offload_time: 1.4822 ms, put_time: 0.0754 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,574] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1200 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,588] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1248 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,594] LMCache INFO:[0m Storing KV cache for 128 out of 512 tokens (skip_leading_tokens=384) for request chatcmpl-70c361c368e348b2ba700419d17db057 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,596] LMCache INFO:[0m Stored 128 out of total 512 tokens. size: 0.0034 gb, cost 1.5387 ms, throughput: 2.2214 GB/s; offload_time: 1.4653 ms, put_time: 0.0734 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,604] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1312 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,617] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1376 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:33988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,623] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-ee807fc8e3ab41518f78c9107a3883df [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,625] LMCache INFO:[0m Stored 128 out of total 1152 tokens. size: 0.0034 gb, cost 1.5300 ms, throughput: 2.2339 GB/s; offload_time: 1.4584 ms, put_time: 0.0717 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,634] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1408 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,647] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1440 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,653] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-53f8caf24b19439c8abfffd3bd6aca86 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,655] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.5792 ms, throughput: 2.1644 GB/s; offload_time: 1.5066 ms, put_time: 0.0726 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,664] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1488 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,671] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-ee03b069b0ef44f386c7850999a7a4bd [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,673] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5326 ms, throughput: 2.2301 GB/s; offload_time: 1.4536 ms, put_time: 0.0790 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,682] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1520 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:34030 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,688] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-e76ab00aa9964d2ca3f848561e5153da [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,690] LMCache INFO:[0m Stored 128 out of total 640 tokens. size: 0.0034 gb, cost 1.5764 ms, throughput: 2.1682 GB/s; offload_time: 1.5019 ms, put_time: 0.0745 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,698] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1536 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,704] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-af506d94ac9b411992b483e31194e2f2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:47,706] LMCache INFO:[0m Stored 128 out of total 1664 tokens. size: 0.0034 gb, cost 1.6406 ms, throughput: 2.0834 GB/s; offload_time: 1.5655 ms, put_time: 0.0751 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,715] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 8064, need to load: 1568 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:34034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34048 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34058 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:47,945] LMCache INFO:[0m Storing KV cache for 8263 out of 16327 tokens (skip_leading_tokens=8064) for request chatcmpl-102619f92b8c47f7840ef2ba214e8cb9 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:47,966] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:47,971] LMCache INFO:[0m Stored 2816 out of total 16327 tokens. size: 0.0752 gb, cost 26.0599 ms, throughput: 2.8855 GB/s; offload_time: 24.3156 ms, put_time: 1.7442 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
INFO:     127.0.0.1:39402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:48,002] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5328 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,017] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5328 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,031] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5248 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,045] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5168 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,060] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5152 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,066] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,068] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,068] LMCache INFO:[0m Stored 0 out of total 1280 tokens. size: 0.0000 gb, cost 1.4626 ms, throughput: 0.0000 GB/s; offload_time: 1.4579 ms, put_time: 0.0047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,077] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5088 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,092] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -5040 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:48,106] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4976 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,113] LMCache INFO:[0m Storing KV cache for 128 out of 1408 tokens (skip_leading_tokens=1280) for request chatcmpl-148a7b713afa438a9709346c61ba9046 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,115] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,115] LMCache INFO:[0m Stored 0 out of total 1408 tokens. size: 0.0000 gb, cost 1.4848 ms, throughput: 0.0000 GB/s; offload_time: 1.4802 ms, put_time: 0.0046 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,115] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-b8e7121a76fd4350846389128ada7ca2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,116] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,116] LMCache INFO:[0m Stored 0 out of total 896 tokens. size: 0.0000 gb, cost 1.1397 ms, throughput: 0.0000 GB/s; offload_time: 1.1360 ms, put_time: 0.0038 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,125] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4928 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,138] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4896 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,153] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4864 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,167] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4816 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,181] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4784 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,195] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4768 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:48,209] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4736 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,215] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-0943c499e87742859795d00307b54cb0 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,217] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,217] LMCache INFO:[0m Stored 0 out of total 2176 tokens. size: 0.0000 gb, cost 1.4746 ms, throughput: 0.0000 GB/s; offload_time: 1.4695 ms, put_time: 0.0052 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,226] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4704 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,233] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,234] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,234] LMCache INFO:[0m Stored 0 out of total 896 tokens. size: 0.0000 gb, cost 1.3469 ms, throughput: 0.0000 GB/s; offload_time: 1.3415 ms, put_time: 0.0054 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,244] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,258] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4592 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,272] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4512 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,279] LMCache INFO:[0m Storing KV cache for 128 out of 1664 tokens (skip_leading_tokens=1536) for request chatcmpl-db5b6cacd4d14501a0dd99d86c132c60 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,280] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,280] LMCache INFO:[0m Stored 0 out of total 1664 tokens. size: 0.0000 gb, cost 1.4555 ms, throughput: 0.0000 GB/s; offload_time: 1.4506 ms, put_time: 0.0048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,290] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4432 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,305] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4416 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,312] LMCache INFO:[0m Storing KV cache for 128 out of 1152 tokens (skip_leading_tokens=1024) for request chatcmpl-21f12b491e6043a3830e062280adefdf [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,313] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,313] LMCache INFO:[0m Stored 0 out of total 1152 tokens. size: 0.0000 gb, cost 1.3862 ms, throughput: 0.0000 GB/s; offload_time: 1.3815 ms, put_time: 0.0047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,323] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4352 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
INFO:     127.0.0.1:39432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[32;20m[2025-07-11 15:21:48,337] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4304 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,351] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4256 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,366] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4208 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,380] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4176 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,386] LMCache INFO:[0m Storing KV cache for 128 out of 2432 tokens (skip_leading_tokens=2304) for request chatcmpl-ec409da573b843f1aab380ef224b2aa5 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,388] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,388] LMCache INFO:[0m Stored 0 out of total 2432 tokens. size: 0.0000 gb, cost 1.5065 ms, throughput: 0.0000 GB/s; offload_time: 1.5018 ms, put_time: 0.0048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,388] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-74069fab2faf400a8f43659fda11fc43 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,389] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,389] LMCache INFO:[0m Stored 0 out of total 896 tokens. size: 0.0000 gb, cost 1.1900 ms, throughput: 0.0000 GB/s; offload_time: 1.1858 ms, put_time: 0.0041 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,398] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4144 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,411] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4096 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,425] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4064 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,439] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4048 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,453] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -4016 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,459] LMCache INFO:[0m Storing KV cache for 128 out of 1536 tokens (skip_leading_tokens=1408) for request chatcmpl-4df310098a0846c89ce9068e941f204a [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,461] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,461] LMCache INFO:[0m Stored 0 out of total 1536 tokens. size: 0.0000 gb, cost 1.4718 ms, throughput: 0.0000 GB/s; offload_time: 1.4669 ms, put_time: 0.0049 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,470] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3984 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,477] LMCache INFO:[0m Storing KV cache for 128 out of 2176 tokens (skip_leading_tokens=2048) for request chatcmpl-82bf6ab90d7647508579a56959bebf5c [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,478] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,478] LMCache INFO:[0m Stored 0 out of total 2176 tokens. size: 0.0000 gb, cost 1.4913 ms, throughput: 0.0000 GB/s; offload_time: 1.4868 ms, put_time: 0.0045 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,488] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,502] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3872 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,517] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3792 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,523] LMCache INFO:[0m Storing KV cache for 128 out of 384 tokens (skip_leading_tokens=256) for request chatcmpl-5821c45129524e0986572a116844b7a2 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,524] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,524] LMCache INFO:[0m Stored 0 out of total 384 tokens. size: 0.0000 gb, cost 1.3760 ms, throughput: 0.0000 GB/s; offload_time: 1.3714 ms, put_time: 0.0046 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,534] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3728 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,549] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3712 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,562] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3648 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,569] LMCache INFO:[0m Storing KV cache for 128 out of 896 tokens (skip_leading_tokens=768) for request chatcmpl-b80aa097db024d71a06dc19980772bc1 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,570] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,570] LMCache INFO:[0m Stored 0 out of total 896 tokens. size: 0.0000 gb, cost 1.3947 ms, throughput: 0.0000 GB/s; offload_time: 1.3899 ms, put_time: 0.0048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,580] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3600 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,586] LMCache INFO:[0m Storing KV cache for 128 out of 1920 tokens (skip_leading_tokens=1792) for request chatcmpl-689f7e55e3994331b23083df9300b128 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,587] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,588] LMCache INFO:[0m Stored 0 out of total 1920 tokens. size: 0.0000 gb, cost 1.4979 ms, throughput: 0.0000 GB/s; offload_time: 1.4931 ms, put_time: 0.0048 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,597] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3552 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,611] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3504 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,626] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3472 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,640] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3456 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,654] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3408 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,668] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3376 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,683] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3360 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,697] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3328 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,711] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3296 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,717] LMCache INFO:[0m Storing KV cache for 128 out of 640 tokens (skip_leading_tokens=512) for request chatcmpl-60f572dae7d34d399023cfb46428ebef [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,719] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,719] LMCache INFO:[0m Stored 0 out of total 640 tokens. size: 0.0000 gb, cost 1.4264 ms, throughput: 0.0000 GB/s; offload_time: 1.4217 ms, put_time: 0.0047 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,719] LMCache INFO:[0m Storing KV cache for 128 out of 1280 tokens (skip_leading_tokens=1152) for request chatcmpl-22f8574668384cbf9fce7959d7b1b4d3 [3m(vllm_v1_adapter.py:663:lmcache.integration.vllm.vllm_v1_adapter)[0m
[33;20m[2025-07-11 15:21:48,720] LMCache WARNING:[0m Failed to allocate memory for the KV cache.
The KV cache will not be stored. [3m(cache_engine.py:201:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,720] LMCache INFO:[0m Stored 0 out of total 1280 tokens. size: 0.0000 gb, cost 1.2533 ms, throughput: 0.0000 GB/s; offload_time: 1.2490 ms, put_time: 0.0043 ms [3m(cache_engine.py:226:lmcache.v1.cache_engine)[0m
[32;20m[2025-07-11 15:21:48,729] LMCache INFO:[0m Reqid: chatcmpl-102619f92b8c47f7840ef2ba214e8cb9, Total tokens 20538, LMCache hit tokens: 10880, need to load: -3216 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,734] LMCache INFO:[0m Reqid: chatcmpl-9727f6edbf3e42dbb828ce16a65b38bc, Total tokens 811, LMCache hit tokens: 512, need to load: 464 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,735] LMCache INFO:[0m Reqid: chatcmpl-e6661c6cfa7e4a8faee434f0bbfcff75, Total tokens 107, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
[32;20m[2025-07-11 15:21:48,735] LMCache INFO:[0m Reqid: chatcmpl-f3ff5ab0cb964912bd2527b00e258535, Total tokens 571, LMCache hit tokens: 0, need to load: -48 [3m(vllm_v1_adapter.py:739:lmcache.integration.vllm.vllm_v1_adapter)[0m
ERROR 07-11 15:21:48 [dump_input.py:69] Dumping input data for V1 LLM engine (v0.9.2rc2.dev15+g87798b0be.d20250707) with config: model='/home/yshan/Downloads/models/Qwen-1_5b', speculative_config=None, tokenizer='/home/yshan/Downloads/models/Qwen-1_5b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=30000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/yshan/Downloads/models/Qwen-1_5b, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"/home/yshan/.cache/vllm/torch_compile_cache/7dffd58a67","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":"/home/yshan/.cache/vllm/torch_compile_cache/7dffd58a67/rank_0_0/backbone"}, 
ERROR 07-11 15:21:48 [dump_input.py:76] Dumping scheduler output for model execution: SchedulerOutput(scheduled_new_reqs=[NewRequestData(req_id=chatcmpl-9727f6edbf3e42dbb828ce16a65b38bc,prompt_token_ids_len=811,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.1, temperature=0.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[151643], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=402, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([1, 113, 114, 1935, 4095, 820, 2287, 3040, 1620, 1918, 325, 44, 2602, 1987, 2146, 389, 3092, 845, 2373, 2357, 2456, 1967, 2668, 3126, 324, 2542, 1518, 165, 1852, 504, 254, 3912, 2490, 3333, 1163, 2926, 1996, 2491, 1294, 2314, 2597, 931, 1778, 509, 1965, 712, 4143, 798, 2741, 3106, 2497],),num_computed_tokens=512,lora_request=None), NewRequestData(req_id=chatcmpl-e6661c6cfa7e4a8faee434f0bbfcff75,prompt_token_ids_len=107,mm_inputs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.1, temperature=0.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[151643], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=68, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([1, 113, 114, 3614, 249, 3226, 3156],),num_computed_tokens=48,lora_request=None)], scheduled_cached_reqs=CachedRequestData(req_ids=['chatcmpl-db5b6cacd4d14501a0dd99d86c132c60', 'chatcmpl-353de32886364fbabe4f37535f54aa9f', 'chatcmpl-1f9cb3ba366746a498abaad8efd2b368', 'chatcmpl-ec409da573b843f1aab380ef224b2aa5', 'chatcmpl-689f7e55e3994331b23083df9300b128', 'chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b', 'chatcmpl-e5c04a2414c84dd2b934921675f628e8', 'chatcmpl-60f572dae7d34d399023cfb46428ebef', 'chatcmpl-70c361c368e348b2ba700419d17db057', 'chatcmpl-af506d94ac9b411992b483e31194e2f2', 'chatcmpl-0943c499e87742859795d00307b54cb0', 'chatcmpl-4d35de664cec442fb9b5148b6b03813c', 'chatcmpl-25242a416c5846e4b77b6989b54840b2', 'chatcmpl-53f8caf24b19439c8abfffd3bd6aca86', 'chatcmpl-d4b0789a654447bd953f773c3c6c45d6', 'chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a', 'chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2', 'chatcmpl-b96360d2ee724e0fb3568d988f30450c', 'chatcmpl-1db73fd196044d5387ceedd876cc445d', 'chatcmpl-ee807fc8e3ab41518f78c9107a3883df', 'chatcmpl-329f6fc01d48415591fd8f43afc98216', 'chatcmpl-21f12b491e6043a3830e062280adefdf', 'chatcmpl-ee03b069b0ef44f386c7850999a7a4bd', 'chatcmpl-4df310098a0846c89ce9068e941f204a', 'chatcmpl-59a57a3bd8004bcb9bee3935db4253d0', 'chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d', 'chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c', 'chatcmpl-b8e7121a76fd4350846389128ada7ca2', 'chatcmpl-b252de372b0f4a1482790c3ebd765c78', 'chatcmpl-b80aa097db024d71a06dc19980772bc1', 'chatcmpl-890100f14f414df696bd740b4baaa601', 'chatcmpl-8bb48364ce6745eb962a21b0183eff74', 'chatcmpl-e76ab00aa9964d2ca3f848561e5153da', 'chatcmpl-d2669ec012e14a368977fece0de74509', 'chatcmpl-323f395e6e8449fd83da450ffe76cbc9', 'chatcmpl-4c98a20ab3cd40d6995f6a6bbb67e146', 'chatcmpl-a4bd0c4edd48432da54f9d7100bde36f', 'chatcmpl-22f8574668384cbf9fce7959d7b1b4d3', 'chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d', 'chatcmpl-3b25b329aac44cd59fa61e792a49b144', 'chatcmpl-102619f92b8c47f7840ef2ba214e8cb9'], resumed_from_preemption=[false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], new_token_ids=[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], new_block_ids=[[[]], [[]], [[]], [[]], [[]], [[2426]], [[]], [[2400]], [[]], [[]], [[]], [[]], [[]], [[]], [[2505]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[]], [[3938]], [[]], [[]], [[]], [[2949]], [[]], [[]], [[1, 113, 114, 1673, 1762, 4064, 3017, 1787, 3830, 2891, 1371, 630, 1649, 1832, 4074, 2197, 2035, 24, 3360, 813, 2067, 3414, 1530, 3287, 3649, 598, 3139, 3685, 760, 3828, 1715, 2662, 1933, 3304, 4039, 3401, 3012, 280, 785, 4001, 1147, 3693, 2416, 1744, 1658, 3989, 2592, 3189, 86, 2659, 3879, 3784, 3526, 175, 1248, 2558, 2116, 3389, 8, 1321, 259, 3651, 4009, 1781, 1074, 2309, 3901, 1598, 923, 279, 1831, 1436, 2389, 4018, 791, 3050, 1785, 2742, 1160, 541, 242, 864, 796, 2178, 3258, 2580, 1322, 2113, 1157, 2495, 225, 997, 25, 2024, 583, 2249, 1026, 3684, 1956, 275, 4070, 3436, 627, 1367, 2578, 159, 773, 2848, 2721, 2060, 1793, 2229, 1811, 1414, 3296, 1119, 3641, 2674, 1141, 3210, 2713, 1991, 174, 3077, 3757, 4072, 1161, 439, 3707, 2110, 702, 4174, 97, 1400, 2411, 2677, 3411, 2471, 3646, 664, 2519, 1276, 3778, 3108, 2695, 1883, 1854, 3929, 1370, 1958, 4037, 3574, 4169, 1561, 2896, 322, 352, 2651, 3451, 3622, 1305, 3217, 3230, 2048, 1266, 2556, 1155, 551, 1868, 744, 299, 3991, 2458, 1352, 3669, 787, 3014, 73, 915, 681, 2758, 1062, 2996, 1578, 205, 3803, 1527, 793, 3118, 3846, 13, 3248, 532, 2381, 3870, 2330, 2264, 782, 2506, 2028, 4164, 2158, 1514, 3418, 1630, 2459, 559, 3555, 2625, 2988, 3340, 3932, 4183, 3278, 1152, 3203, 3701, 905, 3377, 3183, 3122, 3817, 2145, 2935, 2203, 2710, 2254, 248, 286, 1023, 110, 3181, 29, 2362, 2525, 512, 447, 4147, 3949, 1581, 2144, 1800, 2702, 1327, 1886, 3363, 2584, 2900, 1901, 1589, 1306, 3910, 1827, 1208, 2629, 2087, 622, 3082, 1056, 1646, 1098, 2479, 1253, 382, 1395, 2154, 51, 2370, 2201, 665, 4170, 388, 3251, 1873, 1303, 844, 1914, 1909, 2975, 3024, 3155, 1656, 1495, 1750, 788, 1093, 3887, 818, 1515, 209, 2157, 1010, 4097, 1472, 1045, 3642, 2836, 1076, 3704, 2511, 2803, 409, 854, 2107, 4099, 3387, 3283, 1286, 2140, 1888, 909, 1733, 732, 4085, 1623, 3849, 4102, 1501, 2316, 2148, 2225, 2553, 2355, 1857, 2719, 2433, 1137, 2406, 4033, 3037, 957, 3909, 87, 1554, 887, 143, 2489, 199, 1428, 3225, 298, 3588, 432, 2294, 1115, 79, 3533, 1799, 2295, 746, 1677, 4126, 3513, 3681, 3154, 1381, 2941, 1547, 1545, 4013, 129, 37, 3534, 2034, 1222, 1714, 1091, 347, 2573, 3736, 3018, 3022, 2361, 2804, 2019, 1766, 132, 3891, 2999, 1442, 3356, 725, 3288, 871, 4184, 1862, 2270, 1765, 2944, 262, 4124, 2985, 1445, 2413, 2161, 600, 3438, 2180, 2770, 3275, 2562, 207, 1519, 66, 1897, 2851, 3860, 3201, 141, 3489, 1541, 3715, 1393, 1456, 3558, 315, 2393, 420, 642, 2213, 1934, 2266, 127, 3054, 3645, 2747, 76, 1318, 2014, 607, 2638, 1563, 3319, 1070, 3371, 28, 503, 3602, 3004, 3057, 552, 3086, 1808, 101, 2653, 2561, 1474, 3461, 331, 591, 3523, 1433, 3292, 2932, 2398, 3293, 4014, 2802, 2606, 1142, 3807, 3775, 270, 2718, 2026, 1989, 1580, 3337, 3480, 1391, 1789, 851, 3918, 3115, 234, 2672, 3247, 1930, 667, 1705, 1612, 3814, 2779, 2628, 2960, 2234, 1815, 2600, 1410, 805, 181, 1366, 385, 1870, 515, 397, 1151, 1784, 2114, 3767, 1891, 1377, 3625, 640, 2906, 912, 3294, 530, 856, 1770, 3273, 131, 2340, 3976, 4123, 1534, 2129, 1890, 1572, 1959, 381, 2814, 3244, 2445, 448, 3132, 1057, 3997, 1676, 1336, 182, 870, 984, 3090, 4040, 3503, 4190, 3643, 2993, 2321, 306, 3666, 1017, 3880, 4111, 314, 1487, 3818, 1749, 2198, 2821, 3821, 1574, 1084, 1130, 2786, 3945, 3776, 3209, 1193, 1907, 3079, 2776, 3249, 1075, 2815, 1704, 4191, 2961, 3216, 901, 517, 2429, 4063, 4187, 3750, 1748, 3081, 3553, 731, 91, 3647, 294, 2755, 365, 1881, 211, 2905, 2247, 343, 2966, 679, 2502, 3777, 2375, 847, 3410, 3743, 3794, 2998, 2566, 3127, 1929, 2168, 474, 341, 3700, 3501, 227, 2807, 751, 1030, 3078, 2118, 4000, 121, 2919, 2358, 737, 2152, 2692, 1004, 2058, 1044, 2128, 3013, 4029, 2537, 1333, 3266, 890, 3329, 1033, 2513, 4077, 3162, 2444, 1159, 2657, 2263, 717, 3413, 475, 1064, 2874, 2105, 1473, 2480, 2244, 3303, 2992, 3239, 2037, 1829, 4078, 1810, 3871, 3307, 1525, 2971, 3892, 2409, 1655, 1742, 1723, 4045, 1406, 1025, 1233, 1356, 2394, 684, 1507, 1325, 1812, 2927, 3197, 2187, 2189, 636, 4149, 1455, 2585, 2486, 648, 2478, 1054, 289, 1820, 916, 3781, 3100, 4022, 812, 1043, 2866, 133, 2929, 3716, 3043, 2955, 3101, 2705, 492, 2199, 935, 4024, 2847, 2899, 881, 937, 1108, 1628, 1524, 117, 1818, 1242, 2248, 1504, 2579, 1858, 4179, 964, 2338, 799, 336, 2483, 3341, 771, 1116, 2095, 2269, 2794, 2940, 3222, 2701, 2463, 3463, 3361, 4172, 836, 1773, 929, 2122, 239, 3309, 403, 1747, 1992, 1576, 3993, 692, 2083, 1231, 657, 2402, 3351, 3974, 1686, 1077, 804, 1591, 1412, 338, 3159, 1736, 2673, 3396, 711, 2595, 342, 185, 346, 587, 3714, 1732, 2523, 1244, 3512, 952, 2839, 2380, 3206, 2388, 218, 2008, 1232, 1040, 3472, 1920, 2526, 2347, 1470, 869, 3727, 3617, 928, 1408, 855, 4092, 756, 3330, 1928, 2403, 4146, 2800, 1036, 3521, 3527, 1279, 490, 4188, 1981, 1757, 2775, 3551, 3636, 330, 329, 2279, 953, 424, 415, 621, 2771, 1170, 1197, 1788, 2278, 4054, 579, 90, 601, 3504, 3153, 1804, 574, 3331, 3, 1774, 4036, 620, 3431, 1542, 2598, 4005, 2176, 2980, 1926, 1851, 3652, 387, 988, 914, 840, 1319, 884, 4055, 2117, 2642, 3723, 1011, 2276, 72, 3708, 1584, 428, 1971, 3900, 3772, 1970, 1427, 3580, 1634, 1344, 4083, 390, 3152, 69, 649, 269, 2289, 3705, 1999, 3300, 2049, 2268, 743, 4180, 658, 2408, 4142, 1493, 376, 1000, 3484, 3836, 1893, 810, 2466, 1416, 1906, 2734, 4100, 2191, 516, 496, 3648, 2443, 2382, 1240, 800, 3875, 877, 3905, 3507, 2363, 1707, 2073, 4173, 2750, 874, 297, 2366, 355, 1496, 1205, 4065, 1434, 1558, 4127, 1932, 701, 3806, 2136, 3654, 1220, 2916, 2765, 2292, 3281, 1613, 2649, 4041, 3599, 777, 4158, 1984, 2132, 3232, 2310, 3495, 2990, 2088, 3792, 3124, 624, 3722, 2367, 1330, 3074, 1148, 858, 2507, 2078, 1145, 442, 2467, 1974, 2451, 1503, 430, 2654, 508, 2632, 2675, 2252, 1323, 3404, 703, 4103, 676, 3612, 2147, 1389, 2563, 94, 2947, 288, 1196, 1418, 2607, 3603, 2284, 596, 4004, 45, 155, 4017, 1533, 2170, 3933, 2789, 2447, 2946, 1672, 3921, 1950, 917, 3672, 3664, 1479, 1012, 1782, 913, 3626, 3627, 1245, 371, 995, 3917, 3589, 1720, 1211, 3564, 1195, 2108, 1178, 326, 2844, 2978, 2241, 370, 2282, 3888, 1332, 1617, 469, 983, 1299, 1703, 178, 3441, 1618, 3584, 742, 2933, 550, 1824, 1180, 3134, 3968, 237, 393, 3488, 645, 19, 1407, 3009, 2001, 3897, 3659, 797, 1095, 1038, 3611, 316, 2963, 3510, 82, 3935, 2735, 2329, 2305, 3675, 1642, 2453, 1609, 292, 3245, 1128, 3005, 1100, 815, 3399, 1316, 1894, 3062, 3665, 1184, 2273, 3947, 809, 2840, 1954, 9, 1569, 3257, 2097, 335, 1432, 2237, 1411, 3376, 418, 494, 3145, 2262, 1372, 2428, 3524, 85, 833, 2260, 54, 2730, 3229, 1817, 3332, 1249, 2356, 531, 4075, 1731, 3731, 1717, 2872, 3047, 3965, 1390, 2655, 1564, 386, 2326, 2618, 244, 2077, 465, 164, 321, 1872, 1392, 2997, 1185, 950, 482, 634, 2853, 2581, 2379, 575, 2825, 2313, 740, 1588, 1492, 123, 3565, 2238, 1843, 3575, 3609, 4023, 4160, 1027, 3758, 3485, 304, 2981, 2504, 754, 33, 2062, 1422, 168, 3906, 2102, 4073, 1647, 1509, 3114, 3038, 891, 124, 350, 3834, 2455, 770, 540, 1597, 3844, 1229, 1339, 778, 3734, 3095, 3519, 3486, 3941, 3827, 4043, 3173, 2698, 293, 1844, 3044, 1916, 548, 3911, 4167, 3967, 223, 3406, 1035, 1122, 3774, 1734, 2645, 3125, 2617, 2383, 429, 412, 3072, 1126, 3087, 499, 1608, 1553, 89, 88, 3160, 829, 3354, 3391, 1908, 1865, 3712, 3876, 1900, 232, 680, 850, 1409, 2261, 1028, 611, 2696, 4148, 748, 2729, 2583, 1252, 2791, 2094, 484, 593, 1187, 767, 4115, 93, 1298, 2212, 2665, 1485, 1264, 2751, 2849, 1311, 3459, 2637, 2828, 194, 60, 635, 3408, 367, 1882, 400, 4060, 656, 63, 2829, 3829]]], num_computed_tokens=[1693, 1128, 1485, 2454, 1929, 928, 597, 640, 569, 1714, 2209, 2878, 858, 1717, 592, 494, 2125, 1406, 965, 1207, 1497, 1179, 692, 1553, 1646, 1915, 1357, 936, 612, 906, 366, 874, 691, 240, 1083, 226, 631, 1280, 1323, 700, 14096]), num_scheduled_tokens={chatcmpl-e6661c6cfa7e4a8faee434f0bbfcff75: 59, chatcmpl-323f395e6e8449fd83da450ffe76cbc9: 1, chatcmpl-9727f6edbf3e42dbb828ce16a65b38bc: 299, chatcmpl-b8e7121a76fd4350846389128ada7ca2: 1, chatcmpl-21f12b491e6043a3830e062280adefdf: 1, chatcmpl-1245ccc81e2b4f7183cbe1aa15f852b2: 1, chatcmpl-0943c499e87742859795d00307b54cb0: 1, chatcmpl-329f6fc01d48415591fd8f43afc98216: 1, chatcmpl-60f572dae7d34d399023cfb46428ebef: 1, chatcmpl-890100f14f414df696bd740b4baaa601: 1, chatcmpl-af506d94ac9b411992b483e31194e2f2: 1, chatcmpl-b96360d2ee724e0fb3568d988f30450c: 1, chatcmpl-1f12eaba1a6a421a989f68da6bc0fe6b: 1, chatcmpl-689f7e55e3994331b23083df9300b128: 1, chatcmpl-ee807fc8e3ab41518f78c9107a3883df: 1, chatcmpl-dcdd30888a6045cdaafbdcd9f6f4805d: 1, chatcmpl-db5b6cacd4d14501a0dd99d86c132c60: 1, chatcmpl-1f9cb3ba366746a498abaad8efd2b368: 1, chatcmpl-d2669ec012e14a368977fece0de74509: 1, chatcmpl-1db73fd196044d5387ceedd876cc445d: 1, chatcmpl-8bb48364ce6745eb962a21b0183eff74: 1, chatcmpl-25242a416c5846e4b77b6989b54840b2: 1, chatcmpl-e5c04a2414c84dd2b934921675f628e8: 1, chatcmpl-b252de372b0f4a1482790c3ebd765c78: 1, chatcmpl-ec409da573b843f1aab380ef224b2aa5: 1, chatcmpl-b80aa097db024d71a06dc19980772bc1: 1, chatcmpl-07fbaa08fe7b4c56b90c33041d4feb2d: 1, chatcmpl-d4b0789a654447bd953f773c3c6c45d6: 1, chatcmpl-353de32886364fbabe4f37535f54aa9f: 1, chatcmpl-4d35de664cec442fb9b5148b6b03813c: 1, chatcmpl-22f8574668384cbf9fce7959d7b1b4d3: 1, chatcmpl-70c361c368e348b2ba700419d17db057: 1, chatcmpl-3b25b329aac44cd59fa61e792a49b144: 1, chatcmpl-53f8caf24b19439c8abfffd3bd6aca86: 1, chatcmpl-ee03b069b0ef44f386c7850999a7a4bd: 1, chatcmpl-4c98a20ab3cd40d6995f6a6bbb67e146: 1, chatcmpl-e76ab00aa9964d2ca3f848561e5153da: 1, chatcmpl-59a57a3bd8004bcb9bee3935db4253d0: 1, chatcmpl-c5d7f01a3b83401987b5ec7f403f9b5c: 1, chatcmpl-70cdbbcabfa1443ea9d45774e19d0c8a: 1, chatcmpl-4df310098a0846c89ce9068e941f204a: 1, chatcmpl-a4bd0c4edd48432da54f9d7100bde36f: 1, chatcmpl-102619f92b8c47f7840ef2ba214e8cb9: 6442}, total_num_scheduled_tokens=6840, scheduled_spec_decode_tokens={}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[3], finished_req_ids=['chatcmpl-82bf6ab90d7647508579a56959bebf5c'], free_encoder_input_ids=[], structured_output_request_ids={}, grammar_bitmask=null, kv_connector_metadata=LMCacheConnectorMetadata(requests=[ReqMeta(req_id='chatcmpl-9727f6edbf3e42dbb828ce16a65b38bc', token_ids=Tensor(shape=torch.Size([811]), device=cpu,dtype=torch.int64), slot_mapping=Tensor(shape=torch.Size([811]), device=cpu,dtype=torch.int64), save_spec=SaveSpec(skip_leading_tokens=512, can_save=true), load_spec=LoadSpec(vllm_cached_tokens=48, lmcache_cached_tokens=512, can_load=true)), ReqMeta(req_id='chatcmpl-e6661c6cfa7e4a8faee434f0bbfcff75', token_ids=Tensor(shape=torch.Size([107]), device=cpu,dtype=torch.int64), slot_mapping=Tensor(shape=torch.Size([107]), device=cpu,dtype=torch.int64), save_spec=SaveSpec(skip_leading_tokens=0, can_save=true), load_spec=null), ReqMeta(req_id='chatcmpl-102619f92b8c47f7840ef2ba214e8cb9', token_ids=Tensor(shape=torch.Size([20538]), device=cpu,dtype=torch.int64), slot_mapping=Tensor(shape=torch.Size([20538]), device=cpu,dtype=torch.int64), save_spec=SaveSpec(skip_leading_tokens=16327, can_save=true), load_spec=null)]))
ERROR 07-11 15:21:48 [dump_input.py:79] Dumping scheduler stats: SchedulerStats(num_running_reqs=43, num_waiting_reqs=127, kv_cache_usage=0.999761620977354, prefix_cache_stats=PrefixCacheStats(reset=False, requests=4, queries=22027, hits=14240), spec_decoding_stats=None, num_corrupted_reqs=0)
ERROR 07-11 15:21:48 [core.py:588] EngineCore encountered a fatal error.
ERROR 07-11 15:21:48 [core.py:588] Traceback (most recent call last):
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 579, in run_engine_core
ERROR 07-11 15:21:48 [core.py:588]     engine_core.run_busy_loop()
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 606, in run_busy_loop
ERROR 07-11 15:21:48 [core.py:588]     self._process_engine_step()
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 631, in _process_engine_step
ERROR 07-11 15:21:48 [core.py:588]     outputs, model_executed = self.step_fn()
ERROR 07-11 15:21:48 [core.py:588]                               ^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 235, in step
ERROR 07-11 15:21:48 [core.py:588]     model_output = self.execute_model(scheduler_output)
ERROR 07-11 15:21:48 [core.py:588]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 221, in execute_model
ERROR 07-11 15:21:48 [core.py:588]     raise err
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 212, in execute_model
ERROR 07-11 15:21:48 [core.py:588]     return self.model_executor.execute_model(scheduler_output)
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/executor/abstract.py", line 87, in execute_model
ERROR 07-11 15:21:48 [core.py:588]     output = self.collective_rpc("execute_model",
ERROR 07-11 15:21:48 [core.py:588]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
ERROR 07-11 15:21:48 [core.py:588]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 07-11 15:21:48 [core.py:588]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/utils/__init__.py", line 2934, in run_method
ERROR 07-11 15:21:48 [core.py:588]     return func(*args, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
ERROR 07-11 15:21:48 [core.py:588]     return func(*args, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_worker.py", line 309, in execute_model
ERROR 07-11 15:21:48 [core.py:588]     output = self.model_runner.execute_model(scheduler_output,
ERROR 07-11 15:21:48 [core.py:588]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
ERROR 07-11 15:21:48 [core.py:588]     return func(*args, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_model_runner.py", line 1372, in execute_model
ERROR 07-11 15:21:48 [core.py:588]     self.maybe_setup_kv_connector(scheduler_output)
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_model_runner.py", line 1719, in maybe_setup_kv_connector
ERROR 07-11 15:21:48 [core.py:588]     kv_connector.start_load_kv(get_forward_context())
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py", line 48, in start_load_kv
ERROR 07-11 15:21:48 [core.py:588]     self._lmcache_engine.start_load_kv(forward_context, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/LMCache/lmcache/integration/vllm/vllm_v1_adapter.py", line 463, in start_load_kv
ERROR 07-11 15:21:48 [core.py:588]     ret_token_mask = self.lmcache_engine.retrieve(
ERROR 07-11 15:21:48 [core.py:588]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
ERROR 07-11 15:21:48 [core.py:588]     return func(*args, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/LMCache/lmcache/v1/cache_engine.py", line 453, in retrieve
ERROR 07-11 15:21:48 [core.py:588]     self.gpu_connector.batched_to_gpu(
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/LMCache/lmcache/v1/gpu_connector.py", line 288, in batched_to_gpu
ERROR 07-11 15:21:48 [core.py:588]     self.to_gpu(memory_obj, start, end, **kwargs)
ERROR 07-11 15:21:48 [core.py:588]   File "/home/yshan/Programs/LMCache/lmcache/v1/gpu_connector.py", line 183, in to_gpu
ERROR 07-11 15:21:48 [core.py:588]     assert memory_obj.tensor is not None
ERROR 07-11 15:21:48 [core.py:588]            ^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [core.py:588] AttributeError: 'NoneType' object has no attribute 'tensor'
Process EngineCore_0:
ERROR 07-11 15:21:48 [async_llm.py:419] AsyncLLM output_handler failed.
ERROR 07-11 15:21:48 [async_llm.py:419] Traceback (most recent call last):
ERROR 07-11 15:21:48 [async_llm.py:419]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [async_llm.py:419]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [async_llm.py:419]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [async_llm.py:419]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [async_llm.py:419]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [async_llm.py:419] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
  File "/home/yshan/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/yshan/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 590, in run_engine_core
    raise e
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 579, in run_engine_core
    engine_core.run_busy_loop()
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 606, in run_busy_loop
    self._process_engine_step()
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 631, in _process_engine_step
    outputs, model_executed = self.step_fn()
                              ^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 235, in step
    model_output = self.execute_model(scheduler_output)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 221, in execute_model
    raise err
  File "/home/yshan/Programs/vllm/vllm/v1/engine/core.py", line 212, in execute_model
    return self.model_executor.execute_model(scheduler_output)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/v1/executor/abstract.py", line 87, in execute_model
    output = self.collective_rpc("execute_model",
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/utils/__init__.py", line 2934, in run_method
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_worker.py", line 309, in execute_model
    output = self.model_runner.execute_model(scheduler_output,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_model_runner.py", line 1372, in execute_model
    self.maybe_setup_kv_connector(scheduler_output)
  File "/home/yshan/Programs/vllm/vllm/v1/worker/gpu_model_runner.py", line 1719, in maybe_setup_kv_connector
    kv_connector.start_load_kv(get_forward_context())
  File "/home/yshan/Programs/vllm/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py", line 48, in start_load_kv
    self._lmcache_engine.start_load_kv(forward_context, **kwargs)
  File "/home/yshan/Programs/LMCache/lmcache/integration/vllm/vllm_v1_adapter.py", line 463, in start_load_kv
    ret_token_mask = self.lmcache_engine.retrieve(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/vllm/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yshan/Programs/LMCache/lmcache/v1/cache_engine.py", line 453, in retrieve
    self.gpu_connector.batched_to_gpu(
  File "/home/yshan/Programs/LMCache/lmcache/v1/gpu_connector.py", line 288, in batched_to_gpu
    self.to_gpu(memory_obj, start, end, **kwargs)
  File "/home/yshan/Programs/LMCache/lmcache/v1/gpu_connector.py", line 183, in to_gpu
    assert memory_obj.tensor is not None
           ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'tensor'
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 378, in output_handler
ERROR 07-11 15:21:48 [serving_chat.py:948]     outputs = await engine_core.get_output_async()
ERROR 07-11 15:21:48 [serving_chat.py:948]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/core_client.py", line 740, in get_output_async
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise self._format_exception(outputs) from None
ERROR 07-11 15:21:48 [serving_chat.py:948] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
ERROR 07-11 15:21:48 [serving_chat.py:948] Error in chat completion stream generator.
ERROR 07-11 15:21:48 [serving_chat.py:948] Traceback (most recent call last):
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/output_processor.py", line 57, in get
ERROR 07-11 15:21:48 [serving_chat.py:948]     raise output
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/entrypoints/openai/serving_chat.py", line 518, in chat_completion_stream_generator
ERROR 07-11 15:21:48 [serving_chat.py:948]     async for res in result_generator:
ERROR 07-11 15:21:48 [serving_chat.py:948]   File "/home/yshan/Programs/vllm/vllm/v1/engine/async_llm.py", line 326, in generate
ERROR 07-11 15:21:48 [serving_chat.py:948]     out = q.get_nowait() or await q.get()
ERROR 07-11 15:21:48 [serving_chat.py:948]                             ^^^^^^^^^^^^^
ERROR 07-11 15:21:48 [serving_chat.py:948]   